[{"content":"学习一些2025年最新的Nature环境微生物研究文章，了解一下当前较新的研究思路和方法。\nKnight, C.G., Nicolitch, O., Griffiths, R.I., Goodall, T., Jones, B., Weser, C., Langridge, H., Davison, J., Dellavalle, A., Eisenhauer, N., et al. (2024). Soil microbiomes show consistent and predictable responses to extreme events. Nature 636, 690–696. https://doi.org/10.1038/s41586-024-08185-3. 这篇文章通过统一设计的大规模模拟实验，在草地土壤中施加干旱、洪水、冻结和高温等极端气候事件，系统比较微生物群落的结构与功能响应，发现其响应具有高度一致性和系统发育保守性，并提出微生物响应强度可由土壤原生环境预测，建立了土壤微生物对极端气候冲击的普适响应框架。\n土壤微生物组对极端气候事件的响应模式 随着全球气候变迁，极端气候事件（Extreme Climatic Events, ECEs）发生频率显著增加，对陆地生态系统功能带来前所未有的挑战。土壤微生物作为生态系统功能的核心，其对极端事件的响应机制仍不清晰。本研究统一实验设计，在欧洲10个国家的30个草地土壤中模拟干旱、洪水、冻结和热浪，系统评估微生物群落的结构和功能变化。结果显示微生物响应具有高度一致性，并受系统发育约束。这一发现为全球尺度预测极端气候对微生物群落和生态功能的影响提供了理论基础。\n极端气候事件正以前所未有的频率和强度冲击地表生态系统。在陆地生态系统中，土壤微生物群落通过有机质分解、碳氮循环等过程维持生态功能。然而，我们尚不清楚：这些微生物是否存在通用的应对模式？是否可以通过系统发育特征或环境背景来预测群落响应？\n为回答上述问题，本研究设计了一项大规模跨气候区实验，在严格控制条件下施加四种典型极端气候事件，系统比较微生物响应的一致性、系统发育保守性和可预测性。\n研究设计与方法 研究采集自欧洲30个草地土壤（涵盖高山、温带、地中海、寒带等气候区），每个土壤样本在实验室中分别接受五种处理：对照、干旱、洪水、冻结和高温（热浪）。处理持续时间依据生态学合理尺度设定。随后，对样品进行宏基因组测序和代谢活性检测，以揭示微生物群落的组成和功能变化。\n微生物群落响应的整体趋势 所有四类极端气候事件都能显著改变微生物群落结构，特别是高温和干旱处理。高温引起α多样性降低，β多样性增大，群落组成趋于简化和重组。通过主坐标分析（PCoA）和距离分析，研究者发现同类事件下不同土壤样本的微生物变化方向高度一致，说明响应具有普遍性和可预测性。\n其中，高温处理不仅改变了群落结构，还显著增强了孢子形成菌（如芽孢杆菌、放线菌）的相对丰度，而洪水和冻结引发的变化则相对温和。\n展示不同极端事件下土壤微生物群落组成、β多样性和代谢基因群的变化趋势。\n微生物响应具有系统发育保守性 群落组成变化中，具有相近系统发育位置的微生物对同一事件表现出相似的响应。例如，在高温处理中，某些放线菌门和芽孢杆菌表现出显著富集，暗示其具备特有的耐热机制。 将响应信号投射到系统发育树中，发现微生物的响应具有明显的系统发育保守性：亲缘关系近的物种对同一事件表现出相似反应。例如，在热浪处理中，许多革兰氏阳性菌表现出一致的耐受或优势扩张趋势，而革兰氏阴性菌（如变形菌门）则整体下调。这种保守性使得基于系统发育信息可以对不同微生物类群的响应趋势进行合理预测。\n展示微生物群落中不同门类的响应差异及其系统发育树状图对比。\n功能响应：热胁迫引发“休眠化” 高温处理显著上调了与休眠和孢子形成相关的基因表达，如spo0A、sigF、relA等。这种“休眠化”策略降低了微生物的代谢活跃度，同时也可能限制其生态功能输出。\n代谢多样性分析显示，干扰事件总体降低了群落功能多样性，尤其是高温处理，表明微生物进入功能压制状态以应对胁迫。\n展示关键应激基因表达热图、代谢通路富集分析结果等。\n响应强度与原生环境有关 土壤历史气候背景和理化性质能部分预测其对某类事件的响应强度。例如，地中海气候土壤对干旱反应较弱，而寒带土壤对高温异常敏感。\n构建响应强度与环境因子之间的回归模型，发现年均降水、气温波动性、有机质含量等是重要预测因子。\n展示响应强度与历史气候和土壤特性之间的相关性图表、建模残差分析等。\n结论与展望 本研究首次在泛欧洲尺度上、通过统一设计系统考察土壤微生物群落对极端气候事件的响应，揭示出如下关键发现：\n响应一致性强：不同地点、不同背景的土壤微生物群落对同类事件反应方向一致； 系统发育保守性：群落变化受微生物亲缘关系影响，具备进化学上的一致模式； 功能趋同：高温诱导休眠与代谢抑制是主要功能响应路径； 敏感性可预测：土壤历史环境决定其对未来气候冲击的敏感度。 这些发现为未来构建气候事件风险图谱、开展生态恢复和土地管理提供了科学基础。下一步研究可进一步结合代谢组学、稳定同位素追踪等手段，以更全面揭示“微生物–生态功能”之间的耦合响应机制。\n","date":"2025-07-31T00:00:00Z","image":"/p/25-nature-4/images/1-2_hu_14f88c7136f41d18.png","permalink":"/p/25-nature-4/","title":"25年最新的一些Nature环境微生物研究文章（4）"},{"content":"学习一些2025年最新的Nature环境微生物研究文章，了解一下当前较新的研究思路和方法。\nLee, K.K., Liu, S., Crocker, K., Wang, J., Huggins, D.R., Tikhonov, M., Mani, M., and Kuehn, S. (2025). Functional regimes define soil microbiome response to environmental change. Nature, 1–11. https://doi.org/10.1038/s41586-025-09264-9. 这篇文章做了大量的土壤微宇宙（microcosms）扰动实验，测量硝酸盐利用和微生物组，工作量很大。还在此基础上构建了数学模型并实验验证，为理解复杂微生物群落如何应对环境扰动提供了新视角。\n功能机制定义土壤微生物组对环境变化的响应 土壤微生物组的代谢活动在全球养分循环中起着核心作用。理解土壤代谢活动如何响应气候驱动的环境扰动是一个关键挑战。然而，土壤的生态、空间和化学复杂性阻碍了本文对这些群落如何响应扰动的理解。微生物组代谢响应环境变化的机制问题，由于自然微生物组的复杂性而变得尤为困难。这种复杂性在土壤中表现得最为明显，土壤具有巨大的分类多样性、空间异质性和化学多样性环境。\n传统的大规模调查方法通过量化野外环境变化、群落组成和代谢过程之间的相关性来研究这个问题。虽然调查揭示了稳健的相关性，但它们在揭示决定群落对环境变化响应的机制方面面临两个挑战：首先，调查无法控制混杂因素；其次，很难在野外大规模量化代谢动态。因此，调查在确定控制自然群落对环境变化代谢响应的机制方面能力有限。\n研究方法与实验设计 为了控制混杂因素并获得机制性见解，研究团队采用了土壤微宇宙实验方法。这种方法消除了相关的环境波动，并允许在实验室中进行受控扰动。研究选择了美国华盛顿州Cook Agronomy Farm(CAF)的土壤作为研究对象，该地点表现出较大的自然pH变化，但其他环境因素变化最小。重要的是，土壤微宇宙能够高通量量化对环境扰动的代谢物动态。\n研究团队采集了20个表层土壤样品，这些样品的原生pH值从4.7到8.3不等。通过创建土壤-水混合物（浆液），并添加2mM硝酸盐和不同水平的强酸或强碱来扰动每个土壤的pH值至3到9之间的13个不同值。为了将预先存在的硝酸盐利用者的活性与每种条件下的生长分开，研究包括了用氯霉素处理的对照组，氯霉素抑制蛋白质合成。\n图1a显示了在长期pH梯度(n=20个土壤，pH 4.7至8.3)上进行短期pH扰动(n=13)的实验室条件下野外采样示意图。图1b展示了3种不同原生pH土壤在酸性或碱性pH扰动下的硝酸盐浓度随时间变化。图1c是功能机制的示意图。\n三种功能机制的发现 通过测量分析，研究发现了三种不同的硝酸盐利用机制：\n酸性死亡机制(Regime I)：在强酸性扰动(pH≤4)下，氯霉素处理和未处理条件下的硝酸盐还原都很小，表明几乎没有预先存在的硝酸盐还原生物量，也没有生长。\n养分限制机制(Regime II)：在接近原生pH的pH水平(4≤pH≤8)下，即使是非氯霉素样品中，硝酸盐也呈线性下降，但速率比氯霉素处理的对照组快。这表明在非氯霉素条件下发生了一些生长，但可能受到硝酸盐以外的养分缺乏的抑制。\n复苏生长机制(Regime III)：在强碱性条件下(pH\u0026gt;8)，非氯霉素样品显示硝酸盐还原加速，而氯霉素处理的样品显示很少的活性。这表明土著硝酸盐利用种群很小，但这个稀有种群迅速扩大，在非氯霉素条件下耗尽硝酸盐。\n图2左列展示了描述群落水平代谢的消费者-资源模型，包括单一功能生物量(x)、硝酸盐浓度(A)和限制性养分浓度(C)。中间和右列展示了两种机制下x(t)、A(t)和C(t)的动态。\n模型建立与验证 为了描述硝酸盐动态，研究团队使用了消费者-资源模型。该模型将土壤微生物组的生态复杂性归结为单一有效生物量，而不是明确考虑多种类群及其相互作用。模型包括三个变量：功能性硝酸盐利用生物量(x)、硝酸盐浓度(A)和碳养分(C)，以及五个参数：消耗速率(rA和rC)、亲和力(KA和KC)和生物量生长速率(γ)。\n模型有两个关键特性：首先，硝酸盐利用率(Ạ)与功能生物量(x)的数量成正比，即使在没有生长的情况下也是如此；其次，功能生物量对A和C的吸收遵循共同限制的Monod形式，因此任何一种资源的耗尽都会停止生长。这些特性意味着当C耗尽时，生长停止，硝酸盐(A)以与x成正比的恒定速率被消耗。\n研究团队将这个模型拟合到所有20种土壤和13种pH扰动的硝酸盐利用动态中，无论是否使用氯霉素处理。通过固定生长率γ和亲和力参数(KA和KC)，并改变两个重新调整的参数：x̃(0)=x(0)rA和γC̃(0)=γC(0)rA/rC，这些参数保留了与x和C相同的解释：x̃(0)反映了在给定条件下所有可以进行硝酸盐还原的类群的土著代谢活性，γC̃(0)反映了可用的限制性养分。\n图3a展示了从所有样品的硝酸盐动态推断出的两个模型参数——土著生物量活性(x̃(0))和限制性养分浓度(γC̃(0))的散点图。图3b展示了每种机制下中性和酸性土壤的硝酸盐动态示例。图3c和3d分别展示了不同原生pH和扰动pH值下土著生物量和限制性养分的热图。\n分类学模式与机制验证 为了开始确定控制跨机制代谢变化的主导机制，研究团队通过测序量化了组成变化。研究测量了在氯霉素处理和未处理条件下孵育四天后的绝对丰度，计算了门水平的生长倍数，并使用非负矩阵分解(NMF)来分解所有土壤和pH扰动下门水平生长的变化。\n分析表明，大多数生长可以用两个变化轴来捕捉：一个轴包括假单胞菌门和拟杆菌门的组合，另一个轴仅包括芽孢杆菌门。在机制II中，假单胞菌门和拟杆菌门随着pH的增加而增加生长，随后在机制III开始附近下降。这与模型在机制II中揭示的土著生物量活性(x̃(0))的行为相匹配。芽孢杆菌门直到pH阈值在7到8.5之间才开始生长，这与机制III中指数硝酸盐利用动态的开始相匹配。\n图4a和4b分别展示了假单胞菌门和拟杆菌门组合以及芽孢杆菌门在不同pH条件下的生长倍数。图4c展示了假单胞菌门和拟杆菌门与芽孢杆菌门生长倍数的散点图。图4d展示了x̃(0)与γC̃(0)的散点图，其中标出了机制，红色轮廓表示接近机制III边界的机制II条件。\n机制II中碳释放促进生长 在养分限制机制II中，无论是否使用氯霉素，硝酸盐还原速率都保持恒定，但在不使用药物时速率更高。模型将无药物时速率增加归因于养分(C(0))的快速初始利用。此外，随着扰动pH的增加，无氯霉素条件下的硝酸盐还原速率增加。模型提出，随着pH增加的限制性养分可用性(γC̃(0))推动了增加硝酸盐还原速率的生长。\npH增加可以通过粘土颗粒上离子交换位点的取代反应增强土壤中有机碳的可用性。由于养分是通过交换反应释放的，研究假设生物量的增加，因此硝酸盐还原速率应该与添加到系统中的酸或碱的量成正比。在所有土壤中都观察到了这一趋势，表现为硝酸盐还原速率随NaOH一致增加（浅蓝色区域）。如果硝酸盐利用率随NaOH增加是由于限制性养分可用性(γC̃(0))增加推动了硝酸盐还原者的生长，那么预计它们的丰度会随着NaOH的增加而上升。正如预期的那样，通过16S rRNA扩增子测序测量的绝对丰度与添加到系统中的NaOH量呈线性关系。\n图5a展示了硝酸盐还原速率（无氯霉素/氯霉素处理）随添加到土壤中的NaOH量的变化。图5b展示了养分释放的假设机制示意图。图5c展示了模型推断的可用限制性养分(C̃(0))与测量的水溶性有机碳(WSOC)的散点图。图5d和5e展示了在养分限制机制下未扰动pH(5.4)土壤的修正实验结果。\n机制I中生物量减少与细胞死亡相关 在酸性pH扰动响应中，模型显示土著生物量活性(x̃(0))减少和限制性养分可用性降低。为了测试土著生物量活性(x̃(0))随pH下降是否与细菌丰度相关，研究计算了在氯霉素处理条件下每个门终点绝对丰度相对于初始时间点T0的倍数变化(\u0026ldquo;存活倍数\u0026rdquo;)。存活倍数反映了在没有生长的情况下丰度的变化，因此本文将其视为死亡的代理。\n除了芽孢杆菌门外，所有门在酸性扰动下都表现出存活倍数的一致下降。存活倍数与x̃(0)近似线性下降，表明生物量活性的降低可能与细胞死亡有关。然而，存活倍数的变化也可能源于pH依赖性残留DNA的降解。为了测试细胞死亡减少机制I中生物量活性的假设，研究使用了从本文的土壤或代表图4中三个门的菌株集合中分离的菌株。使用这些分离株，测量了pH值从3到7范围内的DNA降解和细胞死亡率。结合这些速率和模型使本文能够得出结论，通过测序测量的丰度变化必须至少部分源于细胞死亡。\n图6a展示了土壤质地（沙、粘土和淤泥的比例）的三元图。图6b展示了来自LaBagh(IL, USA)、Pinhook(IN, USA)和Sedgwick CLG13和ELG13(CA, USA)土壤样品的拟合模型参数(x̃(0)和γC̃(0))的散点图。图6c展示了来自捷克共和国三种土壤的早期反硝化速率(反硝化酶活性(DEA，等同于x̃(0)))和DEA与长期反硝化速率(反硝化潜力(DP，等同于γC̃(0)))差异的散点图。图6d展示了来自LaBagh(IL)、Pinhook(IN)和Sedgwick CLG13和ELG13(CA)土壤样品在不同pH水平下芽孢杆菌门以及假单胞菌门和拟杆菌门组合的生长倍数。图6e展示了Anderson等人研究中pH扰动后门水平相对丰度随时间变化。图6f展示了来自四项研究的土壤在酸性或碱性pH扰动下土著生物量活性(x̃(0))下降。图6g展示了先前研究中土壤在接近原生pH下氮利用的恒定速率。\n长期pH对机制边界的影响 研究观察到，土壤的原生(长期)pH决定了在机制之间转变的pH阈值，酸性土壤在比中性土壤更小的酸性扰动后从机制II转变为机制I。这种行为可能是由群落过去暴露于pH波动所塑造的。虽然本文缺乏历史pH波动的直接记录，但本文可以使用滴定曲线来描述土壤对pH扰动的响应。\n在所有土壤中，这些曲线显示出一致的形状：在高(pH 9)和低(pH 3)pH值处的平台由陡峭的非线性转变连接。土壤的原生pH决定了其在无扰动时沿曲线的位置。酸性土壤位于较低平台附近，因此对pH变化有很强的缓冲作用。相比之下，更多的中性土壤位于陡峭区域，在那里小的酸或碱添加会导致大的pH变化。本文推测这种缓冲能力的差异使得来自酸性土壤的群落对pH波动的耐受性较差，这可能解释了它们在更小的扰动后从机制II转变为机制I。\n此外，本文的测序数据支持微生物组组成反映对原生pH的特定适应，有助于解释跨土壤的机制边界变化。在更酸的土壤中，假单胞菌门和拟杆菌门在较低pH下表现出更大的存活率。相反，芽孢杆菌门开始在机制III中生长的pH随原生土壤pH增加而增加。此外，在机制III中生长的菌株的身份预测了土壤的原生pH。这些发现表明，长期暴露于特定的pH条件会选择特定的类群，可能塑造群落转变功能机制之间的pH阈值。\n讨论与展望 这项研究对理论微生物生态学和微生物组代谢的实证研究具有重要意义。首先，本文的模型将整个群落抽象为单一有效生物量的成功与捕捉许多相互作用物种的复杂生态系统模型形成鲜明对比。这种对比表明，自然群落可能更适合通过粗粒度描述来理解，这种描述捕捉了群落中少数代谢相关的群体或行会。这种生态系统的低维图景尊重潜在机制，并与群落可观察的功能特性紧密相连。将这一成功扩展到更复杂的代谢过程，并将有效生物量变量如x̃与基础丰度动态联系起来，是未来工作的关键方向。\n其次，理解微生物群落代谢如何响应环境扰动仍然是应用微生物组科学的核心问题。这一挑战源于由许多具有不同代谢特征和生态相互作用的物种组成的群落的复杂性，这些相互作用发生在化学复杂的环境中。群落的复杂性促使测量越来越复杂，从宏基因组学和转录组学到单细胞代谢组学和定量稳定同位素探针。然而，将这些数据与群落代谢及其对环境扰动的响应联系起来仍然很困难。本文的研究结果表明，与其单独关注微观过程，不如首先进行定量、系统级的观察，如硝酸盐通量，并使用简单模型描述这些通量。然后，模型提出组织群落代谢的机制，如养分限制或生物量活性的变化。反过来，可以研究这些提出的机制的生理、化学或生态起源。\n本文的分析揭示了与功能机制相关的保守门水平关联。在强碱性扰动下，稀有芽孢杆菌门扩大，而优势假单胞菌门和拟杆菌门在接近原生pH下茁壮成长。这些模式表明，适应瞬时胁迫的稀有类群和适应稳定条件的优势类群，突出了波动在维持多样性中的作用。理解这些分类学模式需要将动态与生理学联系起来。尽管最近的工作已经对平衡生长的生理学产生了定量见解，但本文对波动在决定微生物特征中的作用的理解仍然有限。即使在缺乏生理学见解的情况下，本文的方法也能够从测序和养分测量中预测硝酸盐动态。使用从16S数据推断的硝酸盐还原酶基因丰度和WSOC测量，本文训练了回归来预测模型参数x̃(0)和γC̃(0)。这使本文能够仅从pH、WSOC和扩增子数据预测硝酸盐通量，证明功能机制即使在复杂群落中也能连接结构和功能。\n本文的研究有几个局限性。首先，土壤浆液缺乏完整土壤的物理结构和自然环境波动；特别是，原位硝酸盐利用发生在动态变化条件下。其次，自然pH变化通常很小(小于1个单位)，这意味着大多数土壤可能保持在机制II，除非在肥料或尿液输入等大型外源扰动下。第三，尽管本文的土壤合理地涵盖了全球分类多样性，但它们对高度碱性(pH\u0026gt;8)或强酸性(pH\u0026lt;4)土壤的代表性不足。高度缓冲的碱性土壤可能完全抵抗pH诱导的机制转变。\n","date":"2025-07-30T00:00:00Z","image":"/p/25-nature-3/images/fig1_hu_3ca09b7728abf61.png","permalink":"/p/25-nature-3/","title":"25年最新的一些Nature环境微生物研究文章（3）"},{"content":"学习一些2025年最新的Nature环境微生物研究文章，了解一下当前较新的研究思路和方法。\nBorton, M.A., McGivern, B.B., Willi, K.R., Woodcroft, B.J., Mosier, A.C., Singleton, D.M., Bambakidis, T., Pelly, A., Daly, R.A., Liu, F., et al. (2025). A functional microbiome catalogue crowdsourced from north american rivers. Nature 637, 103–112. https://doi.org/10.1038/s41586-024-08240-z. 这篇文章跟上一篇那个类似，采样贡献很大，同时有数据资源性贡献。然后测了宏基因组+宏转录组（所以可以自信的说功能数据库），还提出了河流连续体概念（这种思想可以借鉴）。最终也是没有做验证实验发表在Nature上。\n北美河流微生物组功能数据库（GROWdb） 在全球气候变化与人类活动加剧的背景下，河流生态系统作为陆地与水生环境的关键连接点，其微生物群落的结构与功能对元素循环、水质维持及生态系统稳定性具有决定性作用。该文章通过创新的众包采样模式与基因组解析技术，构建了首个覆盖北美大陆尺度的河流微生物组功能数据库（GROWdb），为理解河流微生物的生物地理学特征与生态功能提供了突破性视角。\n河流是地球表层物质循环的核心枢纽，承担着营养传输、碳氮转化等关键生态功能，同时直接影响人类的水资源安全与生态健康。尽管海洋微生物组已通过全球联盟（如Tara Oceans）得到深入研究，但河流微生物组的研究仍存在显著不足：多数研究依赖16S rRNA基因测序，难以解析功能潜力；宏基因组研究较少恢复宏基因组组装基因组（MAGs），掩盖了未知类群的贡献；采样范围局限于单一河流或流域，缺乏跨系统的普适性结论。\n针对这些缺口，本研究旨在通过众包协作与基因组分辨率分析，构建一个覆盖北美主要流域的河流微生物组功能数据库（GROWdb）。其核心目标包括：（1）解析河流微生物的分类与功能多样性，识别核心类群及其代谢潜力；（2）揭示微生物群落结构与功能的空间驱动因素（如地理、土地利用、溪流等级）；（3）验证河流连续体概念（RCC）在微生物功能层面的适用性；（4）建立微生物组与新兴污染物转化的关联，为水质管理提供依据。\n研究方法 众包采样与数据整合 研究采用“网络中的网络”模式，联合超过100个团队在北美106个站点采集163个表层水样本，覆盖美国90%的流域（21个水文单元），涵盖不同生态区、溪流等级与流域规模。采样同步记录287项地理空间参数（如土地利用、溪流等级、流域面积）和地球化学数据（如水温、营养盐浓度），确保环境变量的全面性。\n测序与分析技术 对样本进行宏基因组和宏转录组测序，获得约3.8Tb数据。通过三种组装方法（MEGAHIT、IDBA-UD、metaSPAdes）生成重叠群，结合MetaBAT2进行分箱，最终获得3825个中高质量MAGs，去重后保留2093个（99%序列一致性）。采用GTDB-tk进行分类注释，DRAM进行功能注释，并通过Bowtie2将测序 reads 映射到MAGs以量化丰度与表达量。\n数据库构建 GROWdb通过多平台开放访问：NCBI存储原始测序数据与MAGs；国家微生物组数据协作网（NMDC）链接多组学数据；KBase提供基因组注释与代谢模型；GROWdb Explorer提供交互式可视化工具，实现跨学科数据复用。\nGROWdb的核心特征 GROWdb包含2093个去重MAGs，覆盖27个门，其中10个科、128个属为新分类单元，大量类群仅通过字母数字命名（如未培养细菌UBA类群），凸显河流微生物的未知多样性。与现有淡水MAGs对比，河流与湖泊微生物组成差异显著，且河流样本的基因组覆盖率更高，表明GROWdb填补了河流微生物基因组资源的空白。\n通过分析全球266,764个公开宏基因组数据，发现GROWdb的MAGs存在于90%的河流样本和46%的淡水样本中，且在废水、土壤等环境中也有检出，印证了河流作为“景观整合者”的角色——其微生物群落整合了陆地、水生等多源输入。\n核心河流微生物组的功能特征 宏基因组分析显示，放线菌门（Actinobacteriota）、变形菌门（Proteobacteria）、拟杆菌门（Bacteroidota）和疣微菌门（Verrucomicrobiota）为优势类群，占所有样本相对丰度的主导地位。其中，Planktophilia属（放线菌门）在70%的样本中存在，平均相对丰度达12%，是分布最广且最丰富的类群；Limnohabitans_A、Polynucleobacter等5个属也存在于50%以上的样本中。\n宏转录组分析进一步识别出25个高表达属，其中Methylopumilus、Polynucleobacter、Planktophilia等6个属在所有转录组样本中均有活性（核心活性属）。这些类群普遍具备有氧呼吸（编码电子传递链复合体）和光驱动代谢（光合系统、视紫红质）能力，部分还能降解硫、甲烷或参与氮还原，体现了代谢冗余——这是河流微生物应对环境波动的关键策略。\n硝化作用是河流氮循环的核心环节，GROWdb识别出1个Nitrosomonas属MAG（氨氧化）和2个Nitrospiraceae科MAG（亚硝酸盐氧化），均编码抗紫外线损伤和抗氧化应激的基因（如光解酶、超氧化物歧化酶），适应表层水环境。此外，检测到17个Patescibacteria门MAGs，虽为专性发酵菌（无法呼吸），但在表层水中通过生物膜或低氧微生境存活，且其丰度随河流规模增加而降低，暗示与河床交换的关联。\n新兴污染物的微生物响应 河流作为人类活动的“受体”，持续暴露于抗生素、微塑料等新兴污染物。GROWdb分析显示，54.3%的MAGs（1135个）编码25类抗生素抗性基因（ARGs），其中糖肽抗性基因（van）数量最多（1219个），但多数不位于典型抗性基因簇中，功能待验证。30%的ARGs在转录组中表达，且污水处理厂（WWTP）影响的站点中，外排泵和ARGs的表达量显著更高，表明人类活动驱动抗性基因的活跃传播。\n此外，微生物还编码微塑料（如 terephthalate）、氟化物等污染物的转化基因。例如，Limnohabitans_A表达PET降解通路的下游基因，Polynucleobacter表达脱卤酶（参与脱氟），且这些基因的表达与城市用地比例正相关，揭示微生物对人为污染的适应性代谢潜力。\n大陆尺度的微生物地理模式 通过Mantel检验与方差分解分析，发现溪流等级（反映河流规模）是微生物组成的最强驱动因素，其影响超过纬度、总碳等传统变量。宏基因组和宏转录组组成均随溪流等级显著变化：基因组丰富度在6级溪流达到峰值，转录组丰富度随等级升高持续增加，表明功能活性的调控机制与基因存在性不同。\n温度也是关键驱动因素，光驱动代谢（如光合系统、视紫红质）的基因表达与流域最高温度显著相关，核心类群（如Methylopumilus）通过光捕获适应温度变化，暗示气候对河流微生物功能的潜在影响。\n微生物群落组成在Omernik生态区和水文单元（HUC）尺度上存在显著分异——干旱草原区与湿润亚热带区的群落结构差异明显，印证了陆地输入对河流微生物的“接种”效应。但功能组成未表现出地理分异，表明分类水平的变化被功能冗余补偿，这为跨区域的微生物管理指标开发提供了依据。\n河流连续体概念的功能扩展 河流连续体概念（RCC）预测：随河流规模增大，陆地输入影响减弱，生物多样性先增后减。本研究首次将RCC扩展至微生物功能层面：\n多样性模式：基因组丰富度在6级溪流达峰，符合RCC中“中等规模河流生物多样性最高”的预测；但转录组丰富度随等级升高而增加，反映功能活性对河流规模的独特响应。 碳利用策略：低等级溪流中，微生物高表达聚合物、芳香族化合物降解基因（依赖陆地输入）；高等级河流中，甲基营养基因（如甲醇氧化）表达增强（依赖自生源碳），印证RCC中“陆地碳输入随河流规模降低”的预测。 光代谢梯度：高等级河流中光驱动代谢基因表达显著增加，与RCC中“大型河流光照更充足”的特征一致，且光合/呼吸（P/R）比在6-8级溪流最高，支持RCC的能量流动模型。 研究结论 GROWdb通过众包模式与基因组解析，首次系统揭示了北美河流微生物的功能多样性与地理驱动机制，其创新点包括：（1）建立首个跨大陆尺度的河流微生物基因组资源，填补分类与功能研究的缺口；（2）阐明微生物对新兴污染物的代谢潜力，为水质监测提供生物标志物；（3）验证RCC在微生物功能层面的适用性，为生态预测模型提供框架。\n未来研究可基于GROWdb探索：（1）长期气候变化对河流微生物功能的影响；（2）污染物转化基因的水平转移机制；（3）跨大陆河流微生物的对比分析。作为开放数据库，GROWdb为 watershed 预测模型与微生物组管理实践提供了基础，助力应对水资源可持续性与环境变化的挑战。\n","date":"2025-07-29T00:00:00Z","image":"/p/25-nature-2/images/2-1-2_hu_6c1a6873640a2093.png","permalink":"/p/25-nature-2/","title":"25年最新的一些Nature环境微生物研究文章（2）"},{"content":"学习一些2025年最新的Nature环境微生物研究文章，了解一下当前较新的研究思路和方法。\nEzzat, L., Peter, H., Bourquin, M., Busi, S.B., Michoud, G., Fodelianakis, S., Kohler, T.J., Lamy, T., Geers, A., Pramateftaki, P., et al. (2025). Diversity and biogeography of the bacterial microbiome in glacier-fed streams. Nature, 1–9. https://doi.org/10.1038/s41586-024-08313-z. 这篇文章采样贡献很大，全球尺度的，然后冰川补给溪流（Glacier-fed Streams, GFSs）在讲故事时和气候变化联系起来，还有一些生态方面的讨论，最终也是没有做实验发表在Nature上。\n冰川补给溪流中细菌微生物组的多样性和生物地理学 气候变化正以前所未有的速度改变着地球的生态系统，其中山地冰川的快速融化尤为显著。冰川补给溪流（Glacier-fed Streams, GFSs）作为受冰川融化直接影响的生态系统，正面临着深刻的变革。GFSs 是寒冷、寡营养且不稳定的生态系统，其中生命主要由微生物生物膜主导。然而，在过往很长一段时间里，我们对 GFSs 微生物组的了解犹如雾里看花，极为匮乏。这种认知的不足严重阻碍了我们准确理解其对冰川退缩的响应机制。因此，开展一项全面且系统的全球范围调查，揭示 GFSs 微生物群的生物多样性和生物地理分布特征，以及驱动其形成的生态和进化过程，显得尤为迫切。这不仅有助于我们深入认识这一独特生态系统的内在运行规律，更能为应对气候变化对 GFSs 生态系统的影响提供关键的科学依据。\n研究方法 为了达成研究目标，研究团队踏上了一场跨越全球的科研征程。他们从地球上主要山脉的 152 个 GFSs 采集底栖微生物组样本，这其中涵盖了新西兰、俄罗斯高加索、喜马拉雅、帕米尔、天山、非洲、欧洲、阿拉斯加、格陵兰、厄瓜多尔和智利等地的山脉。在采集微生物样本的同时，研究人员还仔细记录了溪流水化学、冰川特性和地理等多方面的互补数据。回到实验室后，运用宏条码和宏基因组学等先进技术对样本进行分析。通过这些技术，能够精准地识别和分析微生物的种类及基因信息。随后，利用基于距离的冗余分析（db - RDAs）和多尺度方差分配等多种模型对数据进行深入挖掘，以探究微生物组组成与环境因素、空间因素之间的复杂关系。\nGFSs 的环境特征 GFSs 拥有一系列独特的环境特征。其水温常年接近冰点，这对大多数生物来说是一个极具挑战性的低温环境。沉积物由于受到冰川融水的强大冲刷力影响，结构松散且不稳定。夏季时，冰川融水携带大量泥沙等颗粒物，使得水体浑浊不堪，光照难以穿透，严重限制了光自养生物的光合作用。而到了冬季，冰和雪的覆盖进一步减少了光照时间和强度，让这里成为一个近乎黑暗的世界。不仅如此，GFSs 整体处于寡营养状态，有机碳和无机营养物质极度匮乏，微生物在这样的环境中面临着食物短缺的严峻考验。不过，不同区域的 GFSs 也存在一定差异，流域地质及相关的沉积矿物学在区域尺度上会对溪流水的地球化学特性产生影响，包括 pH 值和离子组成等，这些因素又会进一步影响微生物的氧化还原反应和生存策略。\n细菌微生物组的特性 研究发现，GFSs 细菌微生物组在分类和功能上与其他冰冻圈微生物组（如冰川冰尘、冰前湖和永久冻土土壤中的微生物组）有着显著差异。从功能潜力来看，基于 KEGG 通路分析，GFSs 微生物组在生物膜形成相关通路方面表现突出，例如分泌系统和双组分系统。这些通路对于细菌在 GFSs 中生存至关重要，它们帮助细菌对抗水流的侵蚀，以及在资源稀缺的环境中更好地获取和利用有限资源。在能量获取和代谢途径上，GFSs 中的细菌展现出了多样化的能力。它们能够在春季和秋季藻类渗出物脉冲期间，通过氨基酸、糖类和异生物质化合物的降解以及硫和氮代谢等途径，抓住短暂的资源丰富期，为自身的生存和繁衍积累能量。\n生物多样性模式 在全球多样性方面，研究人员在 GFSs 中发现了跨越 44 个门的细菌，其中存在大量未分类的物种，这表明 GFSs 中蕴含着丰富的未知细菌多样性。尽管 GFSs 资源可用性低，但令人意外的是，其 alpha 多样性指标（观察到的丰富度和 Shannon H 值）介于其他冰冻圈生态系统和全球分布土壤之间，这意味着 GFSs 沉积物能够支持与这些系统相似水平的细菌多样性。进一步研究发现，ASV 丰富度随海拔升高和冰川覆盖度增加而降低，然而功能多样性却并未遵循这一海拔梯度变化规律，这可能是由于冰川影响下复杂且独特的环境选择压力所致。从群落间差异来看，GFSs 细菌微生物组的 β 多样性在山脉内部和之间均较高，细菌组成呈现出明显的生物地理格局。南方和北方半球间的细菌组成存在显著分离，不同山脉间的聚类也十分明显，这种差异主要是由众多指示 ASV 驱动的。但有趣的是，功能组成的空间格局并不明显，这暗示着 GFSs 细菌微生物组的结构与功能潜力可能存在解耦现象。\n微生物组的特异性与核心 研究深入探究了 GFSs 细菌微生物组的特异性。通过严谨的数据预处理和去噪方法，确定了 62.2% 的 ASVs 为山脉特异性，尽管它们的相对丰度较低，仅占 9.0%，但对 beta 多样性的贡献却高达 20.9%，这充分凸显了它们在整体 GFSs 细菌生物多样性中的重要地位。此外，25.2% 的 ASVs 被认定为 “独特” 的，即仅在一个 GFSs 的多个沉积样本中发现，其中 6.4% 的独特 ASVs 出现在某一特定 GFSs 的所有沉积样本中。这种特异性在不同地区的分布并不均匀，新西兰南阿尔卑斯山和厄瓜多尔安第斯山脉的特异性最高，这一现象符合岛屿生物地理学理论，深刻反映了空间隔离、选择压力及长期气候稳定性对物种形成和特有性的重要影响。尽管 GFSs 细菌微生物组存在高度的山脉间及内部相异性，但研究人员还是成功识别出 165 个核心 ASVs，它们仅占总 ASVs 数量的 0.42%，但相对丰度却达到了 28.3%。这表明即使是在小核心微生物组中，也存在着相对丰富的分类单元。这些核心分类单元在竞争中可能具有明显优势，并且与特定和指示 ASVs 在分类学上存在重叠，主要由假单胞菌门、拟杆菌门、疣微菌门以及丛毛单胞菌科、甲基嗜菌科和几丁质杆菌科主导，在属水平上则以甲基营养菌属、极单胞菌属和红游动菌属为主。这些属不仅在 GFSs 中广泛存在，在其他冰冻圈生态系统中也能发现它们的身影，彰显了它们强大的适应极端环境的能力。\n微生物组组成的驱动因素 GFSs 微生物组在空间上呈现出明显的结构化特征，距离衰减模式（DDPs）清晰可见，这表明即使在相距遥远的 GFSs 之间，也存在着系统发育相似的类群，反映出少数分类单元在其中占据主导地位。通过基于距离的冗余分析（db - RDAs）和多尺度方差分配等分析手段，研究揭示了 GFSs 细菌微生物组组成的 54.9% 可被解释，其中空间过程（地理隔离和扩散限制）对 β 多样性的影响占比高达 23.6%，而纯且空间结构化的环境过程占 15.4%，这有力地强调了地理隔离和扩散限制在塑造 GFSs 微生物组结构中的关键作用。此外，流域地质与大气过程对 GFSs 细菌的影响也不容忽视，这进一步说明了地球多样性（地质、地貌和水文过程）在山区生物多样性形成中扮演着重要角色。与 GFSs 细菌组成相比，其功能潜力（以 KOs 表示）并未显示出强烈的生物地理模式，这在一定程度上支持了群落层面功能冗余的观点，但仍需要更多的研究，特别是借助蛋白质组学等技术，深入探讨细菌基因组的进化变化如何影响其功能冗余，以进一步验证这一结论。\n微生物组的系统发育地理 对 GFSs 细菌微生物组的系统地理学分析，为我们揭示了其进化和生态特征中确定性与随机性装配过程的作用。研究明确指出，扩散限制是最主要的装配过程，在群落对中占比高达 59.4%，其次是生态漂变（30.0%）和同质选择（11.7%）。扩散限制不仅广泛影响系统发育树上的多个支系，而且在每个山脉范围内，其对相对丰度的贡献约为 45.4%。受同质选择影响的支系在不同山脉间的贡献差异较大，例如在高加索山脉和新西兰分别贡献了 43.9% 和 30.4% 的相对丰度，而在智利安第斯山脉和西南格陵兰则分别为 16.6% 和 18.8%。这些支系中既包含全球分布的甲基营养菌属和极单胞菌属，也有较少见的皮雷拉属和铁细菌属。尽管同质环境选择的作用在地理距离上保持相对稳定，但在同一山脉内，随着地理距离的增加，扩散限制的重要性愈发凸显。此外，β 多样性主要发生在系统发育树末端密切相关的类群间，一些属存在微多样性，这种微多样性对生态位空间的优化以及生物地理格局的形成都有着重要贡献。\n研究结论 这项研究全面而深入地揭示了 GFSs 细菌微生物组在分类和功能上的独特性，以及其高度的区域特异性和局部独特性。其结构主要受扩散限制和环境选择的双重影响，核心微生物组虽小但相对丰富。生物地理格局的形成源于少数优势但微多样的类群内变化，功能冗余可能是细菌应对环境波动的重要策略。然而，令人担忧的是，随着全球气候变暖，冰川退缩的速度不断加快，这一独特的微生物组正面临着前所未有的威胁。许多特定的 ASV 可能会因为环境的改变而消失，这将对 GFSs 生态系统的结构和功能产生深远影响。因此，本研究不仅为我们理解 GFSs 生态系统中的微生物提供了全新的视角，更为未来针对正在消失的 GFSs 生态系统的气候变化微生物学研究提供了宝贵的全球性参考，也为保护这一脆弱的生态系统敲响了警钟，呼吁我们尽快采取行动，探索其遗传潜力，以应对气候变化带来的挑战。\n","date":"2025-07-28T00:00:00Z","image":"/p/25-nature/images/1-1-1_hu_64b80afcaa240a91.png","permalink":"/p/25-nature/","title":"25年最新的一些Nature环境微生物研究文章（1）"},{"content":"Introduction 最近有审稿人的comments中建议阅读大佬Susan Holmes (2014) 的经典论文《Waste Not, Want Not: Why Rarefying Microbiome Data Is Inadmissible》，参考在自己的分析中。这篇文章深入探讨了微生物组数据分析中常用的稀释（rarefying）方法的缺陷，并提出了更合适的统计模型。虽然这篇文章已经发表了10多年，但其观点仍然具有重要的参考价值。\n🌱 微生物组测序的统计挑战 高通量 DNA 测序技术让微生物组研究进入爆发期。通过测定来自不同环境或样本（如人体肠道、土壤、水体）的 16S rRNA 序列或宏基因组原始读数，研究者可以获得一个 OTU（操作分类单位，又可视作微生物“物种”）在各样本中的丰度矩阵。\n但一个关键问题是：不同样本之间测序深度存在显著差异——每个样本的读数（library size）可能相差一个数量级。这样直接比较 OTU 计数会导致误导。为此，研究者常用两种“归一化”方式：\n按比例（proportion）处理：将各 OTU 计数除以总读数。 稀释抽平（rarefying）：随机抽取每个样本相同数量的读数（即归到最小 library size）。 然而，McMurdie 和 Holmes 指出，这两种方法都存在严重统计缺陷。作者主张，应该使用更先进的统计模型，比如基于负二项分布的差异表达分析方法（edgeR、DESeq），这些方法能更好地处理 library size 差异和数据方差结构。\n稀释法的两个主要问题 损失统计能力（statistical power） 论文通过例子演示了 rarefying 带来的信息损失，例如样本 B 从 1000 个读数降到 100 后，估计微生物丰度比例的方差显著增加，导致对显著性差异的检验能力下降。即使两个样本在真实生态差异上有明显变化，稀释后信号可能被掩盖。\n丢弃样本 在 rarefying 流程中，通常设定一个最小读数阈值，低于阈值的样本被剔除。例如，如果用 500 读数标准化，而一个 sample 只有 300，则该 sample 会被完全删除。论文中指出，这可能导致有效样本被剔除，从而降低聚类分析或差异检测的结果质量。\n替代方案：基于负二项分布的混合模型 论文提出将微生物组计数数据视作负二项分布（Negative Binomial, NB）的一种表现：\n样本 j 的总体读数可视为 Poisson 随机变量。 OTU i 在样本 j 的计数$K[i,j] ~ NB(mean = s_j × μ_i, dispersion = φ_i)$，其中$s_j$ 是 library size 缩放因子，$μ_i$ 是 OTU 的相对丰度，$φ_i$ 捕捉 biological variability 和过度离散性。 这种模型有三个优点：\n统计理论支持：standard 方法来自 RNA-Seq 领域（edgeR、DESeq）。 变异估计更准确：考虑方差随着丰度增长而变化，避免样本深度不同导致的 heteroscedasticity。 没丢样本：所有样本保留，避免信息丢失。 此外还提及另一种方法，zero-inflated Gaussian 模型（metagenomeSeq），适合候选 OTU 零计数很多的情况，但在生物重复较少时假阳性率仍然较高。\n模拟实验 McMurdie 和 Holmes 为了系统地评估不同归一化和统计分析方法的性能，精心设计了两类模拟实验，分别聚焦于 样本聚类准确性 与 差异丰度检出能力。这些实验通过真实数据构造，并在可控的干预条件下测试各方法的稳健性与准确度，具有非常强的说服力。\nA:样本聚类的准确性（Clustering Accuracy） 作者从真实的微生物组数据集中（如“soil”和“ocean”数据）选取样本，构建两个组成明显不同的样本群体，并在这些群体中模拟不同的测序深度（library size），例如一个样本有 10,000 reads，而另一个只有 1,000 reads，反映现实中常见的不平衡情况。\n接着，他们使用不同的归一化方式处理这些样本，包括：\n稀释（rarefying）：所有样本统一稀释至相同深度。 比例归一化（proportions）：每个 OTU 相对其样本总数转换为相对丰度。 基于模型的方法（edgeR / DESeq）：使用负二项分布估计归一化因子并建模。 metagenomeSeq：使用零膨胀正态模型（zero-inflated Gaussian）。 归一化后，再对 OTU 表进行距离计算（Bray-Curtis 或 UniFrac），最后进行聚类（如 PAM 或 hierarchical clustering）以观察样本是否能准确归类。\n稀释法准确率最低，尤其当稀释程度较高（即大部分样本初始 read 数远高于稀释阈值）时，稀释过程导致数据大幅减少，聚类准确率明显下降； 比例归一化方法略好但仍不稳定，尤其在物种丰富度差异大时，常低估丰度低但重要的 OTU； edgeR 和 DESeq 准确率最高且最稳定，能有效识别样本之间真实的结构差异； metagenomeSeq 表现介于中间，在某些条件下表现尚可，但 replicates 少时不稳定。 这说明：基于模型的方法不仅能保留样本完整性，还能在复杂多变的测序深度下维持稳定的聚类表现。\nB:差异丰度检测能力（Differential Abundance Detection） 作者构建了一个 OTU 表，其中一部分 OTU 被设定为“差异丰度 OTU”——它们在组 A 与组 B 中的丰度存在系统性差异（如增加 2 倍或 5 倍），而其余 OTU 丰度一致不变。\n通过不同方法处理这些数据并检测差异 OTU，然后使用 ROC 曲线和 AUC（Area Under Curve） 来衡量每种方法检出真实差异 OTU 的能力与假阳性控制水平。\nedgeR 与 DESeq 明显优于其他方法，具体表现为：\nAUC 高达 0.95–0.98，说明检出真正差异 OTU 的能力极强； 假阳性率控制良好，尤其在样本数较多时尤为明显； 稀释法表现最差，不仅灵敏度低（漏检多），而且假阳性率高，尤其当稀释阈值较低时更严重； metagenomeSeq 在 replicates 较多时接近 edgeR，但在 n=2~3 样本时性能急剧下降。 此外，作者强调，稀释法带来的最大问题是“有效样本数的减少”——本来可以使用 10,000 个 reads 做差异分析，稀释后只剩 1,000 个，等效于用更小的样本重复去估计参数，导致功效大幅下降。\nMcMurdie \u0026amp; Holmes 在文中总结如下：\n明确反对 rarefying：既浪费数据又带来分析偏差，是 inadmissible 的 normalization 方法。 推荐基于统计混合模型的方法：借用 RNA-Seq 的 edgeR、DESeq，甚至 metagenomeSeq。作者还将这些方法整合进 R 包 phyloseq 中，方便微生物组分析。 树立统计意识：研究者应理解 library size、overdispersion 的本质，并采用合适的 GLM（Generalized Linear Model）模型或经验贝叶斯方法，而不是简单采样。 这篇论文自 2014 年发布后对微生物组数据分析流程影响深远：\n推动了差异丰度分析方法的演进，例如 ANCOM、ALDEx2、Songbird 等工具开始强调 compositional data 和统计模型。 2024 年，Schloss 又在 mSphere 中重访 rarefying，提出一些更新观点，可视为对这篇论文的回应和延伸。 微生物组数据本质是成分数据（compositional），总和约束 → 需要特殊方法处理，而 NB 模型正是合理起点之一。 References McMurdie, P.J., and Holmes, S. (2014). Waste not, want not: why rarefying microbiome data is inadmissible. PLOS Comput. Biol. 10, e1003531. https://doi.org/10.1371/journal.pcbi.1003531. ","date":"2025-07-24T00:00:00Z","image":"/p/rarefaction-10/images/fig1_hu_9754129a0f2d8408.png","permalink":"/p/rarefaction-10/","title":"有关Rarefaction的探讨，一篇10年前的文章"},{"content":"Introduction 在现代社会，人们平均有超过90%的时间在室内度过——无论是家中、办公室，还是学校或医院。然而，我们很少意识到，这些封闭空间并非“无菌”环境，而是充满了肉眼看不见的微生物群落，它们构成了复杂的室内微生物组（Indoor Microbiome）。\n从地板上的灰尘到空调系统的滤网，从厨房台面到浴室的水龙头，微生物无处不在。它们有些来自人体（如皮肤和肠道菌群），有些通过空气、物品或宠物进入室内，还有些在建筑材料和管道中顽强生存。近年来，科学研究逐渐揭示，这些微小的生命不仅影响我们的健康——从免疫系统的发育到过敏和感染的风险——还可能通过“微生物-环境-宿主”的互动，塑造我们的长期福祉。\n随着城市化进程加速和建筑密闭性提高，室内微生物组的平衡变得愈发重要。本文介绍一些关于室内微生物组的研究进展，探讨它们对人类健康的潜在影响。\n室内微生物组与健康 Gilbert, J.A., Hartmann, E.M. The indoors microbiome and human health. Nat Rev Microbiol 22, 742–755 (2024). https://doi.org/10.1038/s41579-024-01077-3\n先看一篇比较新的发表在《Nature Reviews Microbiology》的综述文章对室内微生物有个整体的概念。这篇文章探讨了建筑环境——人类大部分时间居住的地方——的微生物生态对免疫、内分泌和神经健康的影响，还提出了利用室内微生物组来改善健康的策略。\n室内微生物组 室内微生物组与室外环境存在显著差异，主要受人类活动和建筑特性的影响。室内环境通常干燥且营养匮乏，微生物大多来自人体和环境输入。人类皮肤相关的细菌如葡萄球菌和链球菌在频繁接触的表面占主导，而建筑管道内部则以环境菌为主。不同场所的微生物特征各异：农场家庭富含动物粪便相关菌种，医院环境则常见致病菌如假单胞菌。每个人每小时会向周围释放大量微生物颗粒，使得每个室内空间都形成独特的微生物群落。空气流通和建筑材料选择会显著影响微生物定植，例如厨房台面的微生物组成与居民对食品安全的重视程度相关，而浴室则容易滋生肠道相关菌群。即使在严格消毒的医院，耐甲氧西林金黄色葡萄球菌等病原体仍可能持续存在，凸显了室内微生物管理的重要性。\n室内微生物生态学 要实现健康的室内环境，必须将微生物组研究与室内环境质量概念相结合。早期的研究主要集中于阐述室内空间中的细菌和真菌的分类多样性。随着技术进步，研究者开始对包括古菌和病毒在内的广义微生物多样性进行特征阐述，并探索它们的功能代谢特性。全面了解室内微生物组的真实功能和分类多样性，将使我们更接近实现健康建筑设计的崇高目标。\n抗菌耐药性 室内微生物组中抗菌耐药性基因的分布是一个重要研究领域。多个研究发现抗菌化学品和清洁实践与室内尘埃中的抗菌耐药性基因存在关联。医院环境尤其值得关注，研究表明高流量诊所地面上存在比其他环境更多的临床相关抗菌耐药性基因。患者与环境之间可能存在抗菌耐药性基因的交换，这种现象在新生儿重症监护环境中尤为明显。\n建筑管道系统是另一个值得关注的区域。淋浴软管和喷头中的微生物组受到管道材料类型和水源的影响，而水槽排水口由于接收药物和个人护理产品残留，其抗菌耐药性问题尤为突出。\n细菌和真菌的生存能力和代谢 室内微生物的生存能力和代谢活动受到多种因素影响：\n设计因素：如照明和材料选择会影响微生物种类及其生存时间 湿度条件：不同程度的湿润可以诱导真菌生长，使用\u0026quot;湿润时间\u0026quot;框架可以对其进行定量建模 水的存在：在持续潮湿环境（如建筑管道）中，微生物群落的丰度和多样性受到水流速率的强烈影响 值得注意的是，在遭受湿气问题的建筑物内部，发霉材料与相连空间之间的物理距离会影响表面真菌的分布。实验室模拟中还观察到细菌与真菌之间的代谢互动。\n病毒和古菌 病毒动态： 托儿所的病毒组呈现季节性变化，冬季以人源病毒为主 病毒来源多样，包括人类、宠物、植物及外部环境 噬菌体在调节细菌群体方面具有重要作用，可能成为控制耐药菌的工具 古菌特征： 传统检测方法可能低估了古菌存在 最新研究表明古菌确实存在于室内尘埃中，且可能具有生存能力 产甲烷古菌等严格厌氧菌在特定条件下仍可在室内传播 人类与建筑之间的微生物交换 人类是室内微生物的主要来源：\n新医院研究表明高接触环境中皮肤相关微生物占主导 这一现象在其他环境（飞机舱、交通系统等）中也得到证实 研究显示健康成人的微生物组也会受到建筑环境的影响 肠道来源的严格厌氧菌（包括某些古菌）在特定条件下仍可在室内存活 这些发现突显了人-环境微生物交换的双向性，为健康建筑设计提供了重要依据。\n室内微生物组对人类健康的影响 室内微生物组通过多种途径影响人类健康。微生物暴露不仅可能导致感染性疾病，还会影响免疫系统发育，并与多种慢性疾病的发生发展相关。城市化进程带来的微生物多样性降低，可能与抑郁症、肥胖、过敏性疾病等健康风险的增加存在关联。\n感染性疾病 建筑环境在疾病传播中扮演重要角色，这在COVID-19大流行中得到充分印证。医院获得性感染尤其值得关注，其本质是患者、医护人员与医院微生物环境互动的结果。值得注意的是，某些常见共生菌（如金黄色葡萄球菌）在医院环境中可能演变为耐药菌株（如MRSA）。消毒剂和抗菌材料的广泛使用可能通过选择压力促进耐药性的产生，这一现象在家庭环境中同样存在。儿童因免疫系统发育不完善，更容易受到环境病原体的影响。\n代谢性疾病 城市化带来的生活方式改变显著影响了人类微生物组。肠道菌群通过调节能量代谢和脂肪储存，在肥胖发生中起关键作用。研究表明，户外活动时间的减少和自然环境接触的匮乏，可能导致肠道菌群多样性下降，进而增加代谢疾病风险。虽然直接证据有限，但室内微生物多样性降低可能是推动肥胖流行的重要因素之一。\n心理健康 建筑环境可能通过\u0026quot;肠-脑轴\u0026quot;影响心理健康。现代建筑环境中微生物暴露模式的改变，加上城市生活压力，可能导致肠道菌群失调，进而影响神经递质产生、诱发炎症反应，最终增加抑郁和焦虑风险。这一领域的研究尚处于起步阶段，但已显示出微生物-神经-免疫互作的重要性。\n过敏性疾病 著名的\u0026quot;卫生假说\u0026quot;为理解微生物暴露与过敏的关系提供了框架。阿米什人与赫特莱特儿童的对比研究显示，丰富的农场微生物暴露可显著降低哮喘风险。室内环境中的微生物代谢产物（如脂多糖）通过调节Th1/Th2免疫平衡影响过敏发生。生命早期接触特定细菌（如厚壁菌门）对预防过敏至关重要，而建筑潮湿等问题可能促进致敏微生物的生长。\n这些发现突显了建筑环境设计在维护健康方面的重要性，需要平衡感染防控与有益微生物暴露的关系。\n创建健康建筑 在建筑创新浪潮中，\u0026ldquo;健康建筑\u0026quot;理念正成为连接人居环境与生态健康的重要纽带。这一理念超越了传统建筑标准，将微生物组管理纳入整体设计框架，创造性地平衡了健康效益与可持续性目标。\n现代健康建筑通过三大核心要素重塑人居环境：\n生物友好设计：采用透气性建材和动态通风系统，促进有益微生物定植 智能调控系统：实时监测温湿度等参数，优化微生物生长条件 自然融合设计：通过垂直绿化和室内园艺增加环境微生物多样性 尽管前景广阔，健康建筑的推广仍面临显著障碍：\n成本瓶颈：初期建设费用比传统建筑高出15-30% 改造难题：现有建筑结构限制创新技术的整合应用 标准缺失：全球范围内缺乏统一的微生物安全评估体系 前沿研究正在探索三种突破性干预路径：\n城市再野化 通过立体绿化系统和生态走廊设计，将自然微生物群落引入城市空间。研究显示，接触多样化环境微生物可使儿童过敏风险降低40%。\n活性建材开发\n3D打印生物材料成功包埋枯草芽孢杆菌孢子 智能水凝胶材料可特异性激活对抗病原菌 自修复混凝土利用微生物矿化作用延长建筑寿命 微生物组精准调控 益生菌清洁剂重建表面微生物平衡 噬菌体涂层有效控制医院耐药菌传播 空气循环系统选择性富集有益气溶胶微生物 随着合成生物学进步，下一代健康建筑可能实现：\n动态响应型微生物群落调控 个性化微生物环境定制 建筑-人体微生物组双向调节 这种创新范式正在重新定义建筑与健康的边界，为城市化进程中的公共卫生挑战提供全新解决方案。尽管仍需克服技术标准化和长期安全性评估等障碍，健康建筑已展现出改变人类生活方式的巨大潜力。\n住宅区四季室内外空气微生物组 Indoor/outdoor airborne microbiome characteristics in residential areas across four seasons and its indoor purification (2024). Environ. Int. 190, 108857. https://doi.org/10.1016/j.envint.2024.108857.\n发表在Environment International（IF=9.7）的一篇文章，这个研究系统调查了中国广州6个典型住宅区室内外空气微生物组在四季中的分布特征、影响因素及健康风险，并评估了空气净化器的去除效果。研究通过高通量测序和培养方法，揭示了微生物群落结构、粒径分布及其与环境因素的关联。\n核心发现 微生物浓度与粒径分布 季节性差异：夏季微生物浓度最高（细菌64-905 CFU/m³，真菌4-580 CFU/m³），冬季PM2.5浓度最高（室内68.42μg/m³）。 粒径特征：74.6%的微生物为可吸入颗粒（\u0026lt;4.7μm），其中1.1-4.7μm占比最高（秋季达87.5%），易沉积于肺泡区。 微生物群落组成 优势菌群：室内外均以Anoxybacillus（细菌）和Cladosporium（真菌）为主，后者冬季占比高达65.8%。 功能预测：室内微生物含人类肠道相关基因，且医院环境中耐药基因（如MRSA）丰度显著高于其他场所。 环境驱动因素 关键关联：温度与Peanibacillus正相关（r\u0026gt;0.6, p\u0026lt;0.05），PM2.5促进Stenotrophomonas生长；臭氧（O₃）影响细菌代谢。 来源解析：中性模型显示细菌扩散随机性高于真菌（R²=0.694-0.846），秋季随机分布最显著。 健康风险 暴露评估：儿童吸入剂量（ADD）高于成人，秋季风险最高；但危害商数（HQ）均\u0026lt;1，属可接受范围。 致病潜力：检出机会致病菌如Rhodococcus（肺脓肿）和Stenotrophomonas（耐药性强）。 净化效果 空气净化器：对1.1-4.7μm细菌去除率最高（秋季达49.4%），革兰阴性菌去除优于阳性菌；但对真菌效果有限。 研究意义与局限 实践价值：为湿热气候区住宅微生物污染控制提供数据支持，建议结合通风与净化策略。 创新点：首次系统量化净化器对微生物粒径选择性去除效应。 局限性：样本量较小（6个住宅），未考虑居民行为对微生物的直接影响。 室内空气微生物的高度分辨率分析 Shen, F., Wang, M., Ma, J., Sun, Y., Zheng, Y., Mu, Q., Li, X., Wu, Y., and Zhu, T. (2024). Height-resolved analysis of indoor airborne microbiome: comparison with floor dust-borne microbiome and the significance of shoe sole dust. Environ. Sci. Technol. 58, 17364–17375. https://doi.org/10.1021/acs.est.4c06218.\n发表在Environmental Science \u0026amp; Technology（IF=11.3）的一篇文章，通过创新的被动采样方法，系统分析了室内空气中微生物群落在不同高度（天花板附近H1、成人呼吸高度H2、地面附近H3）的垂直分布特征，并与地板灰尘微生物组进行比较。研究首次量化了鞋底灰尘对室内空气微生物的贡献，揭示了传统地板灰尘样本作为空气微生物替代指标的局限性。\n核心发现 空气微生物的垂直分层现象 多样性梯度：细菌和真菌的α多样性（如Chao1指数）随高度降低而增加（H1\u0026lt;H2\u0026lt;H3），但香农指数无显著差异，表明物种分布不均匀。\n群落差异：细菌在H1与H3间存在弱分层（ANOSIM R=0.07），真菌分层更明显（R=0.18）。中高度（H2）细菌群落变异最大，可能与人类活动扰动相关。\n空气与地板灰尘微生物组的显著差异 组成差异：空气中以变形菌门（41.4%）为主，地板灰尘中厚壁菌门（31.4%）更丰富。芽孢杆菌属（空气）与葡萄球菌属（灰尘）分别为优势菌。\n功能差异：空气微生物代谢相关基因（如脂质代谢、异生物质降解）更活跃，而灰尘微生物的遗传信息处理通路更丰富（图5）。\n鞋底灰尘的关键作用 贡献量化：鞋底灰尘贡献4%空气细菌和14%空气真菌，与地板灰尘贡献相当（细菌4.3% vs 真菌12.6%）。对地板灰尘的贡献更高（细菌25.5%、真菌52.7%）。\n生态过程：随机过程（如扩散限制）主导微生物群落构建（\u0026gt;80%），鞋底灰尘通过漂变过程（drift）显著影响真菌群落（贡献79%）。\n健康暴露启示 采样方法革新：矿物油被动采样器实现长期连续采样，克服传统主动采样噪音干扰，更贴近真实暴露场景。 风险评估：地板灰尘不能准确代表可吸入微生物，需开展高度分辨研究（如儿童爬行区与成人呼吸区差异）。 创新点与局限 方法创新：\n首次采用多高度同步被动采样 建立鞋底灰尘贡献的定量模型（FEAST算法） 实际意义：\n为\u0026quot;再野化\u0026quot;室内微生物组提供新思路（通过鞋底引入有益环境微生物） 提示需关注鞋底作为病原传播载体的风险 研究局限：\n未比较主动/被动采样器的捕获效率 样本量较小（5个场所） 未评估室外空气影响 新加坡食品中心微生物组 Teo, J.J.Y., Ho, E.X.P., Ng, A.H.Q., How, S.H.C., Chng, K.R., Ateş, Y.C., Fau’di, M.T., Aung, K.T., and Nagarajan, N. (2024). City-wide metagenomic surveillance of food centres reveals location-specific microbial signatures and enrichment of antibiotic resistance genes. Preprint at medRxiv, https://doi.org/10.1101/2024.07.28.24310840 https://doi.org/10.1101/2024.07.28.24310840.\n这项研究首次对新加坡16个食品中心(又称小贩中心)进行了城市规模的宏基因组监测(n=240样本)，旨在了解这些高人流环境中微生物(细菌、古菌、真菌、病毒)和非微生物DNA的分布特征。食品中心作为亚洲许多大城市主要的食品消费场所，其微生物组成可能对公共卫生有重要影响，特别是在全球食源性和污染物相关疾病发病率上升的背景下。研究重点关注了食品中心特有的微生物特征、抗生素抗性基因(ARGs)的富集情况，以及与食品相关的微生物特征。\n研究团队在两个时间点(2019年3月和2022年7月)采集了样本，采用MetaSUB协议对食品中心桌面进行拭子采样，使用Isohelix DNA Buccal Swabs收集样本。DNA提取后进行了深度shotgun宏基因组测序(平均每样本2000万reads)。数据分析使用了Kraken 2和Bracken进行分类分析，并采用多种统计和机器学习方法进行特征分析。\n主要发现 食品中心特有的微生物特征 研究发现食品中心宏基因组中富含与食品相关的DNA特征，这些特征可以部分解释观察到的微生物谱(解释了44%的变异)。研究发现了特定的食物-微生物关联，如肠杆菌科与鱼类之间的关联。\n位置特异性微生物特征 通过机器学习分析，研究确定了22种微生物物种可以作为不同食品中心高度准确(\u0026gt;80%)的位置特异性标志，其中一些标志在3年后仍然存在。这些标志性微生物的平均相对丰度为4.5%，表明它们是宏基因组中的非优势物种。\n抗生素抗性基因富集 食品中心显示出相对于其他非医疗环境(\u0026gt;2.5倍)和医院环境(某些病原体高出1个数量级)的抗生素抗性基因(ARGs)富集。特别是，粘菌素抗性在食品中心最为富集(\u0026gt;1.5倍)。\n病原体富集情况 研究发现了高优先级ESKAPE病原体(如肺炎克雷伯菌、肠杆菌属等)在食品中心显著富集(\u0026gt;3倍)，甚至比医院环境还要高。\n这项研究首次大规模应用shotgun宏基因组方法对食品中心环境进行监测，证明了该方法在追踪环境中微生物和相关关注基因方面的实用性。研究发现食品中心具有独特的微生物特征，这些特征既反映了食品来源的变化，也反映了地理位置和相关环境因素的影响。研究结果强调了食品中心环境作为抗生素抗性监测重要节点的公共卫生意义，并为未来旨在降低感染风险的各种清洁和行为干预策略研究提供了基础。\nReferences Gilbert, J.A., Hartmann, E.M. The indoors microbiome and human health. Nat Rev Microbiol 22, 742–755 (2024). https://doi.org/10.1038/s41579-024-01077-3 Indoor/outdoor airborne microbiome characteristics in residential areas across four seasons and its indoor purification (2024). Environ. Int. 190, 108857. https://doi.org/10.1016/j.envint.2024.108857. Shen, F., Wang, M., Ma, J., Sun, Y., Zheng, Y., Mu, Q., Li, X., Wu, Y., and Zhu, T. (2024). Height-resolved analysis of indoor airborne microbiome: comparison with floor dust-borne microbiome and the significance of shoe sole dust. Environ. Sci. Technol. 58, 17364–17375. https://doi.org/10.1021/acs.est.4c06218. Teo, J.J.Y., Ho, E.X.P., Ng, A.H.Q., How, S.H.C., Chng, K.R., Ateş, Y.C., Fau’di, M.T., Aung, K.T., and Nagarajan, N. (2024). City-wide metagenomic surveillance of food centres reveals location-specific microbial signatures and enrichment of antibiotic resistance genes. Preprint at medRxiv, https://doi.org/10.1101/2024.07.28.24310840 https://doi.org/10.1101/2024.07.28.24310840. ","date":"2025-07-16T00:00:00Z","image":"/p/indoor/images/ind3_hu_b2111ccb06092ddc.png","permalink":"/p/indoor/","title":"室内微生物组相关研究"},{"content":"Introduction 微生物组研究的一个核心问题是识别与特定表型（如健康状况或环境条件）相关的微生物特征。然而，微生物组数据具有稀疏性、组成性和异方差性等特点，使得统计分析面临巨大挑战。近期发表在bioRxiv上的论文《MaAsLin 3: Refining and extending generalized multivariable linear models for meta-omic association discovery》提出了一个强大的解决方案。\nMaAsLin 3文章简介 MaAsLin3 (Microbiome Multivariable Associations with Linear Models) 是哈佛大学Huttenhower C.大佬团队开发的微生物组多变量关联分析R包工具，相比前代主要有三大突破：\n同时检测丰度和存在性关联 传统方法只能检测微生物相对丰度的变化 MaAsLin 3通过分步建模，分别检测： 存在/缺失（Prevalence） 非零时的丰度变化（Abundance） 创新的组成性校正方法\n通过中位数系数比较策略推断绝对丰度变化 支持实验性绝对定量数据（如spike-in） 扩展的分析能力\n支持混合效应模型 新增有序预测变量分析 支持特征特异性协变量（如宏转录组中的DNA丰度） 性能表现 在模拟数据测试中，MaAsLin 3展现出显著优势：\n在50个以上样本时F1分数最高 平均精确度≥0.82，优于同类工具 系数估计偏差最小（仅-12%） 在IBD研究中的新发现 应用MaAsLin 3分析HMP2炎症性肠病(IBD)数据库时发现：\n77%的显著关联是存在性（而非丰度）变化 确认了成人IBD中Enterocloster spp.的富集 首次发现Dysosmobacter welbionis在IBD中的存在性降低 实际应用建议 数据类型选择：\n优先使用spike-in或qPCR绝对定量数据 相对丰度数据需启用中位数校正 模型设定：\n1 2 3 4 5 6 7 8 # 基础模型 maaslin3( input_data = features, input_metadata = metadata, normalization = \u0026#34;TSS\u0026#34;, transform = \u0026#34;LOG\u0026#34;, analysis_method = \u0026#34;LM\u0026#34; ) 结果解读：\n关注q-value\u0026lt;0.1且|β|\u0026gt;1的关联 区分丰度与存在性变化的生物学意义 使用教程 官方教程：https://github.com/biobakery/biobakery/wiki/MaAsLin3\n安装MaAsLin 3 最新开发版的MaAsLin 3可通过devtools工具包从GitHub安装。\n稳定版MaAsLin 3可通过BiocManager安装：\n1 2 3 4 if (!require(\u0026#34;BiocManager\u0026#34;, quietly = TRUE)) install.packages(\u0026#34;BiocManager\u0026#34;) BiocManager::install(\u0026#34;remotes\u0026#34;) BiocManager::install(\u0026#34;biobakery/maaslin3\u0026#34;) 运行前需加载依赖库：\n1 2 3 for (lib in c(\u0026#39;maaslin3\u0026#39;, \u0026#39;dplyr\u0026#39;, \u0026#39;ggplot2\u0026#39;, \u0026#39;knitr\u0026#39;, \u0026#39;kableExtra\u0026#39;)) { suppressPackageStartupMessages(require(lib, character.only = TRUE)) } 使用MaAsLin 3进行微生物组关联分析 运行MaAsLin 3需要提供以下数据：\n样本特征丰度表（需保留零值） 样本元数据表 指定元数据与特征存在率（特征出现概率）及丰度（存在时的数量级）关系的公式或固定效应（可添加随机效应） 输出结果包括：\n关联分析表（含每个特征-元数据组合的效应量及p值） 可视化文件夹（含显著关联的摘要图及诊断图） 输入文件要求 需准备两个输入文件：\n1.特征丰度数据框\n格式1：列=特征，行=样本 格式2：行=特征，列=样本（转置格式亦可） 特征类型：分类单元或基因（支持相对丰度或绝对计数） 可接受制表符分隔的文件路径 2.元数据数据框\n格式1：列=变量，行=样本 格式2：行=变量，列=样本（转置格式亦可） 变量类型：性别、年龄等 可接受制表符分隔的文件路径 注意事项：\n允许存在仅出现在一个文件中的样本，分析时会自动剔除不匹配样本 两个文件的样本顺序无需一致，程序会自动对齐 含NA值的样本在模型拟合时会被排除，建议在随机缺失假设下预先剔除或使用多重插补处理 示例文件说明： 示例数据来自人类微生物组计划2（HMP2），存放于MaAsLin 3源码的inst/extdata目录或教程文件库：\nHMP2_taxonomy.tsv：物种丰度子集（行=样本，列=物种） HMP2_metadata.tsv：元数据子集（行=样本，列=变量） 数据读取与预处理：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 # 读取物种丰度表 taxa_table_name \u0026lt;- system.file(\u0026#34;extdata\u0026#34;, \u0026#34;HMP2_taxonomy.tsv\u0026#34;, package = \u0026#34;maaslin3\u0026#34;) taxa_table \u0026lt;- read.csv(taxa_table_name, sep = \u0026#39;\\t\u0026#39;, row.names = 1) # 读取元数据表 metadata_name \u0026lt;- system.file(\u0026#34;extdata\u0026#34;, \u0026#34;HMP2_metadata.tsv\u0026#34;, package = \u0026#34;maaslin3\u0026#34;) metadata \u0026lt;- read.csv(metadata_name, sep = \u0026#39;\\t\u0026#39;, row.names = 1) # 分类变量因子化（用于IBD与健康对照比较） metadata$diagnosis \u0026lt;- factor(metadata$diagnosis, levels = c(\u0026#39;nonIBD\u0026#39;, \u0026#39;UC\u0026#39;, \u0026#39;CD\u0026#39;)) metadata$dysbiosis_state \u0026lt;- factor(metadata$dysbiosis_state, levels = c(\u0026#39;none\u0026#39;, \u0026#39;dysbiosis_UC\u0026#39;, \u0026#39;dysbiosis_CD\u0026#39;)) metadata$antibiotics \u0026lt;- factor(metadata$antibiotics, levels = c(\u0026#39;No\u0026#39;, \u0026#39;Yes\u0026#39;)) # 查看数据结构 taxa_table[1:5, 1:5] 1 2 3 4 5 6 7 8 9 10 11 12 ## Phocaeicola_vulgatus Faecalibacterium_prausnitzii ## CSM5FZ3N_P 0.4265226 0.060255109 ## CSM5FZ3R_P 0.5369584 0.007396904 ## CSM5FZ3T_P 0.5911821 0.000000000 ## CSM5FZ3V_P 0.2661378 0.029680329 ## CSM5FZ3X_P 0.6601039 0.003596740 ## Bacteroides_uniformis Prevotella_copri_clade_A Bacteroides_stercoris ## CSM5FZ3N_P 0.269241131 0.0000e+00 0.000000000 ## CSM5FZ3R_P 0.252604847 0.0000e+00 0.008390958 ## CSM5FZ3T_P 0.000000000 0.0000e+00 0.000000000 ## CSM5FZ3V_P 0.400426526 0.0000e+00 0.000000000 ## CSM5FZ3X_P 0.000880428 1.3081e-05 0.001335669 1 metadata[1:5, 1:5] 1 2 3 4 5 6 ## participant_id site_name week_num reads diagnosis ## CSM5FZ3N_P C3001 Cedars-Sinai 0 9961743 CD ## CSM5FZ3R_P C3001 Cedars-Sinai 2 16456391 CD ## CSM5FZ3T_P C3002 Cedars-Sinai 0 10511448 CD ## CSM5FZ3V_P C3001 Cedars-Sinai 6 17808965 CD ## CSM5FZ3X_P C3002 Cedars-Sinai 2 13160893 CD 运行MaAsLin 3分析 MaAsLin 3的运行需要指定以下参数：\n丰度表（input_data） 元数据表（input_metadata） 输出目录（output） 分析模型（可通过公式或变量向量指定） 模型构建方式\n公式法：\n遵循lme4语法规范，可包含： 固定效应 随机效应 交互项 多项式项 分类变量作为固定效应时，各水平将与首个因子水平对比 支持特殊声明： group(variable_name)：分组预测变量 ordered(variable_name)：有序预测变量 strata(variable_name)：配对样本的条件逻辑回归 向量法：\n通过以下参数指定变量： fixed_effects：固定效应 random_effects：随机效应 group_effects：分组变量 ordered_effects：有序变量 strata_effects：配对变量 注意事项： 需使用列名而非$符号引用变量 分类变量需预先因子化，或通过'变量,参考水平;...'格式指定（如diagnosis,nonIBD;antibiotics,No） 重要建议\n当存在测序深度数据时，应将其作为协变量纳入模型（reads参数），以避免因测序深度差异导致的假阳性关联 HMP2数据实战示例 以下代码演示如何分析微生物物种与IBD诊断的关联，同时控制抗生素使用、年龄和测序深度的影响：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 set.seed(1) fit_out \u0026lt;- maaslin3( input_data = taxa_table, input_metadata = metadata, output = \u0026#39;hmp2_output\u0026#39;, formula = \u0026#39;~ diagnosis + dysbiosis_state + antibiotics + age + reads\u0026#39;, normalization = \u0026#39;TSS\u0026#39;, # 总丰度标准化 transform = \u0026#39;LOG\u0026#39;, # 对数转换 augment = TRUE, # 启用数据增强（解决逻辑回归线性可分问题） standardize = TRUE, # 连续变量Z-score标准化 max_significance = 0.1, # FDR阈值设为0.1 median_comparison_abundance = TRUE, # 丰度系数与中位数比较（应对组成性效应） median_comparison_prevalence = FALSE,# 存在率系数与0比较 max_pngs = 250, # 最大可视化结果数 cores = 1 # 单核运行 ) 关键参数解析\n标准化与转换\nTSS+LOG组合是推荐配置，其他选项详见?maaslin3 统计检验策略\n丰度关联：默认与特征的中位数系数比较（median_comparison_abundance=TRUE），适用于相对丰度数据 存在率关联：默认与0比较（median_comparison_prevalence=FALSE） 适用场景建议\n关闭中位数比较的情况： 研究相对丰度关联 假设总绝对丰度不变时的绝对关联分析 使用spike-in或未标准化丰度数据时 输出控制\n默认输出详细日志，可通过verbosity = 'WARN'减少输出 中位数比较机制详解\n当启用median_comparison时：\n丰度系数：与所有特征在该元数据上的中位数系数对比，抵消组成性效应 仅影响p值/q值计算（除非设置subtract_median=TRUE才会修正系数值） 存在率系数：通常保持与0比较，因其不受组成性影响 该设计确保了：\n相对丰度数据可推断绝对丰度变化 避免因技术偏差（如测序深度）导致的假关联 3.3 MaAsLin 3 输出结果解析\nMaAsLin 3的输出包含数据文件和可视化图表两类，完整示例可参考教程文件库中的HMP2分析结果。\n核心结果文件 1. 显著性关联表 (significant_results.tsv)\n按q值升序列出所有通过显著性检验的关联，字段说明：\n字段 说明 示例值 feature 微生物特征名 Phocaeicola_sartorii metadata 元数据变量名 reads coef 效应量系数 1.095 - 丰度模型：表示元数据每增加1单位，特征相对丰度的2^coef倍变化 - 存在率模型：表示对数几率（log-odds）的变化量 null_hypothesis 零假设值（0或中位数） 0 qval_individual 个体检验FDR校正q值 1.06E-40 qval_joint 联合检验q值（基于Beta(1,2)分布计算） 1.14E-40 model 模型类型（abundance/prevalence） prevalence 完整输出文件结构 数据文件\n文件/目录 内容 all_results.tsv 全量关联结果（含错误信息） features/ 处理后的特征表（过滤→标准化→转换） models_*.rds 模型对象（需save_models=TRUE） residuals_*.rds 模型残差（线性模型为普通残差，逻辑模型为偏差残差） maaslin3.log 完整运行日志（含参数设置与报错信息） 可视化文件\n摘要图 (summary_plot.pdf) 左：系数热图（*表示q\u0026lt;0.1，**表示q\u0026lt;0.01） 右：显著关联的效应量排序图 关联详图 (association_plots/) 连续变量：散点图（丰度）或箱线图（存在率） 分类变量：箱线图（丰度）或网格图（存在率） 图表右上角标注：q值、总样本数、非零样本数 诊断与验证要点 错误排查\n检查all_results.tsv的error列：模型拟合失败会标记错误 启用warn_prevalence=TRUE时，存在率关联可能受丰度影响（需通过可视化验证） 有效性验证\n分类变量：每组至少10个样本（丰度模型）且存在/缺失样本均≥10（存在率模型） 连续变量：通过散点图检查异常值影响 超大系数（|coef|\u0026gt;15）：需验证： 样本量充足（建议样本数≥10×变量数） 元数据无多重共线性 随机效应设置合理 多重检验校正\n默认对所有关联进行FDR校正，若需聚焦特定变量，可单独校正目标p值 结果重绘功能 通过maaslin_plot_results_from_output可重新生成图表（无需原始R对象）：\n1 2 3 4 5 6 # 示例：指定热图与系数图的元数据变量 maaslin_plot_results_from_output( output_dir = \u0026#34;hmp2_output\u0026#34;, heatmap_vars = c(\u0026#34;diagnosis\u0026#34;, \u0026#34;dysbiosis_state\u0026#34;), coef_plot_vars = c(\u0026#34;age\u0026#34;, \u0026#34;reads\u0026#34;) ) 更多高级功能，请查看https://github.com/biobakery/biobakery/wiki/MaAsLin3#4-advanced-topics\nReferences Nickols, W.A., Kuntz, T., Shen, J., Maharjan, S., Mallick, H., Franzosa, E.A., Thompson, K.N., Nearing, J.T., and Huttenhower, C. (2024). MaAsLin 3: refining and extending generalized multivariable linear models for meta-omic association discovery. Preprint at bioRxiv, https://doi.org/10.1101/2024.12.13.628459 https://doi.org/10.1101/2024.12.13.628459. https://github.com/biobakery/biobakery/wiki/MaAsLin3 ","date":"2025-07-02T00:00:00Z","image":"/p/maaslin-3/images/git1_hu_70f47e8701de132.png","permalink":"/p/maaslin-3/","title":"MaAsLin 3：微生物组多变量关联分析"},{"content":"我们实验室经常处理低微生物生物量样本（如宿主相关的呼吸道，阴道等微生物组，或是环境相关的沙子，冻土等微生物组），最近看到Nature Microbiology发表了一篇关于低微生物生物量样本污染的指南。\n发布日期：2025年6月20日 原文：https://doi.org/10.1038/s41564-025-02035-2\n众多重要环境中微生物生物量水平较低，包括某些人体组织、大气环境、植物种子、处理后的饮用水、超干旱土壤以及深层地下环境，部分环境甚至完全不存在常驻微生物群落。这些低微生物生物量环境对基于DNA的标准测序方法提出了独特挑战——当检测工作接近技术极限时，外部污染源的干扰必然成为关键问题。同样地，低生物量样本更容易受到交叉污染的严重影响，适用于高生物量样本的操作流程若直接应用于低微生物生物量样本，很可能导致误导性结果。本共识声明系统阐述了降低污染与交叉污染的应对策略，重点关注标记基因和宏基因组分析领域。我们同时制定了污染物信息报告与去除流程的最低标准规范。从样本采集处理到数据分析报告，研究全流程各环节都必须建立污染防控与识别机制。我们强烈建议研究者在设计、实施和报告微生物组研究（特别是低生物量系统研究）时采纳这些建议方案。\nIntroduction 过去二十年，随着非培养方法的普及，微生物组研究迅猛发展。标记基因测序和宏基因组测序已成为探索细菌、古菌、真菌、原生生物及病毒多样性的主流手段。尽管学界已就微生物组研究的最佳实践达成诸多共识，但这些建议主要基于高生物量样本（如表层土壤、污水和人类粪便）的研究经验。此类样本中微生物DNA含量较高，目标信号远强于污染噪声，不易产生假阳性结果。\n然而，许多系统的微生物生物量极低，接近常规DNA测序的检测极限（图1）。由于测序数据的比例特性，微量污染物即可严重影响研究结果，这在低生物量系统研究中尤为突出。这类系统包括：大气、保存不佳的古样本、深层地下环境、超干旱土壤、永久冻土、饮用水、金属表面、岩石、高盐卤水、雪和冰芯等。\n某些宿主相关系统（如人类呼吸道、母乳、胎儿组织、血液，以及植物种子、部分动物肠道等）虽含大量宿主DNA，但微生物DNA含量极低。更有研究报道，人类胎盘、特定动物肠道及极端环境中甚至完全检测不到常驻微生物。\n图 1 | 宿主、自然环境和人工环境系统中原核生物（细菌和古菌）细胞的典型数量（对数尺度）。估算值采用不依赖培养的方法（主要为直接细胞计数）获得，但我们注意到这些是平均近似值，并且从特定环境中采集的样本之间的细胞数量可能存在相当大的差异。细胞数量/计数来自已发表的文献，并根据通常用于 DNA 提取的样本量（体积或重量）进行了调整。详情请参阅补充表 1。图中不同颜色的点表示环境的一般类别。\n研究低微生物生物量环境需要严格把控样本采集、实验操作和数据分析各环节，以降低并识别污染物。污染物来源广泛（如人体、采样设备、试剂耗材、实验室环境），可出现在采样、储存、DNA提取、测序等任何阶段。另一个突出问题是样本间交叉污染（如孔间DNA渗漏，图2）。\n虽然已有多种生物信息学去污染方法，但难以准确区分真实信号与污染噪声，尤其对严重污染的测序数据。尽管已有研究提出污染防控指南，但污染问题依然存在，且对照实验的使用率十年未增。这导致学界对部分微生物组研究（特别是低生物量系统研究）的可靠性存疑。操作不当轻则影响研究质量与结果可比性，重则导致错误结论——污染可能扭曲生态与进化特征、造成病原体暴露途径误判，或导致微生物存在的假阳性判定。例如关于\u0026quot;胎盘微生物组\u0026quot;的争议，促使人们重视污染问题与最佳实践。类似争议也存在于人类血液、脑组织、肿瘤组织，以及深层地下环境、高层大气等系统的研究中。\n本文提出一套污染最小化方案及报告标准（经微生物组领域专家共识制定）。这些建议适用于所有微生物组研究（尤其低生物量系统、病原体追踪等易受污染影响的领域），虽以标记基因（如16S rRNA测序）和宏基因组测序为重点，但同样适用于宏转录组、DNA稳定同位素探针、qPCR和培养等方法。遵循这些建议将提升研究质量，有效规避低生物量系统研究中的常见问题。尽管无法完全消除污染，但通过系统防控可将其影响降至最低。\n图 2 | 概念图说明了微生物组研究三个步骤中污染和交叉污染的发生方式，并提出了缓解控制措施。目标样本（红色光滑形状表示）可能被外部污染物（灰色阴影尖锐形状表示）污染。这些外部污染物可能是来自采样群落以外来源的细胞或 DNA（例如，实验室试剂、采样设备）。此外，目标样本也可能受到交叉污染的影响，在采样、实验室处理和/或通过“标签切换”（例如，当条形码读取被错误分配给错误的样本时会发生这种情况）过程中，细胞或 DNA 被无意地与其他样本（棕色阴影光滑形状表示）交换。此外，污染物和交叉污染物会在整个工作流程中累积。准备，制备。\n低生物量系统的采样策略 污染可能发生在从采样到测序的任何环节（图2）。采样阶段的主要污染源包括操作人员、采样设备及周边环境（如患者血液样本接触皮肤，或沉积物样本混入上层水体）。由于大多数DNA检测方法的非特异性，采样过程中引入的微生物DNA很难与目标样本DNA区分。因此，建议采用污染防控型采样设计，以最大限度减少并识别污染。\n采样时的污染防控措施需根据具体系统调整，但以下核心原则普遍适用：\n全面评估污染源：从原位环境到采样容器，识别样本可能接触的所有污染源，并在采样前后采取防控措施。 采样前准备： 确保采样试剂（如保存液）无DNA污染 通过预实验优化流程并发现问题 采样过程控制： 实时监控样本接触的物体和环境 采用去污染措施或物理隔离阻断污染 人员培训：对采样人员进行标准化操作培训，确保流程规范执行。 需特别注意：初始样本的微生物生物量越低，污染对最终测序数据的比例影响越大。建议尽可能采取以下措施（参见表1）：\n污染源去污染措施 所有采样设备、工具、容器及手套均需进行去污染处理。首选一次性无DNA耗材（如拭子与采集管），若需重复使用则须严格消毒：先用80%乙醇灭活污染微生物，再以核酸降解溶液清除残留DNA，这对连续使用同一设备的场景尤为重要。手套需同等处理且在采样前避免接触任何物品。用于采集或储存样本的塑料/玻璃器皿应经过高压灭菌或紫外辐照预处理，并保持密封至采样时刻。需注意无菌状态不等同于无DNA残留——即便活细胞已被清除，游离DNA仍可能存留于处理后的表面。因此建议在安全可行条件下，采用次氯酸钠、UV-C辐照、过氧化氢、环氧乙烷气体或商用DNA清除剂进行深度处理。\n个人防护装备应用规范 采样操作应遵循最小接触原则。操作人员需根据环境穿戴防护装备（手套、护目镜、防护服/洁净服及鞋套等），以隔绝呼吸气溶胶、衣物皮屑等人体污染源。航天洁净室与古DNA实验室的防护标准具有示范价值：前者要求全覆盖式防护，后者采用口罩、防护面罩及三层可更换手套的配置。尽管极端场景才需如此严密的防护，但常规研究中适度使用PPE仍是经济高效降低人源污染的关键措施。\n污染源对照样本采集 设置采样对照对识别污染来源、评估防控效果及数据校正至关重要。对照类型包括空采集管、环境空气拭子、PPE表面拭子、操作接触面拭子及保存液等分试样等。涉及钻探或切割操作的研究常将工作流体作为阴性对照，部分实验还通过示踪染料标记流体污染。例如胎儿胎粪研究通过采集消毒后产妇皮肤拭子与手术室空气拭子，证实胎粪微生物组与阴性对照无差异。建议每4个样本至少设置1个对照，且所有对照需与实验样本同步经历全流程处理，以便结合DNA提取与建库阶段的阴性对照精准追溯污染环节。所有对照信息均需完整记录并报告（参见表2与框1）。\n实验室污染防控与识别规范 实验室操作流程（包括DNA提取、PCR扩增、文库构建和测序）既可能引入污染物，也会放大其影响。常见污染源包括试剂耗材（如提取试剂盒、保存液、离心管乃至纯化水）中可扩增的游离DNA或顽固菌种（如Ralstonia、Pseudomonas）残留，以及操作人员、实验室环境或其他样本的交叉污染。研究表明，实验室污染特征会随月份、季节及操作者变化，而样本管间DNA气溶胶扩散或\u0026quot;标签跳跃\u0026quot;现象更会导致数据误判。因此，必须通过实验室分区设计、规范操作和系统对照来防控污染。以下为关键措施（参见表1）：\n实验室空间管理 分子实验区应严格划分前处理区（样本制备/DNA提取）与后处理区（PCR/文库构建），并建立单向工作流。所有操作需在生物安全柜内完成，使用专用移液器与滤芯吸头。实验前后需用DNA降解溶液彻底消毒台面，并辅以UV-C辐照。人员须穿戴专用PPE，不同区域设备不得混用，且一次性防护装备应按\u0026quot;洁净区→污染区\u0026quot;单向穿行。定期清洁地面及水平面以控制灰尘污染。\n试剂质量控制 优先选用经认证的无DNA试剂，但使用前仍需通过qPCR或测序验证其洁净度。建议将大宗试剂分装为小份，每批次单独设立阴性对照以监控污染。塑料耗材使用前需UV-C灭菌，样本管进入工作区前应彻底表面消毒。若外包测序环节，需确认服务商具备低生物量样本处理经验，并建议进行预实验。\n对照系统设置 每个实验批次需同步设置多类型对照：\n采样对照（环境空白、试剂空白等） 过程对照（无样本DNA提取、无模板PCR等） 阳性对照（梯度稀释的模拟群落标准品） 交叉污染监控对照（如掺入特异性寡核苷酸）\n所有对照应与样本同步进行全流程处理并测序，即使阴性对照PCR产物不可见也需测序验证。建议每批次试剂均设立独立对照，因不同批次的污染物谱可能存在差异。 样本处理策略 高低生物量样本应分开处理，96孔板布局时需注意中心孔位更易发生交叉污染。推荐使用双索引纠错条形码，必要时可采用亚硫酸盐转化等化学标记技术，以区分预处理后引入的污染DNA。单管操作虽可降低交叉污染风险，但需权衡通量需求。\n检测并潜在去除序列数据中的污染物 在分析微生物组测序数据时，污染识别与清除是至关重要的环节，尤其对于低生物量样本。即便采用最严格的采样和实验流程，污染风险仍无法完全消除。通过系统比对阳性/阴性对照与样本中的序列、分类单元或基因，结合专业去污染软件（表3），可评估污染程度并进行针对性处理。但需注意，宏基因组数据因其复杂性较标记基因更难净化，且去污染过程可能导致信息失真。当信噪比过低时，建议直接弃用受污染数据，但保留原始记录（参见表2与框1）以追溯污染来源。\n分析测序对照并检查意外分类单元 质量控制阶段应重点分析三类信息：阴性对照中的非目标DNA、阳性对照分类单元在样本中的分布、以及污染物在读段中的占比。标记基因数据可通过比对ASVs与常见污染物数据库进行净化，而宏基因组数据则需将样本读段映射至对照组的MAGs。需警惕那些生态学上不合理的分类单元（如南极高空出现人体共生菌、脑组织中发现光合蓝藻等），这些异常信号往往提示污染存在。\n考虑使用净化软件，但要注意其局限性 去污染软件虽能辅助识别外源污染物（如decontam基于检出频率或丰度特征），但对交叉污染识别有限（SCRuB等工具例外）。使用时应考虑其假设前提与适用场景，注意假阳性与假阴性风险。宏基因组分析更需谨慎：即便设置阴性对照，低覆盖度污染物仍可能残留，且近缘物种序列难以区分。建议结合qPCR定量、细胞计数等生物量指标综合判断，同时认识到基于短读长组装的MAGs只能反映部分读段信息这一技术局限。\n防胜于治：污染防控优先原则 研究者应在开展大规模采样与测序前，投入充分精力优化污染防控方案。尽管微量污染难以避免，但系统性污染可被有效控制——已有研究成功获取了极低生物量生态系统的高质量数据，甚至证实了某些环境不存在常驻微生物。这些成果均依赖于全流程污染防控体系的建立，包括无污染采样流程开发、试剂与水质验证，以及测序数据的严谨分析。通过多维度对照实验，可追溯污染来源（如采样操作、试剂或人员），并据此迭代优化实验方案。\n对于已存在显著污染的数据集，事后去污染措施往往收效有限。例如近期一项全球大气微生物组研究中，近半数序列（包括已知试剂污染物如假单胞菌属）被迫剔除，导致群落组成与驱动因素的分析可靠性存疑。任何去污染算法均非完美， retrospective处理可能导致假阳性/假阴性结果。当标记基因或宏基因组数据需剔除大量序列时，应重新评估样本数据的有效性；若污染问题持续且严重，则需质疑整个数据集的可靠性。在关键研究中，跨实验室重复验证仍是确认结果可信度的金标准。\nConclusion 基于DNA技术的微生物组研究中，特别是在处理低生物量样本时，必须预设交叉污染难以完全避免。为此，研究者应当双管齐下：一方面通过标准化操作最大限度降低污染风险，另一方面设置系统对照以准确评估污染性质与程度。尤为关键的是，必须完整报告三项核心信息：污染防控的具体措施、检出污染物的特征、以及后续分析中对可疑污染数据的处理方案。这种全流程透明化记录将显著提升研究结果的可信度。需要说明的是，本文提出的建议并非强制性操作清单，而是旨在推动学界更系统地审视污染问题。我们相信，通过强化对污染和交叉污染问题的认知与管理，不仅能够提升微生物组研究的整体质量，更有助于解决既往研究中因污染导致的可重复性争议。最终目标是为微生物组科学建立更可靠的方法学基础，使研究成果能够经得起时间和实践的检验。\n","date":"2025-06-26T00:00:00Z","image":"/p/lowmass-nm/images/fig2_hu_7e70a37e87e867de.png","permalink":"/p/lowmass-nm/","title":"在低生物量微生物组研究中预防和报告污染｜Nature Microbiology指南"},{"content":"MetaNet是一个用于组学网络分析的R包，提供了多种功能，包括网络构建、可视化、比较和稳定性分析等。最近我把MetaNet的预印本放到了bioRxiv上，欢迎大家阅读和使用。\n预印本地址：https://www.biorxiv.org/content/10.1101/2025.06.26.661636v1 软件主页：https://github.com/Asa12138/MetaNet 大家可以帮忙在github上点点star⭐️，谢谢🙏 详细英文版教程：https://bookdown.org/Asa12138/metanet_book/ 网络分析是揭示高通量组学数据集中复杂关系的有力策略。然而，现有工具通常在可扩展性、灵活性以及多组学整合的原生支持方面存在不足，这为探索复杂生物网络设置了重大障碍。为突破这些限制，我们开发了MetaNet——一个高性能R语言软件包，专为多组学数据集的生物网络构建、可视化与分析而设计。MetaNet支持基于相关性的高效网络构建，可扩展至包含超过10,000个特征的数据集的快速计算，并提供与静态和交互式平台兼容的丰富布局算法与可视化选项。该软件包还包含一套完整的拓扑和稳定性指标，用于深度网络表征。基准测试表明，MetaNet在计算时间上比现有R包快达100倍，内存使用减少达50倍。我们通过两个案例研究展示其实用性：(1) 微生物共现网络的纵向分析揭示了空气微生物组的动态变化；(2) 包含40,000多个特征的暴露组-转录组整合网络，揭示了生物与化学暴露的差异化调控影响。MetaNet通过提供强大、可重复且具有生物学解释力的框架，弥合了网络理论与组学应用之间的鸿沟，支持跨组学平台的大规模、可解释的整合网络分析，推动现代生命科学的系统水平认知。MetaNet已在 CRAN发布(https://cran.r-project.org/web/packages/MetaNet)。\nIntroduction 网络（或称图论模型）是解析复杂生物系统交互关系的基础工具。这种抽象而信息丰富的表征方式，可跨越分子到生态等多个层次揭示生物特征间的相互作用。网络理论已深刻影响生命科学的多个分支领域——蛋白质互作网络阐明信号传导与药物靶点，基因调控网络描绘发育与疾病的级联控制，代谢网络绘制生物合成与能量通路，而生态网络则揭示物种互作与群落动态。随着宏基因组、转录组、蛋白组和代谢组等高通量组学技术的爆发式发展，基于网络的分析方法已成为处理多维生物大数据的核心策略，能有效识别功能模块、推断关联关系并发现关键调控因子。\n现有网络分析工具各具特色：Cytoscape提供分子互作可视化平台，Gephi擅长大规模图布局算法；R/Python生态中的igraph、ggraph和tidygraph包提供灵活的网络功能，WGCNA专注于基因共表达分析，而ggClusterNet、microeco和NetCoMi等工具则针对微生物组分析进行了优化。此外，MENAP、iNAP等在线流程为简单需求提供了快速解决方案。\n然而，这些工具难以满足现代组学数据的复杂需求：首先，缺乏多组学整合的原生支持；其次，高维数据相关性网络构建存在计算瓶颈；第三，相关性阈值选择通常依赖主观判断；第四，可视化功能有限，难以生成出版级图表；最后，在线工具的不可复现性问题突出。这些局限严重制约了组学尺度网络分析的可靠性。\n为此，我们开发了MetaNet——专为组学数据设计的可扩展R包。该工具通过四大创新突破现有局限：(1) 采用并行优化算法，实现万级特征的高效网络构建；(2) 引入随机矩阵理论实现数据驱动的相关性阈值筛选；(3) 集成40余种布局算法，支持与ggplot2/Gephi/Cytoscape的交互；(4) 提供拓扑分析与稳定性评估的全套指标。通过微生物组时序共现网络和暴露组-转录组整合网络两个案例，我们验证了其在复杂生物大数据解析中的卓越性能。\nMethods MetaNet设计与开发 MetaNet是基于R语言的多组学网络分析工具包，兼容Windows、MacOS和Linux系统（需R 4.0以上版本），核心功能基于igraph包实现。其架构包含八大模块（图1A）：计算、操作、布局、可视化、拓扑分析、模块分析、稳定性分析和数据读写，支持从网络构建到分析可视化的全流程。核心数据结构为扩展自igraph的\u0026quot;metanet\u0026quot;对象，兼容所有基础igraph操作，并可转换为tbl_graph对象与ggraph/tidygraph生态交互。所有功能函数均以\u0026quot;c_net_\u0026ldquo;前缀统一命名，便于记忆和使用。\n数据预处理\n提供\u0026quot;trans\u0026quot;函数支持CPM、log转换、aCPM等十余种标准化方法（表S1） 内置\u0026quot;guolv\u0026rdquo;（过滤）和\u0026quot;hebing\u0026quot;（合并）函数用于原始数据清洗 网络构建\n支持四种构建方式： 从原始数据计算（c_net_calculate + c_net_build） 导入graphml/pajek格式文件（c_net_load） 通过边列表生成（c_net_from_edgelist） 升级现有igraph对象（c_net_update） 网络操作\n注释管理：c_net_set/c_net_annotate实现属性标注 子网提取：c_net_filter/c_net_neighbors支持局部网络分析 集合运算：c_net_union/c_net_intersect实现网络比较 可视化与布局\n集成40余种布局算法（c_net_layout） 支持几何变换（缩放/旋转/3D投影等） c_net_plot函数提供出版级绘图参数控制 拓扑分析\nc_net_index计算17种拓扑指标 c_net_stability评估网络鲁棒性（特别适用于微生物生态网络） 性能对比 在Apple M2芯片上的基准测试显示（图1C）：\n计算速度：较WGCNA、NetCoMi等工具提升最高100倍（p\u0026lt;0.001） 内存占用：降低达50倍（特征数=1000时） 优势源于：向量化矩阵运算与t分布解析法求p值 案例应用 微生物共现网络\n数据集：6名受试者24个时间点的微生物组数据 筛选：保留出现频率\u0026gt;10%的914个物种 构建：Spearman相关性（|ρ|\u0026gt;0.6且FDR\u0026lt;0.05） 分析： 快速贪婪算法识别功能模块 时序子网拓扑指标计算（连通性/中心性等） 暴露组-转录组整合网络\n关联分析： 化学暴露-转录组：|ρ|\u0026gt;0.6且FDR\u0026lt;5e-4 生物暴露-转录组：|ρ|\u0026gt;0.5且FDR\u0026lt;5e-4 功能注释：ReporterScore包进行KEGG/GO富集分析 获取方式 CRAN/GitHub/Gitee平台开源 附在线手册（https://bookdown.org/Asa12138/metanet_book/） Results 高效且可扩展的网络计算可以分析更大的omics数据集 MetaNet实现了高效可扩展的网络计算能力，能够处理大规模组学数据集分析。该工具提供多种标准化策略（表S1），支持微生物组、转录组、蛋白组和代谢组等不同组学数据的预处理。网络构建基于Spearman、Pearson和Bray-Curtis等相似性计算方法，通过随机化检验和多重检验校正保留显著关联。相比现有工具，MetaNet采用优化的向量化矩阵算法，将计算速度提升100-10,000倍（p\u0026lt;0.001），在1000个特征规模下仅需0.2秒和100MB内存（图1D），且资源消耗随特征数呈平方级增长（图1E）。\n针对相关性网络阈值选择的主观性问题，MetaNet整合随机矩阵理论（RMT），通过数据驱动方式自动确定最优相关性阈值（图S1A-B），有效减少虚假边的影响。除相关性方法外，该工具还兼容互信息和偏相关等非线性关系分析方法的输出结果，为复杂组学网络构建提供灵活解决方案。\nFigure 1. Overview of the MetaNet workflow and its high-efficiency computation. (A) Functional modules of MetaNet, as visualized using MetaNet. (B) Detailed workflow of MetaNet. Green boxes indicate data objects, blue and red boxes represent MetaNet-specific objects, and gray boxes denote core functions. (C) MetaNet logo and its code repositories and platforms. (D) Line plots comparing memory usage and runtime for correlation-based network construction across different R packages. Comparisons were capped at 1000 features because some packages required too many resources and time to process larger networks. Error bars represent standard deviation (SD). (E) Line plots showing MetaNet’s performance on increasingly larger datasets in terms of memory usage and runtime. Error bars represent SD.\n网络注释、操作与比较的集成化功能工具 MetaNet提供完整的网络操作功能体系。通过\u0026quot;get_*\u0026ldquo;系列函数可快速获取网络、节点和边的属性表，支持数据检查和统计汇总。\u0026ldquo;metanet\u0026quot;对象完全兼容igraph基础操作，并可转换为tbl_graph对象实现与ggraph/tidygraph生态的无缝对接。\n在多组学研究中，网络注释常需整合丰度谱、分类学或临床元数据等外部信息。\u0026ldquo;c_net_set\u0026quot;函数支持批量添加注释表并自动配置可视化参数（图2B），包括颜色映射、线型设置、节点形状及图例生成。针对特定研究需求，\u0026ldquo;c_net_filter\u0026quot;可基于组合条件提取子网络（图2C），而\u0026quot;c_net_highlight\u0026quot;则能高亮显示关键节点或边（图2D）。\n对于复杂网络中的功能模块识别，\u0026ldquo;c_net_module\u0026quot;集成多种社区发现算法（图2E），检测结果可通过弦图或桑基图展示模块间关联（图2F）。通过\u0026quot;c_net_skeleton\u0026quot;函数可实现组间连接的统计汇总，显著提升多条件或时序数据的可解释性（图2G）。\n跨网络比较分析方面，MetaNet提供集合运算功能（图2H），支持通过交集、并集和差集运算揭示实验组间差异边或保守子网，为进化分析和差异比较建立标准化框架。\nFigure 2. MetaNet supports flexible and intuitive network manipulation. (A) Initial multi-omics network constructed without annotations. (B) Annotated multi-omics network using the \u0026ldquo;c_net_set\u0026rdquo; function. Node shape indicates the types of omics data, color represents the subtypes of omics data, size denotes average abundance, edge color indicates positive or negative correlation, edge type (solid or dashed) distinguishes intra- and inter-omics connections, and edge width reflects the absolute value of the correlation coefficient. (C) Subnetwork filtered from intra-omics interactions between the Microbiome and Metabolome layers using \u0026ldquo;c_net_filter\u0026rdquo;. (D) Highlighted nodes centered on \u0026ldquo;Dongia_mobilis\u0026rdquo; and its neighbors using \u0026ldquo;c_net_highlight\u0026rdquo;. (E) Community detection and modular visualization using \u0026ldquo;c_net_module\u0026rdquo;. (F) Chord diagram displaying the proportion of edges between modules. (G) Skeleton network across omics subtypes at a grouped level using \u0026ldquo;c_net_skeleton\u0026rdquo;. (H) Operations among networks: \u0026ldquo;c_net_union\u0026rdquo; merges net1 and net2, \u0026ldquo;c_net_intersect\u0026rdquo; extracts shared nodes and edges, and \u0026ldquo;c_net_difference\u0026rdquo; isolates net1-specific nodes and edges. All networks shown are based on simulated data and are for illustrative purposes only.\n进阶网络布局与可视化功能 网络布局是可视化的重要环节，直接影响网络结构的可解释性。MetaNet采用灵活的\u0026quot;coors\u0026quot;对象存储布局坐标，支持布局设置的便捷控制与复用。\u0026ldquo;c_net_layout\u0026quot;函数集成40余种布局算法（图3A），既包含经典布局也创新开发了\u0026quot;spatstat_layout\u0026quot;方法——该方法支持在用户自定义多边形内或边缘生成节点分布，例如实现星形排布（图3B）或地理映射（图3C）。系统还支持与Gephi、Cytoscape等工具的布局互操作。\n针对分组网络，\u0026ldquo;g_layout\u0026quot;函数提供高级布局接口，允许分别定义各组的空间配置策略。通过嵌套调用可构建多级复合布局，例如人体各部位微生物共现网络的高效排布（图3D）。该功能特别适用于模块化结构展示：\u0026ldquo;g_layout_circlepack\u0026quot;生成紧凑的圆形包块布局（图3E），而\u0026quot;g_layout_multi_layer\u0026quot;则创建突出模块关系的伪3D多层表达（图3F）。\n可视化方面，\u0026ldquo;c_net_plot\u0026quot;提供丰富的参数定制选项（表S2），精确控制节点、边、模块与图例的视觉呈现。系统默认采用igraph的基础绘图体系，同时通过\u0026quot;as.ggig\u0026quot;函数支持转换为ggplot2对象，可进一步应用\u0026quot;labs\u0026rdquo;、\u0026ldquo;theme\u0026quot;等函数优化图表（图S3A）。此外，MetaNet支持导出至NetworkD3、Gephi等工具实现扩展可视化流程（图S3B-D）。\nFigure 3. MetaNet enables diverse and powerful network layout strategies. (A) The application of 24 out of more than 40 built-in layout algorithms from \u0026ldquo;c_net_layout\u0026rdquo; on the Zachary Karate Club network was provided by the igraph package. (B) Layout generated within a star using \u0026ldquo;spatstat_layout\u0026rdquo;. (C) Layout generated within the map of Australia using \u0026ldquo;spatstat_layout\u0026rdquo;. (D) Grouped network layout consisting of four subgroups arranged with \u0026ldquo;with_fr()\u0026rdquo;, \u0026ldquo;on_grid()\u0026rdquo;, \u0026ldquo;as_polycircle(3)\u0026rdquo;, and \u0026ldquo;as_polygon(3)\u0026rdquo; within a human-body schematic. All visualization elements were rendered with MetaNet without manual adjustments. (E) Modular network visualized using \u0026ldquo;g_layout_circlepack\u0026rdquo;. (F) A three-layer modular structure visualized using \u0026ldquo;g_layout_multi_layer\u0026rdquo;. All networks shown are based on simulated data.\n专业生物网络与数据库的扩展支持 MetaNet原生支持多种生物信息学专用网络类型。通过构建Venn式网络（图4A），可突破传统维恩图的局限，直观展示样本组间的集合关系与连接结构。针对分类学或基因本体等树状数据，内置\u0026quot;as_circle_tree\u0026quot;布局能紧凑呈现层级关系（图4B）。特有的饼图节点设计（图4C）支持将多组学丰度等多元注释直接编码于网络结构中。\n该工具深度整合生物数据库资源：可导入STRING数据库的蛋白质互作网络（图4D）和miRTarBase验证的miRNA-靶基因调控网络（图4E），并支持自定义布局与注释。通过与ReporterScore包的无缝衔接，能直接可视化KEGG同源基因与通路的关联网络（图4F），更支持通过KEGG ID实时渲染全注释通路图（图4G）。这些功能使MetaNet成为整合生物知识库与多组学分析的强大平台。\nFigure 4. Diverse specialized network visualizations by MetaNet. (A) Venn-style network: Large nodes represent groups, while smaller nodes denote individual elements within each group, enabling visualization of shared and unique components. (B) Hierarchical tree network: Nodes are organized based on classification hierarchy. Node color corresponds to the taxonomic or categorical level. (C) Pie-node network: Each node is displayed as a pie chart, where slice colors indicate relative abundance across different groups. (D) Protein–protein interaction (PPI) network: Extracted from the STRING database, showing experimentally validated and predicted molecular interactions among proteins. (E) miRNA–gene regulatory network: Sourced from the miRTarBase database, illustrating experimentally supported regulatory relationships between miRNAs and their target genes. (F) KEGG KO–pathway association network: The network shows KEGG orthologs (KOs) involved in selected biological pathways. Small nodes represent KOs, and large nodes represent pathways. KO nodes are colored by their expression trend. Shaded regions surrounding pathways indicate whether the pathway is globally up-regulated (orange) or down-regulated (green). (G) KEGG pathway-specific network: Network representation of the “EGFR tyrosine kinase inhibitor resistance” pathway. Rectangular nodes denote KEGG orthologs, circular nodes indicate compounds, and edge colors reflect interaction types.\n全面的网络拓扑与稳定性分析 MetaNet提供全面的网络拓扑分析功能，涵盖全局和局部两个维度。全局指标包括网络密度、平均连接度、聚类系数、平均路径长度等（表S3），可量化生物网络的冗余性、鲁棒性等特征。例如平均路径长度能反映代谢或基因调控网络中的信号传递效率。局部指标则用于评估节点/边的重要性（表S4），可识别关键调控因子或瓶颈节点。\n系统支持通过Erdős–Rényi模型生成随机网络作为参照（图S4A），用于检测生物网络普遍具有的无标度、小世界等特征。\u0026ldquo;fit_power\u0026quot;函数可验证度分布的幂律特性（图S4B），而\u0026quot;smallworldness\u0026quot;则计算小世界指数σ。针对生物网络典型的模块化结构，通过\u0026quot;c_net_module\u0026quot;函数实现多种社区发现算法（图S4C），并支持分析模块内的表达或丰度模式（图S4D）。基于Zi-Pi方法将节点划分为外围节点、连接节点、模块枢纽和网络枢纽四种拓扑角色（图S4E-F），为功能解析提供新视角。\n在稳定性分析方面，MetaNet集成多种生态与结构稳定性算法。结构鲁棒性测试通过逐步移除节点计算自然连通性变化（图S5A），其下降速率反映网络抗干扰能力。鲁棒性评估则模拟节点删除并跟踪基于丰度的交互强度（图S5B）。脆弱性分析揭示节点对网络通信效率的贡献（图S5C），而正负凝聚指数则量化微生物群落的合作与竞争关系（图S5D-E）。所有分析均支持多核并行加速。\n案例1：微生物共现网络的时序动态分析 为展示MetaNet在多组学整合分析中的灵活性，我们将其应用于一项个体水平的多组学纵向研究数据。该研究通过可穿戴采样器获取19名受试者在特殊环境暴露下的化学与生物暴露组时序数据。我们重点分析了空气微生物组的动态变化，其中时间点A代表自然环境基线，B-D为暴露环境阶段。\n构建的全局微生物共现网络包含871个物种（图5A），覆盖四个分类界（图5B）。通过贪婪模块优化算法识别出六个功能模块，其度分布符合幂律特征（图5C），呈现典型复杂系统特性。模块内物种丰度分析显示，如M3模块成员随时间推移持续下降。拓扑角色分类鉴定出13个模块枢纽和19个连接节点，这些关键物种可能维持网络整体性。\n针对各时间点的细菌子网络分析（图5F）发现，部分微生物物种（灰色标记）的存在与丰度发生显著变化。拓扑指标比较显示，从时间点A到B出现重大转变（图5G）：暴露后网络的模块化程度和平均路径长度增加，而全局效率、聚类系数和自然连通性下降。这些变化暗示微生物群落发生功能解离——模块化增强反映亚群落间交流受限，聚类效率降低表明细菌互作网络受损，共同指向特殊暴露条件下空气微生物组的生态稳定性丧失。该发现与既往关于环境压力导致微生物网络脆弱性增加的研究结论一致。\nFigure 5. Modularity and temporal dynamics of the microbial co-occurrence network. (A) Species-level microbial co-occurrence network constructed from all microbial exposure samples, showing six modules (M1 to M6). Node color indicates module membership, node size reflects relative abundance, and edge color distinguishes intra- versus inter-module connections. (B) Phylogenetic relationship network of all species in panel A, arranged using the \u0026ldquo;as_circle_tree\u0026rdquo; layout. (C) Comparison of degree distribution between the empirical network in panel A and a randomized network with the same number of nodes and edges. (D) Temporal abundance profiles of species within each module. The y-axis represents the scaled abundance of species, while the x-axis represents individual samples sorted by time point (E) Key microbial taxa identified based on topological role classification using the Zi-Pi framework. (F) Subnetwork dynamics across four exposure stages. Node color represents bacterial phylum, node size reflects relative abundance, and gray nodes denote non-core species with presence or abundance changes over time. (G) Changes in global network topological metrics across different stages. P-values for comparisons between timepoints A and B were calculated using the Wilcoxon rank-sum test.\n案例2：多组学整合网络揭示生物与化学暴露组对转录组的差异化影响 基于同一纵向多组学数据集，我们进一步构建了暴露组（生物与化学）与宿主转录组的整合网络。该分析共纳入35,587个转录组基因、2,955个微生物物种和3,729种化学暴露物（图6A），发现590个微生物分类单元与1,983个基因存在显著关联（以正相关为主），而245种化学暴露物与1,026个基因的关联则以负相关为主导。最强关联子网络可视化显示（图6B），微生物暴露与基因表达呈正向关联，而化学暴露则倾向负相关（图6C）。关键环境因子包括：微生物中的Microbacterium lacticum和Aureobasidium melanogenum，化学物中的(SR)-4-甲基-2,3-戊二醇、吲哚等。\n功能富集分析揭示显著差异：微生物暴露关联基因主要富集于免疫负调控通路（图6D），如唾液链球菌与炎症信号枢纽HMGB1的正相关，提示潜在免疫调节机制；而化学暴露则显著关联神经退行性疾病（帕金森病、阿尔茨海默病等）和DNA损伤应答通路（图S6），其中苯系物和多环芳烃等已知神经毒物与认知功能障碍相关基因的负相关尤为突出。\n本案例证实MetaNet能有效解析多组学交互网络，揭示生物与化学暴露通过差异化的基因-环境互作机制影响健康结局——微生物暴露可能通过免疫调节通路发挥作用，而化学暴露更倾向于通过神经毒性和遗传毒性途径产生影响。\nFigure 6. Integrated Network Analysis of Exposome–Transcriptome Interactions. (A) Spearman correlation-based multi-omics network linking all microbial and chemical exposures to transcriptomic data. (B) Spearman correlation-based multi-omics network showing the most prominent associations. Links with |ρ| \u0026gt; 0.7 (for chemical–transcriptome pairs) or \u0026gt; 0.6 (for biological–transcriptome pairs) are included. Only the top 10 ranked node labels are shown. Node size reflects degree centrality. (C) Skeleton structure of the network in panel B, highlighting the core architecture of microbial and chemical associations with genes. (D) Network representations of significantly correlated genes and enriched pathways for biological exposures. Bar charts on either side indicate the number of positively and negatively correlated connections for each exposure.\nDiscussion 本研究推出的MetaNet是一个可扩展、灵活且具有生物学解释力的R语言工具包，专为组学与多组学网络分析设计。通过将网络构建、可视化、拓扑分析和跨组学整合集成至统一的可复现流程，该工具解决了现有方法的多个关键局限。其处理上万特征的能力、支持多样化网络类型以及生成高质量可定制可视化结果的特点，使其特别适用于现代系统生物学研究。两个案例研究证实了MetaNet从复杂数据中提取生物学洞见的价值，基准测试则验证了其计算性能优势，模块化设计则保障了功能的可扩展性。\n当前网络分析工具生态呈现多元化发展：Cytoscape擅长可视化扩展，Gephi支持大规模动态布局，igraph提供跨语言高性能计算，WGCNA专注基因共表达分析，而NetCoMi等工具则聚焦微生物生态网络。面对高通量技术产生的海量多维组学数据，MetaNet通过四大核心优势推动领域发展：(1) 基于相关性的超高效网络构建；(2) 多组学数据的无缝整合；(3) 覆盖40余种布局算法的可视化引擎；(4) 拓扑与稳定性分析的完整指标体系。该工具尤其适用于微生物生态网络、多组学互作网络等需要精确复现的研究场景，并能对接KEGG、STRING等生物知识库。\n尽管取得显著进展，MetaNet仍存在若干局限：当前主要优化相关性网络，对非线性关系的解析能力有待加强；随着数据规模扩大，布局算法与拓扑分析效率需持续提升；此外，生物网络分析领域普遍存在的标准化缺失问题（如阈值选择、零模型构建等）也亟待解决。未来发展方向包括：(1) 整合贝叶斯网络等新型推断方法；(2) 深化与生物知识库的融合；(3) 扩展单细胞组学数据支持；(4) 增加生态网络专用指标。通过持续优化与社区共建，MetaNet有望发展成为多组学网络分析的核心平台。\n","date":"2025-06-26T00:00:00Z","image":"/p/metanet-biorxiv/images/fig4_hu_795c2e261a855265.png","permalink":"/p/metanet-biorxiv/","title":"预印本｜MetaNet: a scalable and integrated tool for reproducible omics network analysis"},{"content":"Introduction 中介分析是一种统计方法，用于研究自变量(X)通过一个或多个中介变量(M)影响因变量(Y)的机制。简单来说，它帮助我们回答”X如何影响Y”而不仅仅是”X是否影响Y”的问题。例如，在教育研究中，我们可能想知道”教师教学水平(X)“是否通过”学生课堂参与度(M)“影响了”学生成绩(Y)“，这就是一个典型的中介分析问题。\n中介分析的核心在于识别和量化三种效应：\n直接效应：X对Y的直接影响 间接效应：X通过M对Y的影响 总效应：直接效应与间接效应之和 结构方程模型（Structural Equation Modeling，简称SEM）可以被视为中介分析的扩展和泛化，它允许更复杂的模型设定，包括多重中介、调节中介以及各种变量间的交互作用，它们后续能用到的可视化工具也类似。\nSEM是一种结合多元统计方法和数学模型的分析技术。它能够帮助研究者探究多个变量之间的关系和影响，包括直接和间接的影响。SEM 可以同时估计多个方程（即多元回归模型），并且允许变量间相互作用，同时还能考虑隐变量（latent variable）和测量误差等因素。\n中介分析 先看一个简单的中介分析示例，使用R语言中的mediation包来进行中介分析。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 # 安装并加载必要的包 library(mediation) # 示例数据 set.seed(123) n \u0026lt;- 200 X \u0026lt;- rnorm(n) M \u0026lt;- 0.5*X + rnorm(n) Y \u0026lt;- 0.3*X + 0.4*M + rnorm(n) data \u0026lt;- data.frame(X, M, Y) # 步骤1: 建立中介模型(M ~ X) model.m \u0026lt;- lm(M ~ X, data = data) # 步骤2: 建立结果模型(Y ~ X + M) model.y \u0026lt;- lm(Y ~ X + M, data = data) # 步骤3: 进行中介分析 med.sum \u0026lt;- mediate(model.m, model.y, treat = \u0026#34;X\u0026#34;, mediator = \u0026#34;M\u0026#34;, boot = TRUE, sims = 500) # 查看结果 summary(med.sum) ## ## Causal Mediation Analysis ## ## Nonparametric Bootstrap Confidence Intervals with the Percentile Method ## ## Estimate 95% CI Lower 95% CI Upper p-value ## ACME 0.1645 0.0997 0.25 \u0026lt;2e-16 *** ## ADE 0.2929 0.1067 0.46 \u0026lt;2e-16 *** ## Total Effect 0.4574 0.2682 0.62 \u0026lt;2e-16 *** ## Prop. Mediated 0.3596 0.2074 0.64 \u0026lt;2e-16 *** ## --- ## Signif. codes: 0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1 ## ## Sample Size Used: 200 ## ## ## Simulations: 500 1 2 # 绘制结果 plot(med.sum) ACME stands for average causal mediation effects.间接因果效应，表示X通过M对Y的效应大小 通过med.sum$d0和med.sum$d0.p可以获得ACME的效应和p值\nADE stands for average direct effects.直接效应，表示X直接对Y的作用大小 通过med.sum$z0和med.sum$z0.p可以获得ADE的效应和p值\nTotal Effect stands for the total effect (direct + indirect) of the IV on the DV. X对Y的直接和间接作用总和\nProp. Mediated describes the proportion of the effect of the IV on the DV that goes through the mediator. X通过M对Y的作用的比例\n中介效应的类型 互补型中介（Complementary Mediation） 定义：间接效应和直接效应都显著且方向一致（例如，均为正或均为负）。\n意义：中介变量部分解释了自变量与因变量之间的关系，并增强了总效应。\n竞争型中介（Competitive Mediation） 定义：间接效应和直接效应都显著，但方向相反（一个为正，一个为负）。\n意义：中介变量的解释部分抵消了直接效应，导致自变量与因变量之间的关系呈现混合效应。\n仅间接中介（Indirect-Only Mediation） 定义：间接效应显著，但直接效应不显著。\n意义：中介变量完全解释了自变量与因变量之间的关系，即完全中介。\n非中介效应的类型\n仅直接非中介（Direct-Only Non-Mediation） 定义：直接效应显著，但间接效应不显著。\n意义：中介变量在自变量与因变量之间未发挥作用，关系主要通过直接路径发生。\n无效非中介（No-Effect Non-Mediation） 定义：直接效应和间接效应均不显著。\n意义：自变量与因变量之间不存在关系，无论是否涉及中介变量。\n或者使用psych包可以进行中介分析并绘制简单的中介图。\n1 2 3 4 library(psych) m2=psych::mediate(Y ~ X + (M),data = data,n.iter = 500,plot = FALSE) psych::mediate.diagram(m2) 这里的\nc = the total effect of X on Y c = c’ + ab c’= the direct effect of X on Y after controlling for M; c’=c - ab ab= indirect effect of X on Y 生存数据中介分析 可以再看一个生存数据的中介分析示例，使用survival包和mediation包来进行中介分析。这里我们使用lung数据集作为示例。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 library(survival) library(dplyr) # 加载 lung 数据集 data(lung) # 数据预处理 dat \u0026lt;- lung %\u0026gt;% mutate(status = ifelse(status == 2, 1, 0), ph.ecog = ifelse(ph.ecog == 0, 0, 1), time = time/30) %\u0026gt;% dplyr::select(ph.ecog, wt.loss, time, status, age, sex) %\u0026gt;% drop_na() # head(dat) library(mediation) # 中介模型 mod_med \u0026lt;- lm(wt.loss ~ ph.ecog + age + sex, data = dat) # 结局模型 mod_out \u0026lt;- survreg(Surv(time, status) ~ wt.loss + ph.ecog + age + sex, dist = \u0026#34;weibull\u0026#34;, data = dat) # nonparametric bootstrap置信区间 set.seed(111) med_res1 \u0026lt;- mediate(model.m = mod_med, model.y = mod_out, sims = 1000, boot = TRUE, boot.ci.type = \u0026#34;perc\u0026#34;, treat = \u0026#34;ph.ecog\u0026#34;, mediator = \u0026#34;wt.loss\u0026#34;, outcome = \u0026#34;time\u0026#34;) summary(med_res1) # 结果总结 ## ## Causal Mediation Analysis ## ## Nonparametric Bootstrap Confidence Intervals with the Percentile Method ## ## Estimate 95% CI Lower 95% CI Upper p-value ## ACME (control) 0.3142 -0.5340 1.70 0.474 ## ACME (treated) 0.2087 -0.3880 1.01 0.474 ## ADE (control) -6.7308 -12.6789 -2.24 0.004 ** ## ADE (treated) -6.8363 -13.2424 -2.28 0.004 ** ## Total Effect -6.5220 -12.3459 -2.01 0.006 ** ## Prop. Mediated (control) -0.0482 -0.2847 0.12 0.480 ## Prop. Mediated (treated) -0.0320 -0.1939 0.09 0.480 ## ACME (average) 0.2615 -0.4739 1.37 0.474 ## ADE (average) -6.7835 -12.9447 -2.26 0.004 ** ## Prop. Mediated (average) -0.0401 -0.2341 0.10 0.480 ## --- ## Signif. codes: 0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1 ## ## Sample Size Used: 213 ## ## ## Simulations: 1000 1 plot(med_res1) 结果解释：主要关注以下指标的p值是否显著，及点估计和置信区间估计： ACME(average)，平均因果中介效应，p=0.474，表明中介效应不显著。 ADE(average)，平均直接效应，p=0.004，表明直接效应显著。 Prop. Mediated (average) ，平均中介比例。 Total Effect，总效应，p=0.006，表明总效应显著。 结论：ph.ecog 直接影响 status，而不是通过 wt.loss 间接影响（中介）。\n结构方程模型（SEM） SEM是一个广泛复杂的话题，这里我们只介绍简单的SEM模型示例，使用lavaan包来实现。更详细的SEM模型可以参考相关文献或教程。比如https://mp.weixin.qq.com/s/NEhoOlAau_jyxHPTf7H3ug这个讲的很详细。\nSEM是一个线性模型框架，它对具有潜变量（ latent variables）的同步回归方程进行建模。\n线性回归(linear regression)、多元回归(multivariate regression)、路径分析(path analysis)、验证因子分析(confirmatory factor analysis)和结构回归(structural regression)等模型可以被认为是 SEM 的特殊情况。\nSEM 中可能存在以下关系：\n从观察变量到观察变量（observed to observed variables）(γ，e.g., regression) 从潜变量到观测变量 （latent to observed variables） (λ, e.g., confirmatory factor analysis) 从潜变量到潜变量 （latent to latent variables）(γ，β，e.g., structural regression) 变量类型划分 观察变量(Observed Variable) 又称”显变量”(Manifest Variable)或”指标变量”(Indicator Variable) 实际测量得到的变量，存在于数据集中 示例：问卷项目得分、生理指标测量值等 潜变量(Latent Variable) 又称”构念”(Construct)或”因子”(Factor) 无法直接测量，需要通过观察变量间接反映 示例：满意度、焦虑程度、智力等抽象概念 因果关系\n外生变量(Exogenous Variable) 独立变量，不受模型中其他变量影响 可以是观察变量(x)或潜在变量(ξ) 在路径图中无指向它的箭头 内生变量(Endogenous Variable) 因变量，至少有一条因果路径指向它 可以是观察变量(y)或潜在变量(η) 在路径图中有指向它的箭头 测量模型(Measurement Model)\n描述潜在变量与观察变量之间的关系 包含以下要素： 指标(Indicator)：测量模型中的观察变量 因子(Factor)：由指标定义的潜在变量 因子载荷(Loading)：指标与因子间的关联强度 结构模型(Structural Model)\n描述变量(包括潜在变量)间的因果关系 主要元素： 回归路径：外生变量到内生变量的因果关系 方差/协方差：外生变量间的相关关系 lavaan包语法速查表 符号 含义 示例 说明 ~ 回归关系 y ~ x y对x的回归 =~ 潜在变量定义 f =~ q + r + s 定义f由q,r,s测量 ~~ 方差/协方差 x ~~ y x与y的协方差 ~1 截距/均值 x ~ 1 估计x的均值 1* 固定参数 f =~ 1*q 固定q的因子载荷为1 NA* 自由参数 f =~ NA*q 释放q的因子载荷 a* 参数标签 f =~ a*q 标记q的因子载荷为a，用于约束 模型设定示例 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 # 测量模型示例 measurement_model \u0026lt;- \u0026#39; # 潜在变量定义 f1 =~ q1 + q2 + q3 # f1由q1-q3测量 f2 =~ q4 + q5 + q6 # f2由q4-q6测量 # 固定第一个指标的载荷为1 f1 =~ 1*q1 f2 =~ 1*q4 # 估计指标残差方差 q1 ~~ q1 q2 ~~ q2 \u0026#39; # 结构模型示例 structural_model \u0026lt;- \u0026#39; # 回归关系 y ~ x1 + x2 # y对x1,x2的回归 f1 ~ f2 + x1 # f1对f2,x1的回归 # 协方差 x1 ~~ x2 # x1与x2的协方差 \u0026#39; # 完整SEM模型 full_model \u0026lt;- \u0026#39; # 测量模型部分 f1 =~ y1 + y2 + y3 f2 =~ y4 + y5 + y6 # 结构模型部分 f1 ~ f2 + x1 f2 ~ x1 + x2 # 残差相关 y1 ~~ y2 \u0026#39; 理解这些核心概念和语法是掌握SEM分析的基础。\nSEM测量中介效应 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 library(lavaan) # 定义模型 model \u0026lt;- \u0026#39; # 直接效应 Y ~ c*X # 中介路径 M ~ a*X Y ~ b*M # 间接效应(a*b) indirect := a*b # 总效应 total := c + (a*b) \u0026#39; # 拟合模型 fit \u0026lt;- sem(model, data = data,sample.nobs = 500) # 查看结果 summary(fit, standardized = TRUE, rsq = TRUE) ## lavaan 0.6.15 ended normally after 1 iteration ## ## Estimator ML ## Optimization method NLMINB ## Number of model parameters 5 ## ## Number of observations 200 ## ## Model Test User Model: ## ## Test statistic 0.000 ## Degrees of freedom 0 ## ## Parameter Estimates: ## ## Standard errors Standard ## Information Expected ## Information saturated (h1) model Structured ## ## Regressions: ## Estimate Std.Err z-value P(\u0026gt;|z|) Std.lv Std.all ## Y ~ ## X (c) 0.293 0.079 3.705 0.000 0.293 0.249 ## M ~ ## X (a) 0.471 0.075 6.307 0.000 0.471 0.407 ## Y ~ ## M (b) 0.349 0.068 5.107 0.000 0.349 0.343 ## ## Variances: ## Estimate Std.Err z-value P(\u0026gt;|z|) Std.lv Std.all ## .Y 0.923 0.092 10.000 0.000 0.923 0.751 ## .M 0.986 0.099 10.000 0.000 0.986 0.834 ## ## R-Square: ## Estimate ## Y 0.249 ## M 0.166 ## ## Defined Parameters: ## Estimate Std.Err z-value P(\u0026gt;|z|) Std.lv Std.all ## indirect 0.164 0.041 3.969 0.000 0.164 0.140 ## total 0.457 0.077 5.958 0.000 0.457 0.388 1 2 # 参数估计 parameterEstimates(fit) ## lhs op rhs label est se z pvalue ci.lower ci.upper ## 1 Y ~ X c 0.293 0.079 3.705 0 0.138 0.448 ## 2 M ~ X a 0.471 0.075 6.307 0 0.324 0.617 ## 3 Y ~ M b 0.349 0.068 5.107 0 0.215 0.483 ## 4 Y ~~ Y 0.923 0.092 10.000 0 0.742 1.104 ## 5 M ~~ M 0.986 0.099 10.000 0 0.793 1.179 ## 6 X ~~ X 0.885 0.000 NA NA 0.885 0.885 ## 7 indirect := a*b indirect 0.164 0.041 3.969 0 0.083 0.246 ## 8 total := c+(a*b) total 0.457 0.077 5.958 0 0.307 0.608 1 2 3 # 最后可以用`semMediation`包或者`semPlot`包来可视化SEM模型 #devtools::install_github(\u0026#34;cardiomoon/semMediation\u0026#34;) semMediation::mediationPlot(fit) https://zhuanlan.zhihu.com/p/53206137\n生物例子 在宏基因组微生物生态学中，研究者通常会测量样品中多个微生物群落的组成和它们所处的环境变量（如温度、pH值等）之间的关系。然而，这些微生物群落之间可能存在相互作用，如竞争、合作等，这些作用可能会影响到它们与环境之间的关系。在这种情况下，SEM可以用来建立微生物群落与环境变量之间的关系网络，同时考虑微生物群落之间的相互作用。\n例如，一项研究调查了植物根际微生物群落与土壤性质之间的关系。研究者测量了植物根际中多个微生物群落的组成，以及土壤中的一些物理化学性质，如有机质含量、pH值等。他们使用SEM来建立微生物群落与土壤性质之间的关系网络，并同时考虑微生物群落之间的相互作用。他们发现，微生物群落之间存在着复杂的相互作用，而这些相互作用会影响到微生物群落与土壤性质之间的关系，提高了对微生物群落与环境之间关系的理解。\n下面给出一个用R生成模拟数据并实现SEM的例子，假设我们研究一些微生物和它们生长环境之间的关系。其中，环境因子包括pH、温度、盐度，微生物包括细菌、真菌和古菌。\n首先，我们需要生成一些符合正态分布的随机数据作为我们的变量。具体代码如下：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 library(mvtnorm) set.seed(123) # 生成环境因子数据 n \u0026lt;- 1000 mu_env \u0026lt;- c(pH = 7, temp = 25, salinity = 3) sigma_env \u0026lt;- matrix(c(1, 0.8, 0.5, 0.8, 1, 0.3, 0.5, 0.3, 1), ncol = 3) env \u0026lt;- rmvnorm(n, mean = mu_env, sigma = sigma_env)%\u0026gt;%as.data.frame() # 生成微生物数据 mu_microbe \u0026lt;- c(bacteria = 20, fungi = 10, archaea = 5) sigma_microbe \u0026lt;- matrix(c(1, 0.5, 0.3, 0.5, 1, 0.2, 0.3, 0.2, 1), ncol = 3) microbe \u0026lt;- rmvnorm(n, mean = mu_microbe, sigma = sigma_microbe)%\u0026gt;%as.data.frame() # 将生成的数据合并为一个数据框 df \u0026lt;- data.frame(env, microbe) 接下来，我们使用sem函数实现SEM。具体代码如下：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 library(lavaan) model \u0026lt;- \u0026#39; # 定义测量模型 # bacteria =~ bacteria # fungi =~ fungi # archaea =~ archaea # 定义结构模型 bacteria ~ pH + temp fungi ~ temp + salinity archaea ~ pH + salinity bacteria ~~ fungi bacteria ~~ archaea fungi ~~ archaea \u0026#39; # 运行SEM fit \u0026lt;- sem(model, data = df) # 查看SEM结果 summary(fit) ## lavaan 0.6.15 ended normally after 22 iterations ## ## Estimator ML ## Optimization method NLMINB ## Number of model parameters 12 ## ## Number of observations 1000 ## ## Model Test User Model: ## ## Test statistic 3.024 ## Degrees of freedom 3 ## P-value (Chi-square) 0.388 ## ## Parameter Estimates: ## ## Standard errors Standard ## Information Expected ## Information saturated (h1) model Structured ## ## Regressions: ## Estimate Std.Err z-value P(\u0026gt;|z|) ## bacteria ~ ## pH -0.022 0.047 -0.463 0.643 ## temp 0.074 0.048 1.541 0.123 ## fungi ~ ## temp 0.019 0.033 0.574 0.566 ## salinity 0.024 0.029 0.828 0.408 ## archaea ~ ## pH 0.017 0.036 0.481 0.631 ## salinity 0.028 0.034 0.822 0.411 ## ## Covariances: ## Estimate Std.Err z-value P(\u0026gt;|z|) ## .bacteria ~~ ## .fungi 0.467 0.035 13.496 0.000 ## .archaea 0.295 0.032 9.221 0.000 ## .fungi ~~ ## .archaea 0.183 0.031 5.869 0.000 ## ## Variances: ## Estimate Std.Err z-value P(\u0026gt;|z|) ## .bacteria 0.990 0.044 22.361 0.000 ## .fungi 0.988 0.044 22.361 0.000 ## .archaea 0.948 0.042 22.361 0.000 最后，我们可以使用semPlot函数绘制SEM图形，以便更好地理解SEM模型的结构。具体代码如下：\n1 2 3 library(semPlot) semPaths(fit, what = \u0026#34;std\u0026#34;, nCharNodes = 10, sizeMan = 8, edge.label.cex = 1.1, curvePivot = TRUE, fade = FALSE) 1 semMediation::mediationPlot(fit) 运行上述代码后，我们就得到了一个可视化的SEM模型图，该模型描述了微生物和环境因子之间的关系。\nReferences https://mp.weixin.qq.com/s/NEhoOlAau_jyxHPTf7H3ug https://mp.weixin.qq.com/s/OLr9Xo-GoAAt0Tu8L-c93g https://mp.weixin.qq.com/s/UhcnqytZUmTHDcSh3mAaOQ ","date":"2025-06-13T00:00:00Z","image":"/p/sem/images/sem_model_hu_5e863a097cf938da.jpg","permalink":"/p/sem/","title":"中介分析与结构方程模型（SEM）学习"},{"content":"Introduction KEGG（Kyoto Encyclopedia of Genes and Genomes）是一个广泛使用的生物信息学数据库，用于研究基因组、代谢组、信号通路和生物化学反应等方面的信息。它提供了基因、蛋白质、代谢物和信号通路等生物分子的综合信息，帮助研究人员理解生物体内分子之间的相互作用和功能。\n之前的文章详细介绍了KEGG 数据库及API的基础使用。其中KEGG pathway是我们经常需要使用的功能之一，它提供了生物体内代谢通路和信号传导通路的详细信息。\n使用KEGG官网提供的绘图功能或者R包pathview可以绘制下面这种KEGG通路图，但这些方法通常只能处理单个通路，且绘图功能较为简单：\n为了更好地处理和可视化KEGG通路网络，我们尝试获取KEGG pathway的网络结构然后用MetaNet绘制，因为涉及到KEGG通路的一些函数我之前已经在ReporterScore包中实现了，所以我这次把通路网络的获取和绘图功能放在了ReporterScore包中，但背后调用的还是MetaNet包的绘图功能。\n软件主页：https://github.com/Asa12138/MetaNet 大家可以帮忙在github上点点star⭐️，谢谢🙏 详细英文版教程：https://bookdown.org/Asa12138/metanet_book 可以从 CRAN 安装稳定版：install.packages(\u0026quot;MetaNet\u0026quot;)\n最新的开发版本可以在 https://github.com/Asa12138/MetaNet 中找到：\n1 2 remotes::install_github(\u0026#34;Asa12138/MetaNet\u0026#34;, dependencies = T) remotes::install_github(\u0026#34;Asa12138/ReporterScore\u0026#34;, dependencies = T) ReporterScore+MetaNet 1 2 3 4 5 6 7 8 9 10 library(ReporterScore) library(MetaNet) tmp_dir \u0026lt;- tempdir() # 下载KEGG通路XML文件 pcutils::download2(\u0026#34;https://rest.kegg.jp/get/ko01521/kgml\u0026#34;, file.path(tmp_dir, \u0026#34;ko01521.xml\u0026#34;)) # 读取KEGG通路XML文件 path_net_c \u0026lt;- c_net_from_pathway_xml(file.path(tmp_dir, \u0026#34;ko01521.xml\u0026#34;)) # 绘制KEGG通路网络图 plot_pathway_net(path_net_c) 我们也可以使用update_pathway_xml_ls()函数来获取或更新所有的KEGG通路XML文件。这个函数会下载最新的KEGG通路XML文件到指定的目录。\n1 2 3 4 # org参数可以指定组织或物种，默认为NULL，表示获取所有通路 update_pathway_xml_ls(download_dir = \u0026#34;~/Documents/\u0026#34;,org = NULL) # 下载过一次之后，就可以用load_pathway_xml_ls获取KEGG通路 load_pathway_xml_ls()-\u0026gt;pathway_xml_ls 想要给节点加上注释，并换上不同颜色，大小，布局等参数也非常简单，与之前介绍的MetaNet包的c_net_plot绘图参数完全一致的，可以查看3.网络注释与操作，4.布局和可视化。\n1 2 3 4 5 6 7 8 9 10 11 12 # 调整一下布局 coors=get_v(path_net_c)[,c(\u0026#34;name\u0026#34;,\u0026#34;x\u0026#34;,\u0026#34;y\u0026#34;)] colnames(coors)=c(\u0026#34;name\u0026#34;,\u0026#34;X\u0026#34;,\u0026#34;Y\u0026#34;) coors=rescale_coors(as_coors(coors)) coors=transform_coors(coors,aspect_ratio = 0.6) # 调整纵横比 plot_pathway_net(path_net_c,coors=coors, label_cex=0.6, vertex.color=c(\u0026#34;#a6cee3\u0026#34;, \u0026#34;#78c679\u0026#34;), vertex.frame.width=0.2, arrow_size_cex=2,arrow_width_cex=2, edge.width=0.5) 添加注释文件，比如基因上调和下调信息。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 # 添加注释信息 anno_df=data.frame( name=V(path_net_c)$name, Group=sample(c(\u0026#34;Up\u0026#34;,\u0026#34;None\u0026#34;,\u0026#34;Down\u0026#34;),vcount(path_net_c),replace = TRUE) ) path_net_c=c_net_set(path_net_c,anno_df,vertex_class = \u0026#34;Group\u0026#34;) # \u0026#34;#FFFFFF00\u0026#34;是透明色 pal=setNames(c(\u0026#34;#92C5DE\u0026#34;,\u0026#34;#FFFFFF00\u0026#34;,\u0026#34;#D6604D\u0026#34;),c(\u0026#34;Down\u0026#34;,\u0026#34;None\u0026#34;,\u0026#34;Up\u0026#34;)) plot_pathway_net(path_net_c,coors=coors, label_cex=0.6, vertex.color=pal, vertex.frame.width=0.2,arrow_size_cex=2,arrow_width_cex=2, edge.width=0.5) 还可以使用MetaNet对网络进行各种操作筛选，比如我想获取某个基因的下游网络：\n1 get_v(path_net_c) 1 2 3 4 5 6 7 8 9 10 11 12 13 ## name _type type reaction graphics_name x y width height fgcolor ## 1 ko:K04357 from ortholog \u0026lt;NA\u0026gt; K04357 155 -247 46 17 #000000 ## 2 ko:K08774 from ortholog \u0026lt;NA\u0026gt; K08774 155 -271 46 17 #000000 ## 3 ko:K05460 from ortholog \u0026lt;NA\u0026gt; K05460 155 -530 46 17 #000000 ## bgcolor graphics_type coords xmin xmax ymin ymax orig.id pathway_id ## 1 #BFBFFF rectangle NA 132 178 -255.5 -238.5 32 ko01521 ## 2 #BFBFFF rectangle NA 132 178 -279.5 -262.5 20 ko01521 ## 3 #BFBFFF rectangle NA 132 178 -538.5 -521.5 75 ko01521 ## label size v_group shape v_class color Group ## 1 K04357 1 ortholog square None #fb9a99 None ## 2 K08774 1 ortholog square None #fb9a99 None ## 3 K05460 1 ortholog square Up #fdbf6f Up ## [ reached \u0026#39;max\u0026#39; / getOption(\u0026#34;max.print\u0026#34;) -- omitted 50 rows ] 1 2 3 c_net_neighbors(path_net_c, nodes = \u0026#34;ko:K04456\u0026#34;,order=2, mode = \u0026#34;out\u0026#34;) -\u0026gt; path_net_c2 plot_pathway_net(path_net_c2,vertex.color=pal) ggkegg 但目前MetaNet不支持一些巨大的代谢网络如ko01100，因为其xml文件不是标准网络信息，可以使用更强大的ggkegg包来绘制，代码稍微复杂一点：\nggkegg是一个基于ggplot2的KEGG通路绘图包，提供了更灵活的绘图功能和更美观的图形输出。它可以处理更复杂的KEGG通路数据，并支持多种自定义样式。\nhttps://github.com/noriakis/ggkegg\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 library(ggkegg) library(ggfx) library(igraph) library(tidygraph) library(dplyr) pathway(\u0026#34;ko01100\u0026#34;) |\u0026gt; process_line() |\u0026gt; highlight_module(module(\u0026#34;M00021\u0026#34;)) |\u0026gt; highlight_module(module(\u0026#34;M00338\u0026#34;)) |\u0026gt; ggraph(x=x, y=y) + geom_node_point(size=1, aes(color=I(fgcolor), filter=fgcolor!=\u0026#34;none\u0026#34; \u0026amp; type!=\u0026#34;line\u0026#34;)) + geom_edge_link0(width=0.1, aes(color=I(fgcolor), filter=type==\u0026#34;line\u0026#34;\u0026amp; fgcolor!=\u0026#34;none\u0026#34;)) + with_outer_glow( geom_edge_link0(width=1, aes(color=I(fgcolor), filter=(M00021 | M00338))), colour=\u0026#34;red\u0026#34;, expand=5 ) + with_outer_glow( geom_node_point(size=1.5, aes(color=I(fgcolor), filter=(M00021 | M00338))), colour=\u0026#34;red\u0026#34;, expand=5 ) + geom_node_text(size=2, aes(x=x, y=y, label=graphics_name, filter=name==\u0026#34;path:ko00270\u0026#34;), repel=TRUE, family=\u0026#34;sans\u0026#34;, bg.colour=\u0026#34;white\u0026#34;) + theme_void() References https://github.com/noriakis/ggkegg https://github.com/datapplab/pathview ","date":"2025-06-12T00:00:00Z","image":"/p/metanet-kegg/index.en_files/figure-html/unnamed-chunk-5-1_hu_77cc3541fb288779.png","permalink":"/p/metanet-kegg/","title":"使用MetaNet绘制KEGG通路网络图"},{"content":"采样地图可以帮助我们直观地展示研究样本的地理分布和采样点信息。我之前也写过一篇R绘制优美的地图的推文，详细介绍了地图文件，坐标参考系统，绘制地图，注释地图，RasterLayer等内容，但对于一些简单的采样地图绘制，可能不需要那么复杂的步骤。\n本文将介绍如何使用pcutils包中的sample_map函数快速绘制采样地图。\n函数介绍 该函数用于绘制 空间采样点分布图，支持三种可视化模式：\n静态基础地图（mode=1）：基于 ggplot2 + 内置世界地图 自定义地理边界（mode=2）：使用用户提供的GeoJSON/SHP文件 交互式地图（mode=3）：基于 leaflet 的动态地图 参数详解\n1. 数据输入\n参数 类型 必填 说明 metadata data.frame 是 必须包含 Longitude 和 Latitude 列（WGS84坐标） group 字符 否 指定分组变量（控制点的颜色映射） label 字符 否 指定点的标签文本列 2. 可视化模式控制\n参数 选项 默认 说明 mode 1/2/3 1 1=静态图, 2=自定义边界, 3=交互地图 map_provider 字符 \u0026ldquo;OpenStreetMap\u0026rdquo; 仅mode=3有效，可选 providers$Esri.WorldTerrain 等 3. 地理数据处理\n参数 类型 默认 说明 shp_file 字符 NULL mode=2 时指定地理边界文件路径 crs 整数 4326 坐标参考系统（EPSG代码），4326=WGS84 xlim/ylim 数值向量 NULL 设置地图显示范围（如 xlim=c(75,135)） 4. 图形元素定制\n参数 类型 说明 point_params list 传递给 geom_point() 的参数（如 list(size=3, shape=17)） map_params list 地图边界样式（mode=1控制geom_polygon，mode=2控制geom_sf） leaflet_pal 函数 mode=3专用，如 leaflet::colorFactor(\u0026quot;Set1\u0026quot;, domain=metadata$group) 5. 地图装饰元素\n参数 类型 默认 说明 add_scale 逻辑 TRUE 是否添加比例尺 scale_params list 空 控制比例尺样式（位置、单位等） add_north_arrow 逻辑 TRUE 是否添加指北针 north_arrow_params list 空 控制指北针样式 以下是一些示例代码，展示如何使用sample_map函数绘制采样地图：\n自带地图（粗糙） 1 2 3 4 5 6 library(pcutils) data(otutab) anno_df \u0026lt;- metadata[, c(\u0026#34;Id\u0026#34;, \u0026#34;long\u0026#34;, \u0026#34;lat\u0026#34;, \u0026#34;Group\u0026#34;)] colnames(anno_df) \u0026lt;- c(\u0026#34;Id\u0026#34;, \u0026#34;Longitude\u0026#34;, \u0026#34;Latitude\u0026#34;, \u0026#34;Group\u0026#34;) head(anno_df) 1 2 3 4 5 6 7 ## Id Longitude Latitude Group ## NS1 NS1 103.4767 26.94422 NS ## NS2 NS2 109.6196 29.08733 NS ## NS3 NS3 104.0361 28.25164 NS ## NS4 NS4 106.8651 33.82415 NS ## NS5 NS5 105.4571 33.51011 NS ## NS6 NS6 102.7832 31.86864 NS 使用mode=1参数可以绘制一个简单的静态地图，默认使用内置的世界地图：\n1 sample_map(anno_df, mode = 1, group = \u0026#34;Group\u0026#34;) 使用xlim和ylim参数可以设置地图的显示范围：\n1 sample_map(anno_df, mode = 1, group = \u0026#34;Group\u0026#34;, xlim = c(90, 135), ylim = c(20, 50)) 自定义地图文件（精细） 自己找一个合适的GeoJSON或Shapefile文件，放在本地，然后指定路径。\n网上能够下载到中国地图的地方很多，比如 GeoJSON.cn，yezongyang/china-geojson等等，而世界上其他区域，不同精度（洲，国家，城市，县\u0026hellip;）的地图数据就需要自己按照需求寻找一下，如GeoJSON Maps of the globe (ash.ms)，georgique/world-geojson，datasets/geo-countries等等。\n使用mode=2参数可以绘制自定义地理边界的地图，指定shp_file参数为GeoJSON或Shapefile文件路径：\n1 2 3 4 5 6 7 sample_map(anno_df, mode = 2, group = \u0026#34;Group\u0026#34;, shp_file = \u0026#34;~/database/china.json\u0026#34;, label = \u0026#34;Id\u0026#34;,xlim = c(90, 135), ylim = c(20, 50), point_params = list(size=4), label_params = list(check_overlap = F,size=1.5))+ theme_bw()+ scale_fill_pc() leaflet交互式地图 Leaflet是一个开源的JavaScript库，用于创建交互式地图。R中的Leaflet包提供了一个轻量级的接口，允许在R中创建交互式地图。Leaflet包提供了许多基本的地图操作功能，例如缩放、平移和旋转，同时还允许添加标记、文本注释、多边形、线条和点。\n1 sample_map(anno_df, mode = 3, group = \u0026#34;Group\u0026#34;) Leaflet包支持多种地图提供商（如OpenStreetMap、Esri、Stamen等），可以通过leaflet::providers函数查看可用的地图提供商列表。\n也可以在这个网站预览列表里的各种效果https://leaflet-extras.github.io/leaflet-providers/preview/index.html。\n1 sample_map(anno_df, mode = 3, group = \u0026#34;Group\u0026#34;,map_provider = \u0026#34;USGS.USImagery\u0026#34;) ","date":"2025-05-26T00:00:00Z","image":"/p/sample-map/images/leaf2_hu_8d4d18b9f664a059.png","permalink":"/p/sample-map/","title":"快速绘制采样地图"},{"content":"Introduction 在生物信息学研究中，从NCBI下载基因组数据是一项基础的任务。无论是进行基因组比较分析、注释研究还是构建本地数据库，高效获取目标基因组数据都是第一步。\n目前已有一些成熟的工具可以实现这一需求，例如：\nncbi-genome-download：一个功能强大的Python工具 NCBI Datasets command-line tools (CLI)：NCBI官方提供的命令行工具 然而，在实际使用中，这些工具经常会遇到网络连接不稳定、下载中断等问题。这里介绍一下自己写的一个函数，可以完成批量根据genome accession id下载相关数据的任务，基本不会有网络问题，只要网页能打开NCBI应该就能下。然后也介绍一下上述已有的轮子，他们的功能还是非常多且强大的。\ndownload_ncbi_genome_file 这是一个很简单的R函数，具体实现如下：\nNCBI的基因组Accession ID具有特定格式，例如：GCF_001036115.1_ASM103611v1，GCA_000005845.2_ASM584v2\n其中：\nGCF开头表示RefSeq数据库 GCA开头表示GenBank数据库 中间9位数字是唯一标识符 .1表示版本号 后缀ASM103611v1是组装名称 文件存储结构与下载原理：\nNCBI的FTP服务器采用分层目录结构存储基因组数据。例如，GCF_001036115.1对应的完整路径为： https://ftp.ncbi.nlm.nih.gov/genomes/all/GCF/001/036/115/GCF_001036115.1_ASM103611v1/\n该目录下通常包含多种文件类型：\ngenomic.fna：基因组FASTA文件； genomic.gff：GFF格式注释文件； genomic.gtf：GTF格式注释文件； genomic.gbff：GenBank格式文件\n实现逻辑：\n从ID（如GCF_001036115.1）解析出FTP基础路径 通过网页爬虫获取完整ID（如GCF_001036115.1_ASM103611v1） 拼接出目标文件的完整URL 使用wget或curl等工具下载文件 使用示例：\n该函数已集成到pcutils R包中，使用非常简便。\n1 2 3 4 5 6 7 8 9 10 11 12 13 library(pcutils) # 下载基因组FASTA文件（可使用简写ID） download_ncbi_genome_file(\u0026#34;GCF_001036115.1\u0026#34;, out_dir = \u0026#34;downloads\u0026#34;, type = \u0026#34;fna\u0026#34;) # 下载GFF注释文件（也可使用完整ID） download_ncbi_genome_file(\u0026#34;GCF_001036115.1_ASM103611v1\u0026#34;, out_dir = \u0026#34;downloads\u0026#34;, type = \u0026#34;gff\u0026#34;) # 批量下载示例 genome_id_list \u0026lt;- c(\u0026#34;GCF_001036115.1\u0026#34;, \u0026#34;GCA_000005845.2\u0026#34;) for (id in genome_id_list) { download_ncbi_genome_file(id, out_dir = \u0026#34;downloads\u0026#34;, type = \u0026#34;fna\u0026#34;) } ncbi-genome-download 软件主页：https://github.com/kblin/ncbi-genome-download\nncbi-genome-download 是一个功能强大的Python命令行工具，专门用于从NCBI FTP服务器批量下载基因组数据。它支持：\n多种生物分类（细菌、真菌、病毒等） RefSeq和GenBank两大数据库 多种文件格式下载 灵活的筛选条件 安装方法 1 2 3 4 5 6 7 # 使用pip安装（推荐） pip install ncbi-genome-download # 或者从源码安装 git clone https://github.com/kblin/ncbi-genome-download.git cd ncbi-genome-download python setup.py install 1 ncbi-genome-download [选项] \u0026lt;分类组\u0026gt; 常用参数详解\n参数 说明 示例 -h, --help 显示帮助信息 - -s, --section 指定数据库（默认为refseq） -s genbank -F, --formats 指定下载格式（逗号分隔） -F fasta,gff -l, --assembly-levels 按组装级别筛选 -l complete -g, --genera 按属名筛选（逗号分隔） -g \u0026quot;Escherichia,Salmonella\u0026quot; -T, --taxids 按分类ID筛选 -T 562 -o, --output-folder 指定输出目录 -o my_genomes -p, --parallel 并行下载数 -p 4 -v, --verbose 显示详细日志 - 实用示例 1 2 3 4 5 6 7 8 9 10 11 # 示例1：下载所有完整组装的细菌基因组（RefSeq） ncbi-genome-download -l complete bacteria # 示例2：下载大肠杆菌和沙门氏菌的基因组（GenBank） ncbi-genome-download -s genbank -g \u0026#34;Escherichia,Salmonella\u0026#34; bacteria # 示例3：下载特定分类ID的基因组（FASTA+GFF格式） ncbi-genome-download -T 562 -F fasta,gff -o ecoli_genomes bacteria # 示例4：并行下载4个真菌基因组 ncbi-genome-download -p 4 fungi NCBI Datasets command-line tools NCBI Datasets是NCBI官方推出的新一代数据获取工具，特点包括：\n官方维护，数据更新及时 支持REST API和命令行两种方式 可下载基因组、基因、转录本、蛋白等多类数据 提供丰富的元数据（JSON格式） 安装 方法一：Conda安装（推荐）\n1 2 conda create -n ncbi_datasets -c conda-forge ncbi-datasets-cli conda activate ncbi_datasets 方法二：直接下载二进制文件\n1 2 3 4 5 6 7 8 9 10 # Linux curl -o datasets https://ftp.ncbi.nlm.nih.gov/pub/datasets/command-line/LATEST/linux-amd64/datasets chmod +x datasets # macOS (Intel) curl -o datasets https://ftp.ncbi.nlm.nih.gov/pub/datasets/command-line/LATEST/mac-amd64/datasets chmod +x datasets # Windows (PowerShell) Invoke-WebRequest -Uri \u0026#34;https://ftp.ncbi.nlm.nih.gov/pub/datasets/command-line/LATEST/win64/datasets.exe\u0026#34; -OutFile \u0026#34;datasets.exe\u0026#34; 核心命令结构\n1 datasets [全局选项] \u0026lt;命令\u0026gt; [命令选项] 主要子命令 命令 功能 download 下载数据包 summary 获取数据摘要 reformat 格式转换 help 帮助信息 基因组下载详解\n1 datasets download genome [选项] \u0026lt;参数\u0026gt; 常用选项\n选项 说明 示例 accession 按accession下载 accession GCF_000001405.40 taxon 按分类单元下载 taxon \u0026quot;Escherichia coli\u0026quot; reference 仅下载参考基因组 --reference filename 指定输出文件名 --filename ecoli.zip include 指定包含的数据类型 --include genome,gff3 dehydrated 仅下载元数据 --dehydrated 实用示例 1 2 3 4 5 6 7 8 9 10 11 # 示例1：下载单个基因组（包含所有文件） datasets download genome accession GCF_000005845.2 --filename ecoli_k12.zip # 示例2：下载大肠杆菌所有参考基因组 datasets download genome taxon \u0026#34;Escherichia coli\u0026#34; --reference --filename all_ecoli_refs.zip # 示例3：自定义下载内容（基因组+注释） datasets download genome accession GCF_000005845.2 --include genome,gff3,protein --filename ecoli_k12_essentials.zip # 示例4：获取数据摘要（不下实际文件） datasets summary genome taxon \u0026#34;Escherichia coli\u0026#34; --reference 数据处理流程\n1 2 3 4 5 6 7 8 # 解压下载包 unzip ecoli.zip # 查看内容 ls ncbi_dataset/data/ # 转换格式（如GBFF转FASTA） datasets reformat gbff --inputfile genomic.gbff --outputfile cds.fasta --fasta 高级应用\n1 2 3 4 5 6 7 8 # 结合jq处理JSON元数据 datasets summary genome accession GCF_000005845.2 --json | jq \u0026#39;.assemblies[0].assembly.assembly_name\u0026#39; # 批量下载脚本示例 accessions=(\u0026#34;GCF_000005845.2\u0026#34; \u0026#34;GCF_000006945.2\u0026#34; \u0026#34;GCF_000007445.1\u0026#34;) for acc in \u0026#34;${accessions[@]}\u0026#34;; do datasets download genome accession \u0026#34;$acc\u0026#34; --filename \u0026#34;${acc}.zip\u0026#34; done ","date":"2025-05-26T00:00:00Z","image":"/p/ncbi-genome/images/datasets_schema_taxonomy.svg","permalink":"/p/ncbi-genome/","title":"批量下载NCBI genome相关数据"},{"content":"Introduction MetaNet是一个用于组学网络分析的R包，提供了多种功能，包括网络构建、可视化、比较和稳定性分析等。\n之前发布的推文中，有多位同学提到如何进行网络的比较，我也根据他们的一些建议改进了MetaNet的一些函数。 本文将介绍如何使用MetaNet进行网络比较，并展示一些示例代码和结果。\n软件主页：https://github.com/Asa12138/MetaNet 大家可以帮忙在github上点点star⭐️，谢谢🙏 详细英文版教程：https://bookdown.org/Asa12138/metanet_book/ 可以从 CRAN 安装稳定版：install.packages(\u0026quot;MetaNet\u0026quot;)，本文请使用最新的开发版本。\n最新的开发版本可以在 https://github.com/Asa12138/MetaNet 中找到：\n1 remotes::install_github(\u0026#34;Asa12138/MetaNet\u0026#34;, dependencies = T) 网络间运算 多个网络之间的比较和运算操作对组学数据分析很重要，例如，比较不同组别网络之间的差异部分，或者是探究动态网络变化中的核心稳定子网络。为了方便比较，MetaNet提供了c_net_union、c_net_intersect、c_net_difference等函数来计算网络的并集、交集和差集。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 library(MetaNet) library(igraph) set.seed(123) g1 \u0026lt;- make_graph(\u0026#34;Icosahedron\u0026#34;) V(g1)$color \u0026lt;- \u0026#34;#4DAF4A77\u0026#34; E(g1)$color \u0026lt;- \u0026#34;#4DAF4A77\u0026#34; g1=as.metanet(g1) g2 \u0026lt;- make_graph(\u0026#34;Octahedron\u0026#34;) V(g2)$name=as.character(9:14) V(g2)$color \u0026lt;- \u0026#34;#984EA366\u0026#34; # 紫色 E(g2)$color \u0026lt;- \u0026#34;#984EA366\u0026#34; g2=as.metanet(g2) # 执行操作 g_union \u0026lt;- c_net_union(g1, g2) E(g_union)$color\u0026lt;-\u0026#34;orange\u0026#34; g_inter \u0026lt;- c_net_intersect(g1, g2) g_diff \u0026lt;- c_net_difference(g1, g2) par_ls=list(main = \u0026#34;\u0026#34;,legend = F,vertex_size_range = c(20,20)) par(mfrow = c(2, 3)) c_net_plot(g1, params_list = par_ls) c_net_plot(g2, params_list = par_ls) c_net_plot(g_union, params_list = par_ls) c_net_plot(g_inter , params_list = par_ls) c_net_plot(g_diff, params_list = par_ls) c_net_compare 基于上述的网络运算，MetaNet提供了c_net_compare函数来比较两个网络的差异部分。该函数可以计算两个网络之间的并集、交集、网络拓扑指标以及计算的网络相似性，并返回一个包含这些信息的列表。\n1 2 3 4 5 6 7 8 set.seed(12) co_net_p1=c_net_filter(co_net,name%in%sample(V(co_net)$name,300)) co_net_p2=c_net_filter(co_net,name%in%sample(V(co_net)$name,300)) c_net_compare(co_net_p1,co_net_p2)-\u0026gt;c_net_comp # 展示网络拓扑指标 c_net_comp$net_par_df 1 2 3 4 5 6 7 8 9 10 11 12 13 ## g1 g2 g_union g_inter ## Node_number 300.000000000 300.000000000 392.0000000 208.000000000 ## Edge_number 334.000000000 321.000000000 499.0000000 156.000000000 ## Edge_density 0.007447046 0.007157191 0.0065113 0.007246377 ## Negative_percentage 0.443113772 0.389408100 0.4128257 0.429487179 ## Average_path_length 6.801472290 6.964863184 7.3484195 5.549893086 ## Global_efficiency 0.088800074 0.067651256 0.1044344 0.033600618 ## Average_degree 2.226666667 2.140000000 2.5459184 1.500000000 ## Average_weighted_degree 0.787061535 0.755481803 0.8992606 0.530061699 ## Diameter 18.000000000 18.000000000 19.0000000 13.000000000 ## Clustering_coefficient 0.330228620 0.311132255 0.2922078 0.337595908 ## Centralized_betweenness 0.127059002 0.074659531 0.1184792 0.049258854 ## Natural_connectivity 3.441388267 2.895183227 4.3359822 1.643829036 直接plot一下，结果图会将两个网络中不同的节点和边变成灰色，相当于共有节点和边高亮出来，帮助我们更好地看见网络的共有或差异部分。\n1 plot(c_net_comp) 网络相似性计算了三种，一个是基于共有节点的jaccard相似性，一个是基于共有边的jaccard相似性，还有一个是基于网络邻接矩阵的相似性。\n1 c_net_comp$net_similarity 1 2 ## node_jaccard edge_jaccard adjacency_similarity ## 0.5306122 0.3126253 0.9331847 邻接矩阵相似性计算的实现代码如下：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 adjacency_similarity \u0026lt;- function(g1, g2, method = \u0026#34;frobenius\u0026#34;) { if(!is_metanet(g1)) g1 \u0026lt;- as.metanet(g1) if(!is_metanet(g2)) g2 \u0026lt;- as.metanet(g2) # 获取邻接矩阵 adj1 \u0026lt;- as.matrix(igraph::as_adjacency_matrix(g1)) adj2 \u0026lt;- as.matrix(igraph::as_adjacency_matrix(g2)) # 统一节点集合 all_nodes \u0026lt;- union(rownames(adj1), rownames(adj2)) # 初始化全零矩阵 adj1_fixed \u0026lt;- matrix(0, nrow = length(all_nodes), ncol = length(all_nodes), dimnames = list(all_nodes, all_nodes)) adj2_fixed \u0026lt;- matrix(0, nrow = length(all_nodes), ncol = length(all_nodes), dimnames = list(all_nodes, all_nodes)) # 填充已知边 adj1_fixed[rownames(adj1), colnames(adj1)] \u0026lt;- adj1 adj2_fixed[rownames(adj2), colnames(adj2)] \u0026lt;- adj2 # 计算相似性 if (method == \u0026#34;frobenius\u0026#34;) { diff_norm \u0026lt;- norm(adj1_fixed - adj2_fixed, \u0026#34;F\u0026#34;) max_norm \u0026lt;- sqrt(nrow(adj1_fixed) * ncol(adj2_fixed)) similarity \u0026lt;- 1 - diff_norm / max_norm } else if (method == \u0026#34;cosine\u0026#34;) { similarity \u0026lt;- sum(adj1_fixed * adj2_fixed) / (norm(adj1_fixed, \u0026#34;F\u0026#34;) * norm(adj2_fixed, \u0026#34;F\u0026#34;)) } else { stop(\u0026#34;Method must be \u0026#39;frobenius\u0026#39; or \u0026#39;cosine\u0026#39;.\u0026#34;) } return(similarity) } 我们还可以使用plot_net_degree函数来绘制网络的度分布图，帮助更好地理解网络的结构特征，下面这两个随机取出来的子网络的度分布非常类似。\n1 plot_net_degree(list(co_net_p1,co_net_p2)) c_net_highlight 我们也可以自行调用以下这些函数：\nc_net_neighbors函数可以获取指定节点的邻居节点，\nc_net_highlight函数可以高亮显示网络中指定的节点和边，方便用户进行网络比较和分析。\nplot_multi_nets函数可以将多个网络图并排显示，便于展示。\n1 2 3 4 5 6 7 8 9 10 11 nodes \u0026lt;- c(\u0026#34;s__Kribbella_catacumbae\u0026#34;, \u0026#34;s__Verrucosispora_andamanensis\u0026#34;) nodes \u0026lt;- V(c_net_neighbors(co_net, nodes, order = 2))$name g_hl \u0026lt;- c_net_highlight(co_net, nodes = nodes) get_e(co_net) %\u0026gt;% head(40) -\u0026gt; hl_edges g_hl2 \u0026lt;- c_net_highlight(co_net, edges = hl_edges[, 2:3]) g_hl3 \u0026lt;- c_net_highlight(co_net, nodes = nodes, edges = hl_edges[, 2:3]) plot_multi_nets( list(g_hl, g_hl2, g_hl3),nrow = 1,multi_params_list = list(list(legend=F)) ) ","date":"2025-05-23T00:00:00Z","image":"/p/metanet-comparison/index.en_files/figure-html/unnamed-chunk-4-1_hu_c6393b8d49ffd7f.png","permalink":"/p/metanet-comparison/","title":"使用MetaNet进行网络比较"},{"content":"MetaNet默认使用的是igraph的绘图系统，其中自带的节点形状是非常有限的，只有circle、square、csquare、rectangle、crectangle、vrectangle、pie、none这几种形状，MetaNet在此基础上添加了更多常用形状，并且可以根据本文方法添加自定义形状。\n软件主页：https://github.com/Asa12138/MetaNet 大家可以帮忙在github上点点star⭐️，谢谢🙏 详细英文版教程：https://bookdown.org/Asa12138/metanet_book 可以从 CRAN 安装稳定版：install.packages(\u0026quot;MetaNet\u0026quot;)\n最新的开发版本可以在 https://github.com/Asa12138/MetaNet 中找到：\n1 remotes::install_github(\u0026#34;Asa12138/MetaNet\u0026#34;, dependencies = T) igraph节点形状 1 2 3 4 5 6 7 8 9 10 11 12 library(igraph) # all vertex shapes, minus \u0026#34;raster\u0026#34;, that might not be available # 默认只有以下这些 shapes \u0026lt;- c(\u0026#34;circle\u0026#34;,\u0026#34;crectangle\u0026#34;,\u0026#34;csquare\u0026#34;,\u0026#34;none\u0026#34;,\u0026#34;pie\u0026#34;,\u0026#34;raster\u0026#34;,\u0026#34;rectangle\u0026#34;,\u0026#34;sphere\u0026#34;,\u0026#34;square\u0026#34;,\u0026#34;vrectangle\u0026#34;) g \u0026lt;- make_ring(length(shapes)) set.seed(42) plot(g, vertex.shape = shapes, vertex.label = shapes, vertex.label.dist = 1, vertex.size = 15, vertex.size2 = 15, vertex.pie = lapply(shapes, function(x) if (x == \u0026#34;pie\u0026#34;) 2:6 else 0), vertex.pie.color = list(heat.colors(5)) ) 可以看到csquare、rectangle、crectangle、vrectangle等形状都是矩形的变种，主要是线的连接方式不同，有时候是难以区分的。\nsphere是一个三维的球体，还是很好看的，可以模拟STRING 数据库的节点形状。\n1 2 3 4 g\u0026lt;-make_graph(\u0026#34;Zachary\u0026#34;) plot(g, vertex.shape = \u0026#34;sphere\u0026#34;, vertex.label = NA, vertex.size = 18, vertex.color= pcutils::get_cols(4) ) MetaNet节点形状 MetaNet在igraph的基础上添加了更多的形状，主要是diamond、triangle1、triangle2、star、polygon等形状。\nMetaNet的形状默认是跟v_group变量绑定的（查看之前的推文 3.网络注释与操作），所以当设定了多个大分组时，需要一些易于区分的形状来区分不同的组。\n默认的形状分配是c(\u0026ldquo;circle\u0026rdquo;,\u0026ldquo;square\u0026rdquo;,\u0026ldquo;diamond\u0026rdquo;,\u0026ldquo;triangle1\u0026rdquo;,\u0026ldquo;triangle2\u0026rdquo;)\n1 2 3 4 5 6 library(MetaNet) # 给一些v_group V(g)$v_group \u0026lt;- sample(paste0(\u0026#34;Group\u0026#34;,1:5), vcount(g), replace = TRUE) V(g)$v_class \u0026lt;- sample(letters[1:3], vcount(g), replace = TRUE) as.metanet(g)-\u0026gt;g2 c_net_plot(g2,vertex.color= pcutils::get_cols(4)) 也可以指定star、ploygon等形状。\n1 2 3 c_net_plot(g2,vertex.color= pcutils::get_cols(4), vertex.shape=c(\u0026#34;star\u0026#34;,\u0026#34;polygon\u0026#34;),vertex.norays=5, legend = F) `star`、`ploygon`两种形状可以指定边数，vertex.norays参数可以指定边数，默认是5角星和5边形。 1 2 3 c_net_plot(g2,vertex.color= pcutils::get_cols(4), vertex.shape=c(\u0026#34;star\u0026#34;,\u0026#34;polygon\u0026#34;), vertex.norays=sample(4:7,vcount(g2), replace = TRUE),legend = F) 添加自定义形状 add_shape 可用于向igraph/MetaNet添加新的顶点形状，提供新形状的剪切和打印功能即可。也可以在参数中列出剪裁和/或绘图函数可以使用的绘图/顶点/边参数。\n拿上述的star做一个例子，构建以下add_metanet_shape_star函数，并运行后，就可以添加上述的star形状了，并且支持color，size，frame.color等参数的修改。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 add_metanet_shape_star \u0026lt;- function() { mystar \u0026lt;- function(coords, v = NULL, params) { vertex.color \u0026lt;- params(\u0026#34;vertex\u0026#34;, \u0026#34;color\u0026#34;) if (length(vertex.color) != 1 \u0026amp;\u0026amp; !is.null(v)) { vertex.color \u0026lt;- vertex.color[v] } vertex.frame.color \u0026lt;- params(\u0026#34;vertex\u0026#34;, \u0026#34;frame.color\u0026#34;) if (length(vertex.frame.color) != 1 \u0026amp;\u0026amp; !is.null(v)) { vertex.frame.color \u0026lt;- vertex.frame.color[v] } vertex.frame.width \u0026lt;- params(\u0026#34;vertex\u0026#34;, \u0026#34;frame.width\u0026#34;) if (length(vertex.frame.width) != 1 \u0026amp;\u0026amp; !is.null(v)) { vertex.frame.width \u0026lt;- vertex.frame.width[v] } vertex.size \u0026lt;- 1 / 150 * params(\u0026#34;vertex\u0026#34;, \u0026#34;size\u0026#34;) if (length(vertex.size) != 1 \u0026amp;\u0026amp; !is.null(v)) { vertex.size \u0026lt;- vertex.size[v] } norays \u0026lt;- params(\u0026#34;vertex\u0026#34;, \u0026#34;norays\u0026#34;) if (is.null(norays)) norays=5 if (length(norays) != 1 \u0026amp;\u0026amp; !is.null(v)) { norays \u0026lt;- norays[v] } # 处理边框宽度和颜色 vertex.frame.color[vertex.frame.width \u0026lt;= 0] \u0026lt;- NA vertex.frame.width[vertex.frame.width \u0026lt;= 0] \u0026lt;- 1 # 避免宽度为0 mapply(coords[, 1], coords[, 2], vertex.color, vertex.frame.color, vertex.size, vertex.frame.width, norays, FUN = function(x, y, bg, fg, size, lwd, nor) { symbols( x = x, y = y, bg = bg, fg = fg, lwd = lwd, stars = matrix(c(size, size / 2), nrow = 1, ncol = nor * 2), add = TRUE, inches = FALSE ) } ) } igraph::add_shape(\u0026#34;star\u0026#34;, clip = igraph::shape_noclip, plot = mystar) } add_metanet_shape_star() 我们当然也可以绘制各种奇怪的多边形：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 new_polygon \u0026lt;- function(coords, v = NULL, params) { vertex.color \u0026lt;- params(\u0026#34;vertex\u0026#34;, \u0026#34;color\u0026#34;) if (length(vertex.color) != 1 \u0026amp;\u0026amp; !is.null(v)) { vertex.color \u0026lt;- vertex.color[v] } vertex.frame.color \u0026lt;- params(\u0026#34;vertex\u0026#34;, \u0026#34;frame.color\u0026#34;) if (length(vertex.frame.color) != 1 \u0026amp;\u0026amp; !is.null(v)) { vertex.frame.color \u0026lt;- vertex.frame.color[v] } vertex.frame.width \u0026lt;- params(\u0026#34;vertex\u0026#34;, \u0026#34;frame.width\u0026#34;) if (length(vertex.frame.width) != 1 \u0026amp;\u0026amp; !is.null(v)) { vertex.frame.width \u0026lt;- vertex.frame.width[v] } vertex.size \u0026lt;- 1 / 200 * params(\u0026#34;vertex\u0026#34;, \u0026#34;size\u0026#34;) if (length(vertex.size) != 1 \u0026amp;\u0026amp; !is.null(v)) { vertex.size \u0026lt;- vertex.size[v] } norays \u0026lt;- params(\u0026#34;vertex\u0026#34;, \u0026#34;norays\u0026#34;) if (is.null(norays)) norays=5 if (length(norays) != 1 \u0026amp;\u0026amp; !is.null(v)) { norays \u0026lt;- norays[v] } weird_polygon_coords \u0026lt;- function(x, y, size) { theta \u0026lt;- seq(0, 2 * pi, length.out = 7)[-7] # 6个顶点 # 每个顶点的半径随机变化（size 的 0.5~1.5 倍） random_size \u0026lt;- size * runif(6, min = 0.5, max = 1.5) x_coords \u0026lt;- x + random_size * cos(theta) y_coords \u0026lt;- y + random_size * sin(theta) list(x = x_coords, y = y_coords) } # 处理边框宽度和颜色 vertex.frame.color[vertex.frame.width \u0026lt;= 0] \u0026lt;- NA vertex.frame.width[vertex.frame.width \u0026lt;= 0] \u0026lt;- 1 mapply(coords[, 1], coords[, 2], vertex.color, vertex.frame.color, vertex.size, vertex.frame.width, FUN = function(x, y, bg, fg, size, lwd) { coords \u0026lt;- weird_polygon_coords(x, y, size) polygon(coords$x, coords$y, col = bg, border = fg, lwd = lwd) } ) } igraph::add_shape(\u0026#34;new_polygon\u0026#34;, clip = igraph::shape_noclip, plot = new_polygon) 然后用用我们新定义的随机奇怪多边形来绘制网络图：\n1 2 3 c_net_plot(g2,vertex.color= pcutils::get_cols(4), vertex.shape=c(\u0026#34;new_polygon\u0026#34;), legend = F) 注意，最好是用symbols()或者polygon()函数来绘制形状，其他的绘图函数比如points()也可以这样添加形状，但是这样添加的形状大小缩放的逻辑和默认形状的不一致，所以我最后也是放弃了支持ggplot和graphics默认的形状1-25，但感觉有上述这些大部分形状也够了。\n","date":"2025-05-22T00:00:00Z","image":"/p/metanet-shape/index.en_files/figure-html/unnamed-chunk-6-1_hu_e254bb19232848ba.png","permalink":"/p/metanet-shape/","title":"使用MetaNet添加更多节点形状"},{"content":"Motivation SCI论文投稿时，我们要整理好作者和对应的单位，一般用数字上标对应下面的单位信息，然后用一些特殊符号如“#，*”来代表贡献相同的作者或者通讯作者。\n一般一个课题组出来的成果，只有几个作者的情况我们手打一下就好了。但现在的研究更多都是交叉性质的，可能会涉及到很多课题组合作，一些大的研究可能还会有几十个作者和单位，比如下面一篇cell，一页纸都写不完。\n一次手打完，不改了就还好，但这时老师叫你把某个单位顺序改一下，或者新加了个作者和单位，那么上面所有的数字上标都要随之改变，改起来就比较费劲了，还容易出错😂。\n所以我简单写了一个R函数，实现从整理好的作者-单位表格中自动生成符合规范的作者-单位 Rmarkdown文件，然后点击一下knit就可以生成对应的word文件，上标也不需要自己手动设置。如果需要改顺序也是在表格中调整一下重新生成即可，还是比较方便的。\n作者-单位 拿一篇cell文章《Molecular Choreography of Acute Exercise》做例子。\n准备一个表格，至少包含两列列名为Author和Affiliation，注意这里的作者顺序就是文章里想要的顺序，默认的单位顺序是根据作者顺位生成的： 如果要指定单位的顺序，那就再准备一列Affiliation的表格，保持想要的单位顺序： 如果还要添加额外的符号上标，如共一的#和通讯的*，再准备一个两列表格，Author和Note： 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 # 安装最新版的pcutils # devtools::install_github(\u0026#34;Asa12138/pcutils\u0026#34;) library(pcutils) df=readxl::read_excel(\u0026#34;~/Desktop/test_author.xlsx\u0026#34;) pcutils::generate_and_write_author_rmd(df,file = \u0026#34;~/Desktop/test_author.rmd\u0026#34;) # 如果要指定单位的顺序 affiliation_df=readxl::read_excel(\u0026#34;~/Desktop/test_author.xlsx\u0026#34;,sheet = 2) pcutils::generate_and_write_author_rmd(df,file = \u0026#34;~/Desktop/test_author.rmd\u0026#34;, affiliation_df = affiliation_df) #如果要添加额外的符号上标 author_note=readxl::read_excel(\u0026#34;~/Desktop/test_author.xlsx\u0026#34;,sheet = 3) pcutils::generate_and_write_author_rmd(df,file = \u0026#34;~/Desktop/test_author.rmd\u0026#34;, affiliation_df = affiliation_df, author_note = author_note) 此时会输出一个test_author.rmd的文件，然后我们用Rstudio打开后点一下knit键进行编织，就可以得到word文件了：\n上标格式也不用自己麻烦一个一个点了，如果要修改顺序也比较方便。\n作者贡献 CRediT（贡献者角色分类法）是一种高级分类法，该方法将作者的贡献划分为14个类别，并对每个类别的角色详细精确地定义了作者的贡献。\n1 2 3 ## Warning: \u0026#39;xfun::attr()\u0026#39; is deprecated. ## Use \u0026#39;xfun::attr2()\u0026#39; instead. ## See help(\u0026#34;Deprecated\u0026#34;) 贡献者角色（中文） 贡献者角色（英文） 定义 论文构思 Conceptualization 产生想法，构造或演绎发展主要的研究目的。 数据管理 Data curation 为数据的首用和后续复用产生元数据，整理数据，维护研究数据（包括软件或程序）。 形式分析 Formal analysis 使用统计、数学、计算或其他形式分析技术分析或合成研究数据。 获取资助 Funding acquisition 为了项目研究成果能够发表而去争取并获得资助。 调查研究 Investigation 实施研究和执行调查过程，特别是从事实验研究或收集数据和证据。 方法论 Methodology 开发或设计研究用的方法，建立模型。 项目管理 Project administration 为研究活动的策划和执行进行管理和协调。 提供资源 Resources 提供研究材料、试剂、病例、实验室样品、动物、仪器、计算设备资源或其他分析工具。 软件 Software 编程，研发软件，设计计算机程序，实施执行计算机程序及支持算法，测试已有的程序。 指导 Supervision 监督和领导研究活动的策划和执行，包括对核心成员以外的人员进行指导。 验证 Validation 对研究结果、实验或其他研究输出内容的复制和重现进行核实验证，包括整体的和部分的核实验证。 可视化呈现 Visualization 对发表的内容进行准备、创建或表述，特别是内容或数据的可视化展现。 初稿写作 Writing – original draft 对发表的内容进行准备、创建或表述，特别是撰写初稿，包括实质性翻译。 审核与编辑写作 Writing – review \u0026amp; editing 对原始研究团队提出的发表内容进行准备、创建或表述，特别是评论、注释或修改，包括发表前和发表后所发生的这些工作。 很多期刊都会让我们以CRediT的格式展示作者贡献，一般手打也很方便。但有时候会统一将名称进行缩写，这里也提供一个函数用来生成，准备一个两列表：\n1 2 author_contributions=readxl::read_excel(\u0026#34;~/Desktop/test_author.xlsx\u0026#34;,sheet = 4) cat(pcutils::format_credit_contributions(author_contributions, short_name = TRUE)) 1 ## Conceptualization, K.C., K.J.M., F.H., M.P.S.; Data curation, K.C., S.W., K.J.M.; Formal analysis, K.C., S.W., K.J.M., D.H.; Methodology, K.C., S.W., K.J.M., F.H., M.P.S.; Project administration, K.C., F.H., M.P.S.; Supervision, F.H., M.P.S.; Visualization, K.C., S.W., K.J.M., D.H., F.H., M.P.S.; Writing – original draft, K.C., F.H., M.P.S. ","date":"2025-05-06T00:00:00Z","image":"/p/author_affiliation/images/Screenshot%202025-05-06%20at%2017.22.32_hu_fc64b65e95a529c9.png","permalink":"/p/author_affiliation/","title":"论文作者和单位太多？如何快速整理和修改"},{"content":"抗生素耐药性（Antimicrobial Resistance, AMR）是21世纪全球公共卫生面临的重大挑战之一。随着抗生素的广泛使用，耐药菌株和抗生素耐药基因（Antibiotic Resistance Genes, ARGs）在医院环境中迅速扩散，尤其是在重症监护病房（ICU）这样高风险的医疗场所。ICU医护人员因长期暴露于高浓度抗生素和耐药菌的环境中，其肠道微生物群是否受到显著影响，成为一个备受关注的研究课题。2025年发表在《Critical Care》期刊上的一篇多中心、跨区域研究通过宏基因组学技术，系统比较了ICU医护人员与健康对照组的肠道ARG丰度及微生物群组成，揭示了ICU医护人员肠道ARG显著升高的现象。\nPaper Info 标题：Elevated antibiotic resistance gene abundance of ICU healthcare workers, a multicentre, cross-sectional study 译名：多中心横断面研究揭示ICU医护人员抗生素耐药基因丰度升高 期刊：Critical Care (IF：8.8) 发表时间：2025年4月30日 链接：https://doi.org/10.1186/s13054-025-05408-5 引言 抗生素耐药性被世界卫生组织列为全球十大公共卫生威胁之一。据《Lancet》2024年报道，1990年至2021年间，全球因AMR导致的死亡人数持续上升，预计未来几十年将进一步加剧。医院作为抗生素使用最密集的场所，是ARG传播的主要来源。ICU尤为突出，因其患者病情危重、抗生素使用频繁、耐药菌（如ESKAPE病原体：粪肠球菌、肺炎克雷伯菌等）高发，导致环境中的ARG浓度远高于外部环境。\nICU医护人员每天接触高危患者、污染表面及空气中的耐药菌，面临较高的职业暴露风险。先前的研究表明，医护人员可能通过直接接触、空气传播或交叉污染成为耐药菌的携带者。然而，传统研究多依赖细菌培养技术，样本量小，难以全面揭示ARG的传播动态。宏基因组学技术的兴起为研究ARG提供了更精确的工具，使研究人员能够深入分析医护人员肠道微生物群的耐药基因特征。\n该研究提出一个核心问题：ICU医护人员的肠道ARG丰度是否高于健康人群？此外，ICU职业暴露的时长是否与ARG丰度相关？通过多中心、跨区域的样本采集和宏基因组学分析，研究旨在填补这一领域的知识空白，为医院感染防控提供科学依据。\n研究设计与方法 这项前瞻性、多中心、横断面研究在中国浙江和河南的八家医疗中心开展，时间为2024年1月至2月。研究对象包括191名ICU医护人员（医生、护士、护理助理）和99名健康对照组，共290人。健康对照组来自常规体检人群，无医疗相关工作背景。研究通过粪便样本的宏基因组测序，比较两组的肠道ARG丰度、ARG多样性及微生物群组成。\n纳入标准：年龄大于18岁，签署知情同意书。 排除标准：存在胃肠道疾病、恶性肿瘤、精神疾病；近6个月使用广谱抗生素（如万古霉素、头孢吡肟等）；孕妇；健康对照组需无医疗相关工作经历。 研究团队收集粪便样本，提取DNA后使用Illumina NovaSeq X Plus平台进行双末端测序（2×150 bp）。通过Fastp去除低质量读数，Bowtie2过滤人类基因组序列，Kraken2进行分类学分析，RGI结合CARD数据库识别ARG。ARG丰度以每千碱基每百万映射读数（RPKM）标准化，ARG丰富度以识别的ARG总数量化。研究还通过Kraken2和RGI的读数ID匹配，追踪ARG的细菌宿主。\n主要结局为比较ICU医护人员与健康对照组的ARG丰度（以RPKM为指标）。使用广义线性模型（GLM）进行分析，矫正了年龄、性别和BMI等混杂因素。次要结局为探索ICU职业暴露时长与ARG丰度的关系，使用限制性立方样条（RCS）模型。亚组分析和敏感性分析进一步验证结果的稳健性，分析工具包括R软件及其相关包（如pctax、rms）。\n结果 ICU医护人员肠道ARG丰度显著升高 研究发现，ICU医护人员的总ARG丰度显著高于健康对照组（调整后倍数变化=1.22，95%置信区间：1.12-1.34，p\u0026lt;0.001）。具体而言，来源于粪肠球菌、肺炎克雷伯菌和肠杆菌属（包括大肠杆菌）的ARG丰度在医护人员中显著增加。特别值得注意的是，与喹诺酮类抗生素耐药相关的qnrE1基因（log2倍数变化=14.03，p-adj=0.02）以及与β-内酰胺类抗生素耐药相关的ACT-12（log2倍数变化=11.23，p-adj=0.03）和MIR-12（log2倍数变化=11.17，p-adj=0.04）基因在医护人员中显著上调。\nARG多样性与微生物群组成差异 ICU医护人员的ARG α多样性（丰富度和Shannon指数）显著高于对照组（p\u0026lt;0.001，p=0.02），β多样性也存在显著差异（Adonis R²=0.0396，p=0.001）。243个ARG在医护人员中显著上调，而仅9个ARG下调。此外，医护人员的肠道细菌组成显示出更高的α多样性（p=0.04）和β多样性（Adonis R²=0.0419，p=0.001），其中克雷伯菌属（如Klebsiella grimontii，log2倍数变化=5.93，p-adj=0.004）和乳酸乳球菌（log2倍数变化=5.78，p-adj=0.009）显著上调。\n职业暴露时长与ARG丰度无关 出乎意料的是，研究未发现ICU职业暴露时长与ARG丰度之间的显著线性或非线性关系（p for overall=0.96，p for nonlinear=0.84）。这表明ARG丰度的增加可能在医护人员职业生涯的早期即已发生。\n4. 亚组与敏感性分析 性别差异：男性医护人员的ARG丰度与职业暴露的关联更强（β=0.29，p\u0026lt;0.001）相比女性（β=0.13，p=0.03）。 地区差异：河南的医护人员ARG丰度高于浙江（倍数变化=1.20 vs. 1.12）。 职业差异：护理助理的ARG丰度最高（倍数变化=1.33），其次为医生（1.18）和护士（1.08）。 讨论 临床意义 感染防控的新视角：ICU医护人员作为潜在的ARG携带者，可能在医院内外的耐药菌传播中扮演重要角色。研究提示需加强对医护人员的感染防控措施，如优化手部卫生、加强环境消毒。 精准医疗的潜力：宏基因组学技术为监测ARG提供了高分辨率工具，可用于识别高风险人群和制定针对性的干预措施。 职业健康保障：医护人员肠道微生物群的变化可能影响其长期健康，需进一步研究这些变化的临床意义。 公共卫生意义 研究结果支持“One Health”框架，强调人类、动物和环境健康的互联性。医院作为ARG的“热点”，其防控策略应扩展到医护人员和社区。减少不必要的抗生素使用、加强耐药性监测是应对AMR的关键。\n局限性 地域局限：研究仅限于中国人群，结论的普遍性需进一步验证。 因果关系：作为观察性研究，无法确定职业暴露与ARG升高之间的因果关系。 未测混杂因素：如旅行史、住院史等可能影响结果。 临床相关性：ARG的升高是否导致实际感染风险尚不明确。 未来研究方向 纵向研究：通过长期随访，探索ARG丰度变化的动态和影响因素。 全球合作：开展跨国研究，验证不同地区医护人员的ARG特征。 干预措施：测试感染防控策略（如益生菌干预、环境净化）对ARG丰度的影响。 健康影响：研究ARG升高对医护人员健康的潜在影响，如免疫功能或代谢疾病风险。 小结 这项多中心研究揭示了ICU医护人员肠道ARG丰度和微生物群多样性的显著升高，提示职业暴露可能是重要驱动因素。尽管未发现暴露时长与ARG丰度的直接关联，但研究强调了医院环境在耐药基因传播中的关键作用。宏基因组学技术的应用为理解AMR动态提供了新视角，未来需进一步探索其临床和公共卫生意义，以优化感染防控策略，保护医护人员和患者的健康。\nCARD数据库中药物类型整理 为了方便分析，我整合了CARD数据库的描述信息到ReporterScore包中，可以通过以下代码调取：\n1 2 3 4 if(!require(ReporterScore))remotes::install_github(\u0026#34;Asa12138/ReporterScore\u0026#34;) library(ReporterScore) CARDinfo \u0026lt;- load_CARDinfo() head(CARDinfo$ARO_index) 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 ## ARO Accession CVTERM ID Model Sequence ID Model ID ## 3005099 ARO:3005099 43314 6143 3831 ## 3002523 ARO:3002523 38923 8144 1781 ## 3002524 ARO:3002524 38924 85 746 ## 3002525 ARO:3002525 38925 4719 1246 ## 3002526 ARO:3002526 38926 228 1415 ## 3002527 ARO:3002527 38927 5510 2832 ## Model Name ## 3005099 23S rRNA (adenine(2058)-N(6))-methyltransferase Erm(A) ## 3002523 AAC(2\u0026#39;)-Ia ## 3002524 AAC(2\u0026#39;)-Ib ## 3002525 AAC(2\u0026#39;)-Ic ## 3002526 AAC(2\u0026#39;)-Id ## 3002527 AAC(2\u0026#39;)-Ie ## ARO Name ## 3005099 23S rRNA (adenine(2058)-N(6))-methyltransferase Erm(A) ## 3002523 AAC(2\u0026#39;)-Ia ## 3002524 AAC(2\u0026#39;)-Ib ## 3002525 AAC(2\u0026#39;)-Ic ## 3002526 AAC(2\u0026#39;)-Id ## 3002527 AAC(2\u0026#39;)-Ie ## Protein Accession DNA Accession AMR Gene Family ## 3005099 AAB60941.1 AF002716.1 Erm 23S ribosomal RNA methyltransferase ## 3002523 AAA03550.1 L06156.2 AAC(2\u0026#39;) ## 3002524 AAC44793.1 U41471.1 AAC(2\u0026#39;) ## 3002525 CCP42991.1 AL123456.3 AAC(2\u0026#39;) ## 3002526 AAB41701.1 U72743.1 AAC(2\u0026#39;) ## 3002527 CAC32082.1 AL583926.1 AAC(2\u0026#39;) ## Drug Class ## 3005099 lincosamide antibiotic;macrolide antibiotic;streptogramin antibiotic ## 3002523 aminoglycoside antibiotic ## 3002524 aminoglycoside antibiotic ## 3002525 aminoglycoside antibiotic ## 3002526 aminoglycoside antibiotic ## 3002527 aminoglycoside antibiotic ## Resistance Mechanism CARD Short Name length Drug_Class ## 3005099 antibiotic target alteration Spyo_ErmA_MLSb 732 MLS ## 3002523 antibiotic inactivation AAC(2\u0026#39;)-Ia 537 Aminoglycoside ## 3002524 antibiotic inactivation AAC(2\u0026#39;)-Ib 588 Aminoglycoside ## 3002525 antibiotic inactivation AAC(2\u0026#39;)-Ic 546 Aminoglycoside ## 3002526 antibiotic inactivation AAC(2\u0026#39;)-Id 633 Aminoglycoside ## 3002527 antibiotic inactivation AAC(2\u0026#39;)-Ie 549 Aminoglycoside 注意CARD数据库中Drug Class，一个ARO可以对应很多种药物类型，不是很方便整合，所以我根据《Assessment of global health risk of antibiotic resistance genes》中的规则新增了一列“Drug_Class”。\nARGs were manually reclassified based on the drugs to which they confer resistance. ARGs referring to penam, cephalosporin, carbapenem, cephamycin, penem and monobactam were grouped into the beta-lactam class. ARGs referring to macrolides, lincosamides and streptogramins were grouped into the MLS class. ARGs referring to more than one drug class were grouped into the multidrug class.\n1 2 3 library(pcutils) gghuan(dplyr::count(CARDinfo$ARO_index,Drug_Class))+ scale_fill_pc() ","date":"2025-05-02T00:00:00Z","image":"/p/critical-care/images/fig1_hu_22838dfac66ffc73.png","permalink":"/p/critical-care/","title":"Critical Care: ICU医护人员肠道抗生素耐药基因显著增加"},{"content":"","date":"2025-04-27T00:00:00Z","permalink":"/p/bgckit-bgc/","title":"BGCkit：组学数据BGC分析流程"},{"content":"Introduction 在基因组学研究中，比较基因组学（Comparative Genomics）是一项核心方法，它通过对不同物种或同一物种不同个体的基因组进行比较，揭示基因的功能、结构和进化历史。在这一领域中，“同线性（synteny）”和“共线性（collinearity）”是关键概念，它们在理解基因组结构的保守性和演化过程中起着重要作用。\n在基因组比较中，“同线性”和“共线性”常被用来描述不同物种或同一物种不同个体之间基因组结构的保守性。同线性指的是在不同基因组中，一组同源基因位于各自染色体上的相似位置，而不考虑这些基因的排列顺序。共线性则进一步要求这些同源基因在染色体上的排列顺序也保持一致。简而言之，共线性是同线性的一种更严格形式。\n根据同线性区域的大小和复杂性，研究人员将其分为“宏同线性（macrosynteny）”和“微同线性（microsynteny）”。宏同线性通常指染色体级别的大尺度保守区域，适用于研究远缘物种之间的基因组结构演化；而微同线性则关注较小的基因簇或基因对之间的保守性，常用于近缘物种或亚种之间的精细比较。\n同线性分析在比较基因组学中具有广泛的应用价值：\n揭示基因组进化历史：通过识别同线性区域，可以推断物种间的基因组重排事件，如倒位、易位、重复和缺失等，从而重建基因组的进化轨迹。\n识别同源基因：同线性分析有助于区分直系同源基因（orthologs）和旁系同源基因（paralogs），这对于功能基因的注释和研究具有重要意义。\n研究全基因组复制事件：在植物等多倍体物种中，同线性分析可用于检测和分析全基因组复制（WGD）事件，理解基因组扩张与物种多样性的关系。\n辅助基因功能预测：通过比较模型生物与目标物种之间的同线性区域，可以推测未知基因的功能，尤其在缺乏实验验证的情况下尤为重要。\n评估基因组组装质量：同线性分析可以作为评估新组装基因组质量的工具，检测可能的组装错误或缺失区域。\n随着高通量测序技术的发展，许多生物信息学工具被开发用于同线性分析和可视化，搜索一下就有一大堆，尤其是可视化工具，所以这里只简单提一下我知道的各种工具，大家可以根据喜好自行选择尝试使用。\n分析软件 同线性分析涉及到全基因组比对，是一个计算密集型的过程。尽管各种软件在输入输出格式上有所差异，但它们的共同目标是识别基因组之间的同线性区块（syntenic blocks），即在不同基因组中保守的基因排列区域。\nMUMmer https://github.com/mummer4/mummer\n简介\nMUMmer 是一个用于快速比对大型序列的开源软件包。它能够高效地比对整个基因组、基因组组装结果以及部分（草图）基因组序列。MUMmer 的最新版本（4.x）引入了新的后缀树算法，进一步提高了比对效率。\n安装\nMUMmer 可在其 GitHub 页面上获取\n1 2 3 4 5 tar -zxvf mummer-4.0.0beta2.tar.gz cd mummer-4.0.0beta2 ./configure --prefix=/data/tengwenkai/software/MUMmer4.0 make make install 或者conda安装：conda install bioconda::mummer\n简单使用\nMUMmer 提供了多个实用工具，其中 nucmer 是最常用的比对脚本，用于标准的 DNA 序列比对。例如，使用 nucmer 对两个基因组进行比对后，可以使用 show-coords 工具查看比对坐标。此外，promer 工具可以基于输入序列的六帧翻译生成比对结果，适用于蛋白质序列的比对。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 nucmer [options] \u0026lt;Reference\u0026gt; \u0026lt;Query\u0026gt; Reference：参考基因组，含有多条序列的FASTA文件名 Query：要匹配的基因组，含有多条序列的FASTA文件名 --mum, --mumreference(默认), --maxmatch：与mumer相同 -b, --breaklen：一个比对尝试延伸的最大距离，默认为200 -c, --mincluster：一个匹配聚类簇的最短长度，默认为65 -D, --diagdiff：一个聚类中两个邻接匹配的最大对角差分，默认5 -d, --diagfactor一个聚类中两个邻接匹配的最大对角差分与gap长度的比值，默认为0.12 --noextend：不执行聚类簇延长步骤，默认关闭 -f, --forward：只使用查询序列的正向链 -g, --maxgap：一个聚类中两个邻接匹配的最大gap长度，默认为90 -l, --minmatch：一个匹配的最短长度，默认为20 -L, --minalign：一个聚类延伸后比对的最短长度，默认为0 -r, --reverse：只使用查询序列的反向互补链 --nosimplify：不简化比对，当使用序列与自身比对来寻找重复时可以选此选项，默认关闭 -p, --prefix：输出结果delta文件的前缀，默认为out --sam-short：保存SAM短格式到文件路径 --sam-long：保存SAM长格式到文件路径 -t, --threads：程序运行使用的核数 1 2 3 4 # 使用MUMmer进行局部比对（适合低相似度基因组） nucmer --prefix=out genome1.fna genome2.fna delta-filter -q -r out.delta \u0026gt; out.filtered.delta # 保留唯一最佳比对 show-coords -rcl out.filtered.delta \u0026gt; out.coords # 输出坐标 MUMmer 的高效性能使其成为进行全基因组比对和同线性分析的有力工具，尤其适用于处理大型基因组数据。\nMCScanX https://github.com/wyp1125/MCScanX\n简介\nMCScanX 是一个用于检测基因组间同线性和共线性关系的工具包。它实现了改进的 MCScan 算法，能够识别同线性区块，并提供多种可视化和分析工具。\n安装\nMCScanX 可在其 GitHub 页面上获取，下载源代码并按照说明进行编译安装。\n1 2 3 unzip MCscanX.zip cd MCScanX make 简单使用\nMCScanX 的使用需要两个主要输入文件：\nBLASTP 比对结果文件（xyz.blast）\n该文件为标准的 BLASTP 输出，格式为 m8。每行表示一对同源基因的比对结果，包含以下字段：\n1 gene1 gene2 identity alignment_length mismatches gap_opens q_start q_end s_start s_end e_value bit_score 示例：\n1 AT1G50920 AT1G50920 100.00 671 0 0 1 671 1 671 0.0 1316 建议使用以下命令生成该文件：\n1 blastall -i query_file -d database -p blastp -e 1e-10 -b 5 -v 5 -m 8 -o xyz.blast 其中，-b 5 -v 5 参数限制每个基因的比对结果为前 5 个，以提高分析的准确性。\n基因注释文件（xyz.gff）\n该文件包含基因在染色体上的位置信息，格式为制表符分隔的四列：\n1 chromosome gene_id start_position end_position 示例：\n1 2 at1 AT1G01010 3631 5899 at1 AT1G01020 5928 8737 注意事项：\nchromosome 字段应使用两字母的物种缩写加染色体编号，例如 Arabidopsis thaliana 的第二染色体应为 at2。 每个基因只能出现一次，重复的基因会导致错误。 该文件可通过解析 GFF3 文件生成。 在进行多个基因组比较时，可将所有物种的 BLAST 输出合并为一个 xyz.blast 文件，所有基因注释信息合并为一个 xyz.gff 文件。\n将 xyz.blast 和 xyz.gff 文件放在同一目录下，使用以下命令运行 MCScanX：\n1 ./MCScanX xyz 其中，xyz 为输入文件的前缀，MCScanX 将自动识别并处理对应的 .blast 和 .gff 文件。\n输出结果解析\n运行完成后，MCScanX 会生成以下主要输出：\nxyz.collinearity 文件\n该文本文件包含识别到的同线性区块信息，每个区块以 ## Alignment 开头，包含区块编号、得分、e-value、基因对数量等信息。示例：\n1 2 3 4 5 ## Alignment 0: score=9171.0 e_value=0 N=187 at1\u0026amp;at1 plus 0-0: AT1G17240 AT1G72300 0 0-1: AT1G17290 AT1G72330 0 ... 0-186: AT1G22340 AT1G78270 3e-174 每行表示一对共线性基因对，最后一列为比对的 e-value。\nxyz.html 目录\n该目录包含多个 HTML 文件，用于可视化同线性区块在染色体上的分布。每个 HTML 文件对应一个参考染色体，展示了该染色体上的基因及其与其他染色体的同线性关系。这些文件可通过网页浏览器查看，便于直观分析。\n此外，MCScanX 提供了多种可视化工具，如 dot plot、circle plot 等，便于用户直观地观察基因组间的同线性关系。\nMugsy https://github.com/kloetzl/mugsy\n简介\nMugsy 是一个用于多个完整基因组比对的工具，特别适用于比对密切相关的基因组。它不需要参考基因组，能够处理混合的草图和完整基因组数据，识别包括重复、重排和大规模序列增减等在内的遗传变异。\n安装\nMugsy 可在其官方网站上获取\n1 2 3 4 5 6 7 wget https://sourceforge.net/projects/mugsy/files/latest/download tar xvzf download #将Mugsy安装路径加到PATH里 vim ~/.bashrc export PATH=\u0026#34;/picb/evolgen/users/gushanshan/software/mugsy/mugsy_1.2.2:$PATH\u0026#34; source ~/.bashrc 或者conda安装：conda install bioconda::mugsy\n简单使用\nMugsy 的输入为多组基因组序列（FASTA 格式）。文件要求：\n一个或多个FASTA文件 每个文件应该包括单个物种的所有序列 FASTA的header中不能包括：或- 模糊字符将被转换成N 使用示例命令：\n1 ./mugsy --directory output_dir genome1.fasta genome2.fasta genome3.fasta 运行后，Mugsy 会在指定的输出目录中生成多个文件，包括比对结果和同线性区块信息。这些结果可用于进一步的比较基因组分析。\n可视化软件 可以用来画synteny图的软件就太多了，各种编程语言都有，还有很多在线网站，风格各异，这里推荐一些，可以根据demo效果或者整理input格式的难度挑选一下：\nR 我用来做可视化最多的工具还是R语言，所以优先介绍几个R包了：\ngggenomes https://thackl.github.io/gggenomes/index.html\ngggenomes是用于比较基因组学的多功能图形包。基于ggplot的语法，非常好上手用，主页提供的demo代码也非常好看：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 library(gggenomes) # to inspect the example data shipped with gggenomes data(package=\u0026#34;gggenomes\u0026#34;) gggenomes( genes = emale_genes, seqs = emale_seqs, links = emale_ava, feats = list(emale_tirs, ngaros=emale_ngaros, gc=emale_gc)) |\u0026gt; add_sublinks(emale_prot_ava) |\u0026gt; sync() + # synchronize genome directions based on links geom_feat(position=\u0026#34;identity\u0026#34;, size=6) + geom_seq() + geom_link(data=links(2)) + geom_bin_label() + geom_gene(aes(fill=name)) + geom_gene_tag(aes(label=name), nudge_y=0.1, check_overlap = TRUE) + geom_feat(data=feats(ngaros), alpha=.3, size=10, position=\u0026#34;identity\u0026#34;) + geom_feat_note(aes(label=\u0026#34;Ngaro-transposon\u0026#34;), data=feats(ngaros), nudge_y=.1, vjust=0) + geom_wiggle(aes(z=score, linetype=\u0026#34;GC-content\u0026#34;), feats(gc), fill=\u0026#34;lavenderblush4\u0026#34;, position=position_nudge(y=-.2), height = .2) + scale_fill_brewer(\u0026#34;Genes\u0026#34;, palette=\u0026#34;Dark2\u0026#34;, na.value=\u0026#34;cornsilk3\u0026#34;) syntenyPlotteR https://github.com/Farre-lab/syntenyPlotteR\n这个包也是用ggplot画的，但是不是ggplot语法，draw.linear函数输出包含线性样式对齐的图像文件。默认情况下，该函数将文件保存到临时目录，可以使用目录参数（即Directory =\u0026ldquo;path/to/to/Directory\u0026rdquo;）覆盖。\n1 2 3 4 5 6 library(syntenyPlotteR) old_wd=getwd() setwd(system.file(\u0026#34;extdata\u0026#34;,package = \u0026#34;syntenyPlotteR\u0026#34;)) # example data draw.linear(\u0026#34;example_linear\u0026#34;, \u0026#34;example_lengths.txt\u0026#34;, \u0026#34;example_alignment_1.txt\u0026#34;, \u0026#34;example_alignment_2.txt\u0026#34;, \u0026#34;example_alignment_3.txt\u0026#34;) setwd(old_wd) macrosyntR https://github.com/SamiLhll/macrosyntR\n这是一个用于在全基因组范围内评估同线性保守性的R软件包。它通过读取正交同源基因表和BED格式的基因组注释文件，自动识别显著保守的连锁群，并基于网络贪婪算法将这些连锁群排序展示在牛津网格图或弦图中。\n准备输入数据\n要开始比较物种，您需要准备以下两类文件：\n正交同源基因表（两列格式）\n• 包含待比较物种之间的正交同源基因对（每行一对）。\n• 可通过工具生成，例如：\n◦ rbhxpress 的输出结果\n◦ OrthoFinder 的结果\nBED 格式的基因组注释文件\n• 列出所有物种的正交同源基因的基因组坐标和序列名称。\n• 关键要求：\n◦ BED 文件中的基因名称必须与正交同源基因表（文件1）的列名匹配。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 library(macrosyntR) # Load table of orthologs and integrate with genomic coordinates : my_orthologs_table \u0026lt;- load_orthologs(orthologs_table = system.file(\u0026#34;extdata\u0026#34;,\u0026#34;Bflo_vs_Pech.tab\u0026#34;,package=\u0026#34;macrosyntR\u0026#34;), bedfiles = c(system.file(\u0026#34;extdata\u0026#34;,\u0026#34;Bflo.bed\u0026#34;,package=\u0026#34;macrosyntR\u0026#34;), system.file(\u0026#34;extdata\u0026#34;,\u0026#34;Pech.bed\u0026#34;,package=\u0026#34;macrosyntR\u0026#34;))) # Draw an oxford grid : p1 \u0026lt;- plot_oxford_grid(my_orthologs, sp1_label = \u0026#34;B.floridae\u0026#34;, sp2_label = \u0026#34;P.echinospica\u0026#34;) p1 # Automatically reorder the Oxford grid and color the detected clusters (communities): p2 \u0026lt;- plot_oxford_grid(my_orthologs, sp1_label = \u0026#34;B.floridae\u0026#34;, sp2_label = \u0026#34;P.echinospica\u0026#34;, reorder = TRUE, color_by = \u0026#34;clust\u0026#34;) p2 # Plot the significant linkage groups : my_macrosynteny \u0026lt;- compute_macrosynteny(my_orthologs) p3 \u0026lt;- plot_macrosynteny(my_macrosynteny) p3 # Call the reordering function, test significance and plot it : my_orthologs_reordered \u0026lt;- reorder_macrosynteny(my_orthologs) my_macrosynteny \u0026lt;- compute_macrosynteny(my_orthologs_reordered) p4 \u0026lt;- plot_macrosynteny(my_macrosynteny) p4 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 # load data my_orthologs_with_3_sp \u0026lt;- load_orthologs(orthologs_table = system.file(\u0026#34;extdata\u0026#34;,\u0026#34;Single_copy_orthologs.tsv\u0026#34;,package=\u0026#34;macrosyntR\u0026#34;), bedfiles = c(system.file(\u0026#34;extdata\u0026#34;,\u0026#34;Bflo.bed\u0026#34;,package=\u0026#34;macrosyntR\u0026#34;), system.file(\u0026#34;extdata\u0026#34;,\u0026#34;Pech.bed\u0026#34;,package=\u0026#34;macrosyntR\u0026#34;), system.file(\u0026#34;extdata\u0026#34;,\u0026#34;Pyes.bed\u0026#34;,package=\u0026#34;macrosyntR\u0026#34;))) # Change the chromosome names to keep only numbers levels(my_orthologs_with_3_sp$sp1.Chr) \u0026lt;- stringr::str_replace(levels(my_orthologs_with_3_sp$sp1.Chr),\u0026#34;BFL\u0026#34;,\u0026#34;\u0026#34;) levels(my_orthologs_with_3_sp$sp2.Chr) \u0026lt;- stringr::str_replace(levels(my_orthologs_with_3_sp$sp2.Chr),\u0026#34;PEC\u0026#34;,\u0026#34;\u0026#34;) levels(my_orthologs_with_3_sp$sp3.Chr) \u0026lt;- stringr::str_replace(levels(my_orthologs_with_3_sp$sp3.Chr),\u0026#34;chr\u0026#34;,\u0026#34;\u0026#34;) # Plot an automatically ordered chord diagram colored by the linkage groups : plot_chord_diagram(my_orthologs_with_3_sp, species_labels = c(\u0026#34;B. flo\u0026#34;,\u0026#34;P. ech\u0026#34;, \u0026#34;P. yes\u0026#34;), color_by = \u0026#34;LGs\u0026#34;) + theme(legend.position = \u0026#34;none\u0026#34;) # The linkage groups were automatically computed but you can also get them as a table using : my_linkage_groups \u0026lt;- compute_linkage_groups(my_orthologs_with_3_sp) Python plotsr https://github.com/schneebergerlab/plotsr\nPlotsr使用了多个染色体级组件之间的基因组结构注释来产生多个基因组之间同义和结构重排的高质量可视化：\n示例里面用了minimap2对齐基因组，并使用SamTools索引对齐BAM文件，然后用Syri在基因组之间找到同线性和结构重排，最后用Plotsr做可视化。\nJCVI https://github.com/tanghaibao/jcvi\nJCVI 库是一个基于 Python 的多功能工具库，发在了imeta上面，其模块化设计提供了一系列高效工具，涵盖以下核心功能：\n格式解析与数据操作 可视化与图形生成 基因组算法支持 开发与维护理念 我们关注其synteny图的可视化：\npyGenomeViz https://github.com/moshi4/pyGenomeViz\npyGenomeViz 是一款基于 matplotlib 开发的 Python 基因组可视化工具包，专注于 比较基因组学 分析。该工具旨在以简洁美观的方式绘制 多基因组间的特征比对 和 序列相似性关联。\n• 支持输入格式：Genbank / GFF 格式文件\n• 输出格式灵活：可保存为 JPG、PNG、SVG、PDF 或 HTML\n• 交互式可视化：在 Jupyter Notebook 中动态调整与查看\n• 自动化分析集成：可嵌入基因组分析脚本或工作流，实现批量绘图\n（适用于 基因组共线性分析、基因簇比较 和 进化研究 等场景。）\n这个工具主页的介绍也非常详细，可以一步一步学习\nPerl circos https://circos.ca/\n鼎鼎大名的circos，这个值得有空单独介绍了，能画出来的图很夸张。\n网上的教程也非常多，可以跟着官方教程仔细学一遍：https://circos.ca/support/getting_started/。 我们可以通过修改配置文件一步一步的画出自己想要的图。\nGenomeSyn https://github.com/jmsong2/GenomeSyn\n这个软件内置了MUMmer帮忙跑分析，属于是一键出图了，我们也可以自己跑MUMmer筛选位点，出的图效果也不错，但主页说的在线服务已经没有了。\n1 2 3 GenomeSyn -t 3 -g1 rice_MH63.fa -g2 rice_ZS97.fa -cf1 rice_MH63vsZS97.delta.filter.coords GenomeSyn -t 3 -g1 ../data/rice_MH63.fa -g2 ../data/rice_ZS97.fa -cf1 ../data/rice_MH63vsZS97.delta.filter.coords NGenomeSyn https://github.com/hewm2008/NGenomeSyn\nNGenomeSyn是于基于多个基因组共线性关系的可视工具，该软件可以添加多个基因组一起进行分析绘图（可超过12个），各基因组顺序可以自由定制以及添加特殊属性。绘图效果规律鲜明，结果易于呈现出各类共线性，大尺度变异，细部标识特殊基因区域等。\n这里放两个展示其特点的例子：\n在线网站 能实现这类可视化的在线网站也有非常多，有些是生物公司的云平台需要注册一下，我这里提几个免费且无需注册的网站：\npyGenomeViz：https://pygenomeviz.streamlit.app/ ，简单功能实现 chiplot：https://www.chiplot.online/McScanX_synteny_plot.html ，国产，直接接上McScanX结果可视化 SynVisio：https://synvisio.github.io/#/ ，直接接上McScanX结果可视化，各种展示形式 shinyCircos：https://venyao.xyz/shinyCircos/ ，画环形弦图的，觉得circos难用可以试试 \u0026hellip; References https://thisvsthat.io/collinearity-vs-synteny Dewey, C.N. (2019). Whole-Genome Alignment. In: Anisimova, M. (eds) Evolutionary Genomics. Methods in Molecular Biology, vol 1910. Humana, New York, NY. https://doi.org/10.1007/978-1-4939-9074-0_4 ","date":"2025-04-24T00:00:00Z","image":"/p/synteny/images/emales_hu_b46dfbd76b1f2de4.png","permalink":"/p/synteny/","title":"基因组同线性（synteny）分析和可视化"},{"content":"Introduction 在宏基因组学研究中，准确地将组装后的基因组片段（contigs）归属到各自的微生物基因组中，是解析微生物群落功能和生态关系的关键步骤。然而，很多分箱（binning）方法在面对复杂的微生物群落时，常常难以重建出高质量的基因组，且不同工具在不同样本和生态环境中的表现差异显著。\n为了解决这一问题，研究人员开发了DAS Tool（Dereplication, Aggregation and Scoring Tool），这是一种自动化的方法，能够整合多个已有的分箱算法的结果，生成优化的、非冗余的高质量基因组集合。在多个复杂环境样本中，DAS Tool展示了比任何单一分箱工具更强的能力，能够恢复更多接近完整的基因组，包括一些之前未被发现的谱系。本文将介绍使用DAS Tool优化宏基因组分箱结果，提升基因组重建的质量和数量。\nDAS Tool的文章于2018年发表于Nature Microbiology，软件主页：https://github.com/cmks/DAS_Tool，logo也很有意思。\n工作流程 Step 1｜整合多种分箱结果\nDAS Tool 的输入包括：一个宏基因组组装（scaffolds）和来自不同 binning 工具的多个 bin 结果（每种颜色表示一个工具的输出）。这些分箱工具可能依据不同特征（如 GC 含量、k-mer 频率或丰度信息）进行聚类。\nStep 2｜识别单拷贝基因并打分\nDAS Tool 会在 scaffolds 上预测单拷贝标志基因（single-copy marker genes），并以此对每个 bin 进行质量打分（例如完整度和污染度），用于后续筛选。\nStep 3｜合并候选 bin 并去除冗余\n来自不同工具的 bin 可能存在重叠。DAS Tool 会将这些候选 bin 进行去冗余整合，构建一个统一的候选 bin 集合。\nStep 4｜迭代优化与筛选\nDAS Tool 通过迭代方式从所有候选 bin 中优先选择得分最高的，并在每轮迭代中更新剩余 bin 的得分（考虑重复和覆盖情况），最终输出一个非冗余、高质量的 bin 集合。\n这个流程的关键在于：充分融合多个 binning 工具的优点，利用标志基因和打分机制，自动筛选出最优的 bin 组合，有效提升基因组重建的质量和覆盖范围。\n效果评估 DAS Tool在模拟微生物群落中的表现验证 为了验证 DAS Tool 的效果，研究者将其应用于 CAMI challenge 提供的三种复杂度不同的模拟微生物群落数据集（包含 40、132 和 596 个基因组）。使用五种主流 binning 工具（ABAWACA、CONCOCT、MaxBin 2、MetaBAT、ESOM）分别预测分箱，并用 DAS Tool 进行整合优化。\n在高复杂度（596 个基因组）数据集中，DAS Tool 重建的高质量基因组数量（F1 分数 \u0026gt; 0.6）显著高于任何单一工具：\nDAS Tool： 共识菌株 41 个、唯一菌株 299 个 次优 MaxBin 2： 共识菌株 23 个、唯一菌株 253 个 ESOM： 虽对唯一菌株效果尚可（173 个），但对存在菌株变异的基因组恢复能力较差（仅 6 个） 此外，DAS Tool 重建的基因组 F1 分数中位数也优于其它工具，尤其在处理菌株变异时展现出更强的能力。不仅在高复杂度样本中表现优越，在中低复杂度数据集上也优于单一方法。\nDAS Tool在真实环境样本中的应用 Probst 等人曾从高 CO₂ 冷泉系统中构建了一个经过精细人工筛选的基因组分箱集，成为评估 DAS Tool 表现的理想样本。这些数据来自对不同滤膜（3.0 μm 与 0.2 μm）过滤后的样品进行组装，并采用三种 binning 方法 + 人工校正获得结果。\n研究者对原始发表的 bins 及不同 binning 工具（ABAWACA 1.0/1.07、ESOM、CONCOCT、MetaBAT、MaxBin 2）与 DAS Tool 的整合结果进行了对比评估。质量评估采用 CheckM，高质量定义为 \u0026gt;90% 完整度且污染率 \u0026lt;5%。\n主要发现如下：\n使用3种工具整合的 DAS Tool 已超过任一单一方法的效果，但略低于人工精修结果。 使用7种工具整合的 DAS Tool 成果优于原始发表结果： 0.2 μm 样本： DAS Tool 重建 36 个近全基因组，高于原始的 32 个； 3.0 μm 样本： DAS Tool 重建 38 个，高于原始的 31 个； 草稿级基因组数量也全面提升。 当适度放宽污染率阈值时，草稿基因组数量进一步增加。 在真实环境样本中，DAS Tool 同样展现出强大整合能力，尤其当结合更多 binning 工具时，不仅能提高高质量基因组的数量，也能有效替代部分人工精修过程。\n使用方法 安装 1. 最简单的安装方式：使用 conda 1 2 3 4 5 conda config --add channels defaults conda config --add channels bioconda conda config --add channels conda-forge conda install -c bioconda das_tool 但我发现conda安装好了之后也需要下载github主页的db.zip文件并解压，后续运行需指定db目录，不然默认用当前目录下的db：\n1 2 3 4 5 6 # 下载并解压缩DASTool.zip存档: unzip DAS_Tool-1.x.x.zip cd ./DAS_Tool-1.x.x # Unzip SCG database: unzip ./db.zip -d db 2. 手动安装（需满足以下依赖项） R (\u0026gt;= 3.2.3)：https://www.r-project.org R 包： data.table (\u0026gt;= 1.9.6) magrittr (\u0026gt;= 2.0.1) docopt (\u0026gt;= 0.7.1) ruby (\u0026gt;= 2.3.1)：https://www.ruby-lang.org Pullseq (\u0026gt;= 1.0.2)：https://github.com/bcthomas/pullseq Prodigal (\u0026gt;= 2.6.3)：https://github.com/hyattpd/Prodigal coreutils（仅 macOS 需要）：https://www.gnu.org/software/coreutils 以下三种搜索引擎之一： DIAMOND (\u0026gt;= 0.9.14)：推荐，用于大数据集：https://ab.inf.uni-tuebingen.de/software/diamond BLAST+ (\u0026gt;= 2.5.0)：https://blast.ncbi.nlm.nih.gov/Blast.cgi USEARCH (\u0026gt;= 8.1)：http://www.drive5.com/usearch/download.html 注意：USEARCH 免费版仅支持最多 4GB 内存，因此推荐使用 DIAMOND 或 BLAST+。\n1 2 3 4 5 6 7 8 9 # 下载并解压缩DASTool.zip存档: unzip DAS_Tool-1.x.x.zip cd ./DAS_Tool-1.x.x # Unzip SCG database: unzip ./db.zip -d db # Run DAS Tool: ./DAS_Tool -h 1 2 3 4 5 6 $ R \u0026gt; repo=\u0026#39;http://cran.us.r-project.org\u0026#39; #select a repository \u0026gt; install.packages(\u0026#39;data.table\u0026#39;, repos=repo, dependencies = T) \u0026gt; install.packages(\u0026#39;magrittr\u0026#39;, repos=repo, dependencies = T) \u0026gt; install.packages(\u0026#39;docopt\u0026#39;, repos=repo, dependencies = T) \u0026gt; q() #quit R-session 3. 使用 Docker 1 2 cd ./DAS_Tool-1.x.x docker build -t cmks/das_tool . 参数说明 安装完成后，可以通过 DAS_Tool -h 查看可用参数：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 DAS_Tool [选项] -i \u0026lt;contig2bin\u0026gt; -c \u0026lt;contigs_fasta\u0026gt; -o \u0026lt;输出前缀\u0026gt; 主要参数： -i, --bins=\u0026lt;contig2bin\u0026gt; 多个 contig-to-bin 表格文件（以逗号分隔） -c, --contigs=\u0026lt;contigs\u0026gt; 组装后的 contig（FASTA 格式） -o, --outputbasename=\u0026lt;前缀\u0026gt; 输出文件名前缀 -l, --labels=\u0026lt;标签\u0026gt; 每个 binning 工具的名称（以逗号分隔） --search_engine=\u0026lt;搜索工具\u0026gt; 用于识别单拷贝基因的搜索工具（diamond/blastp/usearch）[默认：diamond] -p, --proteins=\u0026lt;蛋白文件\u0026gt; 预测蛋白（可选），跳过基因预测步骤（FASTA 格式） --write_bin_evals 输出原始 bin 评估结果 --write_bins 输出最终整合的 bin（FASTA） --write_unbinned 输出未归类的 contigs -t, --threads=\u0026lt;线程数\u0026gt; 并行线程数 [默认：1] --score_threshold=\u0026lt;阈值\u0026gt; bin 筛选的得分阈值（0~1）[默认：0.5] --duplicate_penalty=\u0026lt;重复惩罚\u0026gt; 单拷贝基因重复的惩罚因子（0~3）[默认：0.6] --megabin_penalty=\u0026lt;megabin惩罚\u0026gt; 超大 bin 的惩罚因子（0~3）[默认：0.5] --dbDirectory=\u0026lt;数据库路径\u0026gt; 单拷贝基因数据库路径 [默认：db] --resume 使用之前预测过的单拷贝基因结果 --debug 输出调试信息 -v, --version 查看版本 -h, --help 查看帮助 输入文件准备 1. 多个 binning 工具的输出 [--bins, -i] 每个 binning 工具生成的 contig-to-bin 表格，TSV 格式：\n1 2 3 4 Contig_1 bin.01 Contig_8 bin.01 Contig_42 bin.02 Contig_49 bin.03 不是所有 binning 工具都直接生成此格式。可使用官方提供的脚本 Fasta_to_Contigs2Bin.sh 进行转换，在github主页上：\n1 2 # 示例：将 MaxBin 输出 fasta 文件转为 contigs2bin 表格 ~/biosoft/DAS_Tool/src/Fasta_to_Contig2Bin.sh -i /maxbin/output/folder -e fa \u0026gt; maxbin.contigs2bin.tsv 某些工具如 CONCOCT 输出为 CSV，可用 perl 一行命令转为 TSV：\n1 perl -pe \u0026#34;s/,/\\tconcoct./g;\u0026#34; concoct_clustering_gt1000.csv \u0026gt; concoct.contigs2bin.tsv 2. 组装后的 contig 文件 [--contigs, -c] FASTA 格式，如：\n1 2 3 4 \u0026gt;Contig_1 ATCATCGTCCGCATCGACGAATTCGGCGAACGAGTACCCCTGACCATCTCCGATTA... \u0026gt;Contig_2 GATCGTCACGCAGGCTATCGGAGCCTCGACCCGCAAGCTCTGCGCCTTGGAGCAGG... 3. 可选：预测蛋白序列 [--proteins] 若已有 prodigal 预测结果（.faa 格式），可跳过基因预测步骤。\n运行 DAS Tool 基本命令格式如下：\n1 DAS_Tool -i \u0026lt;binning_results.tsv\u0026gt; -l \u0026lt;binning_labels\u0026gt; -c \u0026lt;scaffolds.fasta\u0026gt; -o \u0026lt;输出前缀\u0026gt; 参数说明：\n-i：多个 binning 工具的 contigs-to-bin TSV 文件（用逗号连接），注意逗号之间绝对不能有空格，不然会引发Docopt报错 -l：与 -i 对应的 binning 工具名称（用逗号连接） -c：组装后 contigs 的 FASTA 文件 -o：输出文件名前缀 示例：\n1 DAS_Tool -i bins.tsv -l metabat,maxbin,concoct -c assembly.fasta -o DAS_Tool_output 输出结果 运行后将生成以下输出文件：\n*_DASTool_summary.tsv：输出 bin 的质量与完整性评估汇总 *_DASTool_contigs2bin.tsv：最终 contigs-to-bin 映射表 *_allBins.eval：若启用 --write_bin_evals，输出输入 bin 的评估结果 DASTool_bins/：若启用 --write_bins，输出整合后的 bin（FASTA 格式） 示例数据与测试 使用 GitHub 提供的 sample_data：\n示例 1：使用 4 个 bin 工具结果运行 DAS Tool 1 2 3 4 5 6 7 8 DAS_Tool -t 4 -i sample_data/sample.human.gut_concoct_contigs2bin.tsv,\\ sample_data/sample.human.gut_maxbin2_contigs2bin.tsv,\\ sample_data/sample.human.gut_metabat_contigs2bin.tsv,\\ sample_data/sample.human.gut_tetraESOM_contigs2bin.tsv \\ --dbDirectory ~/db/DAS_Tool_db \\ -l concoct,maxbin,metabat,tetraESOM \\ -c sample_data/sample.human.gut_contigs.fa \\ -o sample_output2/DASToolRun1 用了4核，对于一个32M的contig文件，用时1min，内存占用200MB。\n示例 2：设置更多参数，跳过基因预测，输出评估结果，输出最终的bins，使用多线程 1 2 3 4 5 6 7 8 9 10 11 12 DAS_Tool -t 4 -i sample_data/sample.human.gut_concoct_contigs2bin.tsv,\\ sample_data/sample.human.gut_maxbin2_contigs2bin.tsv,\\ sample_data/sample.human.gut_metabat_contigs2bin.tsv,\\ sample_data/sample.human.gut_tetraESOM_contigs2bin.tsv \\ --dbDirectory ~/db/DAS_Tool_db \\ -l concoct,maxbin,metabat,tetraESOM \\ -c sample_data/sample.human.gut_contigs.fa \\ -o sample_output2/DASToolRun2 \\ --proteins sample_output2/DASToolRun1_proteins.faa \\ --write_bin_evals \\ --write_bins \\ --score_threshold 0.6 承接MetaWRAP输出结果 MetaWRAP是我们之前介绍过的一个binning流程工具，假如我们一开始已经用MetaWRAP进行了3种工具的binning，现在我们想用DAS_Tool来进行进一步的优化，那么可以用如下命令：\n1 2 3 i=KY01867_1_T006D metawrap binning -o l -t 2 -m 4 -a contigs/contigs_${i}.fasta \\ --metabat2 --maxbin2 --concoct reads/${i}*.fastq 那么在INITIAL_BINNING_${i}文件夹下会有如下文件夹：\nINITIAL_BINNING_KY01867_1_T006D/ ├── concoct_bins ├── maxbin2_bins ├── metabat2_bins └── work_files\n我们使用DAS_Tool进行整合：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 mkdir DAS_Tool_${i} #整理list mkdir tmp/ rm tmp/* find INITIAL_BINNING_${i}/metabat2_bins/ -type f -name \u0026#34;bin.[0-9].fa\u0026#34; -exec cp {} tmp/ \\; ~/biosoft/DAS_Tool/src/Fasta_to_Contig2Bin.sh -i tmp/ -e fa \u0026gt; DAS_Tool_${i}/metabat_contigs2bin.tsv ~/biosoft/DAS_Tool/src/Fasta_to_Contig2Bin.sh -i INITIAL_BINNING_${i}/maxbin2_bins/ -e fa \u0026gt; DAS_Tool_${i}/maxbin_contigs2bin.tsv rm tmp/* cp INITIAL_BINNING_${i}/concoct_bins/bin.*.fa tmp/ ~/biosoft/DAS_Tool/src/Fasta_to_Contig2Bin.sh -i tmp/ -e fa \u0026gt; DAS_Tool_${i}/concoct_contigs2bin.tsv #运行DAS_Tool DAS_Tool -t 4 -i DAS_Tool_${i}/concoct_contigs2bin.tsv,\\ DAS_Tool_${i}/maxbin_contigs2bin.tsv,\\ DAS_Tool_${i}/metabat_contigs2bin.tsv \\ --dbDirectory ~/db/DAS_Tool_db \\ -l concoct,maxbin,metabat \\ -c INITIAL_BINNING_${i}/work_files/assembly.fa \\ -o DAS_Tool_${i}/DASToolRun2 \\ --write_bin_evals \\ --write_bins References Sieber, C.M.K., Probst, A.J., Sharrar, A. et al. Recovery of genomes from metagenomes via a dereplication, aggregation and scoring strategy. Nat Microbiol 3, 836–843 (2018). https://doi.org/10.1038/s41564-018-0171-1 ","date":"2025-04-22T00:00:00Z","image":"/p/binning-4-das-tool-binning/images/workflow_hu_6313fd077daf3954.png","permalink":"/p/binning-4-das-tool-binning/","title":"宏基因组分箱（binning）｜4. DAS Tool优化binning结果"},{"content":"除了之前讲的网络拓扑特征（数学指标）外，网络的稳定性也是生物研究的重点。网络稳定性是理解分子调控，代谢网络，生态系统等稳健性的重要因素。\n我们收集了许多方法在MetaNet中来计算和反映网络的稳定性和复杂性，这些算法都是并行计算的，这可以快得多。所有网络稳定性计算都提供并行版本，使用parallel::detectCores()获取设备核数，并设置threads \u0026gt;1使用并行计算。\n软件主页：https://github.com/Asa12138/MetaNet 大家可以帮忙在github上点点star⭐️，谢谢🙏 详细英文版教程：https://bookdown.org/Asa12138/metanet_book/ 可以从 CRAN 安装稳定版：install.packages(\u0026quot;MetaNet\u0026quot;)\n依赖包 pcutils和igraph（需提前安装），推荐配合 dplyr 进行数据操作。\n1 2 3 4 5 6 library(MetaNet) library(igraph) # ========data manipulation library(dplyr) library(pcutils) 多组网络构建 比较基于不同组的网络稳定性非常重要。\n例如，我们有三组样本：NS、WS、CS，n=6（在实际研究中，n应该更大才能得到有意义的结果），我们可以获得每组的网络并进行比较。\n1 2 3 4 5 data(\u0026#34;otutab\u0026#34;, package = \u0026#34;pcutils\u0026#34;) table(metadata$Group) # check all rows matched all(colnames(otutab) == rownames(metadata)) 我们可以从整个网络中提取三组子网: 1 2 3 4 5 6 7 8 9 10 11 12 13 # extract three-group sub-nets hebing(otutab, metadata$Group) -\u0026gt; otutab_G head(otutab_G) # whole network t(otutab) -\u0026gt; totu c_net_calculate(totu) -\u0026gt; corr c_net_build(corr, r_threshold = 0.65) -\u0026gt; co_net group_net_par \u0026lt;- extract_sample_net(co_net, otutab_G, save_net = \u0026#34;../Group_subnet\u0026#34;) group_nets \u0026lt;- readRDS(\u0026#34;../Group_subnet.RDS\u0026#34;) names(group_nets) 或者为每个组专门构建一个网络： 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 data(\u0026#34;otutab\u0026#34;, package = \u0026#34;pcutils\u0026#34;) totu \u0026lt;- t(otutab) # check all rows matched all(rownames(totu) == rownames(metadata)) # Use RMT threshold or not? rmt \u0026lt;- FALSE group_nets \u0026lt;- lapply(levels(metadata$Group), \\(i){ totu[rownames(filter(metadata, Group == !!i)), ] -\u0026gt; t_tmp t_tmp[, colSums(t_tmp) \u0026gt; 0] -\u0026gt; t_tmp c_net_calculate(t_tmp) -\u0026gt; c_tmp if (rmt) { RMT_threshold(c_tmp, verbose = F, out_dir = \u0026#34;test/\u0026#34;) -\u0026gt; tmp_rmt r_thres \u0026lt;- tmp_rmt$r_threshold } else { r_thres \u0026lt;- 0.6 } c_net_build(c_tmp, r_threshold = r_thres, p_threshold = 0.01, delete_single = T) -\u0026gt; n_tmp Abundance_df \u0026lt;- data.frame(\u0026#34;Abundance\u0026#34; = colSums(t_tmp)) c_net_set(n_tmp, Abundance_df, taxonomy %\u0026gt;% select(\u0026#34;Phylum\u0026#34;), vertex_class = \u0026#34;Phylum\u0026#34;, vertex_size = \u0026#34;Abundance\u0026#34;) }) names(group_nets) \u0026lt;- levels(metadata$Group) 网络稳健测试 参考：M. B. WU Jun, Natural Connectivity of Complex Networks. Chinese Physics Letters. 27, 78902–078902 (2010).\n网络的稳健测试（Robust test）是计算自然联通度来进行的，因为它可以反映网络的稳定性。它认为复杂网络的功能和性能取决于当一个网络的部分节点被破坏（或移除）时，该网络保持其连通性的能力。\n来看下图，两个闭环网络。两个网络都含有a-e共5个节点，理论上，两个网络中任意节点间都是相通的，也就是从一个节点出发，无论选择怎样的路径，最终都能到达另一节点。 但是当我们进行节点或边的移除，比如删除ed，左边还能ed2条边相连，右边就要5条边才能连上，移除更多的边时右边的网络就会出现孤立节点。\n自然连通度从复杂网络的内部结构属性出发，通过计算网络中不同长度闭途径数目的加权和来刻画网络中替代途径的冗余性，其数学形式可以从网络邻接矩阵特征谱直接导出，具有明确的物理意义，但比较复杂。 自然连通度关于移除节点或边是单调减的，这意味着自然连通度能够精确刻画网络抗毁性的细微差别，且对于不连通图仍然有效。\n右下角这个例子就是逐步移出网络的节点，观察自然联通度的下降趋势，越平缓的说明稳定性越好\n具体来说，我们可以在删除节点后计算自然连接（一次从网络中删除多个节点，直到指定比例的节点消失）， 自然连通性的下降趋势水平表明了网络在受到一定程度的破坏后的连通性性能。\n1 2 3 #建议“reps”大于99，您可以将“threads\u0026gt;1”设置为使用并行计算。 robust_test(group_nets, partial = 0.5, step = 10, reps = 9, threads = 1) -\u0026gt; robust_res plot(robust_res, mode = 2) 网络群落稳定性 群落稳定性可以用各种指标来表征，如鲁棒性（Robustness）、脆弱性(Vulnerability)和凝聚力。\nRobustness 参考 Yuan, M. M. et al. Climate warming enhances microbial network complexity and stability. Nat. Clim. Chang. 11, 343–348 (2021).\n作者将网络的鲁棒性（Robustness）定义为网络在随机或有针对性的节点删除后对节点丢失的抵抗力。\n为了模拟随机物种去除，随机去除一定比例的节点，为了测试移除的物种对剩余物种的影响，作者计算了节点 i 的丰度加权平均相互作用强度（wMIS）：移除所选节点后，如果 wMISi = 0（与物种 i 相关的所有物种都被移除） ）或 wMISi \u0026lt; 0（物种 i 与其他物种没有足够的互惠关联以使其生存），则节点 i 被视为灭绝/孤立并从网络中删除。整个过程一直持续到所有物种的 wMIS 呈正数为止。 剩余节点的比例被报告为网络鲁棒性。\n1 2 3 #建议“reps”大于99，您可以将“threads\u0026gt;1”设置为使用并行计算。 robustness(group_nets, keystone = F, reps = 99, threads = 1) -\u0026gt; robustness_res plot(robustness_res, p_value2 = T) Vulnerability 参考 Yuan, M. M. et al. Climate warming enhances microbial network complexity and stability. Nat. Clim. Chang. 11, 343–348 (2021).\n为了评估网络内干扰传播的速度，全局效率被视为所有节点对效率的平均值，其通过成对节点之间的最短路径中的边的数量来计算。\n脆弱性(Vulnerability)反映了每个节点对全局效率的相对贡献，由网络中节点的最大脆弱性表示。\n$$ Vulnerability=\\max\\left(\\frac{E-E_i}E\\right) $$\n其中E是全局效率，Ei是去除节点i及其整个链路后的全局效率。图的全局效率计算为所有节点对效率的平均值：\n$$ E=\\frac1{n(n-1)}\\sum_{i\\neq j}\\frac1{d(i,j)} $$ 其中d（i，j）是节点i和j之间的最短路径长度。\n1 2 vulnerability_res \u0026lt;- vulnerability(group_nets, threads = 1) plot(vulnerability_res) Cohesion 参考 C. M. Herren, K. McMahon, Cohesion: A method for quantifying the connectivity of microbial communities (2017), doi:10.1038/ismej.2017.91.\n还有一个指标是cohesion凝聚力指数，通过分别表征群落中物种间的正负共现关系，来了解由正/负物种相互作用或由生态位相似性/差异引起群落连通性跨时间、空间或环境梯度的变化。\n首先从丰度表构建相关性矩阵，然后对它做零模型消除随机效应，这样对于每一个物种，都有与其他所有物种的相关性，然后把其中的正值负值分开取平均，就能得到每个物种的connectedness，再乘上丰度表，就能得到每一个样本的正负凝聚力了。\n$$ \\text{Cohesion}=\\sum_{i=1}^n\\text{abundance}_i\\times\\text{connectednes}s_i $$\n正Cohesion是由两两正相关产生的，可以反映样本中合作行为的程度，而负Cohesion可以表明群落成员之间竞争行为的程度。然后作者认为负：正Cohesion的绝对值越高的的群落更稳定。（Hernandez, D. J., David, A. S., Menges, E. S., Searcy, C. A. \u0026amp; Afkhami, M. E. Environmental stress destabilizes microbial networks. ISME J 15, 1722–1734 (2021).）\n1 2 3 4 5 #建议“reps”大于99，您可以将“threads\u0026gt;1”设置为使用并行计算。 Cohesion(otutab, reps = 9, threads = 1) -\u0026gt; cohesion_res p1 \u0026lt;- plot(cohesion_res, group = \u0026#34;Group\u0026#34;, metadata, mode = 1) + theme_bw() p2 \u0026lt;- plot(cohesion_res, group = \u0026#34;Group\u0026#34;, metadata, mode = 2) p1 + p2 References Yuan, M. M. et al. Climate warming enhances microbial network complexity and stability. Nat. Clim. Chang. 11, 343–348 (2021). M. B. WU Jun, Natural Connectivity of Complex Networks. Chinese Physics Letters. 27, 78902–078902 (2010). C. M. Herren, K. McMahon, Cohesion: A method for quantifying the connectivity of microbial communities (2017), doi:10.1038/ismej.2017.91. Hernandez, D. J., David, A. S., Menges, E. S., Searcy, C. A. \u0026amp; Afkhami, M. E. Environmental stress destabilizes microbial networks. ISME J 15, 1722–1734 (2021). ","date":"2025-04-16T00:00:00Z","image":"/p/metanet-8/images/nc_hu_b18b361e32b2bda1.png","permalink":"/p/metanet-8/","title":"MetaNet：多组学网络分析工具｜8.网络稳定性分析"},{"content":"在复杂网络分析中，模块（module）或社区（community）是指网络中连接更为紧密的子图结构。这些模块通常代表功能相关的节点群组，在生物网络中可能对应特定的功能单元或调控模块。MetaNet工具包提供了全面的功能，本文将详细介绍其核心方法和应用场景。\n软件主页：https://github.com/Asa12138/MetaNet 大家可以帮忙在github上点点star⭐️，谢谢🙏 详细英文版教程：https://bookdown.org/Asa12138/metanet_book/ 可以从 CRAN 安装稳定版：install.packages(\u0026quot;MetaNet\u0026quot;)\n依赖包 pcutils和igraph（需提前安装），推荐配合 dplyr 进行数据操作。\n1 2 3 4 5 6 library(MetaNet) library(igraph) # ========data manipulation library(dplyr) library(pcutils) 网络模块（module） 模块（module）或社区（community）是指包含节点的子图，其中节点之间的连接密度高于它们与图中其他节点的连接密度。用数学语言表达：当任何子图内部的连接数高于这些子图之间的连接数时，我们就说这个图具有社区结构。\n在MetaNet中，可以使用module_net()函数生成具有指定模块数的网络：\n1 2 3 4 set.seed(12) # 生成包含3个模块的网络，每个模块30个节点 test_module_net \u0026lt;- module_net(module_number = 3, n_node_in_module = 30) plot(test_module_net, mark_module = TRUE) 网络科学领域已开发出多种模块检测算法，各有其优势和适用场景：\n短随机游走法：基于随机游走的动态过程识别社区 社区矩阵的主特征向量法：利用矩阵特征向量进行谱聚类 模拟退火法：通过优化模块度指标寻找全局最优解 贪婪模块度优化：局部搜索算法，计算效率较高 \u0026hellip; MetaNet的module_detect()函数集成了这些主流算法，用户可以根据网络特性选择合适的方法。对于大型网络，建议先测试不同算法的运行时间和效果。\n1 2 # 使用快速贪婪算法检测模块 module_detect(co_net, method = \u0026#34;cluster_fast_greedy\u0026#34;) -\u0026gt; co_net_modu 模块筛选合并 实际分析中，我们常关注特定规模的模块。filter_n_module()函数支持多种筛选方式：\n• 按节点数筛选：保留节点数超过阈值的模块 • 按模块ID筛选：指定需要保留的特定模块 • 组合筛选：同时应用多种条件\n网络布局对模块展示效果至关重要，之前介绍了很多g_layout方法都可以在这里用上了。g_layout_circlepack()可生成基于模块的圆形堆积布局：\n1 2 3 4 par(mfrow = c(2, 2), mai = rep(1, 4)) # module detection module_detect(co_net, method = \u0026#34;cluster_fast_greedy\u0026#34;) -\u0026gt; co_net_modu get_v(co_net_modu)[, c(\u0026#34;name\u0026#34;, \u0026#34;module\u0026#34;)] %\u0026gt;% head() 1 2 3 4 5 6 7 ## name module ## 1 s__un_f__Thermomonosporaceae 10 ## 2 s__Pelomonas_puraquae 9 ## 3 s__Rhizobacter_bergeniae 1 ## 4 s__Flavobacterium_terrae 3 ## 5 s__un_g__Rhizobacter 14 ## 6 s__un_o__Burkholderiales 9 1 2 3 4 5 plot(co_net_modu, plot_module = T, mark_module = T, legend_position = c(-1.8, 1.6, 1.1, 1.3), edge_legend = F ) table(V(co_net_modu)$module) 1 2 3 4 5 ## ## 1 10 11 12 13 14 15 16 17 18 19 2 20 21 22 23 24 25 26 27 28 29 3 4 5 6 ## 36 18 35 16 17 12 21 15 6 4 4 24 2 3 2 2 2 2 3 2 3 2 27 23 35 23 ## 7 8 9 ## 33 18 61 1 2 3 4 5 6 7 8 9 10 11 # 保留节点数≥30的模块和ID为10的模块 co_net_modu2 \u0026lt;- filter_n_module(co_net_modu, n_node_in_module = 30, keep_id = 10) plot(co_net_modu2, plot_module = T, mark_module = T, legend_position = c(-1.8, 1.3, 1.1, 1.3)) # change group layout g_layout_circlepack(co_net_modu, group = \u0026#34;module\u0026#34;) -\u0026gt; coors plot(co_net_modu2, coors = coors, plot_module = T, mark_module = T, edge_legend = F) # extract some modules, delete =T will delete other modules. co_net_modu3 \u0026lt;- filter_n_module(co_net_modu, n_node_in_module = 30, keep_id = 10, delete = T) plot(co_net_modu3, coors, plot_module = T) 看看网络的components，一些太小的sub_graphs会影响模块，如果您不关心这些小型组件，则可以过滤掉它们。\n1 table(V(co_net_modu)$components) 1 2 3 ## ## 1 10 11 12 13 2 3 4 5 6 7 8 9 ## 418 2 2 2 2 6 4 2 2 3 2 3 3 1 2 3 4 5 6 co_net_modu4 \u0026lt;- c_net_filter(co_net_modu, components == 1) # re-do a module detection co_net_modu4 \u0026lt;- module_detect(co_net_modu4) g_layout_circlepack(co_net_modu4, group = \u0026#34;module\u0026#34;) -\u0026gt; coors plot(co_net_modu4, coors, plot_module = T) plot_module_tree()函数可展示模块的树状关系，揭示模块间的层次结构。当模块数量过多时，combine_n_module()可将模块合并到指定数量，便于高层次分析。\n1 2 3 4 5 6 7 8 9 # 展示模块树状图 p1 \u0026lt;- plot_module_tree(co_net_modu4, label.size = 0.6) # 将17个模块合并为5个 co_net_modu5 \u0026lt;- combine_n_module(co_net_modu4, 5) p2 \u0026lt;- plot_module_tree(co_net_modu5, label.size = 0.6) library(patchwork) p1+p2 模块pattern分析 在生物网络中，模块常对应功能相关的分子集合。我们还可以使用此网络模块指示具有相似表达/丰度的群集。但是我们应该首先过滤正边，因为模块检测仅考虑拓扑结构而不是边缘类型。过滤正相关边和模块检测后，将找到一些模块，很像是WGCNA里的基因模块，我们还可以使用module_eigen查看每个模块表达模式。\n1 2 3 4 5 6 7 8 data(\u0026#34;otutab\u0026#34;, package = \u0026#34;pcutils\u0026#34;) totu \u0026lt;- t(otutab) # filter positive edges c_net_filter(co_net, e_type == \u0026#34;positive\u0026#34;, mode = \u0026#34;e\u0026#34;) -\u0026gt; co_net_pos co_net_pos_modu \u0026lt;- module_detect(co_net_pos, n_node_in_module = 15, delete = T) g_layout_circlepack(co_net_pos_modu, group = \u0026#34;module\u0026#34;) -\u0026gt; coors1 plot(co_net_pos_modu, coors1, plot_module = T) module_eigen()和module_expression()可计算和可视化模块特征基因及表达模式：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 # map the original abundance table module_eigen(co_net_pos_modu, totu) -\u0026gt; co_net_pos_modu # plot the expression pattern p1 \u0026lt;- module_expression(co_net_pos_modu, totu, r_threshold = 0.6, facet_param = list(ncol = 4), plot_eigen = T ) + theme(axis.text.x = element_text(size = 5, angle = 90, vjust = 0.5)) # correlate to metadata env \u0026lt;- metadata[, 3:8] p2 \u0026lt;- cor_plot(get_module_eigen(co_net_pos_modu), env) + coord_flip() p1 / p2 + patchwork::plot_layout(heights = c(2, 1.4)) 1 2 3 4 5 6 # summary some variable according to modules. p3 \u0026lt;- summary_module(co_net_pos_modu, var = \u0026#34;Phylum\u0026#34;) + scale_fill_pc() p4 \u0026lt;- summary_module(co_net_pos_modu, var = \u0026#34;node_eigen_cor\u0026#34;) + scale_color_pc(palette = \u0026#34;col2\u0026#34;) p3 + p4 使用links_stat()对边进行汇总，发现大多数边都是从一个模块到同一个模块的（意味着模块检测正常）。\n1 links_stat(co_net_modu2, group = \u0026#34;module\u0026#34;) 拓扑角色分析 在我们确定了网络的这些模块后，可以根据Zi-Pi计算每个节点的拓扑角色。\nWithin-module connectivity (Zi):\n$$ Z_i= \\frac{\\kappa_i-\\overline{\\kappa_{si}}}{\\sigma_{\\kappa_{si}}} $$\n其中$κ_i$是节点i到其模块si中其他节点的链接数，$\\overline{\\kappa_{si}}$是si中所有节点的k的平均值，$\\sigma_{\\kappa_{si}}$是si中κ的标准偏差。\nAmong-module connectivity (Pi):\n$$ P_i=1-\\sum_{s=1}^{N_m}{\\left( {\\frac{\\kappa_{is}}{k_i}} \\right)^2} $$\n其中$\\kappa_{is}$是节点i到模块s中节点的链接数，$k_i$是节点i的总度数。\n参考R. Guimerà, L. Amaral, Functional cartography of complex metabolic networks (2005), doi:10.1038/nature03288.，基于Zi-Pi指标，节点可分为四类拓扑角色：\n外围节点(Peripherals)：Zi\u0026lt;2.5且Pi\u0026lt;0.62 模块枢纽(Module hubs)：Zi\u0026gt;2.5且Pi\u0026lt;0.62 连接节点(Connectors)：Zi\u0026lt;2.5且Pi\u0026gt;0.62 网络枢纽(Network hubs)：Zi\u0026gt;2.5且Pi\u0026gt;0.62 其中除了Peripherals的节点通常被视为网络的关键节点(keystone)，参考 S. Liu, H. Yu, Y. Yu, J. Huang, et al., Ecological stability of microbial communities in Lake Donghu regulated by keystone taxa. Ecological Indicators. 136, 108695 (2022).\n使用zp_analyse拿到模块角色并存储在顶点属性中，然后我们可以使用zp_plot（）可视化。我们可以看到模块中心是模块的中心，而连接器通常是介导不同模块的连接。\n1 2 zp_analyse(co_net_modu4) -\u0026gt; co_net_modu4 get_v(co_net_modu4)[, c(1, 16:21)] %\u0026gt;% head() 1 2 3 4 5 6 7 8 9 10 11 12 13 14 ## name components module original_module Ki Zi ## 1 s__un_f__Thermomonosporaceae 1 6 6 3 0.4358899 ## 2 s__Pelomonas_puraquae 1 11 11 15 1.9019177 ## 3 s__Rhizobacter_bergeniae 1 1 1 4 1.0951304 ## 4 s__Flavobacterium_terrae 1 3 3 4 1.8027756 ## 5 s__un_g__Rhizobacter 1 14 14 1 -1.0488088 ## 6 s__un_o__Burkholderiales 1 11 11 17 2.3326783 ## Pi ## 1 0.3750000 ## 2 0.3490305 ## 3 0.5714286 ## 4 0.0000000 ## 5 0.0000000 ## 6 0.1939058 1 2 3 # color map to roles co_net_modu6 \u0026lt;- c_net_set(co_net_modu4, vertex_class = \u0026#34;roles\u0026#34;) plot(co_net_modu6, coors, mark_module = T, labels_num = 0, group_legend_title = \u0026#34;Roles\u0026#34;) 1 2 3 library(patchwork) zp_plot(co_net_modu4, mode = 1) + zp_plot(co_net_modu4, mode = 3) References Koutrouli M, Karatzas E, Paez-Espino D and Pavlopoulos GA (2020) A Guide to Conquer the Biological Network Era Using Graph Theory. Front. Bioeng. Biotechnol. 8:34. doi: 10.3389/fbioe.2020.00034 Faust, K., and Raes, J. (2012). Microbial interactions: from networks to models. Nat. Rev. Microbiol. https://doi.org/10.1038/nrmicro2832. Y. Deng, Y. Jiang, Y. Yang, Z. He, et al., Molecular ecological network analyses. BMC bioinformatics (2012), doi:10.1186/1471-2105-13-113. R. Guimerà, L. Amaral, Functional cartography of complex metabolic networks (2005), doi:10.1038/nature03288. S. Liu, H. Yu, Y. Yu, J. Huang, et al., Ecological stability of microbial communities in Lake Donghu regulated by keystone taxa. Ecological Indicators. 136, 108695 (2022). ","date":"2025-04-15T00:00:00Z","image":"/p/metanet-7/index.en_files/figure-html/unnamed-chunk-5-1_hu_840041755cac7693.png","permalink":"/p/metanet-7/","title":"MetaNet：多组学网络分析工具｜7.网络模块分析"},{"content":"本文我们介绍网络的各种拓扑指标计算和分析。网络拓扑（Network Topology）是指网络中节点与边的连接模式所呈现的全局或局部结构特征。在生物组学研究中，拓扑分析能揭示分子互作网络的功能组织规律，是理解复杂生物系统的关键手段。\n软件主页：https://github.com/Asa12138/MetaNet 大家可以帮忙在github上点点star⭐️，谢谢🙏 详细英文版教程：https://bookdown.org/Asa12138/metanet_book/ 可以从 CRAN 安装稳定版：install.packages(\u0026quot;MetaNet\u0026quot;)\n依赖包 pcutils和igraph（需提前安装），推荐配合 dplyr 进行数据操作。\n1 2 3 4 5 6 library(MetaNet) library(igraph) # ========data manipulation library(dplyr) library(pcutils) 拓扑指标 全局拓扑（Global Topology）描述网络整体连接特性，局部拓扑（Local Topology）聚焦单个节点/边的结构重要性，MetaNet可以对构建好的网络进行多种拓扑指标的计算和分析。\n局部拓扑指标 Connectivity/Degree centrality\n衡量节点直接连接数量的基础指标，反映节点的局部影响力。\nBetweenness centrality\n统计节点出现在所有最短路径中的频率，识别网络中的\u0026quot;桥梁\u0026quot;节点。\nCloseness centrality\n计算节点到其他所有节点的平均最短距离倒数，体现信息传播效率。\nEigenvector centrality\n考虑邻居节点的重要性加权计算，适用于评估依赖高端连接的节点影响力。\nClustering coefficient\n量化节点邻居间的连接紧密程度，揭示网络局部模块化特性。\nEccentricity\n定义节点到网络中最远节点的距离，反映节点的全局位置特征。\nPageRank\n基于随机游走模型迭代计算的节点重要性，适用于有向网络（如基因调控网络）。\nKleinberg\u0026rsquo;s hub/authority centrality\n双向评价节点价值：hub（指向重要节点）和authority（被重要节点指向）。\n更细致的介绍可以看下表，来自MetaNet教程网页：\n全局拓扑指标 Average connectivity/degree\n网络中所有节点连接数的平均值，反映整体连接密度。\nAverage path length/Average geodesic distance\n所有节点对之间最短路径的平均值，衡量网络信息传递效率。\nGlobal efficiency/Geodesic efficiency\n节点间最短路径倒数和的标准化值（0-1），值越高表示信息流动越高效。\nCentralization of degree\n节点度分布的集中程度（0-1），值越高说明网络越依赖少数枢纽节点。\nCentralization of betweenness\n节点介数中心性的方差，反映网络对\u0026quot;桥梁\u0026quot;节点的依赖程度。\nCentralization of closeness\n接近中心性的分布偏态，表征网络核心-边缘结构的强度。\nCentralization of eigenvector centrality\n特征向量中心性的异质性，评估高端连接节点的支配性。\nDensity\n实际边数与最大可能边数的比值（0-1），描述网络的稀疏程度。\nAverage clustering coefficient\n所有节点局部聚类系数的均值，量化网络模块化趋势。\nTransitivity\n三元闭包比例（三角形结构占比），反映网络局部聚集特性。\nNatural connectivity\n基于网络特征谱的鲁棒性指标，值越高表示网络越稳定。\n一些潜在的生物网络分析应用场景：\n指标类型 典型应用场景 计算复杂度 Degree 快速筛选高连接分子 O(n) Betweenness 发现跨模块调控因子 O(n²) PageRank 识别关键调控基因 O(n log n) 指标 典型生物学意义 示例场景 Average path length 代谢物信号传导速度 短路径=快速调控响应 Centralization of degree 关键基因的支配性 转录因子网络分析 Transitivity 蛋白复合体的形成倾向 PPI网络功能模块检测 Natural connectivity 基因网络抗突变能力 疾病相关网络稳定性评估 MetaNet计算 MetaNet提供net_par()函数一键计算网络/节点/边三个层级的拓扑指标：\n1 2 3 4 5 6 7 8 library(MetaNet) library(igraph) # 示例1：获取Walther网络的所有指标（返回列表） make_graph(\u0026#34;Walther\u0026#34;) %\u0026gt;% net_par(mode = \u0026#34;all\u0026#34;) # 示例2：仅获取网络级全局指标 make_graph(\u0026#34;Walther\u0026#34;) %\u0026gt;% net_par(mode = \u0026#34;n\u0026#34;) 参数说明：\nmode：计算范围 \u0026quot;n\u0026quot;：网络级指标（如密度、平均路径长度） \u0026quot;v\u0026quot;：节点级指标（如度中心性、介数） \u0026quot;e\u0026quot;：边级指标（如边介数） \u0026quot;all\u0026quot;：全部指标（返回嵌套列表） 也可以通过c_net_index()计算并存储拓扑指标到网络中，便于后续分析和可视化：\n1 2 3 4 5 6 7 8 # 生成随机网络 go \u0026lt;- erdos.renyi.game(30, 0.25) %\u0026gt;% c_net_update() # 计算拓扑指标并存入网络属性 go \u0026lt;- c_net_index(go) # 查看节点属性表（前6行） head(get_v(go)) # 包含Degree、Betweenness等列 1 2 3 4 5 6 7 8 9 10 11 12 13 14 ## name label size v_group shape v_class color Degree ## 1 1 1 1 v_group1 circle v_class1 #a6bce3 12 ## 2 2 2 1 v_group1 circle v_class1 #a6bce3 5 ## 3 3 3 1 v_group1 circle v_class1 #a6bce3 6 ## 4 4 4 1 v_group1 circle v_class1 #a6bce3 10 ## 5 5 5 1 v_group1 circle v_class1 #a6bce3 10 ## 6 6 6 1 v_group1 circle v_class1 #a6bce3 8 ## Clustering_coefficient Betweenness Eccentricity Closeness Hub_score ## 1 0.3030303 28.397972 3 0.02127660 1.0000000 ## 2 0.2000000 6.660256 3 0.01666667 0.3248811 ## 3 0.2666667 6.069444 3 0.01694915 0.4109319 ## 4 0.2000000 28.380145 3 0.02000000 0.7223088 ## 5 0.2666667 21.248995 3 0.02000000 0.7955976 ## 6 0.2857143 11.864627 2 0.02000000 0.6595919 将节点度中心性映射为可视化属性：\n1 2 3 4 5 6 7 8 9 # get a metanet go \u0026lt;- erdos.renyi.game(30, 0.25) go \u0026lt;- c_net_update(go) par(mfrow = c(1, 2)) plot(go, vertex_size_range = c(5, 20), legend = F, main = \u0026#34;Same size\u0026#34;) # calculate topological indexes and store go \u0026lt;- c_net_index(go) head(get_v(go)) 1 2 3 4 5 6 7 8 9 10 11 12 13 14 ## name label size v_group shape v_class color Degree ## 1 1 1 1 v_group1 circle v_class1 #a6bce3 5 ## 2 2 2 1 v_group1 circle v_class1 #a6bce3 6 ## 3 3 3 1 v_group1 circle v_class1 #a6bce3 6 ## 4 4 4 1 v_group1 circle v_class1 #a6bce3 5 ## 5 5 5 1 v_group1 circle v_class1 #a6bce3 5 ## 6 6 6 1 v_group1 circle v_class1 #a6bce3 10 ## Clustering_coefficient Betweenness Eccentricity Closeness Hub_score ## 1 0.10000000 10.013921 3 0.01785714 0.4610096 ## 2 0.26666667 6.727020 3 0.01754386 0.6577058 ## 3 0.20000000 10.684066 3 0.01694915 0.5397470 ## 4 0.20000000 8.271461 3 0.01724138 0.4504656 ## 5 0.20000000 8.340112 3 0.01694915 0.4305194 ## 6 0.08888889 41.647508 3 0.02040816 0.8463154 1 2 3 # use vertex.size to indicate degree go \u0026lt;- c_net_set(go, vertex_size = \u0026#34;Degree\u0026#34;) plot(go, vertex_size_range = c(5, 20), legend = F, main = \u0026#34;Size map to degree\u0026#34;) 随机网络 随机网络（Random Network）是网络科学中的一类基础网络模型，其核心特征是网络连接遵循某种随机生成规则。Erdős-Rényi（ER）模型是最著名的代表：\n定义：给定N个节点，每对节点以概率p独立连接\n特性：\n度分布呈泊松分布 $ P(k) \\sim e^{-\\lambda}\\lambda^k/k! $ 平均聚类系数：$C \\approx p $ 平均路径长度：$L \\sim \\ln(N) $ 生物学意义：\n作为\u0026quot;零模型\u0026quot;（null model）用于评估真实生物网络的显著性 帮助识别网络中的非随机结构（如模块、枢纽节点） MetaNet提供两种随机网络生成方法用于网络分析对比：\n单次随机网络生成\n使用rand_net()基于Erdős-Rényi模型生成与目标网络（相同节点数和边数）的随机对照网络： 1 rand_net(co_net) -\u0026gt; random_net 批量生成与统计比较\n通过rand_net_par()生成多个随机网络并计算拓扑指标分布，再使用compare_rand()进行显著性比较： 1 2 3 4 rand_net_par(co_net, reps = 30) -\u0026gt; randp # 生成30个随机网络 net_par(co_net) -\u0026gt; pars # 计算原网络指标 compare_rand(pars, randp, # 指标对比 index = c(\u0026#34;Average_path_length\u0026#34;, \u0026#34;Clustering_coefficient\u0026#34;)) 复杂网络 在组学研究中构建的网络大多属于复杂网络，其核心特征包括无标度性、小世界性、模块化和层次性，具体定义如下所示：\n无标度性验证 使用fit_power()函数拟合网络的度分布幂律曲线：\n1 2 data(\u0026#34;c_net\u0026#34;, package = \u0026#34;MetaNet\u0026#34;) fit_power(co_net) 小世界性量化\n通过smallworldness()计算小世界指数σ： $$ \\sigma=\\frac{C/C_{random}}{L/L_{random}} $$ 其中C和L分别表示实际网络的聚类系数和平均路径长度，$C_{random}$和$L_{random}$为随机网络对应值。当σ\u0026gt;1时，网络具有小世界特性。\n1 smallworldness(co_net) # 示例输出：43.09368 网络的模块分析下一次介绍。\nReferences Koutrouli M, Karatzas E, Paez-Espino D and Pavlopoulos GA (2020) A Guide to Conquer the Biological Network Era Using Graph Theory. Front. Bioeng. Biotechnol. 8:34. doi: 10.3389/fbioe.2020.00034 Faust, K., and Raes, J. (2012). Microbial interactions: from networks to models. Nat. Rev. Microbiol. https://doi.org/10.1038/nrmicro2832. Y. Deng, Y. Jiang, Y. Yang, Z. He, et al., Molecular ecological network analyses. BMC bioinformatics (2012), doi:10.1186/1471-2105-13-113. ","date":"2025-04-14T00:00:00Z","image":"/p/metanet-6/images/node_topo_hu_6567168b7a277b42.png","permalink":"/p/metanet-6/","title":"MetaNet：多组学网络分析工具｜6.网络拓扑指标分析"},{"content":"上一篇推文介绍了MetaNet进行网络可视化以及各种布局方法，本文将介绍一些扩展绘图方法以及兼容工具。\n软件主页：https://github.com/Asa12138/MetaNet 大家可以帮忙在github上点点star⭐️，谢谢🙏 详细英文版教程：https://bookdown.org/Asa12138/metanet_book/ 可以从 CRAN 安装稳定版：install.packages(\u0026quot;MetaNet\u0026quot;)\n依赖包 pcutils和igraph（需提前安装），推荐配合 dplyr 进行数据操作。\n1 2 3 4 5 6 library(MetaNet) library(igraph) # ========data manipulation library(dplyr) library(pcutils) 兼容工具 ggplot2风格 如果你更熟悉ggplot2，可以使用as.ggig()函数将基础R绘图转换为ggplot2风格：\n1 2 as.ggig(multi1_with_anno) -\u0026gt; ggig class(ggig) 1 ## [1] \u0026#34;ggig\u0026#34; \u0026#34;list\u0026#34; 1 plot(ggig) 这样你就可以使用labs()、theme()、ggsave()和cowplot::plot_grid()等函数来制作更好的图形。\nGephi集成 处理大型数据集时，我推荐使用Gephi进行布局，运行比较快且美观。MetaNet提供了通过graphml格式文件与Gephi的接口：\n1 c_net_save(co_net, filename = \u0026#34;~/Desktop/test\u0026#34;, format = \u0026#34;graphml\u0026#34;) 将test.graphml导入Gephi并进行布局，从Gephi导出graphml文件：test2.graphml，然后在MetaNet中重新绘制：\n1 2 3 4 input_gephi(\u0026#34;~/Desktop/test2.graphml\u0026#34;) -\u0026gt; gephi c_net_plot(gephi$go, coors = gephi$coors, legend_number = T, group_legend_title = \u0026#34;Phylum\u0026#34;) Cytoscape集成 Cytoscape是另一个优秀的网络可视化软件，包含许多插件。将test.graphml导入Cytoscape进行布局，然后导出为cyjs文件，MetaNet可以读取：\n1 2 3 4 input_cytoscape(\u0026#34;~/Desktop/test2.cyjs\u0026#34;) -\u0026gt; cyto c_net_plot(co_net, coors = cyto$coors, legend_number = T, group_legend_title = \u0026#34;Phylum\u0026#34;) NetworkD3交互式可视化 NetworkD3可以生成基于JavaScript的交互式网络图，输出对象是适合网页的htmlwidgets：\n1 netD3plot(multi1_with_anno) 扩展绘图 模块图 使用mark_module=T在网络中标记你的模块，下次会具体介绍网络模块分析：\n1 2 test_module_net \u0026lt;- module_net(module_number = 3, n_node_in_module = 30) c_net_plot(test_module_net, mark_module = T,module_label = T,module_label_just=c(0.2,0.8)) pie节点 把网络里的节点直接画成pie图，不用在AI里面一个个拖过去了：\n1 2 3 4 data(\u0026#34;otutab\u0026#34;) data(\u0026#34;c_net\u0026#34;) hebing(otutab, metadata$Group) -\u0026gt; otutab_G head(otutab_G) 1 2 3 4 5 6 7 ## NS WS CS ## s__un_f__Thermomonosporaceae 1218.3333 1227.3333 1912.1667 ## s__Pelomonas_puraquae 2087.6667 873.5000 1241.6667 ## s__Rhizobacter_bergeniae 819.1667 781.3333 1164.8333 ## s__Flavobacterium_terrae 816.1667 944.6667 986.5000 ## s__un_g__Rhizobacter 821.8333 540.6667 953.3333 ## s__un_o__Burkholderiales 972.6667 327.5000 522.6667 1 2 3 4 co_net_f=c_net_filter(co_net,name%in%head(rownames(otutab_G),40)) c_net_plot(co_net_f,pie_value=otutab_G, vertex.shape=c(\u0026#34;pie\u0026#34;), #把你需要展示pie的节点的shape设置为pie pie_legend=T,color_legend=F,vertex_size_range=c(10,18)) 韦恩图网络 当集合里的点数量合适时，韦恩图网络算是个不错的展示方法\n1 2 3 4 data(otutab, package = \u0026#34;pcutils\u0026#34;) tab \u0026lt;- otutab[400:485, 1:3] head(tab) #0代表不存在 1 2 3 4 5 6 7 ## NS1 NS2 NS3 ## s__un_g__Brevundimonas 0 4 0 ## s__un_g__Shinella 0 10 12 ## s__Ramlibacter_henchirensis 0 9 6 ## s__Cystobacter_gracilis 3 4 17 ## s__un_g__Gordonia 0 6 16 ## s__un_f__Nannocystaceae 0 6 0 1 2 venn_net(tab) -\u0026gt; v_net plot(v_net) 两列边列表 1 2 3 4 5 6 twocol \u0026lt;- data.frame( \u0026#34;col1\u0026#34; = sample(letters, 30, replace = TRUE), \u0026#34;col2\u0026#34; = sample(c(\u0026#34;A\u0026#34;, \u0026#34;B\u0026#34;), 30, replace = TRUE) ) twocol_net \u0026lt;- twocol_edgelist(twocol) c_net_plot(twocol_net, g_layout_polygon(twocol_net),labels_num = \u0026#34;all\u0026#34;) 网络树 1 2 3 4 5 6 7 8 9 data(\u0026#34;otutab\u0026#34;, package = \u0026#34;pcutils\u0026#34;) cbind(taxonomy, num = rowSums(otutab))[1:20, ] -\u0026gt; test df2net_tree(test) -\u0026gt; ttt par(mfrow = c(1, 2)) plot(ttt, edge_legend = F, main = \u0026#34;Tree network\u0026#34;, legend_position = c(left_leg_x = -1.3), edge.arrow.size = 1,edge.arrow.width = 1,rescale=T) plot(ttt, coors = as_circle_tree(), legend = F, main = \u0026#34;Circle tree network\u0026#34;, edge.arrow.size = 0.5,edge.arrow.width = 1,rescale=T) 奥运五环图 1 olympic_rings_net() 这个也是上次讲的分组布局的应用了，g_layout函数布局，用下面的代码就可以绘制：\n1 2 3 4 5 6 7 8 9 10 11 12 13 r \u0026lt;- 1 pensize \u0026lt;- r / 6 rings_data \u0026lt;- data.frame( x = c(-2 * (r + pensize), -(r + pensize), 0, (r + pensize), 2 * (r + pensize)), y = c(r, 0, r, 0, r), color = c(\u0026#34;#0081C8\u0026#34;, \u0026#34;#FCB131\u0026#34;, \u0026#34;#000000\u0026#34;, \u0026#34;#00A651\u0026#34;, \u0026#34;#EE334E\u0026#34;) ) g1 \u0026lt;- module_net(module_number = 5, n_node_in_module = 30) plot(g1, coors = g_layout(g1, layout1 = rings_data[, 1:2], zoom1 = 1.2, zoom2 = 0.5), rescale = FALSE, legend = FALSE, main = \u0026#34;Olympic Rings\u0026#34;, vertex.frame.color = NA, edge.width = 0, vertex.color = setNames(rings_data$color, 1:5), vertex.size = 7 ) References Koutrouli M, Karatzas E, Paez-Espino D and Pavlopoulos GA (2020) A Guide to Conquer the Biological Network Era Using Graph Theory. Front. Bioeng. Biotechnol. 8:34. doi: 10.3389/fbioe.2020.00034 Faust, K., and Raes, J. (2012). Microbial interactions: from networks to models. Nat. Rev. Microbiol. https://doi.org/10.1038/nrmicro2832. Y. Deng, Y. Jiang, Y. Yang, Z. He, et al., Molecular ecological network analyses. BMC bioinformatics (2012), doi:10.1186/1471-2105-13-113. ","date":"2025-04-13T00:00:00Z","image":"/p/metanet-5/index.en_files/figure-html/unnamed-chunk-10-1_hu_4b960fbf3d789897.png","permalink":"/p/metanet-5/","title":"MetaNet：多组学网络分析工具｜5.扩展绘图与兼容工具"},{"content":"之前已经介绍了网络计算，构建以及各种注释了。本文将详细介绍MetaNet中的各种可视化方法，从基础绘图到高级布局技巧。\n软件主页：https://github.com/Asa12138/MetaNet 大家可以帮忙在github上点点star⭐️，谢谢🙏 详细英文版教程：https://bookdown.org/Asa12138/metanet_book/ 可以从 CRAN 安装稳定版：install.packages(\u0026quot;MetaNet\u0026quot;)\n最新的开发版本可以在 https://github.com/Asa12138/MetaNet 中找到：\n1 remotes::install_github(\u0026#34;Asa12138/MetaNet\u0026#34;, dependencies = T) 依赖包 pcutils和igraph（需提前安装），推荐配合 dplyr 进行数据操作。\n1 2 3 4 5 6 library(MetaNet) library(igraph) # ========data manipulation library(dplyr) library(pcutils) 绘图设置 在构建网络时，MetaNet已经设置了一些与可视化相关的内部属性。我们可以使用c_net_set()函数自定义这些属性以满足研究需求。\n如果需要更灵活地自定义网络图，可以使用c_net_plot()函数，它包含许多灵活的绘图参数：\n示例代码，尝试各种设置看看：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 c_net_plot(multi1_with_anno, labels_num = 5, vertex.color = get_cols(11, \u0026#34;col1\u0026#34;), vertex_size_range = c(3, 10), vertex.label.color = \u0026#34;red\u0026#34;, edge_width_range = c(0.5, 3), edge.color = c(\u0026#34;orange\u0026#34;, \u0026#34;green4\u0026#34;), edge.curved = 0.5, legend = T, legend_number = T, group_legend_order = c(\u0026#34;Microbiome\u0026#34;, \u0026#34;Metabolome\u0026#34;, \u0026#34;Transcriptome\u0026#34;), group_legend_title = c(\u0026#34;Phylum\u0026#34;, \u0026#34;Metabolome\u0026#34;, \u0026#34;Transcriptome\u0026#34;), edge_legend_title = \u0026#34;Correlation\u0026#34;, edge_legend_order = c(\u0026#34;positive\u0026#34;, \u0026#34;negative\u0026#34;), size_legend = T, size_legend_title = \u0026#34;Abundance\u0026#34;, width_legend = T, width_legend_title = \u0026#34;abs(r)\u0026#34;, lty_legend = T, lty_legend_title = \u0026#34;Omics relationship\u0026#34;) 使用params_list params_list是c_net_plot()中的一个特殊参数，它是一个包含参数的列表，可以方便地用于绘制一系列具有相同属性的网络图：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 node_colors \u0026lt;- setNames(get_cols(9, \u0026#34;col1\u0026#34;), unique(V(multi1_with_anno)$v_class)) params_list \u0026lt;- list( labels_num = 5, vertex.color = node_colors, vertex_size_range = c(3, 10), vertex.label.color = \u0026#34;red\u0026#34;, edge_width_range = c(0.5, 3), edge.color = c(\u0026#34;orange\u0026#34;, \u0026#34;green4\u0026#34;), edge.curved = 0.5, legend = T, legend_number = T, group_legend_order = c(\u0026#34;Microbiome\u0026#34;, \u0026#34;Metabolome\u0026#34;, \u0026#34;Transcriptome\u0026#34;), group_legend_title = c(\u0026#34;Phylum\u0026#34;, \u0026#34;Metabolome\u0026#34;, \u0026#34;Transcriptome\u0026#34;), edge_legend_title = \u0026#34;Correlation\u0026#34;, edge_legend_order = c(\u0026#34;positive\u0026#34;, \u0026#34;negative\u0026#34;), size_legend = T, size_legend_title = \u0026#34;Abundance\u0026#34;, width_legend = T, width_legend_title = \u0026#34;abs(r)\u0026#34;, lty_legend = T, lty_legend_title = \u0026#34;Omics relationship\u0026#34; ) c_net_plot(multi1_with_anno, params_list = params_list) 1 2 3 4 5 # 构建另一个多组学网络 multi1_with_anno2 \u0026lt;- c_net_filter(multi1_with_anno, v_group %in% c(\u0026#34;Microbiome\u0026#34;, \u0026#34;Metabolome\u0026#34;)) %\u0026gt;% c_net_filter(., e_class == \u0026#34;intra\u0026#34;, mode = \u0026#34;e\u0026#34;) c_net_plot(multi1_with_anno2, params_list = params_list) 网络布局 布局是网络可视化的重要组成部分，一个好的布局可以清晰地呈现信息。\n在MetaNet中，我们使用coors对象来存储布局的坐标。coors是一个具有\u0026quot;name\u0026quot;, \u0026ldquo;X\u0026rdquo;, \u0026ldquo;Y\u0026quot;三列的dataframe。\n基础布局 使用c_net_layout()获取特定布局方法的坐标：\n1 2 c_net_layout(co_net2, method = in_circle()) -\u0026gt; coors c_net_plot(co_net2, coors) 可用的基础布局方法包括：\nigraph布局：in_circle(), nicely(), on_grid(), on_sphere(), randomly(), with_dh(), with_fr(), with_gem(), with_graphopt(), with_kk(), with_lgl(), with_mds() metanet新布局方法：as_line(), as_arc(), as_polygon(), as_polyarc(), as_polycircle(), as_circle_tree(), as_multi_layer(), as_poly_sector() ggraph布局：\u0026ldquo;auto\u0026rdquo;, \u0026ldquo;backbone\u0026rdquo;, \u0026ldquo;centrality\u0026rdquo;, \u0026ldquo;circlepack\u0026rdquo;, \u0026ldquo;dendrogram\u0026rdquo;, \u0026ldquo;eigen\u0026rdquo;, \u0026ldquo;focus\u0026rdquo;, \u0026ldquo;hive\u0026rdquo;, \u0026ldquo;igraph\u0026rdquo;, \u0026ldquo;linear\u0026rdquo;, \u0026ldquo;manual\u0026rdquo;, \u0026ldquo;matrix\u0026rdquo;, \u0026ldquo;partition\u0026rdquo;, \u0026ldquo;pmds\u0026rdquo;, \u0026ldquo;stress\u0026rdquo;, \u0026ldquo;treemap\u0026rdquo;, \u0026ldquo;unrooted\u0026rdquo; 示例代码展示不同布局效果：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 go \u0026lt;- erdos.renyi.game(30, 0.25) # get a metanet go \u0026lt;- c_net_update(go) layout_methods \u0026lt;- list( as_star(), as_tree(), in_circle(), nicely(), on_grid(), on_sphere(), randomly(), with_dh(), with_fr(), with_gem(), with_graphopt(), with_kk(), with_lgl(), with_mds(), as_line(), as_arc(), as_polygon(), as_polyarc(), as_polycircle(3), as_circle_tree(), as_multi_layer(2), as_poly_sector() ) names(layout_methods) \u0026lt;- c( \u0026#34;as_star \u0026#34;, \u0026#34;as_tree \u0026#34;, \u0026#34;in_circle \u0026#34;, \u0026#34;nicely \u0026#34;, \u0026#34;on_grid \u0026#34;, \u0026#34;on_sphere \u0026#34;, \u0026#34;randomly \u0026#34;, \u0026#34;with_dh \u0026#34;, \u0026#34;with_fr \u0026#34;, \u0026#34;with_gem \u0026#34;, \u0026#34;with_graphopt \u0026#34;, \u0026#34;with_kk \u0026#34;, \u0026#34;with_lgl \u0026#34;, \u0026#34;with_mds\u0026#34;, \u0026#34;as_line\u0026#34;, \u0026#34;as_arc\u0026#34;, \u0026#34;as_polygon\u0026#34;, \u0026#34;as_polyarc\u0026#34;, \u0026#34;as_polycircle\u0026#34;, \u0026#34;as_circle_tree\u0026#34;, \u0026#34;as_multi_layer\u0026#34;, \u0026#34;as_poly_sector\u0026#34; ) par(mfrow = c(6, 4)) for (i in names(layout_methods)) { plot(go, layout_methods[[i]], legend = F, main = i, labels_num = 0) } 对于每种方法，可以在其中额外添加一些参数： 1 2 3 4 5 6 # get a metanet go \u0026lt;- erdos.renyi.game(30, 0.25) go \u0026lt;- c_net_update(go) plot(go, coors = with_fr()) plot(go, coors = with_fr(niter = 99, grid = \u0026#34;nogrid\u0026#34;)) as_polygon()很有趣，它可以绘制多边形形状的网络，您可以更改多边形的边数:\n变换布局 使用transform_comors可以转换布局，包括缩放，X/Y比，旋转角度，镜像，伪3D效果等：\n1 2 3 4 5 6 7 8 9 c_net_layout(multi1_with_anno)-\u0026gt;coors c_net_plot(multi1_with_anno, transform_coors(coors, scale = 0.8, aspect_ratio = 0.5, rotation = i, mirror_x = T, shear_x = 1) ) 分组布局 除c_net_layout()外，我们还为具有分组变量的网络提供了一种高级布局方法：g_layout()。 使用g_layout()可以轻松控制每个组的位置及其内部布局。g_layout()返回的也是coors对象，这意味着我们可以继续用g_layout()组合，实现疯狂套娃，高度自定义的布局！\ng_layout()在处理多组学网络或模块网络）时，是布局分组变量网络的极佳选择。\n首先，指定分组变量group 设置组间布局layout1，可选： 数据框或矩阵：行名为组名，两列分别为X和Y坐标 函数：c_net_layout()的各种布局方法（默认：in_circle()） 调整layout1的缩放比例zoom1 设置组内布局layout2（使用c_net_layout()的各种布局方法）， 用一个list，为每个组单独指定布局函数或者直接给一个坐标数据框。 调整layout2的缩放比例zoom2，可用向量分别控制各组缩放 设置show_big_layout = T可查看layout1的分布情况 1 2 3 4 5 # 为每个组设置圆形布局 g_layout(multi1_with_anno, group = \u0026#34;v_group\u0026#34;, layout1 = in_circle(), zoom1 = 10, layout2 = in_circle(), zoom2 = 5) -\u0026gt; g_coors plot(multi1_with_anno, coors = g_coors) 1 2 3 4 5 6 # 为每个组设置不同的布局 g_layout(multi1_with_anno, group = \u0026#34;v_group\u0026#34;, layout1 = in_circle(), zoom1 = 10, layout2 = list(in_circle(), with_fr(), as_polygon()), zoom2 = 3:5) -\u0026gt; g_coors plot(multi1_with_anno, coors = g_coors) tkplot手动调整大布局 1 2 3 4 5 6 7 8 9 10 11 12 13 14 # 首先获取网络骨架 get_group_skeleton(co_net, \u0026#34;v_class\u0026#34;) %\u0026gt;% clean_igraph() -\u0026gt; s_net # 使用tkplot进行手动调整 x \u0026lt;- igraph::tkplot(s_net) # 在tkplot窗口中移动节点到你喜欢的布局！ da \u0026lt;- igraph::tkplot.getcoords(x) igraph::tkplot.close(x) # 将调整后的坐标传递给layout1 g_layout(co_net, group = \u0026#34;v_class\u0026#34;, layout1 = da, zoom1 = 20, layout2 = in_circle(), zoom2 = c(1, 4, 2, 1, 3, 5)) -\u0026gt; g_coors plot(co_net, coors = g_coors) MetaNet还提供了一些预设的分组布局方法：\ng_layout_circlepack() g_layout_treemap() g_layout_backbone() g_layout_stress() g_layout_polyarc() g_layout_polygon() g_layout_polycircle() g_layout_multi_layer() 伪3D效果 g_layout_poly_sector() 示例代码：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 E(co_net)$color \u0026lt;- rep(\u0026#34;grey\u0026#34;, length(E(co_net))) plot(co_net, coors = g_layout_circlepack(co_net, group = \u0026#34;v_class\u0026#34;), legend = F, labels_num = 0, main = \u0026#34;g_layout_circlepack\u0026#34;) plot(co_net, coors = g_layout_polyarc(co_net, group = \u0026#34;v_class\u0026#34;), legend = F, labels_num = 0, main = \u0026#34;g_layout_polyarc\u0026#34;) plot(co_net, coors = g_layout_polycircle(co_net, group = \u0026#34;v_class\u0026#34;), legend = F, labels_num = 0, main = \u0026#34;g_layout_polycircle\u0026#34;) g1 \u0026lt;- module_net(3) plot(g1, coors = g_layout_multi_layer(g1, group = \u0026#34;v_class\u0026#34;, layout = on_grid()), legend = F, labels_num = 0, main = \u0026#34;g_layout_multi_layer\u0026#34; ) spatstat layout 1 2 3 4 5 6 7 8 9 10 11 12 13 14 if(!require(\u0026#34;spatstat\u0026#34;))install.packages(\u0026#34;spatstat\u0026#34;) E(co_net)$color \u0026lt;- rep(\u0026#34;grey\u0026#34;, length(E(co_net))) par(mfrow = c(2, 2)) poly_x \u0026lt;- c(0, 2, 2, 0) poly_y \u0026lt;- c(0, 0, 1, 1) win_poly \u0026lt;- spatstat.geom::owin(poly = list(x = poly_x, y = poly_y)) plot(win_poly) coors1 \u0026lt;- spatstat_layout(co_net, win_poly, type = \u0026#34;random\u0026#34;, mode = \u0026#34;surface\u0026#34;) plot(co_net, coors = coors1) coors1 \u0026lt;- spatstat_layout(co_net, win_poly, type = \u0026#34;regular\u0026#34;, mode = \u0026#34;surface\u0026#34;,order_by=\u0026#34;v_class\u0026#34;) plot(co_net, coors = coors1) coors2 \u0026lt;- spatstat_layout(co_net2, win_poly, type = \u0026#34;random\u0026#34;, mode = \u0026#34;boundary\u0026#34;) plot(co_net2, coors = coors2) 尝试画个五角星⭐️：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 library(spatstat.geom) create_star_window \u0026lt;- function(r_outer = 1, r_inner = 0.4, center = c(0, 0)) { # 创建五角星的10个顶点（外、内交替） theta \u0026lt;- seq(0, 2 * pi, length.out = 11)[-11] # 10个点 theta_outer \u0026lt;- theta[seq(1, 10, 2)] theta_inner \u0026lt;- theta[seq(2, 10, 2)] x \u0026lt;- c(r_outer * cos(theta_outer), r_inner * cos(theta_inner)) y \u0026lt;- c(r_outer * sin(theta_outer), r_inner * sin(theta_inner)) # 重新排序成首尾相连的路径 order_index \u0026lt;- c(1,6,2,7,3,8,4,9,5,10) x \u0026lt;- x[order_index] + center[1] y \u0026lt;- y[order_index] + center[2] # 构建 spatstat 的 owin 窗口 win \u0026lt;- owin(poly = list(x = x, y = y)) return(win) } win_star \u0026lt;- create_star_window() plot(co_net, coors = spatstat_layout(co_net, win_star, order_by=\u0026#34;v_class\u0026#34;)) 甚至可以画成地图：\n1 2 3 4 5 6 7 8 library(rnaturalearth) library(sf) # 获取非洲国家边界（1:50m精度） africa_sf \u0026lt;- ne_countries(continent = \u0026#34;Africa\u0026#34;, scale = 50, returnclass = \u0026#34;sf\u0026#34;) # 可视化 plot(st_geometry(africa_sf), col = \u0026#34;sandybrown\u0026#34;, main = \u0026#34;Africa Outline (1:50m)\u0026#34;, ) 1 plot(co_net, coors = spatstat_layout(co_net, africa_sf, type = \u0026#34;regular\u0026#34;, order_by=\u0026#34;v_class\u0026#34;)) MetaNet使用的是igraph的绘图方式，R的基础绘图，所以需要用pdf,png等设备保存图片。下一节介绍MetaNet和其他绘图方式如ggplot2，D3等的转换，以及MetaNet配合Gephi，Cytoscape等交互式软件使用。\nReferences Koutrouli M, Karatzas E, Paez-Espino D and Pavlopoulos GA (2020) A Guide to Conquer the Biological Network Era Using Graph Theory. Front. Bioeng. Biotechnol. 8:34. doi: 10.3389/fbioe.2020.00034 Faust, K., and Raes, J. (2012). Microbial interactions: from networks to models. Nat. Rev. Microbiol. https://doi.org/10.1038/nrmicro2832. Y. Deng, Y. Jiang, Y. Yang, Z. He, et al., Molecular ecological network analyses. BMC bioinformatics (2012), doi:10.1186/1471-2105-13-113. ","date":"2025-04-12T00:00:00Z","image":"/p/metanet-4/index.en_files/figure-html/unnamed-chunk-13-1_hu_1feb6a74e37c3b32.png","permalink":"/p/metanet-4/","title":"MetaNet：多组学网络分析工具｜4.布局和可视化"},{"content":"上一篇推文已经介绍了使用R包MetaNet进行网络计算和构建，本文将介绍如何对我们构建好的网络进行各种操作，包括添加注释和属性，筛选合并等。\n软件主页：https://github.com/Asa12138/MetaNet 大家可以帮忙在github上点点star⭐️，谢谢🙏 详细英文版教程：https://bookdown.org/Asa12138/metanet_book/ 可以从 CRAN 安装稳定版：install.packages(\u0026quot;MetaNet\u0026quot;)\n最新的开发版本可以在 https://github.com/Asa12138/MetaNet 中找到：\n1 remotes::install_github(\u0026#34;Asa12138/MetaNet\u0026#34;, dependencies = T) 依赖包 pcutils和igraph（需提前安装），推荐配合 dplyr 进行数据操作。\n1 2 3 4 5 6 library(MetaNet) library(igraph) # ========data manipulation library(dplyr) library(pcutils) MetaNet网络对象(metanet)继承自igraph类，因此可以使用所有igraph的函数，可以参考igraph manual 。构建网络的基本流程如下：\n1 2 3 4 5 6 7 8 9 10 11 12 # 加载数据 data(otutab, package=\u0026#34;pcutils\u0026#34;) t(otutab) -\u0026gt; totu # 计算相关性 c_net_calculate(totu, method=\u0026#34;spearman\u0026#34;) -\u0026gt; corr # 构建网络(设置相关系数阈值0.6，p值阈值0.05) c_net_build(corr, r_threshold =0.6, p_threshold = 0.05, delete_single=T) -\u0026gt; co_net # 查看网络类 class(co_net) 1 ## [1] \u0026#34;metanet\u0026#34; \u0026#34;igraph\u0026#34; 网络属性 MetaNet提供了便捷的函数获取网络、节点和边的属性，使用get_*()获取属性表格：\n1 2 # 获取网络整体属性 get_n(co_net) 1 2 ## n_type ## 1 single 1 2 # 获取节点属性(前5行) get_v(co_net) %\u0026gt;% head(5) 1 2 3 4 5 6 7 8 9 10 11 12 ## name v_group v_class size ## 1 s__un_f__Thermomonosporaceae v_group1 v_class1 4 ## 2 s__Pelomonas_puraquae v_group1 v_class1 4 ## 3 s__Rhizobacter_bergeniae v_group1 v_class1 4 ## 4 s__Flavobacterium_terrae v_group1 v_class1 4 ## 5 s__un_g__Rhizobacter v_group1 v_class1 4 ## label shape color ## 1 s__un_f__Thermomonosporaceae circle #a6bce3 ## 2 s__Pelomonas_puraquae circle #a6bce3 ## 3 s__Rhizobacter_bergeniae circle #a6bce3 ## 4 s__Flavobacterium_terrae circle #a6bce3 ## 5 s__un_g__Rhizobacter circle #a6bce3 1 2 # 获取边属性(前5行) get_e(co_net) %\u0026gt;% head(5) 1 2 3 4 5 6 7 8 9 10 11 12 ## id from to weight ## 1 1 s__un_f__Thermomonosporaceae s__Actinocorallia_herbida 0.6759546 ## 2 2 s__un_f__Thermomonosporaceae s__Kribbella_catacumbae 0.6742386 ## 3 3 s__un_f__Thermomonosporaceae s__Kineosporia_rhamnosa 0.7378741 ## 4 4 s__un_f__Thermomonosporaceae s__un_f__Micromonosporaceae 0.6236449 ## 5 5 s__un_f__Thermomonosporaceae s__Flavobacterium_saliperosum 0.6045747 ## cor p.value e_type width color e_class lty ## 1 0.6759546 0.0020739524 positive 0.6759546 #48A4F0 e_class1 1 ## 2 0.6742386 0.0021502138 positive 0.6742386 #48A4F0 e_class1 1 ## 3 0.7378741 0.0004730567 positive 0.7378741 #48A4F0 e_class1 1 ## 4 0.6236449 0.0056818984 positive 0.6236449 #48A4F0 e_class1 1 ## 5 0.6045747 0.0078660171 positive 0.6045747 #48A4F0 e_class1 1 MetaNet网络在构建时会自动设置一些内部属性，这些属性与后续分析和可视化密切相关：\n属性名称 描述 可视化关联 v_group 节点的大分组(通常一个组学数据产生一个分组) 节点形状 v_class 节点的分类或网络模块注释 节点颜色 size 节点的数值属性 节点大小 e_type 边的类型(通常根据相关性分为positive/negative) 边颜色 width 边的数值属性 边宽度 e_class 边的第二类型(通常根据节点分组分为intra/inter) 边线型 网络注释添加 在微生物组学或多组学分析中，我们经常需要将大量注释表格添加到网络对象中，例如物种丰度表、分类学表格等。\nc_net_annotate 可以方便添加注释表格，anno_tab是一个dataframe，如果注释节点，需要有一列name对应node name。如果注释边，需要有一列from和to对应边的起点和终点。\n添加点注释 注释数据框需要包含行名或\u0026quot;name\u0026quot;列，这些标识需要与metanet网络中的顶点名称匹配。使用c_net_annotate(mode = \u0026quot;v\u0026quot;)或等效的anno_vertex()函数时，系统会自动匹配顶点名称并合并表格。\n1 2 3 # 添加分类注释(Phylum级别) c_net_annotate(co_net, anno_tab = taxonomy[\u0026#34;Phylum\u0026#34;], mode=\u0026#34;v\u0026#34;) -\u0026gt; co_net1 get_v(co_net1) %\u0026gt;% head(5) 1 2 3 4 5 6 7 8 9 10 11 12 ## name v_group v_class size ## 1 s__un_f__Thermomonosporaceae v_group1 v_class1 4 ## 2 s__Pelomonas_puraquae v_group1 v_class1 4 ## 3 s__Rhizobacter_bergeniae v_group1 v_class1 4 ## 4 s__Flavobacterium_terrae v_group1 v_class1 4 ## 5 s__un_g__Rhizobacter v_group1 v_class1 4 ## label shape color Phylum ## 1 s__un_f__Thermomonosporaceae circle #a6bce3 p__Actinobacteria ## 2 s__Pelomonas_puraquae circle #a6bce3 p__Proteobacteria ## 3 s__Rhizobacter_bergeniae circle #a6bce3 p__Proteobacteria ## 4 s__Flavobacterium_terrae circle #a6bce3 p__Bacteroidetes ## 5 s__un_g__Rhizobacter circle #a6bce3 p__Proteobacteria 添加边注释 c_net_annotate(mode = \u0026quot;e\u0026quot;)或anno_edge()函数接受相同格式的注释数据框，但会自动匹配\u0026quot;from\u0026quot;和\u0026quot;to\u0026quot;列，方便用户进行网络连接的统计分析。\n1 2 3 4 5 6 7 8 # 创建边注释数据 anno \u0026lt;- data.frame(\u0026#34;from\u0026#34;=\u0026#34;s__un_f__Thermomonosporaceae\u0026#34;, \u0026#34;to\u0026#34;=\u0026#34;s__Actinocorallia_herbida\u0026#34;, new_atr=\u0026#34;new\u0026#34;) # 添加边注释 c_net_annotate(co_net, anno, mode=\u0026#34;e\u0026#34;) -\u0026gt; co_net1 get_e(co_net1) %\u0026gt;% head(5) 1 2 3 4 5 6 7 8 9 10 11 12 ## id from to weight ## 1 1 s__un_f__Thermomonosporaceae s__Actinocorallia_herbida 0.6759546 ## 2 2 s__un_f__Thermomonosporaceae s__Kribbella_catacumbae 0.6742386 ## 3 3 s__un_f__Thermomonosporaceae s__Kineosporia_rhamnosa 0.7378741 ## 4 4 s__un_f__Thermomonosporaceae s__un_f__Micromonosporaceae 0.6236449 ## 5 5 s__un_f__Thermomonosporaceae s__Flavobacterium_saliperosum 0.6045747 ## cor p.value e_type width color e_class lty new_atr ## 1 0.6759546 0.0020739524 positive 0.6759546 #48A4F0 e_class1 1 new ## 2 0.6742386 0.0021502138 positive 0.6742386 #48A4F0 e_class1 1 \u0026lt;NA\u0026gt; ## 3 0.7378741 0.0004730567 positive 0.7378741 #48A4F0 e_class1 1 \u0026lt;NA\u0026gt; ## 4 0.6236449 0.0056818984 positive 0.6236449 #48A4F0 e_class1 1 \u0026lt;NA\u0026gt; ## 5 0.6045747 0.0078660171 positive 0.6045747 #48A4F0 e_class1 1 \u0026lt;NA\u0026gt; 使用igraph方法添加属性 如果您有一个向量，并且确定与网络的顶点名称匹配，则可以使用igraph方法来注释（不建议），边注释向量相同。有关更多详细信息，请参阅igraph手册。\n1 2 3 4 5 # 添加节点属性 V(co_net1)$new_attri \u0026lt;- seq_len(length(co_net1)) # 添加边属性 E(co_net1)$new_attri \u0026lt;- \u0026#34;new attribute\u0026#34; 网络属性设置 c_net_set()函数可以方便地添加多个注释表格并设置网络可视化相关的内部属性。\n为网络添加多个注释表格后，可以通过指定列名来设置以下属性：\nvertex_group：顶点分组（可指定一个或多个列） vertex_class：顶点类别 vertex_size：顶点大小 edge_type：边类型 edge_class：边类别 edge_width：边宽度 系统会自动完成以下设置：\n颜色方案 线条类型 节点形状 图例生成 只需使用plot()函数即可生成基础网络图。如需进一步自定义可视化效果，下一次会详细介绍网络布局和可视化。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 # 加载多组学数据 data(\u0026#34;multi_test\u0026#34;, package=\u0026#34;MetaNet\u0026#34;) data(\u0026#34;c_net\u0026#34;, package=\u0026#34;MetaNet\u0026#34;) # 构建多组学网络 multi1 \u0026lt;- multi_net_build(list(Microbiome=micro, Metabolome=metab, Transcriptome=transc)) plot(multi1) # 设置节点分类属性 multi1_with_anno \u0026lt;- c_net_set(multi1, micro_g, metab_g, transc_g, vertex_class=c(\u0026#34;Phylum\u0026#34;,\u0026#34;kingdom\u0026#34;,\u0026#34;type\u0026#34;)) # 设置节点大小属性 multi1_with_anno \u0026lt;- c_net_set(multi1_with_anno, data.frame(\u0026#34;Abundance1\u0026#34;=colSums(micro)), data.frame(\u0026#34;Abundance2\u0026#34;=colSums(metab)), data.frame(\u0026#34;Abundance3\u0026#34;=colSums(transc)), vertex_size=paste0(\u0026#34;Abundance\u0026#34;,1:3)) # 绘制网络 plot(multi1_with_anno) 网络操作 网络过滤/子网络 正确设置网络后，你可能有时候需要分析整个网络的一部分（尤其是在多组学分析中），c_net_filter()可以方便地获取子网络，您可以放置大量的过滤条件（例如dplyr::filter）并获得所需的子网络。\n1 2 3 4 5 6 7 8 # 过滤特定组和边类型 multi2 \u0026lt;- c_net_filter(multi1_with_anno, v_group %in% c(\u0026#34;Microbiome\u0026#34;,\u0026#34;Metabolome\u0026#34;)) %\u0026gt;% c_net_filter(., e_class==\u0026#34;intra\u0026#34;, mode=\u0026#34;e\u0026#34;) # 绘制对比图 par(mfrow=c(2,1)) plot(multi1_with_anno, lty_legend=T, main=\u0026#34;Before filtering network\u0026#34;) plot(multi2, lty_legend=T, main=\u0026#34;After filtering network\u0026#34;) 网络合并 如果你有多个网络并想将它们组合在一起，你可以使用c_net_union()函数：\n1 2 3 4 5 6 data(\u0026#34;c_net\u0026#34;) plot(co_net) plot(co_net2) co_net_union \u0026lt;- c_net_union(co_net, co_net2) plot(co_net_union) 网络骨架提取 若需根据分组统计边的来源和目标，summ_2col函数提供了简便的实现方式。\n参数direct = F表示处理无向关系，此时\u0026quot;a-b\u0026quot;和\u0026quot;b-a\u0026quot;会被合并统计为同一种边类型。\n1 2 3 4 5 6 # 添加Phylum分类注释 c_net_annotate(co_net, select(taxonomy,\u0026#34;Phylum\u0026#34;), mode=\u0026#34;e\u0026#34;) -\u0026gt; co_net1 # 统计Phylum间的连接 df \u0026lt;- get_e(co_net1)[,c(\u0026#34;Phylum_from\u0026#34;,\u0026#34;Phylum_to\u0026#34;)] summ_2col(df, direct=F) %\u0026gt;% arrange(-count) -\u0026gt; Phylum_from_to 1 2 # 桑基图展示 pcutils::my_sankey(Phylum_from_to, dragY=T, fontSize=10, width=600, numberFormat=\u0026#34;,.4\u0026#34;) 1 2 # 环形布局展示 links_stat(co_net1, topN=5, group=\u0026#34;Phylum\u0026#34;, e_type=\u0026#34;all\u0026#34;) 1 2 3 4 5 6 7 8 # 设置Phylum分类 c_net_set(co_net, select(taxonomy,\u0026#34;Phylum\u0026#34;)) -\u0026gt; co_net1 # 提取网络骨架 get_group_skeleton(co_net1, Group=\u0026#34;Phylum\u0026#34;) -\u0026gt; ske_net # 绘制骨架图 plot(ske_net, vertex.label=NA) 网络保存导出 MetaNet支持多种格式的网络导出：\n1 2 3 4 5 6 7 8 # 导出为数据框格式 c_net_save(co_net, filename=\u0026#34;My_net\u0026#34;, format=\u0026#34;data.frame\u0026#34;) # 导出为graphml格式(兼容Gephi等软件) c_net_save(co_net, filename=\u0026#34;My_net\u0026#34;, format=\u0026#34;graphml\u0026#34;) # 从文件加载网络 c_net_load(\u0026#34;My_net.graphml\u0026#34;)-\u0026gt;mynet References Koutrouli M, Karatzas E, Paez-Espino D and Pavlopoulos GA (2020) A Guide to Conquer the Biological Network Era Using Graph Theory. Front. Bioeng. Biotechnol. 8:34. doi: 10.3389/fbioe.2020.00034 Faust, K., and Raes, J. (2012). Microbial interactions: from networks to models. Nat. Rev. Microbiol. https://doi.org/10.1038/nrmicro2832. Y. Deng, Y. Jiang, Y. Yang, Z. He, et al., Molecular ecological network analyses. BMC bioinformatics (2012), doi:10.1186/1471-2105-13-113. ","date":"2025-04-11T00:00:00Z","image":"/p/metanet-3/images/anno_hu_6537b44cfb7f7d8b.png","permalink":"/p/metanet-3/","title":"MetaNet：多组学网络分析工具｜3.网络注释与操作"},{"content":"上一篇推文简单介绍了网络基本概念和用于组学网络分析的R包MetaNet，这里我们具体介绍网络分析第一步，网络计算和构建。\n软件主页：https://github.com/Asa12138/MetaNet 大家可以帮忙在github上点点star⭐️，谢谢🙏 详细英文版教程：https://bookdown.org/Asa12138/metanet_book/ 可以从 CRAN 安装稳定版：install.packages(\u0026quot;MetaNet\u0026quot;)\n最新的开发版本可以在 https://github.com/Asa12138/MetaNet 中找到：\n1 remotes::install_github(\u0026#34;Asa12138/MetaNet\u0026#34;, dependencies = T) 依赖包 pcutils和igraph（需提前安装），推荐配合 dplyr 进行数据操作。\n1 2 3 4 5 6 library(MetaNet) library(igraph) # ========data manipulation library(dplyr) library(pcutils) 预处理 在构建各类组学网络之前，不同组学数据（如微生物组、转录组、代谢组等）需要经过适当的预处理，以确保数据质量并提高网络分析的可靠性。\ntrans函数包含许多归一化方法，适用于预处理不同的组学：\n方法 描述 cpm 百万分计数 minmax 线性转换到(min, max)区间 acpm 百万分计数后进行反双曲正弦转换 log1 log(n+1)转换 total 除以总和 max 除以最大值 frequency 除以总和并乘以非零项数量，使非零项平均值为1 normalize 使边际平方和等于1 range 标准化到(0,1)范围(同minmax(0,1)) rank 用递增秩替换丰度值，零保持不变 rrank 类似rank但使用相对秩，最大为1 pa 将x缩放到存在/不存在尺度(0/1) standardize 缩放到零均值和单位方差 hellinger \u0026ldquo;total\u0026quot;方法的平方根 log Anderson等(2006)建议的对数变换 alr 加性对数比(\u0026lsquo;alr\u0026rsquo;)变换(Aitchison 1986) clr 中心对数比(\u0026lsquo;clr\u0026rsquo;)变换(Aitchison 1986) rclr 稳健clr(\u0026lsquo;rclr\u0026rsquo;)，允许数据包含零 1 trans(otutab, method = \u0026#34;log1\u0026#34;) %\u0026gt;% head() 此外，rm_low()， guolv() ， hebing() 函数可以帮助过滤或聚合组学数据，这些函数在数据清洗和特征选择阶段非常有用。\n成对关系计算 成对关系是网络构建的基础。由于实验数据通常相对稀少，我们主要依赖统计推断来确定成对关系，当然如果你已经有确定的关系了就可以跳过这一部分直接去构建网络即可。目前主要有两种统计方式：\n相似性或相关性：例如Spearman、Pearson、Bray-Curtis等。可以计算配对特征之间的相似性矩阵，并使用随机化数据重复计算显著性。最终在网络中保留有意义的相似性。 回归分析：将特征分为源和目标，使用多元回归计算特征之间的关系。\n还有一些工具使用特殊方法来优化网络构建，如SparCC等。\nCorrelation 相关性是描述两个变量协调运动程度的统计术语。相关性计算是所有组学网络分析软件的第一步，有许多方法可以获取ρ和p值。然而，随着组学数据规模越来越大，一些方法变得非常耗时且计算资源密集。\nMetaNet提供了c_net_calculate()函数，可以快速计算单个表或两个表之间的相关性，返回包含ρ和p值的coor对象。\n1 2 3 4 # 单表计算 t(otutab) -\u0026gt; totu c_net_calculate(totu, method = \u0026#34;spearman\u0026#34;) -\u0026gt; corr corr 1 2 3 ## Correlation table: ## Table dimensions: 485 rows, 485 columns ## Use method: spearman 1 2 3 4 # 双表计算 metadata[,3:10] -\u0026gt; env c_net_calculate(totu, env, method = \u0026#34;spearman\u0026#34;) -\u0026gt; corr2 corr2 1 2 3 ## Correlation table: ## Table dimensions: 485 rows, 8 columns ## Use method: spearman 对于大型输入表，计算可能需要较长时间，可以保存结果稍后读取：\n1 2 3 c_net_calculate(matrix(rnorm(1000*100), ncol=1000), method=\u0026#34;spearman\u0026#34;) -\u0026gt; corr save_corr(corr, \u0026#34;../saved_corr1\u0026#34;) read_corr(\u0026#34;../saved_corr1\u0026#34;) -\u0026gt; corr_new 性能测试表明，计算1000个特征的表相关性约需0.2秒，保存的.corr文件大小约6MB。时间、内存消耗和保存文件大小大致随特征数量的平方线性增加。\nc_net_calculate的计算速度比其他R包快得多，特别是在特征数量很大的情况下：\nDistance 在群落分析中，我们需要理解相异指数(距离)。vegan::vegdist()函数提供了基于丰度计算的广泛距离度量。此外，还有一些包含系统发育数据的距离度量，如\u0026quot;unifrac\u0026rdquo;、\u0026ldquo;beta_mpd\u0026rdquo;、\u0026ldquo;beta_mntd\u0026quot;和\u0026quot;phylosor\u0026quot;等。相似性指数通常是距离指数的倒数或1-distance。\n我们也可以使用c_net_calculate()来计算距离：\n1 2 c_net_calculate(otutab, method=\u0026#34;bray\u0026#34;) -\u0026gt; sim_df sim_df 1 2 3 ## Similarity (1-Distance) table: ## Table dimensions: 18 rows, 18 columns ## Use method: bray 常用的群落不相似性指数包括：\n距离系数 描述 Manhattan 曼哈顿距离计算每个维度中坐标的绝对差之和。适用于具有分类变量或属性的数据。 Euclidean 欧几里得距离计算多维空间中两点之间的直线距离。通常用于连续且没有分类属性的数据。 Canberra 堪培拉距离是曼哈顿距离的加权版本，强调坐标之间微小差异的重要性。常用于生态数据分析。 Clark Clark距离测量两个样本之间不同非零属性的比例。 Bray Bray距离基于丰度绝对差异之和计算样本间不相似性。 Kulczynski Kulczynski距离基于共有属性比例的算术平均值测量样本间相似性。 Jaccard Jaccard距离基于独特属性的比例测量样本间不相似性。常用于生态学中的二元数据。 Gower Gower距离是曼哈顿距离的泛化，适用于包括分类和连续变量的混合数据类型。 AltGower AltGower距离是Gower距离的替代形式，使用替代方法标准化连续变量。 Morisita Morisita距离基于共享属性的频率测量样本间不相似性，强调稀有属性。 Horn Horn距离基于共享属性比例的几何平均值测量样本间不相似性。 Mountford Mountford距离基于共享属性比例的算术平均值的倒数测量样本间不相似性。 Raup Raup距离基于共享属性的概率测量样本间不相似性。 Binomial Binomial距离基于观察共享属性的概率测量样本间不相似性。 Chao Chao距离是Jaccard距离的修正，调整了对稀有物种的欠采样。 Cao Cao距离是Chao距离的修正，加入了物种丰度信息。 Mahalanobis Mahalanobis距离考虑变量间相关性，测量多维空间中两个样本的距离。 Chisq Chisq距离基于分类变量间的卡方距离计算样本间不相似性。 Chord Chord距离基于多维空间中点之间角度计算样本间不相似性。 Hellinger Hellinger距离基于平方根转换丰度的平方差之和的平方根测量样本间不相似性。 Aitchison Aitchison距离是对组成数据的转换，允许在对数比空间中进行欧几里得距离计算。 Robust Aitchison 稳健Aitchison距离是Aitchison距离的稳健版本，减少了数据中异常值的影响。 Unifrac Unifrac距离基于系统发育树中的进化距离测量微生物群落间不相似性。 Beta MPD Beta MPD(平均系统发育距离)基于物种对的平均系统发育距离测量两个群落间的系统发育多样性。 Beta MNTD Beta MNTD(平均最近分类单元距离)基于平均最近分类单元距离测量两个群落间的系统发育周转。 Phylosor Phylosor距离基于系统发育树中共享分支的比例测量群落间不相似性。 Others NetCoMi包中还有一些其他可用于网络构建的方法：\nBiweight Midcorrelation bicor() from WGCNA package\nCCLasso (R code on GitHub)\nCCREPE (ccrepe package)\nSPRING (SPRING package)\ngCoda (R code on GitHub)\npropr (propr package)\nKullback-Leibler divergence (KLD) (KLD() from LaplacesDemon package)\nJeffrey divergence (own code using KLD() from LaplacesDemon package)\nJensen-Shannon divergence (own code using KLD() from LaplacesDemon package)\n网络构建 手动阈值构建 如果已经完成了c_net_calculate()步骤，那么可以通过c_net_build()轻松获得网络(metanet对象，继承自igraph对象)。一些常见属性会自动设置。\n1 2 c_net_build(corr, r_threshold =0.6, p_threshold =0.05, delete_single=T) -\u0026gt; co_net co_net 1 2 3 4 5 6 7 8 9 10 11 12 13 ## =================================== metanet ==================================== ## IGRAPH 179b785 UNW- 483 1513 -- ## + attr: n_type (g/c), name (v/c), v_group (v/c), v_class (v/c), size ## | (v/n), label (v/c), shape (v/c), color (v/c), id (e/n), from (e/c), ## | to (e/c), weight (e/n), cor (e/n), p.value (e/n), e_type (e/c), width ## | (e/n), color (e/c), e_class (e/c), lty (e/n) ## + edges from 179b785 (vertex names): ## [1] s__un_f__Thermomonosporaceae--s__Actinocorallia_herbida ## [2] s__un_f__Thermomonosporaceae--s__Kribbella_catacumbae ## [3] s__un_f__Thermomonosporaceae--s__Kineosporia_rhamnosa ## [4] s__un_f__Thermomonosporaceae--s__un_f__Micromonosporaceae ## [5] s__un_f__Thermomonosporaceae--s__Flavobacterium_saliperosum ## + ... omitted several edges 1 plot(co_net) 对于多表分析，可以使用multi_net_build()计算和构建网络：\n1 2 3 data(\u0026#34;multi_test\u0026#34;, package=\u0026#34;MetaNet\u0026#34;) multi_net_build(list(Microbiome=micro, Metabolome=metab, Transcriptome=transc)) -\u0026gt; multi1 plot(multi1) RMT优化 基于相关性的关联网络方法因其简单的计算过程和噪声容限而最常用。然而，大多数涉及关联网络分析的研究使用任意阈值(通常使用r\u0026gt;0.6, p\u0026lt;0.05)，因此构建的网络是主观的而非客观的。\n这个问题已经通过基于随机矩阵理论(RMT)的方法部分解决，该方法能够从微阵列数据(以及其他组学数据)中自动识别网络构建的适当阈值。(Y. Deng, Y. Jiang, Y. Yang, Z. He, et al., Molecular ecological network analyses. BMC bioinformatics (2012), doi:10.1186/1471-2105-13-113.)\n使用RMT_threshold()，我们可以找到一个合适的r_threshold来构建噪声最小的网络。较大的log_LE、较小的log_LW、较小的log_see、较大的p_ks_test表明r_threshold对于有意义的网络构建更好。可以更改阈值范围以进行更精细的计算。（但其实也很难确定一个非常合适的结果，几个指标指示的也不一致😂，有时候还是跟着文献自定义阈值方便）\n1 2 3 RMT_threshold(corr, out_dir=\u0026#34;../RMT_temp/\u0026#34;, min_threshold=0.5, max_threshold=0.9, step=0.02, verbose=T) -\u0026gt; rmt_res plot(rmt_res) 可以在RMT_threshold()中设置gif=TRUE并获取gif文件，以观察不同r阈值下特征值间距的分布。\n边表格 如果已经从其他方法(数据库)获得了数据的成对关系，可以将其形成边列表并使用c_net_from_edgelist构建网络：\n1 2 3 data(\u0026#34;edgelist\u0026#34;, package=\u0026#34;MetaNet\u0026#34;) dnet \u0026lt;- c_net_from_edgelist(arc_count, direct=T) plot(dnet) 其他 如果已经有其他格式的网络，如pajek、lgl、graphml、dimacs、graphdb、gml和dl，可以使用c_net_load将其读取为metanet对象。也可以使用graph_from_*函数获取igraph对象，然后使用c_net_update将其转换为metanet对象。\n1 2 3 4 5 6 7 8 9 g1 \u0026lt;- graph_from_lcf(12, c(5, -5), 6) class(g1) ## [1] \u0026#34;igraph\u0026#34; plot(g1) c_net_update(g1) -\u0026gt; g2 class(g2) ## [1] \u0026#34;metanet\u0026#34; \u0026#34;igraph\u0026#34; plot(g2) 通过本文介绍的方法，可以了解从组学数据预处理到网络构建的流程，为后续的网络分析和生物学解释奠定基础。MetaNet包提供的这些功能使得组学网络分析变得更加高效。下一篇就将介绍如何给我们构建好的网络进行各种操作，包括添加注释和属性，筛选合并等。\nReferences Koutrouli M, Karatzas E, Paez-Espino D and Pavlopoulos GA (2020) A Guide to Conquer the Biological Network Era Using Graph Theory. Front. Bioeng. Biotechnol. 8:34. doi: 10.3389/fbioe.2020.00034 Faust, K., and Raes, J. (2012). Microbial interactions: from networks to models. Nat. Rev. Microbiol. https://doi.org/10.1038/nrmicro2832. Y. Deng, Y. Jiang, Y. Yang, Z. He, et al., Molecular ecological network analyses. BMC bioinformatics (2012), doi:10.1186/1471-2105-13-113. ","date":"2025-04-10T00:00:00Z","image":"/p/metanet-2/images/pairwise_relationship_hu_383f7ee51bf1717d.png","permalink":"/p/metanet-2/","title":"MetaNet：多组学网络分析工具｜2.网络计算和构建"},{"content":"网络分析是各种组学数据分析的重要组成部分。我在刚接触生信时对这类分析还挺感兴趣的，一边学一边写了个R包MetaNet。因为同类型工具有不少，包括在线网站，交互界面等，也就一直没有推广，主要是给自己用的。但现在整着整着感觉也比较系统了，也有一些别的工具不好实现的功能，想发出来让大家用用看。大家也可以帮忙在github上点点star⭐️，谢谢🙏\n软件主页：https://github.com/Asa12138/MetaNet 详细英文版教程：https://bookdown.org/Asa12138/metanet_book/ ps，我是看到\u0026quot;生信益站\u0026quot;有篇推文翻译了一下我的MetaNet的README文件，收获了近2万阅读量😂想起来搞一下这个。最近可能也会先提交一个preprint。\nIntroduction 网络（Network）或图（Graph）是用于描述复杂系统中元素间相互关系的数学结构，广泛应用于生物学、计算机科学、社会学等领域。网络由节点（Node/Vertex） 和 边（Edge） 组成，其中节点代表系统中的实体（如基因、蛋白质、用户），边表示它们之间的连接关系（如相互作用、通信、调控）。\n基本类型 1. 无向图（Undirected Graph）\n无向图中的连接没有方向性，节点之间的关系是双向的。例如，在社交网络中，两个人成为好友意味着彼此互为邻居。在生物学中，基因共表达网络就是一种典型的无向图，连接表示两个基因的表达水平具有相关性。\n2. 有向图（Directed Graph）\n有向图中的连接带有方向，表示单向关系。例如，在信号通路中，一个蛋白质可能激活或抑制另一个蛋白质，这种调控关系具有明确的指向性。生物学中常用不同箭头样式表示不同类型的调控作用（如激活、抑制）。\n3. 加权图（Weighted Graph）\n加权图的每条连接都有一个权重值，用于表示关系的强度或重要性。例如，在蛋白质相互作用网络中，权重可以反映实验验证的可靠性；在基因共表达网络中，权重可能代表相关性的大小。\n4. 二分图（Bipartite Graph）\n二分图的节点可以分成两组，连接只存在于不同组的节点之间。例如，在药物-靶点网络中，药物和靶点属于不同的组，连接表示某种药物作用于某个靶点。\n5. 多重边图（Multi-edge Graph）\n多重边图允许同一对节点之间存在多条连接。例如，在知识图谱中，两个实体之间可能有多种不同类型的关系（如基因A既调控基因B，又与基因B有物理相互作用）。\n6. 超图（Hypergraph）\n超图的连接可以同时关联多个节点，适用于描述复杂的高阶关系。例如，在代谢网络中，一个生化反应可能涉及多个底物和产物，超图可以更自然地表示这种多分子参与的相互作用。\n7. 树（Tree）\n树是一种特殊的无向图，其中任意两个节点之间只有一条路径相连，且没有环路。例如，进化树描述物种之间的演化关系，基因本体树则用于表示功能分类的层级结构。\n8. 连通图（Connected Graph）\n在连通图中，任意两个节点之间至少存在一条路径。如果网络不连通，则可能由多个独立子图组成，例如某些微生物群落网络可能包含多个互不关联的物种群体。\n9. 完全图（Complete Graph）\n完全图中每对不同的节点之间都有一条连接。虽然在实际生物网络中较少见，但在某些模拟分析中，完全图可以作为理论参考模型。\n10. 团（Clique）\n团是指无向图中一个节点子集，其中每对节点之间都有连接。在蛋白质相互作用网络中，高度紧密的团可能代表蛋白质复合物或功能模块。\n组学应用 在生物医学，尤其是近期的组学研究中，网络可以捕获任何类型的生物实体之间的关联，例如蛋白质，基因，小分子，代谢产物，配体，疾病，药物甚至数据库记录。网络分析提供系统级视角解析复杂机制，覆盖从分子到生态系统的多层次研究，是整合多组学数据的重要方法。\n1. 蛋白质-蛋白质相互作用网络（PPIs） 蛋白质-蛋白质相互作用网络通过实验或计算方法揭示蛋白质间的物理结合或功能协作关系，是研究细胞信号转导、复合体形成和疾病机制的重要工具。例如，癌症相关蛋白通常在PPI网络中呈现高度连接性，帮助识别关键调控节点和潜在药物靶点。\n2. 序列相似性网络（SSNs） 序列相似性网络基于基因或蛋白质序列的相似性构建，用于分析基因家族进化、功能分化和水平基因转移。通过设定相似性阈值，可聚类同源基因并预测新功能，广泛应用于酶家族分类（如P450超家族）和宏基因组数据分析。\n3. 基因调控网络（GRNs） 基因调控网络描述转录因子与靶基因间的调控关系，整合ChIP-seq、RNA-seq等数据以揭示发育、疾病或环境响应中的调控逻辑。例如，干细胞多能性网络中的核心转录因子（如OCT4、SOX2）通过GRN分析被确定为命运决定的关键因子。\n4. 代谢网络（Metabolic Networks） 代谢网络以生化反应为基础，节点代表代谢物，边表示酶催化的反应，用于模拟代谢通量并优化生物合成途径。在微生物工程中，此类网络指导设计高产菌株，如抗生素或生物燃料的微生物生产。\n5. 基因共表达网络（Gene Co-expression Networks） 基因共表达网络通过转录组数据（如RNA-seq）计算基因表达相关性，挖掘功能模块或生物标记物。例如，WGCNA算法可识别与特定性状相关的共表达模块，如植物抗逆性或肿瘤亚型特征基因群。\n6. 物种互作网络（Species Interaction Networks） 物种互作网络（如食物网、共生网络）量化生态系统中物种间的捕食、竞争或互利关系，评估生态稳定性和多样性。网络拓扑分析可预测物种灭绝的级联效应，助力保护生物学研究。\n当然还有其他很多很多重要的生物学研究中的网络了。\n常用工具 Cytoscape是最流行的生物网络可视化分析平台，支持多种网络类型和插件扩展。 Gephi是专注于大规模网络可视化的工具，提供多种布局算法和动态网络分析功能。 igraph是高效的网络分析库，支持R/Python等语言。 STRING是综合蛋白质相互作用数据库，提供实验验证和预测的相互作用数据。 BioGRID是全面的PPI数据库，包含超过100万条蛋白质相互作用记录。 GENIE3基于机器学习算法推断基因调控网络，适用于单细胞RNA-seq数据。 iRegulon整合ChIP-seq和motif数据预测转录调控网络。KEGG Mapper是基于KEGG数据库的代谢网络分析工具。 COBRA Toolbox是MATLAB平台的代谢网络建模工具，支持通量平衡分析。 WGCNA是加权基因共表达网络分析的标准工具。 EcoNet是专为生态网络设计的分析工具。 NetworkX是Python的通用复杂网络分析库。 NetworkAnalyst是在线网络分析平台，支持多种网络类型。 MetaNet MetaNet 是一个专注于生物组学（omics）数据的综合性网络分析 R 包。旨在帮助研究人员快速构建、分析和可视化多组学数据的复杂网络，支持高通量数据的处理（如超过 10,000 个节点的网络）。以下是其主要特点：\n多组学整合分析\n支持多种组学数据（如微生物组、转录组等）的联合网络分析，便于挖掘跨组学关联。\n高效计算\n• 快速计算相关性网络（如物种间互作），通过并行计算加速分析。\n• 优化大数据处理能力，适用于大规模网络。\n可视化与兼容性\n• 提供多种网络布局算法，支持交互式可视化。\n• 可导出至常用工具（如 Gephi、Cytoscape）或与 ggplot2 集成绘图。\n拓扑分析\n计算丰富的网络拓扑指标（包括生态网络稳定性），适用于复杂网络研究。\n安装 可以从 CRAN 安装稳定版：install.packages(\u0026quot;MetaNet\u0026quot;)\n最新的开发版本可以在 https://github.com/Asa12138/MetaNet 中找到：\n1 remotes::install_github(\u0026#34;Asa12138/MetaNet\u0026#34;, dependencies = T) 依赖包 pcutils和igraph（需提前安装），推荐配合 dplyr 进行数据操作。\n1 2 3 4 5 6 library(MetaNet) library(igraph) # ========data manipulation library(dplyr) library(pcutils) 快速使用 下图是 MetaNet 的整体开发框架，包括数据处理，网络构建，网络分析，网络可视化和其他功能，核心是一个继承igraph的metanet对象：\n下面以一个微生物共丰度网络为例（是我最早也是做得最多的分析）：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 # 加载示例数据（otu表，来自pcutils包） data(\u0026#34;otutab\u0026#34;, package = \u0026#34;pcutils\u0026#34;) # 转置数据（微生物组分析通常需要行为样本，列为物种/OTU） t(otutab) -\u0026gt; totu # totu: 转置后的矩阵，行=样本，列=物种/OTU # 计算物种间相关性矩阵（使用Spearman秩相关） c_net_calculate( totu, method = \u0026#34;spearman\u0026#34; # 可选\u0026#34;pearson\u0026#34;/\u0026#34;spearman\u0026#34;/\u0026#34;kendall\u0026#34; ) -\u0026gt; corr # corr: 存储相关系数和p值的矩阵 # 构建共现网络（基于阈值筛选） c_net_build( corr, r_threshold = 0.65, # 保留|r| ≥ 0.65的边 p_threshold = 0.05, # 保留p \u0026lt; 0.05的边（统计显著性） delete_single = TRUE # 删除无连接的孤立节点 ) -\u0026gt; co_net # co_net: 生成的metanet网络对象 # 添加网络属性（注释节点信息） co_net \u0026lt;- c_net_set( co_net, taxonomy, # 数据框：物种分类信息（如Phylum列） data.frame(\u0026#34;Abundance\u0026#34; = colSums(totu)), # 节点属性：总丰度 vertex_class = \u0026#34;Phylum\u0026#34;, # 用Phylum分类作为节点颜色分组 vertex_size = \u0026#34;Abundance\u0026#34; # 用Abundance值调整节点大小 ) # 计算网络布局（可视化坐标） coors \u0026lt;- c_net_layout( co_net, method = nicely() # 使用默认美观布局 ) # 绘制网络图（默认显示节点、边和分类颜色） c_net_plot(co_net, coors = coors) 再来一个多组学网络构建：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 data(\u0026#34;multi_test\u0026#34;, package = \u0026#34;MetaNet\u0026#34;) # build a multi-network multi1 \u0026lt;- multi_net_build(list(Microbiome = micro, Metabolome = metab, Transcriptome = transc), r_threshold = 0.6, # 保留|r| ≥ 0.6的边 p_threshold = 0.05) # set vertex_class multi1_with_anno \u0026lt;- c_net_set(multi1, micro_g, metab_g, transc_g, vertex_class = c(\u0026#34;Phylum\u0026#34;, \u0026#34;kingdom\u0026#34;, \u0026#34;type\u0026#34;)) # set vertex_size multi1_with_anno \u0026lt;- c_net_set(multi1_with_anno, data.frame(\u0026#34;Abundance1\u0026#34; = colSums(micro)), data.frame(\u0026#34;Abundance2\u0026#34; = colSums(metab)), data.frame(\u0026#34;Abundance3\u0026#34; = colSums(transc)), vertex_size = paste0(\u0026#34;Abundance\u0026#34;, 1:3) ) plot(multi1_with_anno) 后续我会发推文具体介绍MetaNet分析流程的每个功能模块，大家也可以先直接看详细英文版教程：https://bookdown.org/Asa12138/metanet_book/，我也尽可能为每个函数编写了详细的help文件和examples，欢迎大家提出宝贵意见。\nReferences Koutrouli M, Karatzas E, Paez-Espino D and Pavlopoulos GA (2020) A Guide to Conquer the Biological Network Era Using Graph Theory. Front. Bioeng. Biotechnol. 8:34. doi: 10.3389/fbioe.2020.00034 Faust, K., and Raes, J. (2012). Microbial interactions: from networks to models. Nat. Rev. Microbiol. https://doi.org/10.1038/nrmicro2832. Deng, Y., Jiang, Y., Yang, Y., He, Z., Luo, F., and Zhou, J. (2012). Molecular ecological network analyses. BMC Bioinf. https://doi.org/10.1186/1471-2105-13-113. Girvan, M., and Newman, M.E.J. (2002). Community structure in social and biological networks. Proc. Natl. Acad. Sci. 99, 7821–7826. https://doi.org/10.1073/pnas.122653799. Shannon, P., Markiel, A., Ozier, O., Baliga, N.S., Wang, J.T., Ramage, D., Amin, N., Schwikowski, B., and Ideker, T. (2003). Cytoscape: a software environment for integrated models of biomolecular interaction networks. Genome Res. 13, 2498–2504. https://doi.org/10.1101/gr.1239303. ","date":"2025-03-27T00:00:00Z","image":"/p/metanet-1/images/bio_net_hu_1fd0e9eff4ff51d7.png","permalink":"/p/metanet-1/","title":"MetaNet：多组学网络分析工具｜1.基础介绍"},{"content":"Introduction 在生物信息学分析中，许多软件的中间文件或输出结果是数据库格式，例如 .db 文件。同时，很多生物数据库的存储和下载格式也是数据库格式。因此，掌握数据库的基本操作，不仅有助于数据存储，还能提高数据查询和处理的效率。\nSQLite 是一款轻量级的嵌入式关系型数据库管理系统，它不需要单独的服务器进程，而是直接将数据库存储在单个文件中。SQLite 具有以下特点：\n零配置：无需安装或管理，直接使用。 跨平台：支持 Windows、Linux、Mac 等主流操作系统。 高性能：对于单机应用场景，SQLite 处理速度比 MySQL 和 PostgreSQL 更快。 小体积：核心库只需几百 KB 内存，适用于资源受限的环境。 在数据分析领域，R 语言与 SQLite 结合可以带来以下优势：\n处理超出内存限制的大型数据集。 实现数据的持久化存储。 利用 SQL 进行高效查询和数据操作。 便于不同编程语言之间的数据共享。 本文将介绍 SQLite 的基础使用方法，并讲解如何在 R 语言中操作 SQLite 数据库。\nSQLite 基础使用 SQLite 不需要单独安装，可以直接从官网 https://sqlite.org/下载命令行工具，或者使用编程语言（如 Python、R）的 SQLite 接口。\nSQLite 提供了一系列实用的点命令(dot commands)来管理数据库，这些命令以点(.)开头，下面介绍几个常用的命令：\n.open 命令 .open 命令用于打开或创建数据库文件：\n语法：.open 数据库文件名.db 功能： 如果指定的数据库文件不存在，则会创建一个新的数据库文件 如果数据库已存在，则打开该数据库 示例：.open test.db 打开或创建test.db数据库 .databases 命令 .databases 命令用于显示当前连接的数据库信息：\n语法：.databases 功能： 显示所有附加的数据库 显示每个数据库的文件路径和名称 主数据库通常名为\u0026quot;main\u0026quot; 示例输出： 1 2 3 seq name file --- --------------- ---------------------------------------------------------- 0 main /path/to/your/database.db 其他相关命令 .exit 命令\n语法：.exit 功能：退出SQLite命令行界面 .quit 命令\n语法：.quit 功能：与.exit相同，退出SQLite命令行界面 .help 命令\n语法：.help 功能：显示所有可用的点命令及其简要说明 .tables 命令\n语法：.tables [模式] 功能：列出当前数据库中的所有表，可选使用模式匹配 .schema 命令\n语法：.schema [表名] 功能：显示表的创建语句(DDL)，不指定表名则显示所有表的创建语句 这些点命令为SQLite数据库的管理提供了便捷的操作方式，特别适合在命令行环境下使用。需要注意的是，这些命令不是标准SQL语句，而是SQLite特有的命令行工具命令。\n常用 SQL 语句 SQLite 几乎完全兼容常见的 SQL 语句规范，因此可以直接编写和执行标准的 SQL 语句。\n标准 SQL (Structured Query Language) 语句具有以下主要特点：\n结构化与声明式 非过程化语言：SQL 是声明式语言，用户只需指定\u0026quot;做什么\u0026quot;而非\u0026quot;如何做\u0026quot; 结构化语法：由清晰的关键字、子句和表达式组成 标准化 遵循 ANSI/ISO 标准：有 SQL-86、SQL-89、SQL-92、SQL:1999、SQL:2003、SQL:2008、SQL:2011、SQL:2016 等多个标准版本 跨平台兼容：基本语法在大多数关系型数据库中通用 分类明确 SQL 语句主要分为几大类： DDL (数据定义语言)\n用于定义数据库结构 主要语句：CREATE, ALTER, DROP, TRUNCATE, RENAME 示例：CREATE TABLE employees (id INT, name VARCHAR(50)); DML (数据操作语言)\n用于操作数据 主要语句：SELECT, INSERT, UPDATE, DELETE, MERGE 示例：UPDATE employees SET salary = 5000 WHERE id = 101; DCL (数据控制语言)\n用于权限控制 主要语句：GRANT, REVOKE, DENY 示例：GRANT SELECT ON employees TO user1; TCL (事务控制语言)\n用于事务管理 主要语句：COMMIT, ROLLBACK, SAVEPOINT, SET TRANSACTION 示例：COMMIT; 语法特点 不区分大小写：但通常关键字用大写，标识符用小写 使用分号结束：多数数据库要求语句以分号(;)结尾 可嵌套子查询：支持多层嵌套查询 支持注释：单行(\u0026ndash;)和多行(/* */)注释 功能特点 强大的查询能力：支持复杂条件、多表连接、聚合函数等 数据完整性保障：支持主键、外键、约束等机制 事务支持：ACID特性(原子性、一致性、隔离性、持久性) 视图支持：可以创建虚拟表简化复杂查询 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 -- 创建表 CREATE TABLE users ( id INTEGER PRIMARY KEY AUTOINCREMENT, name TEXT NOT NULL, age INTEGER, email TEXT UNIQUE, created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP ); -- 插入数据 INSERT INTO users (name, age, email) VALUES (\u0026#39;张三\u0026#39;, 25, \u0026#39;zhangsan@example.com\u0026#39;); INSERT INTO users (name, age, email) VALUES (\u0026#39;李四\u0026#39;, 30, \u0026#39;lisi@example.com\u0026#39;); -- 查询数据 SELECT * FROM users WHERE age \u0026gt; 20; SELECT name, age FROM users ORDER BY age DESC LIMIT 5; SELECT COUNT(*) FROM users; -- 更新数据 UPDATE users SET age = 26 WHERE name = \u0026#39;张三\u0026#39;; -- 删除数据 DELETE FROM users WHERE id = 1; SQLite 高级查询 1 2 3 4 5 6 7 8 9 10 11 12 13 14 -- 聚合查询 SELECT age, COUNT(*) FROM users GROUP BY age; -- 多表连接查询 CREATE TABLE orders ( id INTEGER PRIMARY KEY AUTOINCREMENT, user_id INTEGER, amount REAL, FOREIGN KEY(user_id) REFERENCES users(id) ); SELECT users.name, orders.amount FROM users JOIN orders ON users.id = orders.user_id; SQLite 导出表格 使用 SQLite 命令行工具导出 导出为 CSV 格式\n1 2 3 4 5 6 sqlite3 your_database.db .headers on .mode csv .output data.csv SELECT * FROM your_table; .output stdout 导出为 SQL 格式（包含表结构和数据） 1 sqlite3 your_database.db .dump your_table \u0026gt; output.sql 数据库管理工具 如果不习惯使用 SQL 语句操作数据库，可以使用可视化工具，如 DB Browser for SQLite 或 SQLite Expert，这些工具可以方便地：\n创建/删除数据库。 设计表结构。 执行 SQL 查询。 导入/导出数据。 在 R 中操作 SQLite 在 R 语言中操作 SQLite 可以安装 RSQLite 和 sqldf 包：\n1 2 3 4 install.packages(\u0026#34;RSQLite\u0026#34;) library(RSQLite) install.packages(\u0026#34;sqldf\u0026#34;) library(sqldf) RSQLite：提供 R 与 SQLite 之间的接口。 sqldf：允许使用 SQL 查询 R 中的数据框。 连接 SQLite 数据库 1 2 3 4 5 6 7 8 # 创建/连接数据库 con \u0026lt;- dbConnect(SQLite(), \u0026#34;example.sqlite\u0026#34;) # 查看数据库中的表 dbListTables(con) # 读取数据库中的表 dbReadTable(con, \u0026#34;table_name\u0026#34;) 写入数据 1 2 3 4 5 6 7 8 9 # 创建数据框 df \u0026lt;- data.frame( id = 1:3, name = c(\u0026#34;Alice\u0026#34;, \u0026#34;Bob\u0026#34;, \u0026#34;Charlie\u0026#34;), score = c(85, 92, 78) ) # 写入数据库 dbWriteTable(con, \u0026#34;students\u0026#34;, df, overwrite = TRUE) 查询数据 1 2 3 4 5 6 7 # 查询数据库内容 result \u0026lt;- dbGetQuery(con, \u0026#34;SELECT * FROM students WHERE score \u0026gt; 80\u0026#34;) print(result) # 使用参数化查询防止 SQL 注入 query \u0026lt;- \u0026#34;SELECT * FROM students WHERE name = ?\u0026#34; result \u0026lt;- dbGetQuery(con, query, params = list(\u0026#34;Alice\u0026#34;)) sqldf 直接查询 sqldf 允许直接使用 SQL 语句查询 R 数据框，而无需创建 SQLite 数据库。\n1 2 3 4 5 6 7 8 9 10 11 12 library(sqldf) # 创建数据框 df \u0026lt;- data.frame( name = c(\u0026#34;Alice\u0026#34;, \u0026#34;Bob\u0026#34;, \u0026#34;Charlie\u0026#34;), age = c(25, 30, 28), score = c(85, 92, 78) ) # 直接使用 SQL 进行查询 result \u0026lt;- sqldf(\u0026#34;SELECT name, score FROM df WHERE age \u0026gt; 26\u0026#34;) print(result) 关闭数据库连接 操作完成后，务必关闭数据库连接以释放资源：\n1 dbDisconnect(con) SQLite 作为轻量级数据库，在数据存储和查询方面具有极高的灵活性。结合 R 语言的分析能力，可以实现高效的数据处理和自动化工作流。此外，sqldf 提供了一种在 R 语言环境下直接使用 SQL 查询数据框的方式，使得数据分析更加直观高效。\nReferences https://cloud.tencent.com/developer/article/1938211 https://blog.51cto.com/u_16099343/13578231 https://blog.csdn.net/m0_73500130/article/details/142286358 https://www.5axxw.com/questions/simple/2jy747 ","date":"2025-03-26T00:00:00Z","image":"/p/sqlite-r/images/R-C_hu_154d127bd26f14a5.png","permalink":"/p/sqlite-r/","title":"SQLite使用基础以及在R中操作数据库"},{"content":"Introduction 陆生植物将大部分光合作用固定的碳转化为木质纤维素（lignocellulose），这是一种由纤维素（cellulose）、半纤维素（hemicellulose）、果胶（pectin）和木质素（lignin）等聚合物组成的复合物。在植物生命周期中，这种复杂的基质为其提供结构完整性，并抵御植食性动物和病原体的侵害，因此大部分木质纤维素生物质由腐生生物和碎屑食性生物在碎屑食物网中分解。木质纤维素可作为生物燃料生产的原料，但由于纤维素的准结晶性、半纤维素对纤维素微纤维的复杂包覆以及木质素对多糖组分的穿插和包裹，其难以被酶解处理。在工业过程中，通常通过剧烈的化学和物理预处理来克服这种抗降解性，而生物体则能在生理耐受条件下实现木质纤维素的分解。\n降解机制的多样性 生物体通过多种方式降解木质纤维素，包括氧化攻击、半纤维素酶的作用以及动物的机械破坏，这些方式降低了木质纤维素的抗降解性，从而为解聚酶提供了更好的作用条件。碳水化合物活性酶及其底物结合蛋白的信息被整合在CAZy数据库中。近年来，肽模式识别技术被用于基于功能预测将糖苷水解酶（GH）和辅助活性酶（AA）家族分类为亚家族，并为挖掘基因组数据中的新酶提供工具。本文重点关注CAZy分类中的糖苷水解酶（GHs）和辅助活性酶（AAs），后者作为氧化还原酶，常与GHs协同作用。\n纤维素和半纤维素的酶解 在自然界中，纤维素和半纤维素的降解通过多种碳水化合物活性酶的协同作用实现。糖苷水解酶（GHs）是主要酶类，负责切断纤维素和半纤维素中的糖苷键。多糖酯酶通过去除甲基、乙酰基和酚酯基团辅助GHs发挥作用。在某些情况下，多糖裂解酶也参与解聚过程。不同生物类群中，GH酶的组合因物种、进化压力和环境生态位的不同而存在显著差异。例如，丝状真菌主要产生GH7家族酶，而原核生物则依赖GH48家族酶。尽管GH7家族酶曾被认为仅存在于真菌中，但最新研究表明它们也存在于其他真核生物中。尽管该家族酶在序列和结构上具有高度相似性，但其表面性质可能存在显著差异。其他GH家族则表现出更大的序列和功能多样性。\n多糖的氧化解聚 近年来，一种新的氧化酶学机制被发现，用于切断多糖链，这类酶被称为裂解多糖单加氧酶（LPMOs）。其中一些最初被归类为GH61家族纤维素酶，另一些则属于碳水化合物结合模块家族33。目前，降解纤维素的LPMOs被归入AA9家族（主要为真菌酶）和AA10家族（主要为细菌酶）。LPMOs不仅能作用于结晶纤维素，还能降解半纤维素。它们通过平坦活性位点中的铜原子直接氧化攻击聚合物链。此外，非酶解机制如褐腐真菌中的铁依赖芬顿化学反应也能降解纤维素。\n木质素的解聚 木质素是一种异质性烷基芳香族聚合物，由三种甲氧基化程度不同的芳香醇组成。自然界中存在多种木质素修饰策略，但能降解木质素的生物远少于降解纤维素的生物。白腐担子菌和一些木质素降解细菌通过分泌过氧化物酶和漆酶等氧化酶降解木质素，生成一系列异质性芳香族化合物，最终被分泌生物或其他微生物代谢。褐腐真菌虽缺乏木质素降解酶，但利用小分子活性物质解聚木质素，切断丙基侧链并脱甲氧基，随后在其他部位重新聚合，以释放纤维素组分并促进降解。修饰后的木质素不被褐腐真菌代谢，而是残留在土壤中。\n木质纤维素降解生物的多样性 纤维素由多种海洋生物合成，其降解机制可能起源古老。木质素降解的演化则与二叠纪末期有机碳埋藏量的下降同步。陆生植物出现时，生命之树的主要分支已分化，因此木质纤维素降解能力具有多源性，并在生命之树的多个小分支中持续演化。例如，昆虫-原生生物共生关系（促进木质纤维素消化）在侏罗纪晚期出现，而依赖细菌共生的木材消化能力则是双壳类家族Teredinidae和Xylophagainae最后共同祖先的特征。在自然界中，具有互补酶的生物共生体和群落广泛参与生物质的降解。降解过程在多种（有时极端的）环境条件下进行，涉及pH、氧化还原电位、温度和压力的广泛范围，这反映了参与生物的多样性。\n原核生物 近年来，强大的宏组学技术使得从富含木质纤维素的环境（如堆肥）中挖掘原核生物群落的遗传多样性成为可能，从而发现可能在工业条件下表现优异的新型木质纤维素降解酶。通过比较宏转录组分析，研究人员已识别出在高负荷条件下能够降解稻草的堆肥微生物群落中高表达的基因。利用宏基因组学和宏蛋白质学对复杂群落中木质纤维素降解微生物的研究，揭示了群落成员的结构、功能及其在营养供应等环境条件变化下的遗传和功能响应。\n宏组学还为肠道微生物群落的复杂相互关系提供了新见解。白蚁是消化共生的典型例子。在低等白蚁中，细菌和古菌生活在肠道内吞噬木质颗粒的鞭毛虫的细胞质和表面，也存在于粘稠的肠道液体中。拟杆菌门、厚壁菌门、螺旋体门、变形菌门和Elusibacteria是该微生物群的主要成员，参与将生物质转化为甲烷、氢气和乙酸的代谢途径。在低等白蚁Reticulitermes中，通过16S rRNA探针检测到超过4700种细菌系统型。高等白蚁的后肠仅含有原核生物，这些微生物促进经白蚁酶预处理的木质颗粒的分解。后肠液体的纤维素酶活性较低，但与木质颗粒相关的细菌表现出强纤维素酶活性。\n一些土壤细菌被证实能够氧化木质素，主要属于放线菌门、α-变形菌门或γ-变形菌门，其中一些也存在于白蚁肠道和钻木昆虫中。近年来，原核生物中木质素降解酶的研究取得进展，染料脱色过氧化物酶家族的酶在革兰氏阳性放线菌Rhodococcus jostii RHA1、Amycolatopsis sp. 75iv2和革兰氏阴性γ-变形菌Pseudomonas fluorescens Pf-5中显示出对Mn(II)和β-芳基醚木质素模型化合物的氧化活性。细菌漆酶在链霉菌A3(2)中被证明是酸沉淀木质素生成所必需的。此外，Sphingobium SYK-6中的谷胱甘肽依赖性β-醚酶已被表征，但其在木质纤维素降解中的作用仍需进一步研究。\n古菌也存在于堆肥和白蚁肠道中，但其木质纤维素降解机制研究较少。一些古菌能在高温下降解木质纤维素，例如在Pyrococcus中发现的GH12内切葡聚糖酶。古菌中已鉴定出五个可能氧化木质素的漆酶基因，其中三个属于盐杆菌目，一个属于热变形菌目。\n海洋中的自由生活木质降解原核生物分为隧道细菌和侵蚀细菌，其植物细胞壁降解模式不同。隧道细菌为革兰氏阴性杆菌，侵蚀细菌属于黄杆菌-噬纤维菌群。由于两者均未在纯培养中生长，其独立作用机制尚不清楚，但其降解速率较真菌缓慢，主要降解纤维素和半纤维素，而对木质素的改变较小。深水中的木材会招募特定的耐压细菌群落，这些群落与以木材为食的钻孔动物粪便中的细菌明显不同。\n单细胞真核生物和原生生物 一些自由生活的原生生物被发现具有内源性纤维素酶。黏菌Dictyostelium的基因组编码一种推测的GH7纤维二糖水解酶，而绿藻Chlamydomonas则利用内切葡聚糖酶降解胞外纤维素。甲藻Alexandrium产生一种与白蚁共生菌相似的纤维素酶，但其功能可能更倾向于辅助细胞分裂而非消化。然而，致病性卵菌Phytophthora则分泌一系列针对半纤维素和纤维素的细胞壁降解酶，包括GH家族1、5、6、7、10以及AA9和AA10的成员。低等白蚁的肠道中寄宿多达19种鞭毛虫类原生生物，这些原生生物吞噬木质颗粒，并在其消化液泡中含有多种酶，如内切葡聚糖酶、GH7纤维二糖水解酶、β-葡萄糖苷酶、木聚糖酶、甘露糖苷酶和阿拉伯糖苷酶。\n真菌 生物质降解真菌依赖复杂的降解机制，主要包括两类过程：一是直接酶解（如纤维二糖水解酶的作用），二是生成氧化性物质（如自由基）作用于生物质。随着对担子菌门基因组研究的新进展，传统上分类为白腐菌或褐腐菌的真菌可能不再完全符合这些类别，因为其代谢物表达和降解模式存在渐变。然而，在典型的白腐菌降解中，真菌主要采用酶解攻击模式。由于降解酶体积过大，无法穿透完整的细胞壁，白腐菌仅从木质纤维素表面开始攻击。白腐菌使用的酶包括完整的纤维素酶，以及能够氧化木质素成分的酶，如木质素酶、锰过氧化物酶、多功能过氧化物酶或漆酶，或这些酶的组合。一些白腐菌还被发现具有大量LPMO基因。\n褐腐菌从白腐菌的祖先中多次独立演化而来，在这些进化过程中，木质素降解酶系统和关键纤维素酶逐渐丢失。至少三个褐腐菌目（Gloeophyllales、Polyporales和Boletales）演化出螯合剂介导的芬顿（CMF）系统，替代了大部分纤维素酶机制，从而提供了一种高效的生物质解聚和生物修饰途径。CMF系统是生物系统中唯一基于氧自由基化学的底物降解机制，能够在距离生物体数微米的位置进行非酶解降解。CMF系统的高效性被认为使褐腐菌在生态位竞争中占据优势，例如在针叶木材降解中取代了白腐菌。\n一些子囊菌也能降解木材细胞壁，形成沿S2基本纤维方向排列的菱形腔链，导致软腐。软腐真菌已知能产生完整的纤维素酶，但其木质素降解能力存在争议，据报道其分泌的未指定胞外过氧化物酶和氧化酶功能较白腐菌更为有限。\n动物 许多无脊椎动物表达内源性纤维素酶。植物寄生线虫、蟑螂和白蚁是最早被证实携带纤维素酶基因的动物，但近年来，这些基因（主要属于GH5、9和45家族）也在其他类群中被明确发现，如其他昆虫、腹足类、甲壳类和环节动物。由于许多昆虫或甲壳类缺乏类似反刍动物和白蚁的大型消化肠道腔室来培养肠道共生微生物，因此这些草食性和碎屑食性动物需要依赖内源性纤维素酶。它们通过口器或外壳对底物进行机械破碎，部分克服了木质纤维素的抗降解性。\n钻木双壳类（如船蛆）通过外壳的研磨作用摄入木质颗粒。它们缺乏显著的肠道微生物群，而是在鳃的特化细胞内寄宿γ-变形菌内共生体。在船蛆Bankia setacea中，这些细菌产生的木质纤维素降解酶被选择性运输到肠道，包括GH家族5、6、9、10、11、45和53以及碳水化合物酯酶家族1、3、4、6和15的代表，以及AA10家族的LPMOs。这种细菌与消化部位的分离可能使宿主能够捕获释放的糖类，而无需与肠道微生物群竞争。内共生细菌还被证明能够在体内固氮，从而补充木材中有限的有机氮源。船蛆的深海近缘类群Xylophagainae具有类似的共生和降解机制，但能够在极端压力下运作。在摄食陆地植物碎屑的双壳类Corbicula的消化腺和晶杆中，也检测到内源性GH9、10和45酶，但其晶杆在高度木质化底物降解中的作用尚待阐明。\n在白蚁中，内源性纤维素酶（由唾液腺和中肠产生）与后肠中鞭毛虫和细菌产生的微生物酶协同作用，后者还通过氧化降解木质素基质部分接触纤维素纤维。其他无脊椎动物中内源性酚氧化酶样酶在木质素降解中的作用尚不明确，但近期研究表明活化血蓝蛋白可能参与酚氧化。甲壳类中被证实具有内源性半纤维素酶（如昆布多糖酶），而在白蚁中，半纤维素酶（如木聚糖酶、半乳聚糖酶）主要来自细菌，尽管甘露聚糖酶活性被归因于白蚁的共生原生生物。\n大多数白蚁依赖肠道微生物群，有时这些微生物甚至存在于鞭毛虫的细胞或细胞核内。而大白蚁亚科则在其巢穴中培养担子菌Termitomyces，该真菌产生多种能够水解复杂多糖的GHs。白蚁工蚁携带能够消化真菌释放的寡糖的细菌。\n食木甲壳类Chelura（端足类）和Limnoria（等足类）产生属于多个CAZy家族的内源性酶，其中GH5、7和9成员在消化腺转录组中最为显著。它们是已知唯一产生GH7酶的后生动物，其消化道缺乏常驻微生物，因此不具备白蚁中复杂的肠道化学结构。这些动物具有类似酶反应器的肠道，为研究酶功能提供了一个不受微生物相互作用干扰的理想模型。\n木质纤维素消化在脊椎动物中是一种罕见的饮食策略，但少数陆生（如河狸、熊猫和豪猪）和水生脊椎动物在其正常饮食中摄入大量木质纤维素。除熊猫外，尚不清楚这是否为专性食木性，而熊猫对其饮食的适应性出人意料地差。目前正在研究促进脊椎动物木质纤维素消化的微生物组。新热带淡水生态系统中的鲶鱼科鱼类（如Panaque spp.）是食木性动物。通过16S rRNA基因分析发现，P. nigrolineatus的胃肠道拥有一个包含纤维素降解和固氮微生物近缘种的微生物群落。该群落中的纤维素降解细菌已被表征，并发现其与固氮菌在脊椎动物胃肠道内共生。\nCAZy数据库 官网: CAZy\nCAZy（Carbohydrate-Active Enzymes，碳水化合物活性酶）数据库是一个专门收录与碳水化合物降解、修饰和合成相关酶的综合性数据库。它基于酶的功能和结构特征，将碳水化合物活性酶分为多个家族，包括糖苷水解酶（Glycoside Hydrolases, GHs）、糖基转移酶（Glycosyl Transferases, GTs）、多糖裂解酶（Polysaccharide Lyases, PLs）、碳水化合物酯酶（Carbohydrate Esterases, CEs）以及辅助活性酶（Auxiliary Activities, AAs）。这些酶在木质纤维素降解、生物质转化以及工业生物技术中具有重要作用。\nCAZy数据库通过系统化的分类和注释，为研究人员提供了丰富的基因和酶功能信息。例如，糖苷水解酶（GHs）家族包含多种能够切断纤维素和半纤维素中糖苷键的酶，而辅助活性酶（AAs）家族则包括氧化还原酶，常与GHs协同作用以增强降解效率。CAZy数据库不仅收录了已知酶的序列和结构信息，还提供了基于基因组和宏基因组数据的预测工具，帮助研究人员识别新型碳水化合物活性酶。\n在木质纤维素降解研究中，CAZy数据库被广泛应用于基因功能注释和酶家族分类。通过结合宏基因组学、宏转录组学和宏蛋白质组学数据，研究人员可以挖掘环境中微生物群落的遗传潜力，识别具有工业应用价值的新型酶。例如，利用CAZy数据库，科学家能够快速筛选出参与纤维素、半纤维素和木质素降解的关键酶基因，并进一步研究其功能和应用潜力。\ndbCAN 官网: dbCAN\ndbCAN（Database for automated Carbohydrate-active enzyme ANnotation）是一个专门用于自动化注释碳水化合物活性酶（CAZymes）的数据库和工具集。它基于CAZy数据库的分类框架，结合了多种计算方法，能够快速、准确地从基因组、宏基因组或蛋白质组数据中识别和注释CAZymes。dbCAN的目标是为研究人员提供一个高效的工具，帮助他们挖掘和分析与碳水化合物代谢相关的基因和酶。\n主要特点与功能 基于CAZy分类框架\ndbCAN延续了CAZy数据库的分类体系，将碳水化合物活性酶分为六大类：糖苷水解酶（GHs）、糖基转移酶（GTs）、多糖裂解酶（PLs）、碳水化合物酯酶（CEs）、辅助活性酶（AAs）以及碳水化合物结合模块（CBMs）。这种分类方式便于研究人员快速理解酶的功能和分类。\n自动化注释工具\ndbCAN提供了一套自动化注释工具，包括：\nHMMER：基于隐马尔可夫模型（HMM）的搜索工具，用于识别CAZymes家族。 DIAMOND：一种快速的序列比对工具，用于初步筛选CAZymes。 Hotpep：基于短肽模式的搜索工具，用于补充HMMER和DIAMOND的结果。\n这些工具可以单独或联合使用，以提高注释的准确性和全面性。 用户友好的在线平台\ndbCAN提供了一个在线平台，用户可以通过上传基因组或蛋白质序列文件，快速获得CAZymes的注释结果。平台支持多种输入格式，并生成详细的注释报告，包括酶家族分类、功能预测和序列比对信息。\n数据库更新与扩展\ndbCAN定期更新，与CAZy数据库保持同步，确保注释结果的准确性和时效性。此外，dbCAN还整合了其他相关数据库的信息，如UniProt和PDB，为用户提供更全面的酶功能信息。\n基因组与宏基因组分析：dbCAN广泛应用于基因组和宏基因组数据中CAZymes的挖掘，帮助研究人员识别与碳水化合物降解、修饰和合成相关的基因。 功能驱动研究：通过dbCAN注释，研究人员可以快速筛选出特定功能的酶家族，进一步研究其催化机制和底物特异性。 References Dashora, K. et al. Leveraging multiomics approaches for producing lignocellulose degrading enzymes. Cell. Mol. Life Sci. 79, 132 (2022). Andlar, M. et al. Lignocellulose degradation: an overview of fungi and fungal enzymes involved in lignocellulose degradation. Eng. Life Sci. 18, 768–778 (2018). Cragg, S. M. et al. Lignocellulose degradation mechanisms across the tree of life. Curr. Opin. Chem. Biol. 29, 108–119 (2015). ","date":"2025-03-13T00:00:00Z","image":"/p/lignocellulose/images/fig2_hu_9db5353ebce4bcba.png","permalink":"/p/lignocellulose/","title":"功能基因探索：木质纤维素（lignocellulose）降解"},{"content":"Introduction 在进化过程中，细菌发展出多种机制以应对不同的环境压力，如酸性、温度和抗生素等。其中，酸性环境是细菌最常面临的极端条件之一。耐酸细菌是一类能够在pH 2.0至5.0（也有说6.0的）的强酸性环境中生存的极端微生物（另外还有生长的最适pH在4以下的微生物叫嗜酸微生物，它们不仅耐酸，还依赖酸性环境生长）。这些酸性环境可能由自然过程（如酸性矿山排水、海洋火山喷口和酸性硫泉）或人类活动（如工业废水排放）形成。工业废水中含有大量有机物、悬浮固体和氨氮，其低pH值为耐酸细菌的生存提供了条件。\n耐酸细菌通过多种机制适应酸性环境，包括生理适应、代谢响应和质子消耗机制。在生理适应方面，细菌通过改变细胞膜组成和流动性来减少质子的内流。例如，降低不饱和脂质的浓度，并通过环丙烷脂肪酸磷脂合成酶修饰磷脂尾结构。此外，外膜蛋白（OMPs）可通过多磷酸盐或尸胺被阻断，而HdeA和HdeB等伴侣蛋白则能在酸性压力下释放底物蛋白。在大肠杆菌中，Hsp31伴侣蛋白和DNA结合蛋白Dps也在酸性压力下保护DNA的完整性。\n在代谢响应方面，细菌通过质子外排和质子消耗机制应对酸性压力。例如，大肠杆菌K-12在轻度酸性压力下通过氧化电子传递链介导质子外排。此外，细胞膜在细菌适应极端环境中起关键作用，溶质通过ATP驱动的初级运输或质子动力驱动的次级运输系统跨膜运输。某些耐酸细菌（如大肠杆菌和丙酸杆菌）甚至能在pH 2.5的极端条件下存活数小时，主要通过进入稳定期并激活多种耐酸机制来实现。\n耐酸细菌的机制在工业生物过程、有机酸生产、微生物燃料电池和工业废水生物处理中具有广泛应用。工业废水中含有大量有机物和有毒重金属，直接排放会对环境和人类健康造成严重危害。传统的化学处理方法（如混凝、沉淀和氧化）存在污泥产生、副产物生成和化学品消耗高等问题，而生物修复则是一种更环保的替代方案。耐酸细菌通过生物吸附、生物积累、生物降解和生物沉淀等机制修复酸性矿山排水或污染污泥中的重金属和石油烃化合物（如邻二甲苯、苯和甲苯）。\n非典型环境 耐酸细菌是一类能够在pH 5.0及以下的极端酸性环境中繁衍生息的极端微生物。这些酸性环境可能由自然过程（如酸性矿山排水、海洋火山喷口和酸性硫泉）或人类活动（如工业革命后的工业废水排放）形成。\n耐酸细菌的非典型环境与生态系统 耐酸细菌主要存在于硫或黄铁矿氧化形成的pH低于5.0的酸性环境中。硫和亚铁在耐酸细菌的作用下分别被氧化为硫酸和三价铁。酸性黄铁矿区域常见于煤矿和硫矿周围，这些区域通常具有较高的硫化物浓度。由于重金属含量高而有机质含量低，这些区域的pH可低至1.0。参与硫酸盐氧化反应的极端耐酸细菌包括Sulfobacillus thermosulfidooxidans、Thiobacillus acidophilus和Thiobacillus thiooxidans等。此外，海底火山区域和热液喷口释放的大量还原硫也为耐酸细菌提供了适宜的生存环境。在金属氧化物中，锌和铜的硫化物最为丰富，而耐酸细菌如Acidithiobacillus、Ferrimicrobium、Sulfobacillus、Acidimicrobium和Leptospirillum等能够氧化铁和硫化物矿物。\n工业废水、农业用地和市政排放的污染物通常含有高浓度的有机物和无机物（如重金属、异生物质、微塑料以及硝酸盐、磷酸盐和总氮），这些污染物导致废水pH降低，从而形成极端酸性环境。Acidophilus、Brevibacterium、Leptospirillum、Stenotrophomonas和Thermogymnomonas等极端耐酸细菌能够在低pH废水中生存。研究表明，酸性矿山排水、海洋火山喷口、酸性硫泉和工业废水是耐酸细菌的主要栖息地。\n耐酸细菌在微生物生态中的作用 由于酸性环境中溶解有机碳浓度较低，耐酸细菌通常被认为是寡营养型生物。在深矿等无阳光环境中，化能自养型耐酸细菌通过氧化硫化物和铁矿物生存。例如，Leptospirillum ferrooxidans在铁循环中起关键作用，它是一种专性化能自养菌，能够好氧氧化铁。在酸性矿山中，Ferroplasma、Leptospirillum和Acidithiobacillus等属的细菌广泛存在，其基因组测序显示存在编码固氮酶的基因。\n废水中的重金属是导致低pH的主要原因，而耐酸细菌通过产生脲酶中和酸性环境。脲酶通过生成氨（NH₃）与细胞内质子结合，从而降低细胞内pH。工业废水中的氨去除包括硝化和反硝化两个步骤：化能自养细菌将氨转化为亚硝酸盐（NO₂⁻）和硝酸盐（NO₃⁻），随后硝酸盐通过反硝化过程转化为氮气（N₂）。耐酸细菌的氮源主要包括氨、亚硝酸盐、硝酸盐和其他溶解有机氮化合物。硝酸盐还原为氨的过程涉及两个独立的酶促反应：NADH₂-硝酸还原酶催化NO₃⁻还原为NO₂⁻，铁氧还蛋白-亚硝酸还原酶催化NO₂⁻还原为NH₃，这一过程需要大量能量。\n耐酸的细胞机制 耐酸细菌在稳定期能够在低pH环境中存活数小时。为了适应极端酸性环境，多种细菌进化出了不同的细胞机制。当细菌暴露于酸性环境时，外膜和周质空间首先受到损害，因为外膜直接接触外部环境。在压力响应下，膜生物能量学、质子渗透和脂质生理学发生改变，从而降低膜的流动性和质子的通透性。细菌的耐酸细胞机制包括细胞膜修饰、F₁F₀-ATPase质子泵、生物膜形成、碱生成（脲酶活性）以及大分子的保护和修复。\n细胞膜修饰 外膜结构的改变主要发生在脂肪酸链或头基组成上。通过多磷酸盐或尸胺阻断外膜蛋白（OMPs），可以进一步减少质子的内流。例如，多磷酸盐阴离子（polyP）阻断PhoE3孔蛋白，而尸胺阻断OmpC3和OmpF3孔蛋白。在Picrophilus oshimae中，刚性单层膜和庞大的异戊二烯核心使其对质子不渗透。耐酸细菌通过改变脂肪酸的组成或结构来调节膜流动性。例如，环丙烷脂肪酸磷脂合成酶（CFAS）降低不饱和脂质的浓度，并对不饱和磷脂尾进行甲基化。\n为维持pH稳态，耐酸细菌利用反向膜电位。在Acidithiobacillus thioxidans和Acidithiobacillus ferrooxidans中，丰富的次级转运蛋白（如H⁺-ATPase、同向转运蛋白和反向转运蛋白）帮助维持pH稳态。Picophilus torridus和Thermoplasma acidophilum则通过利用跨膜质子电化学梯度进行主动运输来调节酸性环境。膜通道的大小和通透性也是维持pH稳态的重要机制。例如，在Acidithiobacillus ferrooxidans中，当pH从3.5降至1.5时，外膜蛋白Omp40上调，其外部L3环调节孔蛋白入口的大小和离子选择性。\n有机酸（如乙酸和乳酸）对耐酸细菌有害，因为这些质子化酸能够轻易通过细胞膜。Picophilus torridus的基因组揭示了编码有机酸降解途径的基因，包括丙酰-CoA合成酶、两种乙酰-CoA合成酶和乳酸-2-单加氧酶，这些酶将乳酸转化为丙酮酸。\n伴侣蛋白与DNA保护 HdeA和HdeB是两种周质伴侣蛋白，能够耐受酸性压力。HdeA的主要功能是防止酸诱导的蛋白质积累，并帮助蛋白质溶解和复性。HdeB具有类似功能。在大肠杆菌中，热休克伴侣蛋白Hsp31在酸性压力下结合并稳定未折叠的蛋白质中间体，随后允许蛋白质自发复性或依赖ATP的伴侣蛋白辅助复性。在酸性环境中，DNA结合蛋白Dps保护DNA免受损害。\nF₁F₀-ATPase质子泵 质子动力势（PMF）是细胞内质子梯度的体现，由细胞质与外部环境之间的电荷分离产生。依赖PMF的质子泵是细菌耐酸系统的重要组成部分，在维持pH稳态中起关键作用。在酸性环境中，H⁺的积累降低细胞内pH，随后质子泵开始消耗ATP。通过F₁F₀-ATPase进入细胞的质子在末端氧化酶处还原分子氧，导致代谢活动暂停。例如，Sulfolobus acidocaldarius通过F₁F₀-ATPase将质子排出细胞，从而在酸性环境中生存。在多种耐酸细菌（如Streptococcus pneumoniae和Lactobacillus acidophilus）中，F₁F₀操纵子因酸性pH的刺激而被转录。Streptococcus mutans则通过上调F₁F₀-ATPase应对酸性压力。因此，耐酸细菌通过F₁F₀-ATPase质子泵催化ATP水解，排出过量H⁺，从而耐受外部酸性环境并维持pH稳态。\n生物膜形成 许多细菌通过形成生物膜（biofilm）以社区形式附着在表面，从而抵御酸性压力。生物膜形成是一种独特的耐酸机制，涉及细胞群体间的信号交流。在某些细菌中，生物膜对酸性环境具有强耐受性，而其浮游细胞则对酸性敏感。生物膜之所以能够耐受酸性压力，是因为某些蛋白质仅在生物膜形成时表达。例如，在Pseudomonas aeruginosa中，vfr和gacA基因调控luxR同源基因lasR，后者激活lasI表达，生成3-oxo-C12-HSL，与受体蛋白LasR结合形成复合物，从而调控生物膜形成。负调控因子rsaL则抑制lasR表达。这种LasR蛋白-AHL复合物正向驱动与生物膜形成、致病性和次级代谢相关的多个结构基因的表达。\n在Streptococcus mutans中，luxS合成并分泌AL2，同时抑制irvA的转录。然而，当细胞遭遇酸性压力时，irvA基因的表达显著增加，进而抑制mutA和mutR的转录。Streptococcus mutans的群体感应系统通过调控生物膜形成实现耐酸性。ABC转运蛋白编码基因comAB的产物切割comC基因的产物，生成群体感应肽（CSP）。当CSP达到临界浓度时，传感器激酶ComD（由comD编码）磷酸化comE，启动替代σ因子comX的转录。在Streptococcus pneumoniae中，磷酸化的comE激活两个特异性操纵子comAB和comCDE，以及comX基因，后者诱导遗传竞争性和其他依赖细胞密度的表型。\n碱生成——脲酶活性 耐酸细菌通过胞外代谢产生碱性化合物来中和酸性环境。脲酶将尿素水解为氨和二氧化碳（CO₂）。脲酶通过生成氨与细胞内的质子结合，从而降低细胞内pH，起到中和酸性的作用。脲酶系统由ureIABCEFGD操纵子组成，耐酸细菌通过调控这一系统在pH低至2.5的环境中存活。例如，在Helicobacter pylori和Streptococcus salivarius中，ureI基因帮助将尿素从外部转运至细胞质。因此，脲酶通过生成碱性产物氨，保护细胞免受酸性环境的损害。Streptococcus sanguis和Streptococcus suis也依赖脲酶活性抵御酸性压力。此外，苹果酸乳酸发酵是Streptococcus mutans和Oenococcus oeni产生碱的另一种方式，其在细胞质内通过碱生成过程应对酸性压力，同时生成并排出CO₂。因此，碱生成机制是耐酸细菌在酸性环境中生存的有效策略。\n大分子的保护与修复 在酸性压力条件下，膜蛋白的稳定性至关重要。特定蛋白质在酸性环境中被诱导，以保护DNA和其他蛋白质。例如，dps蛋白通过形成笼状结构结合铁并减少过氧化氢的毒性来保护DNA，而recA则在DNA修复和激活SOS响应中起关键作用。Oenococcus oeni的热休克蛋白Lo18通过减少蛋白质聚集来增强细菌的耐酸性，从而稳定膜结构并保护蛋白质。Ffh蛋白参与膜内蛋白质转运途径，并帮助蛋白质向细胞外运输。此外，多种伴侣蛋白（如DnaK、DnaJ、GroEL、GroES、GrpE、Clp蛋白酶和EF-Tu）在酸性压力下作为分子伴侣参与蛋白质修复。\nDNA损伤的修复则依赖于uvrABCD、DNA聚合酶和DNA连接酶。例如，在Streptococcus mutans中，uvrA在pH 5.0的酸性压力下修复DNA损伤。Escherichia coli的DnaK和Deinococcus radiodurans的IrrE也参与酸性压力下的DNA修复机制。在Bacillus caldontenax中，uvrA和uvrB协同识别并修复DNA损伤。\n耐酸的遗传机制 除了细胞层面的相互作用，耐酸细菌还通过耐酸基因适应酸性环境。这些基因调控的耐酸机制包括四种依赖吡哆醛-5\u0026rsquo;-磷酸（PLP）的氨基酸脱羧酶酸耐受系统：谷氨酸依赖酸耐受系统（GDAR）、精氨酸依赖酸耐受系统（ADAR）、赖氨酸依赖酸耐受系统（LDAR）和鸟氨酸依赖酸耐受系统（ODAR）。这些系统协同作用，确保耐酸细菌在极端低pH环境中的代谢和生长。\n谷氨酸依赖酸耐受系统（GDAR） GDAR系统由gadA和gadB基因编码的两种Gad酶以及gadC基因编码的谷氨酸/γ-氨基丁酸（GABA）反向转运蛋白组成。GadC将细胞外的质子化谷氨酸转运至细胞内，同时将细胞内的GABA转运至细胞外。通过谷氨酸与GABA的交换，细胞内质子被消耗，从而提高细胞内pH，保护细胞免受酸冲击。在Lactobacillus reuteri中，GadC通过交换GABA和谷氨酸发挥作用。此外，GadC还将谷氨酰胺转运至细胞内，在酸激活的ybaS基因帮助下转化为谷氨酸和氨。在Escherichia coli中，ybaS基因编码的谷氨酰胺酶将L-谷氨酰胺转化为L-谷氨酸，并通过生成氨中和H⁺。GDAR系统在pH低至2.0的极端酸性环境中对多种耐酸细菌的生存至关重要。\n精氨酸依赖酸耐受系统（ADAR） ADAR系统在酸性条件下（通常pH∼5.0）被最大程度诱导，主要存在于厌氧环境中生长的耐酸细菌中。该系统由adiA基因编码的胞质可诱导精氨酸脱羧酶、adiY基因编码的调控蛋白以及adiC基因编码的反向转运蛋白组成。精氨酸通过AdiC进入细胞，在AdiA的催化下转化为胍丁胺，随后胍丁胺被转运至细胞外。这一交换过程消耗细胞内质子，从而保护细胞。在Escherichia coli中，AdiC通过交换精氨酸和胍丁胺发挥作用。此外，ADAR系统还受ArcD反向转运蛋白调控，精氨酸通过ArcD进入细胞，经精氨酸脱亚胺酶（ADI）代谢为氨和瓜氨酸，最终生成ATP。在Streptococcus pyogenes中，ADAR系统是抵御酸性压力的主要机制。\n赖氨酸依赖酸耐受系统（LDAR） LDAR系统在pH 5.5的厌氧条件下被诱导，由cadBA操纵子组成，包括cadA和cadB基因，受cadC基因产物调控。CadC通过与赖氨酸特异性渗透酶LysP的相互作用诱导cadBA操纵子。在Escherichia coli中，CadC通过LysP间接感知赖氨酸。赖氨酸通过CadB进入细胞，在CadA的催化下转化为尸胺，随后被CadB转运至细胞外。在Edwardsiella tarda中，cadBA操纵子帮助细菌在低pH环境中生存。\n鸟氨酸依赖酸耐受系统（ODAR） ODAR系统在低pH条件下诱导speF和potE基因。鸟氨酸通过PotE进入细胞，转化为腐胺后被转运至细胞外。在Escherichia coli中，PotE通过交换鸟氨酸和腐胺发挥作用。这些脱羧酶在特定低pH范围内表现出最佳酶活性，例如gadA/gadB在pH 1.7-2.8范围内，adiA在pH 4.9-5.2范围内，ldcI在pH 5.7，speF在pH 6.5。因此，耐酸细菌在pH 4.0-7.0范围内表现出强酸应激响应，酶活性随pH升高而降低。\n耐酸基因与细菌的进化与多样性 为适应高度酸性环境，不同耐酸细菌发展出多种耐酸机制。耐酸基因从1924年发现的Streptococcus mutans逐渐进化而来。在酸性环境中，细胞质酸化导致蛋白质和DNA结构损伤，进而诱导蛋白修复伴侣DnaK和信号识别基因ffh的表达，增加氨基酸代谢和氨生成，并上调H⁺-ATPase和DNA损伤修复蛋白RecA。此外，Streptococcus mutans通过群体感应系统irvA和luxS调控生物膜形成，增强耐酸性。在Streptococcus pyogenes中，ADAR系统和F₁F₀-ATPase是主要的耐酸机制。Salmonella enterica则通过ADAR和LDAR系统在低pH环境中生存。cadBA操纵子在arc操纵子之后进化，参与赖氨酸脱羧和精氨酸脱羧机制。近年来，更复杂的耐酸操纵子（如gad操纵子）被广泛发现，这些系统通过水平基因转移和重组进化，从简单系统逐渐发展为广泛分布的复杂系统。\n耐酸细菌在工业与生物修复中的应用 耐酸细菌的耐酸机制在工业生物过程和工业废水处理（如矿山废水和石油泄漏）中具有广泛应用（Feng等，2021）。这些机制还可用于提高有机酸的生产效率。开发有效的工具以增强耐酸机制，对扩大工业耐酸细菌的应用至关重要。\n工业生物过程与生物发电中的耐酸菌株 耐酸细菌在工业生物过程中发挥重要作用。例如，在乳酸发酵过程中，Lactobacillus通过大分子修复和谷氨酰胺酶依赖的酸耐受系统应对酸性压力。低pH激活谷氨酸脱羧酶系统，增加γ-氨基丁酸（GABA）的生成，从而筛选高效乳酸菌。Lactobacillus reuteri通过GadA/GadB将谷氨酸转化为GABA，并由GadC转运至细胞外。此外，Lactobacillus lactis通过减少细胞内质子、消耗H⁺和改变细胞膜成分来耐受酸性环境。分子伴侣GroES和GroEL蛋白以及murG、gshA和gshB基因通过遗传工程提高其耐酸性。\n在乙酸和丁酸生产中，发酵细菌如Clostridium tyrobutyricum和Acetobacter pasteurianus通过gadA、gadB、gadC和uvrA等基因抵御酸性压力。RNA-Seq转录组学分析揭示了Acetobacter pasteurianus通过yro2、mrh1、COX20、PEP3和RTT109等基因修饰细胞膜并保护细胞。丙酸生产菌Propionibacteria acidipropionici则通过GDAR和ADAR系统以及atpA基因编码的F₁F₀-ATPase质子泵维持pH稳态，从而提高丙酸产量。\n废水处理与生物发电 耐酸细菌广泛用于处理市政污水、农业用地和工业废水。此外，它们还可用于生物发电。微生物燃料电池（MFC）是一种生物电化学装置，利用耐酸细菌催化废水中的可降解化合物生成生物电。在MFC中，耐酸细菌位于阳极室，氧化废水中的有机和无机底物，生成二氧化碳、质子和电子。质子通过质子交换膜传递至阴极，电子通过外部电路传递至阴极，最终还原氧气。Acidithiobacillus和Ferroplasma等菌株在pH 1.5-3.0范围内以四硫酸盐为电子供体产生生物电。然而，MFC的发电效率受高内电阻限制，需通过系统架构的优化提高电力输出。\n在生物修复中的应用 耐酸细菌在生物修复中广泛应用，尤其是在酸性压力条件下。生物修复是指细菌将有害有机物质矿化或转化为无毒物质，进而参与自然生物地球化学循环的过程。酸性矿山排水（AMD）含有高浓度的铝、铅、砷和锌等重金属，其高酸性进一步溶解其他金属和类金属，增加矿物溶解。耐酸细菌如Clostridium spp. 和Desulfovibrio spp. 通过上流式厌氧污泥床反应器修复酸性矿山排水，其中Desulfovibrio spp. 利用F₁F₀-ATPase质子泵排出细胞内H⁺以耐受酸性环境。\n废水中的有机污染物和有毒重金属可通过耐酸细菌的酶促反应降解。水解酶、脱氢酶、脱卤酶、蛋白酶和脂肪酶等代谢酶将有机污染物转化为无毒代谢物，实现环境友好型降解。耐酸细菌还可通过生物吸附、生物积累、生物转化和生物沉淀等机制修复重金属污染。例如，生物膜形成的耐酸细菌在去除金属方面更为高效，其胞外聚合物（EPS）通过带负电荷的功能基团吸附金属阳离子。Desulfovibrio desulfuricans产生的EPS有助于锌的生物吸附和生物沉淀，而Lysinibacillus sphaericus RTA-01则通过纳米吸附去除水溶液中的Cr⁶⁺。\n硫酸盐氧化和硫酸盐还原耐酸细菌分别参与生物浸出和生物沉淀过程。Acidithiobacillus ferrooxidans和Acidithiobacillus thiooxidans等细菌通过生物浸出将低品位铁矿石中的金属氧化为低毒可溶性化合物。Clostridium spp. 和Desulfovibrio spp. 的混合培养物可高效去除铜、镉和镍等重金属。Pseudomonas aeruginosa通过产生金属螯合剂（如铁载体）提高金属溶解性。\n耐酸细菌还可用于处理工业废水。Acidophilus、Brevibacterium、Leptospirillum和Stenotrophomonas等极端耐酸细菌可用于酸性矿山排水的生物处理。Lysinibacillus sphaericus RTA-01和Bacillus pumilus CTO-05可去除橡胶加工废水中的硝酸盐和磷酸盐。基因复制和耐酸基因的插入有助于提高细菌的生物修复能力。\n多环芳烃（PAHs）是酸性废水中的常见污染物。Acidocella sp.和Acidiphilium facilis可在pH 2.0的极端条件下降解甲苯、萘、菲和蒽等石油烃。Pseudomonas putida也可用于降解邻二甲苯、苯和甲苯等化合物。生物修复效率受温度、pH、营养物可用性、溶解氧和电子受体等多种因素影响。ybaS、cfa、dnaK和rpoS等耐酸基因在PAHs的降解中起关键作用。因此，提高耐酸基因的表达是增强生物修复和降解效率的关键。\n通过工程酸耐受性基因提高酸耐受性 通过基因工程技术改造耐酸基因，可显著提高细菌的耐酸性。基因组改组和原生质体融合是高效的技术手段。例如，Propionibacterium acidipropionici通过紫外线诱变和原生质体融合，获得耐酸菌株，丙酸产量提高了65%。Lactococcus lactis通过表达Escherichia coli的谷胱甘肽合成酶和Propionibacterium freudenreichii的海藻糖生物合成途径，增强了耐酸性。Propionibacterium acidipropionici工程化atpA基因，利用F₁F₀-ATPase泵出过量质子，维持细胞内pH；Propionibacterium jensenii ATCC 4868引入arcA、arcC、gadB、gdh和ybaS基因，提高了丙酸生产效率。\n耐酸基因的引入为细菌提供了额外的耐酸机制，基因工程菌株在生物修复和有机污染物降解中具有重要应用。未来需进一步探索耐酸基因的作用，并利用先进基因工程技术进行深入表征，以实现工业废水、重金属和有机污染物的高效、可持续生物修复。\nReferences Mallick, S., Das, S. Acid-tolerant bacteria and prospects in industrial and environmental applications. Appl Microbiol Biotechnol 107, 3355–3374 (2023). https://doi.org/10.1007/s00253-023-12529-w Mirete, S., Morgante, V., González-Pastor, J.E. (2017). Acidophiles: Diversity and Mechanisms of Adaptation to Acidic Environments. In: Stan-Lotter, H., Fendrihan, S. (eds) Adaption of Microbial Life to Environmental Extremes. Springer, Cham. https://doi.org/10.1007/978-3-319-48327-6_9 Guan, N., Liu, L. Microbial response to acid stress: mechanisms and applications. Appl Microbiol Biotechnol 104, 51–65 (2020). https://doi.org/10.1007/s00253-019-10226-1 Lund PA, De Biase D, Liran O, Scheler O, Mira NP, Cetecioglu Z, Fernández EN, Bover-Cid S, Hall R, Sauer M, O\u0026rsquo;Byrne C. Understanding How Microorganisms Respond to Acid pH Is Central to Their Control and Successful Exploitation. Front Microbiol. 2020 Sep 24;11:556140. doi: 10.3389/fmicb.2020.556140. PMID: 33117305; PMCID: PMC7553086. ","date":"2025-03-12T00:00:00Z","image":"/p/acid/images/fig1_hu_c3edc6960e3d9113.png","permalink":"/p/acid/","title":"微生物的耐酸机制研究"},{"content":"Introduction 在宏基因组学的研究领域中，对病毒序列宿主的预测已经成为一项极具挑战性但又至关重要的任务。病毒是一种非细胞生命形态的微生物，它们必须依赖宿主细胞才能进行繁殖和生存。然而，在复杂的生态环境中，病毒所感染的宿主往往是未知的。病毒宿主预测就是通过各种技术手段和方法，利用病毒基因组中的信息来推测其可能感染的宿主（如细菌等微生物）的过程。\n目前已有的宿主预测方法已经有很多了，比如2022年前就有以下工具：\n名称 模型 描述 预测水平 WIsH 马尔可夫模型 针对潜在宿主基因组训练了一个同质的马尔可夫模型，并计算原核生物基因组作为查询病毒宿主的可能性。 属 PHP 高斯混合模型 利用 - mers频率（可反映病毒和宿主共享的密码子使用模式）来训练高斯混合模型。 属 HoPhage 深度学习模型和马尔可夫链算法 使用每个候选宿主基因组的编码序列（CDS）构建马尔可夫链模型，然后计算查询噬菌体片段感染候选宿主基因组的可能性。还使用深度学习模型，并最终将深度学习模型的结果与马尔可夫模型的结果整合用于宿主预测。 属 VPF-Class 基于序列匹配的模型 利用从IMG/VR系统下载的病毒蛋白家族（VPFs）来估计查询病毒与已知宿主病毒之间的相似性。 属 RaFAH 随机森林模型 使用MMseqs2生成蛋白质簇并构建轮廓隐马尔可夫模型（HMMs）。然后，使用HMM比对输出的特征训练多类别随机森林模型。 属 HostG 图卷积网络（GCN） 利用病毒和原核生物之间共享的蛋白质簇创建知识图谱，并训练GCN进行预测。 属 PHIST 基于比对的模型 基于病毒和宿主基因组之间的精确匹配来预测病毒的宿主原核生物。 种 PredPHI 卷积神经网络（CNN） 利用蛋白质序列中的化学成分信息（如氨基酸丰度）训练CNN进行宿主预测。 种 PHIAF 生成对抗网络（GAN）和卷积神经网络（CNN） 使用来自DNA和蛋白质序列的特征（如 - mers频率和分子量）训练CNN进行宿主预测，并应用GAN从已知的病毒 - 宿主相互作用生成伪病毒 - 宿主对以扩充数据集。 种 vHULK 多层感知机模型（MLP） 将宿主预测表述为一个多类别分类问题，输入为病毒，标签为原核生物，模型使用的特征是针对噬菌体蛋白家族pVOGs数据库的蛋白质轮廓比对结果。 种 DeepHost 卷积神经网络（CNN） 设计了一种基因组编码方法，使用 - mers特征将各种长度的基因组编码成3D矩阵，并训练CNN模型进行宿主预测。 种 VHM-net 马尔可夫随机场 利用马尔可夫随机场框架，通过结合病毒和原核生物之间的多种特征（如CRISPRs、WIsH的输出得分、BLASTN比对等）来预测病毒是否感染目标原核生物。 种 CHERRY 图卷积编码器和解码器用于链接预测 将宿主预测问题表述为多模态图中的链接预测问题，并设计了用于宿主预测的编码器 - 解码器结构。多模态图将不同类型的特征（包括蛋白质组织、CRISPR、序列相似性和 - mers频率）集成到节点和边中，边连接来自标记（训练）和未标记（测试）数据的病毒和原核生物。 种 主要原理 （一）基于比对的方法\n基于病毒间相似性或病毒与原核生物基因组相似性 这类方法主要利用病毒之间或病毒与原核生物基因组之间的相似性来实现宿主识别。例如，VPF - Class方法，它利用从IMG/VR系统下载的病毒蛋白家族（VPFs）。通过计算查询病毒与已知宿主病毒之间的VPFs相似性，根据与VPFs的比对结果，就能对查询的每个病毒片段（contig）给出宿主预测结果。 PHIST方法则是利用病毒基因组与原核生物基因组之间的序列匹配来进行宿主预测。它通过识别病毒和原核生物基因组共有的 - mers（长度为k的连续核苷酸序列），从而估计病毒 - 原核生物对形成真实相互作用（即感染关系）的概率。 利用CRISPR的比对预测 一些原核生物会通过CRISPR（成簇的规律间隔的短回文重复序列）记录病毒感染信息以预防再次感染。部分基于比对的工具利用这一特性来预测宿主。比如使用BLAST（基本局部比对搜索工具）等方法，通过搜索原核生物和病毒之间的短序列匹配来预测宿主。然而，这种方法存在一定的局限性，因为只有2 - 10%的测序原核生物含有CRISPRs，而且很多病毒与原核生物注释或预测的CRISPRs没有比对结果，所以无法利用这一信号进行宿主预测。 （二）基于学习的方法\n基于序列特征构建模型 机器学习和深度学习学习基于学习的方法更加灵活，大多数这类方法是学习基于序列的特征用于宿主预测。 例如，WIsH方法会针对潜在宿主基因组训练一个同质的马尔可夫模型。该模型随后计算一个原核生物基因组作为查询病毒宿主的可能性，并将可能性最高的原核生物指定为宿主。 vHULK方法将宿主预测表述为一个多类别分类问题，其中输入是病毒，标签是原核生物。它在其深度学习模型中使用的特征是针对噬菌体蛋白家族pVOGs数据库的蛋白质轮廓比对结果。 RaFAH方法不使用公共数据库，而是使用MMseqs2软件生成蛋白质簇并构建轮廓隐马尔可夫模型（HMMs）。然后，它利用HMM比对输出的特征并训练一个多类别随机森林模型。 HoPhage是另一个基于多类别分类模型的宿主预测工具，它使用深度学习和马尔可夫链算法。它通过利用每个候选宿主基因组的编码序列（CDS）构建马尔可夫链模型，计算查询噬菌体片段感染候选宿主基因组的可能性，然后还使用一个深度学习模型，并最终将深度学习模型与马尔可夫模型的结果整合以预测宿主。 基于 - mers频率和相关蛋白的特征预测 PHP方法利用 - mers频率，因为它可以反映病毒和宿主共享的密码子使用模式来预测宿主。 DeepHost和PHIAF也利用基于 - mers的特征来训练卷积神经网络进行宿主预测。 基于受体结合蛋白（RBPs）的特征预测 Boeckaerts等人构建学习模型时使用从受体结合蛋白（RBPs）提取的特征进行宿主预测。不过，这一方法存在局限性，因为在所有病毒中注释RBPs并不容易，该作者仅收集了与九个宿主相关的RBPs，所以这个工具只能预测非常有限的宿主物种。 构建知识图谱或整合多种特征预测 HostG利用病毒和原核生物之间共享的蛋白质簇创建知识图谱，并训练图卷积网络进行预测。虽然它预测的准确性较高，但只能预测到属水平的主机。VHM - Net结合了病毒和原核生物之间的多种特征，如CRISPRs、WIsH的输出得分、BLASTN比对得分等。 近几年也有更多方法不断被发表出来，很难评判哪个软件最好用最准确，大家可以挑选最适合自己数据和研究问题的工具。这篇文章简要介绍一下几个我用过的软件。\nVPF-Class：基于病毒蛋白家族的病毒分类分配和宿主预测 VPF-Class是一种基于病毒蛋白家族（VPFs）信息的工具，用于对未培养病毒进行分类和宿主预测。它通过将病毒蛋白质分配到已分类的VPFs中，实现了在多个分类级别（包括Baltimore分类系统、病毒科和属）上的自动化分类和宿主预测。VPF-Class在RefSeq数据库中表现出高准确性，属级别的分类准确率接近100%，宿主预测准确率为86.4%。该工具无需下载或选择参考数据库，避免了映射过程中的偏差，使其更易于使用。VPF-Class适用于宏基因组研究、病毒发现和病毒生态学研究，帮助研究人员在没有培养条件的情况下识别新的病毒序列并预测其宿主。\n在VPF-Class中，主要步骤包括：\nVPFs的分类和宿主预测：首先，对VPFs进行分类，并根据其与已知病毒的同源关系进行宿主预测。\n病毒基因组的分类和宿主预测：利用分类后的VPFs对未培养病毒基因组进行分类和宿主预测。\n交叉验证和VPFs的第二轮分类：通过比较未培养病毒的分类结果来更新VPFs的分类信息，以提高分类的准确性。\n病毒基因组的分类和评分：为每个病毒基因组提供分类和宿主预测结果，并计算相应的置信度评分。\n安装使用 在GitHub上的biocom-uib/vpf-tools项目中，提供了两种安装方法：使用Docker和从源代码构建（但是我的服务器上直接没有sudo权限，docker也用不了，stack也装不了😂，只能在自己的电脑上安装了）。以下是详细的安装步骤：\n方法1：使用Docker\n1 2 3 4 5 6 7 8 docker volume create vpf-data docker run --rm -it \\ -v \u0026#34;vpf-data:/opt/vpf-tools/vpf-data\u0026#34; \\ -v \u0026#34;$PWD/seqs:/opt/vpf-tools/input-sequences:ro\u0026#34; \\ -v \u0026#34;$PWD/outputs:/opt/vpf-tools/outputs:rw\u0026#34; \\ bielr/vpf-tools \\ vpf-class -i seqs/test.fna -o outputs/test-classified 我尝试将本地的docker转换为HPC上的singularity来运行：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 # 在 Docker 环境下转换 sif docker run --rm -v /var/run/docker.sock:/var/run/docker.sock \\ -v $PWD:/output quay.io/singularity/docker2singularity \\ bielr/vpf-tools docker save -o vpf-tools.tar bielr/vpf-tools singularity build vpf-tools.sif docker-archive://vpf-tools.tar mkdir -p $PWD/vpf-data docker run --rm -v \u0026#34;$PWD/vpf-data:/opt/vpf-tools/vpf-data\u0026#34; bielr/vpf-tools cp -r /opt/vpf-tools/vpf-data/ # 在singularity环境运行 # 把vpf-tools.sif和vpf-data文件夹拷贝到HPC上 singularity exec --bind \u0026#34;$PWD/vpf-data:/opt/vpf-tools/vpf-data\u0026#34; \\ --bind \u0026#34;$PWD/seqs:/opt/vpf-tools/input-sequences:ro\u0026#34; \\ --bind \u0026#34;$PWD/outputs:/opt/vpf-tools/outputs:rw\u0026#34; \\ vpf-tools.sif \\ vpf-class -i seqs/test.fna -o outputs/test-classified 方法2：从源代码构建\n安装Stack： 使用以下命令安装Stack（适用于Mac OS和Linux，未在Windows上测试）：\n1 curl -sSL https://get.haskellstack.org/ | sh 克隆仓库： 克隆vpf-tools仓库：\n1 2 git clone https://github.com/biocom-uib/vpf-tools cd vpf-tools 编译工具： 使用Stack编译所有目标：\n1 stack build 第一次编译可能需要一些时间，因为Stack还需要安装GHC并编译所有依赖项。\n运行工具： 编译完成后，可以通过在命令前加上stack exec --来运行工具，例如：\n1 stack exec -- vpf-class --help 实验性支持OpenMPI： 如果需要使用OpenMPI，可以在构建时添加--flag vpf-class:+mpi标志，然后像其他程序一样使用mpirun运行工具。\n补充材料\n分类文件： 可以在这里找到VPF的分类文件，包括index.yaml。\n单个数据文件： 可以在这里下载单个数据文件，选择“VPF classification”选项卡。\nHMMER模型文件： 最新的包含VPF HMMER模型的文件可以从IMG/VR下载（注意：链接可能已失效，可以在这里找到一个副本）。将final_list.hmms解压到数据目录中，与index.yaml相邻。\n常见问题 HMMERNotFound： 确保HMMER安装正确，并且可以通过$PATH访问。如果不在$PATH中，可以使用--hmmer-prefix指定路径。\nProdigalNotFound： 确保Prodigal已安装，并且可以通过$PATH访问。如果不在$PATH中，可以使用--prodigal指定可执行文件的位置。\nStack安装问题： 如果在安装过程中遇到问题，请参考Stack文档以确保所有依赖项都满足。（还挺难搞的😂）\nConda环境问题： 由于一些用户报告了Stack和Conda的问题，建议避免在Conda污染的环境中安装Stack。\nCherry：图编码器模型准确预测病毒-原核宿主相互作用 在微生物群落中，感染细菌和古菌的原核病毒是关键参与者。预测原核病毒的宿主有助于解码微生物之间的动态关系。然而，实验方法无法跟上高通量测序技术产生的噬菌体序列的快速积累，因此需要计算方法来进行宿主预测。尽管取得了一些有希望的结果，但由于已知相互作用的限制和大量测序噬菌体的数量，计算宿主预测仍然是一个挑战。目前最先进的方法在物种水平上的准确率只能达到43%。\n在这项工作中，研究者将宿主预测问题表述为一个知识图中的链接预测问题，整合了多种基于蛋白质和DNA的序列特征。研究者实现的工具名为CHERRY，可以应用于预测新发现病毒的宿主，并识别感染目标细菌的病毒。研究者展示了CHERRY在这两种应用中的实用性，并将其性能与其他11种流行的宿主预测方法进行了比较。据研究者所知，CHERRY在识别病毒-原核生物相互作用方面具有最高的准确性。它在物种水平上超越了所有现有方法，准确率提高了37%。此外，CHERRY在短片段上的表现比其他工具更稳定。\n安装使用 CHERRY 是一个用于预测病毒与原核生物基因组相互作用的 Python 库。使用 Conda 安装：\n克隆仓库：\n1 git clone https://github.com/KennthShang/CHERRY.git 创建并激活 Conda 环境：\n1 2 3 cd CHERRY conda env create -f CHERRY.yaml -n cherry conda activate cherry 准备数据库： 由于 GitHub 文件大小限制，数据库文件被压缩为 .bz2 格式。需要解压这些文件：\n1 2 3 4 5 6 cd dataset bzip2 -d protein.fasta.bz2 bzip2 -d nucl.fasta.bz2 cd ../prokaryote gunzip * cd .. 激活环境： 每次使用 CHERRY 之前，确保激活 cherry 环境：\n1 conda activate cherry 使用 输入文件： 输入文件应该是一个包含病毒序列的 FASTA 文件。研究者提供了一个示例文件 test_contigs.fa。\n运行命令： 使用以下命令进行宿主预测：\n1 python run_Speed_up.py [--contigs INPUT_FA] [--len MINIMUM_LEN] [--model MODEL] [--topk TOPK_PRED] --contigs INPUT_FA：输入的 FASTA 文件（默认为 test_contigs.fa）。 --len MINIMUM_LEN：仅对长度大于等于指定长度的序列进行预测（默认为 8000）。 --model MODEL：使用预训练参数或重新训练的参数进行预测（默认为 pretrain）。 --topk TOPK_PRED：输出前 K 个预测结果（默认为 1）。 示例：\n1 python run_Speed_up.py --contigs test_contigs.fa --len 8000 --model pretrain --topk 1 输出文件： 输出文件格式为 CSV 文件（final_prediction.csv），包含每个病毒的预测结果。列 contig_name 是输入文件的访问号。\n生成分类树： 使用以下命令将预测结果转换为完整的分类树：\n1 python run_Taxonomy_tree.py [--k TOPK_PRED] 需要指定 k 来生成树，输出文件为 Top_k_prediction_taxonomy.csv。\n扩展病毒-原核生物相互作用数据库 如果有比预训练模型更多的病毒-原核生物相互作用信息，可以添加它们来训练自定义模型：\n添加病毒基因组： 将病毒基因组添加到 nucl.fasta 文件中，并运行 python refresh.py 以生成新的 protein.fasta 和 database_gene_to_genome.csv 文件。\n添加宿主分类信息： 在 dataset/virus.csv 中添加宿主分类信息。表头为：\nAccession（病毒） Superkingdom Phylum Class Order Family Genus Species（必填） 添加原核生物基因组： 将原核生物基因组放入 prokaryote/ 文件夹，并在 dataset/prokaryote.csv 中添加条目。\n重新训练模型： 使用 retrain 作为 --mode 参数运行程序：\n1 python run_Speed_up.py --mode retrain 预测感染特定原核生物的病毒 输入文件：\n将原核生物基因组放入 new_prokaryote/ 文件夹。 提供一个包含病毒序列的 FASTA 文件。 在 database/prokaryote.csv 中添加分类信息。 运行命令： 使用以下命令进行预测：\n1 python run_Speed_up.py [--mode MODE] [--t THRESHOLD] --mode MODE：切换模式为预测病毒或宿主（prokaryote 或 virus）。 --t THRESHOLD：预测病毒的置信度阈值，阈值越高，精度越高（默认为 0.98）。 示例：\n1 python run_Speed_up.py --contigs test_contigs.fa --mode prokaryote --t 0.98 输出文件： 输出文件格式为 CSV 文件，包含每个病毒的预测结果。列 prokaryote 是给定原核生物基因组的访问号，列 virus 是可能感染这些基因组的病毒列表。\n常见问题 如果程序输出错误（通常是由于机器配置问题）：\n1 Error: mkl-service + Intel(R) MKL: MKL_THREADING_LAYER=INTEL is incompatible with libgomp.so.1 library. 可以尝试在运行 run_Speed_up.py 之前执行以下命令：\n1 export MKL_SERVICE_FORCE_INTEL=1 如果不想上面这样安装到本地或者很难运行成功，可以使用作者提供的在线网站phabox（https://phage.ee.cityu.edu.hk/phabox），可以直接上传文件进行预测。还是比较方便且运行较快的。\nIPEV：深度学习鉴定原核/真核病毒衍生序列 上面👆的CHERRY是只能鉴定潜在的原核生物宿主，而IPEV可以准确预测原核/真核病毒，可以作为一个扩充。\n通过病毒样颗粒富集获得的病毒组包含原核和真核病毒来源的片段混合物。准确识别和分类这些元素对于理解它们在微生物群落中的作用和功能至关重要。然而，病毒基因组的快速突变率对开发高性能分类工具提出了挑战，可能会限制下游分析。\n研究者提出了一种新颖的方法 IPEV，用于区分病毒组中的原核和真核病毒。该方法结合了二维卷积神经网络，利用三核苷酸对的相对距离和频率进行识别。IPEV 的交叉验证评估显示其在独立测试集上的精度处于领先地位，与现有方法相比，在查询病毒与已知病毒序列相似性低于 30% 的情况下，F1 分数显著提高了约 22%。此外，IPEV 在海洋和肠道病毒组样本上的准确性优于基于序列比对注释的其他方法。IPEV 相较于现有方法在同一计算配置下最多减少了 1,225 倍的运行时间。研究者还利用 IPEV 分析纵向样本，发现肠道病毒组比以往观察到的持久个人病毒组展现出更高的时间稳定性，为个体肠道病毒组的韧性提供了新的见解。\nIPEV 是一种高性能、用户友好的工具，帮助生物学家在病毒组中识别和分类原核和真核病毒。该工具可在 IPEV GitHub 仓库 或 Docker Hub 获取。IPEV 基于 Python3.8.6 和 TensorFlow 2.3.1 构建，通过并行处理和算法优化，能够快速获得计算结果。\n安装使用 IPEV 是一个用于识别病毒组数据中原核和真核病毒序列的深度学习软件工具。以下是安装和使用 IPEV 的详细步骤：\n方法一：从 GitHub 使用\n克隆仓库：\n1 git clone https://github.com/basehc/IPEV.git 创建新环境（推荐以避免与现有包冲突）：\n使用 Conda： 1 2 conda create -n your_env_name python=3.8.6 conda activate your_env_name 使用 virtualenv： 1 2 python3 -m venv /path/to/new/virtual/environment source /path/to/new/virtual/environment/bin/activate 设置操作环境： 进入项目目录并安装必要的依赖项：\n1 2 cd IPEV python -m pip install -r requirements.txt 方法二：从 Docker Hub 使用\n拉取镜像：\n1 docker pull dryinhc/ipev_v1 运行容器： 打开一个新的终端窗口并运行以下命令以启动基于镜像的容器：\n1 docker run -it --rm dryinhc/ipev_v1 传输数据文件： 在新的终端窗口中，将数据文件传输到容器内：\n1 docker cp data.fasta dryinhc/ipev_v1:/app/tool/ 在容器内运行程序： 切换到容器内并运行程序：\n1 2 3 docker exec -it \u0026lt;container_id\u0026gt; /bin/bash cd tool python run.py data.fasta 退出容器： 按 Ctrl+D 或输入 exit 退出容器。\n使用 基本使用： 进入 IPEV 目录并运行示例文件：\n1 2 cd ./IPEV python run.py example.fasta 去除非病毒序列： IPEV 提供了一个功能来过滤掉病毒组数据中的非病毒成分。使用以下命令启用该功能（默认为关闭）：\n1 python run.py example.fasta -filter yes 序列评分文件：程序会生成一个 TSV 文件，包含每个序列的最终评分，存储在以当前日期和时间命名的文件夹中。\n评分直方图：程序还会创建一个直方图，显示不同评分在 FASTA 文件中序列中出现的频率。\n为了节省时间，最好将所有序列放在一个单独的 FASTA 文件中，这样程序可以更快地处理。\n如果需要去除非病毒序列，请确保在运行时使用 -filter yes 参数。\nReferences Joan Carles Pons, David Paez-Espino, Gabriel Riera, Natalia Ivanova, Nikos C Kyrpides, Mercè Llabrés, VPF-Class: taxonomic assignment and host prediction of uncultivated viruses based on viral protein families, Bioinformatics, Volume 37, Issue 13, July 2021, Pages 1805–1813, https://doi.org/10.1093/bioinformatics/btab026 Jiayu Shang, Yanni Sun, CHERRY: a Computational metHod for accuratE pRediction of virus–pRokarYotic interactions using a graph encoder–decoder model, Briefings in Bioinformatics, Volume 23, Issue 5, September 2022, bbac182, https://doi.org/10.1093/bib/bbac182 Hengchuang Yin, Shufang Wu, Jie Tan, Qian Guo, Mo Li, Jinyuan Guo, Yaqi Wang, Xiaoqing Jiang, Huaiqiu Zhu, IPEV: identification of prokaryotic and eukaryotic virus-derived sequences in virome using deep learning, GigaScience, Volume 13, 2024, giae018, https://doi.org/10.1093/gigascience/giae018 ","date":"2025-03-05T00:00:00Z","image":"/p/virus-host/images/IPEV_hu_edf3f79347556902.png","permalink":"/p/virus-host/","title":"宏基因组中病毒序列的宿主预测"},{"content":"Introduction 在生物信息学（生信）研究领域，数据处理和分析任务日益复杂，对计算资源的需求也越来越高。为了提高研究效率、确保环境一致性和可重复性，容器技术应运而生。Docker和Singularity作为两种主流的容器解决方案，在生信领域得到了广泛应用。本文将简单介绍这两种容器的基本概念、使用方法，至少在面对一些提供了Docker安装方式的软件（有可能其他安装方法都报错😂）时可以作为使用的一个选择。\n容器是一种轻量级的虚拟化技术，它允许在单个操作系统实例上运行多个隔离的应用程序。容器将应用程序及其所有依赖项（如库、配置文件等）打包成一个独立的运行环境，称为容器。这种技术使得应用程序可以在不同的环境中一致地运行，而无需担心底层基础设施的差异。\n特点 轻量级：容器共享宿主机的操作系统内核，因此相比传统的虚拟机，容器需要更少的系统资源，启动更快，资源占用更少。 隔离性：容器提供了一定程度的隔离，每个容器都有自己的运行环境，互不干扰。这种隔离是通过操作系统级别的虚拟化技术实现的，如Linux的cgroups和namespaces。 可移植性：由于容器包含了运行应用程序所需的所有依赖项，因此可以在不同的环境（开发、测试、生产等）中无缝迁移和部署。 可扩展性：容器可以快速启动和停止，这使得它们非常适合用于动态扩展应用程序的规模，以应对变化的负载需求。 资源控制：可以为每个容器分配特定的CPU、内存和存储资源，确保应用程序的性能和稳定性。 版本控制和一致性：容器镜像可以被视为应用程序的“快照”，可以通过版本控制工具进行管理。这有助于确保在不同环境中部署的应用程序保持一致。 Docker Docker是目前最流行的容器技术，广泛应用于云计算和开发测试环境，由Docker公司（原名dotCloud）于2013年推出。Docker通过容器技术，将应用程序及其所有依赖项打包到一个独立的单元中，使其能够在任何环境中一致地运行。它通过Docker镜像和容器的概念，实现了应用的快速部署和管理。然而，Docker在高性能计算（HPC）环境中的应用受到一些限制，如权限管理、资源限制等。\nDocker的基本组件 Docker镜像（Image）：一个只读的模板，包含运行应用程序所需的所有文件和依赖项。镜像是构建容器的基础。 Docker容器（Container）：基于镜像创建的可运行实例。容器可以被启动、停止、删除等操作。 Docker仓库（Registry）：用于存储和分发Docker镜像的地方。Docker Hub是最常用的公共仓库，用户也可以搭建私有仓库。 Docker引擎（Engine）：Docker的核心组件，负责构建、运行和管理容器。 基本使用方法 安装Docker 在安装Docker之前，请确保系统满足Docker的最低要求。以下是在常见操作系统上安装Docker的简要步骤：\nUbuntu：\n1 2 sudo apt-get update sudo apt-get install docker-ce docker-ce-cli containerd.io CentOS：\n1 2 3 sudo yum install -y docker sudo systemctl start docker sudo systemctl enable docker macOS：下载并安装Docker Desktop for Mac。\nWindows：下载并安装Docker Desktop for Windows。\n验证安装 安装完成后，可以通过以下命令验证Docker是否安装成功：\n1 docker --version 基本命令 拉取镜像 从Docker Hub或其他仓库拉取镜像：\n1 docker pull ubuntu:latest 查看本地镜像 列出本地已有的镜像：\n1 docker images 运行容器 基于镜像创建并运行一个容器：\n1 docker run -it --name my_ubuntu ubuntu:latest /bin/bash -i：保持容器的标准输入打开。\n-t：分配一个伪终端。\n--name：指定容器的名称。\n查看运行中的容器\n列出当前正在运行的容器：\n1 docker ps 查看所有容器（包括停止的）：\n1 docker ps -a 停止和删除容器 停止容器：\n1 docker stop my_ubuntu 删除容器：\n1 docker rm my_ubuntu 删除镜像 删除本地镜像：\n1 docker rmi ubuntu:latest Dockerfile简介 Dockerfile 是一个用于定义如何构建Docker镜像的文本文件。通过编写Dockerfile，可以自动化构建过程，确保镜像的一致性和可重复性。以下是一个简单的Dockerfile示例：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 # 使用官方Ubuntu镜像作为基础 FROM ubuntu:latest # 更新包列表并安装常用软件 RUN apt-get update \u0026amp;\u0026amp; apt-get install -y \\ python3 \\ python3-pip \\ \u0026amp;\u0026amp; rm -rf /var/lib/apt/lists/* # 设置工作目录 WORKDIR /app # 复制当前目录下的文件到容器的/app目录 COPY . /app # 安装Python依赖 RUN pip3 install --no-cache-dir -r requirements.txt # 暴露端口 EXPOSE 5000 # 设置容器启动时执行的命令 CMD [\u0026#34;python3\u0026#34;, \u0026#34;app.py\u0026#34;] 构建和运行自定义镜像 在包含Dockerfile的目录下，使用以下命令构建镜像：\n1 docker build -t my_python_app . -t：指定镜像名称及标签。 .：指定Dockerfile所在的路径。 构建完成后，运行容器：\n1 docker run -d -p 5000:5000 --name my_running_app my_python_app -d：后台运行容器。 -p：将宿主机的端口映射到容器的端口。 Singularity Singularity是一种开源的容器化技术，专为科学计算、高性能计算（HPC）和大规模计算工作流程设计。它允许用户将应用程序、环境和依赖项打包到一个独立的、可移植的单个文件中，称为SIF（Singularity Image Format）容器镜像。这使得用户可以在不同的系统上无缝地运行相同的容器，包括在没有root权限的环境中运行。\n基本使用方法 安装Singularity\nSingularity可以通过源码、包管理器或Conda等方式安装。以下是通过包管理器安装的示例：\n1 2 3 4 5 # Ubuntu sudo apt-get update \u0026amp;\u0026amp; sudo apt-get install -y singularity-container # CentOS sudo dnf install -y singularity 拉取镜像\n1 singularity pull docker://ubuntu:latest 运行容器\n1 singularity run ubuntu_latest.sif 进入容器交互模式\n1 singularity shell ubuntu_latest.sif 查看容器信息\n1 singularity inspect ubuntu_latest.sif Docker转化Singularity容器 Docker和Singularity都是流行的容器技术，但在设计目标、使用场景和功能上有一些关键区别。\n设计目标\nDocker：最初设计用于开发、测试和部署微服务，强调快速部署和资源隔离。Docker广泛应用于企业级应用和开发测试环境。 Singularity：专为高性能计算（HPC）和科学计算设计，强调在无root权限环境下的安全性和可移植性。Singularity广泛应用于HPC中心和大规模计算工作流程。 安全性\nDocker：默认以root用户运行容器，存在一定的安全风险。虽然可以通过用户命名空间等技术提高安全性，但配置较为复杂。 Singularity：默认以非root用户运行容器，避免了root权限带来的安全问题。它提供了更强的安全保障，适合在多用户HPC环境中使用。 资源管理\nDocker：在资源管理方面较为灵活，但需要用户手动配置资源限制，如内存和CPU的使用。 Singularity：在资源管理方面更加简单直观，支持自动化的资源分配和管理，适合大规模计算任务。 可移植性\nDocker：Docker镜像可以在不同的操作系统和平台上运行，但在HPC环境中可能会遇到兼容性问题。 Singularity：Singularity容器具有更高的可移植性，能够在不同的HPC系统和云平台上无缝运行。 使用场景\nDocker：适合微服务架构、持续集成和持续交付（CI/CD）、跨平台部署等场景。 Singularity：适合高性能计算（HPC）、科学计算、大规模数据分析和需要高效利用资源的场景。 我们实验室的集群就是不允许使用Docker但能用Singularity的。所以有时候要尝试自己将Docker转化Singularity容器：\n将Docker容器转化为Singularity容器是一种常见的操作，因为Singularity提供了更灵活和安全的容器化解决方案，特别是在高性能计算（HPC）环境中。以下是将Docker容器转化为Singularity容器的几种方法：\n方法一：使用本地现有的Docker镜像 查找Docker镜像ID：\n在运行Docker的主机上，使用docker images命令查找所需的Docker镜像ID。 创建Docker镜像的tarball文件：\n使用docker save命令将Docker镜像保存为一个tarball文件。例如： 1 docker save \u0026lt;IMAGE_ID\u0026gt; -o \u0026lt;IMAGE_NAME\u0026gt;.tar 拷贝tarball文件：\n使用scp或其他文件传输工具将tarball文件拷贝到运行Singularity的主机上。 将tarball转换为Singularity镜像：\n在Singularity主机上，使用singularity build命令将tarball文件转换为Singularity镜像。例如： 1 singularity build --sandbox \u0026lt;SINGULARITY_IMAGE_NAME\u0026gt; docker-archive://\u0026lt;PATH_TO_TARBALL\u0026gt; 运行Singularity沙箱镜像：\n使用singularity shell或singularity exec命令进入Singularity容器并执行命令。 方法二：使用Docker容器仓库中的镜像 如果Docker镜像已经上传到Docker Hub或其他Docker托管存储库中，可以直接下载并转化为Singularity容器。\n从Docker Hub下载：\n使用singularity build命令从Docker Hub下载并构建Singularity镜像。例如： 1 singularity build \u0026lt;SINGULARITY_IMAGE_NAME\u0026gt;.sif docker://godlovedc/lolcow 从Quay下载：\n同样，可以从Quay或其他Docker托管存储库下载并构建Singularity镜像。例如： 1 singularity build \u0026lt;SINGULARITY_IMAGE_NAME\u0026gt;.sif docker://quay.io/biocontainers/samtools:1.17--hd87286a_1 方法三：使用Dockerfiles 从Singularity 4.1版本开始，可以直接从Dockerfiles构建OCI-SIF映像。\n编写Dockerfile：\n编写一个Dockerfile，定义所需的基础镜像和命令。 构建Singularity镜像：\n使用singularity build命令从Dockerfile构建Singularity镜像。例如： 1 singularity build --oci \u0026lt;SINGULARITY_IMAGE_NAME\u0026gt;.oci.sif \u0026lt;Dockerfile\u0026gt; 运行Singularity镜像：\n使用singularity run命令运行构建的Singularity镜像。 通过这些方法，可以将Docker容器轻松地转化为Singularity容器，从而在需要更高安全性和灵活性的环境中使用。\n参考文献： https://cloud.tencent.com/developer/news/1351431 https://www.showapi.com/news/article/66c4d6274ddd79f11a08c187 https://segmentfault.com/a/1190000044706625 ","date":"2025-03-05T00:00:00Z","image":"/p/docker-singularity/images/docker_hu_31ad446a8d9e59a5.webp","permalink":"/p/docker-singularity/","title":"容器（Docker \u0026 Singularity）使用入门"},{"content":"Introduction 随着基因组挖掘技术的进步，生物合成基因簇（BGCs）的研究已成为天然产物发现的核心环节。目前，超过20万个公开的微生物基因组中蕴藏着丰富的化学多样性信息。然而，现有的工具在处理大规模BGCs时，常因基于网络的聚类方法效率低下而面临瓶颈。\nBiG-SLiCE（Biosynthetic Gene clusters - Super Linear Clustering Engine） 应运而生，这是一款专为高效聚类大规模BGCs而设计的工具。它通过将BGCs映射到欧几里得空间，以近乎线性的方式将BGCs分组为基因簇家族（GCFs）。在短短10天内，BiG-SLiCE成功分析了来自209,206个微生物基因组和宏基因组组装基因组（MAGs）的1,225,071个BGCs，并构建了全球次级代谢多样性的分布图谱，揭示了未被开发的生物合成潜力。此外，BiG-SLiCE还提供了“查询模式”，能够快速将新测序的BGCs归类到已有的GCFs中，并配备了强大的可视化引擎，便于用户探索数据。这一工具不仅加速了天然产物的发现，还为构建全球可搜索的BGC网络奠定了基础。\nBiG-SLiCE的开源地址：https://github.com/medema-group/bigslice\nBGCs（以及GCFs）与催化酶及其编码途径产生的化合物直接相关，因此可以作为探索微生物次级代谢化学空间的代理。通过编目所有已测序微生物基因组中的GCFs，可以全面了解现有的化学多样性，并为未来的先导化合物发现提供方向。例如，可以重点关注具有新颖潜力的物种，或识别已知抗生素生产BGC的天然变体。然而，进行此类全球分析需要能够处理海量数据的聚类算法。尽管过去五年中工具的处理能力有所提升（从2014年的11,000–33,000个BGCs到2019年的73,260个），但与当前可用数据量相比仍显不足。截至2020年3月27日，antiSMASH-DB和IMG-ABC两大BGC数据库共包含565,096个BGCs，预测自85,221个细菌基因组。若考虑未覆盖的基因组和宏基因组，这一数字将更大。例如，NCBI RefSeq数据库中的约180,000个细菌基因组可能产生超过1,000,000个BGCs。\n处理如此大规模的数据集，即使是目前最快的工具（如BiG-SCAPE）在36核CPU上也需要约37,000小时运行时间，这在实际中几乎不可行。主要瓶颈在于构建相似性网络和聚类分析时使用的成对BGC比较方法，其时间复杂度为O(n²)。因此，迫切需要一种能够更好适应基因组数据增长的替代方法。为此，研究者开发了BiG-SLiCE（Biosynthetic Genes Super-Linear Clustering Engine），它将BGCs映射到欧几里得空间，采用分区聚类算法，时间复杂度接近线性[∼O(n)]，从而能够快速分析大规模BGC数据集，实现真正全球化的GCF分析。\n为了实现大规模分析，BiG-SLiCE在设计时将可扩展性和速度作为首要目标。与之前的工具BiG-SCAPE（能够敏感捕捉BGCs之间域结构和序列相似性的细微差异）不同，BiG-SLiCE能够在36核CPU、128GB内存的机器上，以不到一周的时间处理超过120万个BGCs的输入数据，同时保持足够的灵敏度以区分输入BGCs中的关键生物合成“信号”。此外，为了便于用户探索和分析结果，BiG-SLiCE还提供了交互式、易于使用的可视化输出，且对软硬件要求极低。\nInstallation 安装方法非常简单，用以下两种选一个即可\n从PyPI安装（稳定版） 1 pip install bigslice 从源码安装（开发版——仅适用于熟悉操作的用户） 1 pip install git+https://github.com/medema-group/bigslice.git 然后下载最新的HMM模型（约271MB压缩文件）\n1 download_bigslice_hmmdb 如果感觉下载太慢了，也可以手动下载：https://github.com/medema-group/bigslice/releases/download/v2.0.0rc/bigslice-models.2022-11-30.tar.gz，下载后重命名为bigslice_models.tar.gz放到whcih download_bigslice_hmmdb的统一目录下再运行即可，就会跳过下载步骤。\n最后检查安装是否成功\n1 bigslice --version 成功安装后，将显示如下信息：\n1 2 3 4 5 6 ============== BiG-SLiCE version 2.0.0 HMM databases version: bigslice-models-2022-11-30 Biosynthetic-pfam md5: 37495cac452bf1dd8aff2c4ad92065fe Sub-pfam md5: 2e6b41d06f3c318c61dffb022798091e ============== Usage BiG-SLiCE 运行模式 [模式1] 聚类分析 解析输入数据集，构建GCF模型（BIRCH聚类），并根据指定阈值（T）进行成员分配。\n参数说明：\n-i|--input_folder \u0026lt;folder_path\u0026gt;：输入文件夹路径，需包含 datasets.tsv 文件及数据集子文件夹。 --resume：继续上一次的聚类运行（不要与 --input_folder 同时使用）。 --complete：构建GCF模型时，仅使用完整的BGCs（antiSMASH \u0026gt; 4.2 标注为 on_contig_edge = False 的BGCs）。 --threshold：用于GCF模型构建（BIRCH算法）和成员分配的聚类阈值（T）。与 --threshold_pct 互斥，使用 -1 关闭此参数（默认：300）。 --threshold_pct：基于数据间成对距离的随机采样计算聚类阈值（T），取第N百分位值作为阈值。与 --threshold 互斥，使用 -1 关闭此参数（默认：-1）。 [模式2] GCF查询 基于[模式1]生成的GCF模型，从输入文件夹中的BGC GenBank文件中提取特征并进行成员分配。\n参数说明：\n--query \u0026lt;folder_path\u0026gt;：输入文件夹路径，需包含所有BGC的GenBank文件（支持antiSMASH4的 clusterXXX.gbk、antiSMASH5的 regionXXX.gbk 或MIBiG ≥ 2.0的 BGCXXXXXXX.gbk）。 --query_name：为查询运行指定唯一名称，便于在输出可视化中追踪。 [模式1+2] 通用参数 适用于聚类和查询模式的参数。\n参数说明：\n--run_id：指定运行ID进行查询（或继续聚类），而非使用最新运行（可在输出可视化中查看运行ID列表）。 --n_ranks \u0026lt;N_RANKS\u0026gt;：为每个BGC的成员分配过程取N个最佳GCF匹配（默认：5）。 --program_db_folder \u0026lt;PROGRAM_DB_FOLDER\u0026gt;：HMM库路径（默认：/mnt/local_scratch/kauts001/general-env/bin/bigslice-models）。 CPU/RAM优化 -t|--num_threads：并行运行的作业数（默认：56）。 --hmmscan_chunk_size：将 biosyn_pfam 扫描拆分为每组N个BGCs的块（默认：100）。 --subpfam_chunk_size：将 sub_pfam 扫描拆分为每组N个BGCs的块（默认：100）。 --extraction_chunk_size \u0026lt;EXTRACTION_CHUNK_SIZE\u0026gt;：将特征提取拆分为每组N个BGCs的块（默认：100）。 --scratch：不将Sqlite3数据库加载到内存中（降低RAM使用，但可能降低速度）。 [Misc] 其他可选参数： -h, --help 显示帮助信息。 --export-tsv \u0026lt;folder_path\u0026gt; 将现有的预计算输出数据导出为TSV格式文件（指定目标文件夹路径）。 --program_db_folder PROGRAM_DB_FOLDER 指定HMM库的路径（默认路径：/share/home/jianglab/pengchen/miniconda3/envs/antismash_5.2.0/bin/bigslice-models）。 --version 显示BiG-SLiCE的版本信息。 Example 可以使用提供的示例输入文件夹进行“最小化”测试运行：\n下载https://github.com/medema-group/bigslice/tree/master/misc/input_folder_template这个文件夹，里面只有1个dataset，1个genome，2个gbk。\n1 bigslice -i input_folder_template/ test_out/ 这里我遇到了一个问题：\n1 AttributeError: \u0026#39;pyhmmer.plan7.TopHits\u0026#39; object has no attribute \u0026#39;query_accession\u0026#39; 应该是pyhmmer的版本问题，我尝试安装v0.10.7版本后解决：\n1 pip install pyhmmer==0.10.7 通过以上步骤，可以轻松安装并运行 BiG-SLiCE，开始大规模 BGC 聚类分析！我测试了运行了2min，消耗内存160MB\nInput files 为了充分利用BiG-SLiCE的强大功能，其输入的BGC文件需要按数据集和基因组的结构进行组织。一个典型的输入文件夹可能如下所示：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 input_folder/ │ ├── datasets.tsv │ ├── dataset_1/ │ ├── genome_1A/ │ │ ├── genome_1A.region001.gbk │ │ ├── genome_1A.region002.gbk │ │ └── ... │ ├── genome_1B/ │ └── ... │ ├── dataset_2/ │ ├── genome_2A/ │ └── ... │ ├── dataset_3/ │ ├── genome_3A/ │ └── ... │ └── taxonomy/ ├── taxonomy_dataset_1.tsv ├── taxonomy_dataset_2.tsv └── ... datasets.tsv 文件 该文件需要严格命名为 datasets.tsv，并放置在输入文件夹的根目录中。它是一个描述所有BGC元数据的文件，BiG-SLiCE使用它来解析输入文件夹中的所有BGC数据。该文件应该是一个以制表符分隔的文件（.tsv），每一行按以下顺序包含以下内容： •\t数据集名称 •\t数据集文件夹的路径（相对于输入文件夹根目录的路径） •\t分类信息文件路径（见 \u0026lt;taxonomy_X.tsv\u0026gt; 文件） •\t数据集描述\n以 # 开头的行将被解析器跳过，因此可以用来定义表头等。可以从代码库下载一个模板 datasets.tsv 文件作为起始点。\n\u0026lt;dataset_X\u0026gt; 文件夹 数据集是BiG-SLiCE中用来分组基因组和BGCs的灵活分类方案。例如，可以根据样本来源将Metagenome-Assembled Genomes（MAGs）归为一个数据集，也可以根据原始文献将基因组和MAGs归类，用于元分析研究。每个数据集文件夹下应直接包含基因组文件夹。\n\u0026lt;genome_X\u0026gt; 文件夹与 \u0026lt;genome_X.regionXXX.gbk\u0026gt; 文件 这些文件夹是由antiSMASH运行产生的输出文件夹，包含 \u0026lt;genome_name\u0026gt;.regionXXX.gbk（antiSMASH 5）或 \u0026lt;genome_name\u0026gt;.clusterXXX.gbk（antiSMASH 4）文件。此外，MIBiG \u0026gt;= 2.0格式的文件（名为 BGCXXXXXXX.gbk，可以通过“Download GenBank summary file”获取）也被BiG-SLiCE接受。请确保不修改这些命名格式，因为BiG-SLiCE依赖它们快速区分集群文件（clustergbks）和常规基因组文件。\n\u0026lt;taxonomy_X.tsv\u0026gt; 文件 虽然可以从antiSMASH 5（和MIBiG \u0026gt;= 2.0）生成的cluster genbank文件中提取分类信息（因为这些文件保留了原始基因组的注释），但这些信息并没有统一的方式来为提供的分类名（通常是分号分隔的 ;）指定等级（如：界、门、纲、目、科、属、种等）。为了确保最佳的注释质量和分析结果，BiG-SLiCE要求用户为每个数据集手动提供分类学元数据（如果可能的话），并以制表符分隔的文件（.tsv）格式包含以下内容（按照此顺序）：\n1 2 3 4 5 6 7 8 Genome folder name (ends with \u0026#39;/\u0026#39;) Kingdom / Domain name Class name Order name Family name Genus name Species name Organism / Strain name 为了确保所有数据集中的分类名称一致，建议使用相同的参考数据库为分类名称指定等级。为了帮助用户自动化这一过程，BiG-SLiCE提供了一些Python脚本，可以基于原始输入基因组（而非集群基因组文件）使用GTDB工具包为分类信息赋予等级（此脚本仅适用于完整的古菌和细菌基因组，下载脚本）。如果基因组来自NCBI RefSeq/GenBank（即具有GCF_*或GCA_*号的基因组），可以使用此脚本从GTDB API提取分类信息。\nOutput 输出文件夹结构：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 test_out/ ├── app │ ├── config.py │ ├── controllers │ ├── __init__.py │ ├── __pycache__ │ ├── run.py │ ├── static │ └── views ├── LICENSE.txt ├── requirements.txt ├── result │ ├── cache │ ├── data.db │ └── tmp └── start_server.sh 直接这样的输出db文件是很难查看的，新版介绍可以用--export-tsv导出表格，\n1 bigslice test_out/ --export-tsv test_out/result_tsv 但是目前有AttributeError: 'tuple' object has no attribute 'values'的报错，官方还没解决。但是可以自己使用sqlite3对结果的data.db文件进行查看和文件导出。\n或者使用用户交互输出：\nBiG-SLiCE的输出文件夹包含处理后的输入数据（以SQLite3数据库文件的形式）以及一些脚本，这些脚本支持一个小型的Web应用程序来可视化这些数据。要运行该可视化引擎，按照以下步骤操作：\n安装Web应用的依赖包： 首先，确保安装了所需的依赖包。运行以下命令来安装requirements.txt中列出的所有依赖： 1 pip install -r \u0026lt;output_folder\u0026gt;/requirements.txt 启动Flask服务器： 然后，通过以下命令启动Flask服务器： 1 bash \u0026lt;output_folder\u0026gt;/start_server.sh \u0026lt;port(可选)\u0026gt; 默认情况下，服务器会在端口5000上启动。如果需要自定义端口，可以在命令中指定端口号。\n打开浏览器访问： 启动服务器后，浏览器将显示如下信息： Running on http://0.0.0.0:5000/ (Press CTRL+C to quit)\n在浏览器中输入 http://0.0.0.0:5000 即可访问Web应用进行数据可视化。\n通过上述步骤，您可以轻松启动BiG-SLiCE的可视化应用，查看处理结果和数据分析图表，如下图所示：\nBGC Atlas 上次提到过的BGC Atlas，那个数据库用的就是BiG-SLiCE的输出结果。该数据库可供下载的有这几个文件：\ncomplete-bgcs.tar.gz A tarball containing the GBK files for only the complete BGC (3.5GB).\nall-bgcs.tar.gz A tarball containing the GBK files for all BGCs (13GB).\nbigslice_2.0.0_T0.4_16April.tar.gz A tarball containing the BiG-SliCE clustering of complete BGCs (2.0 GB).\natlas_17_07_2004.sql The sql dump of the BGC-Atlas database (2.0 GB).\nbigslice_2.0.0_T0.4_16April.tar.gz文件解压后就是BiG-SLiCE的输出文件夹，里面有result文件夹，里面有data.db文件，这个就是BiG-SLiCE处理后的数据库文件。\n另外atlas_17_07_2004.sql里面有所有用到的宏基因组metadata，但它是个PostgreSQL database dump，作为文本文件可以直接打开，但不好转换为数据库或是表格，需要用一下postgresql。\n使用案例 比如我们自己产生的BGC想要和BGC Atlas进行比较，就可以用[模式2] GCF查询：\n1 bigslice --query gbk_files/ --query_name test_MAGs bigslice_2.0.0_T0.4_16April/ -t 8 然后就会在big_slice_test_out目录下产生一个report文件夹（如果原来没有的话），report文件夹下可以找到自己本次运行的结果。可以考虑用户交互输出或用数据库软件查看结果。\n主要是查看distance（membership_value）这一列，按默认定义的话\u0026lt;0.4才可以认为我们的query和数据库已有的部分聚成了GCF。\n然后我们可以查看相应的GCF中有哪些BGCs以及所对应的metadata：\n比如我们的BGC和BGC Atlas中的GCF 13734的distance\u0026lt;0.4，可以认为也是GCF 13734的一员，然后快速的方法是去官网查询https://bgc-atlas.cs.uni-tuebingen.de/bgcs?gcf=13734，可以看到一共有258条核心BGC，我们可以下载相应的metadata（一次最多1000条），然后和我们的进行比较分析。\n但上述方法只适合查询的BGC不多的情况，很多的话最好还是考虑用代码处理atlas_17_07_2004.sql文件，获取metadata，需要使用postgresql进行处理：\n假设你已经会用并成功运行了postgresql（有点难）\n1 2 3 4 5 6 # 运行 brew services start postgresql # 创建 createdb -U asa atlas_db # 导入 psql -U asa -d atlas_db -f atlas_17_07_2004.sql 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 # 查看表 atlas_db=# \\dt List of relations Schema | Name | Type | Owner --------+-------------------------+-------+------- public | antismash_runs | table | asa public | antismash_runs_bk | table | asa public | assembly2biome | table | asa public | assembly2longestbiome | table | asa public | bigscape_clustering | table | asa public | bigscape_networks | table | asa public | bigslice_gcf | table | asa public | bigslice_gcf_membership | table | asa public | biomes | table | asa public | mgnify_asms | table | asa public | mgnify_asms_old | table | asa public | mibig_membership | table | asa public | protoclusters | table | asa public | protoclusters_bk | table | asa public | regions | table | asa public | regions_backup | table | asa public | regions_bk | table | asa public | sample_metadata | table | asa public | sample_metadata_old | table | asa (19 rows) atlas_db=# SELECT * FROM assembly2longestbiome limit 10; assembly | longest_biome --------------+------------------------------------------------- MGYA00002187 | root:Host-associated:Animal:Digestive system MGYA00002188 | root:Environmental:Terrestrial:Soil:Forest soil MGYA00002318 | root:Host-associated:Animal:Digestive system MGYA00002319 | root:Host-associated:Animal:Digestive system MGYA00002320 | root:Host-associated:Animal:Digestive system MGYA00003147 | root:Host-associated MGYA00003148 | root:Host-associated MGYA00004354 | root:Environmental MGYA00004355 | root:Environmental MGYA00004356 | root:Environmental (10 rows) 1 2 #导出csv psql -U asa -d atlas_db -c \u0026#34;COPY assembly2longestbiome TO STDOUT WITH CSV HEADER\u0026#34; \u0026gt; assembly2longestbiome.csv 然后就可以查看csv并和自己的数据整合分析。\nReference Satria A Kautsar, Justin J J van der Hooft, Dick de Ridder, Marnix H Medema, BiG-SLiCE: A highly scalable tool maps the diversity of 1.2 million biosynthetic gene clusters, GigaScience, Volume 10, Issue 1, January 2021, giaa154. https://doi.org/10.1093/gigascience/giaa154\n","date":"2025-02-27T00:00:00Z","image":"/p/big-slice-bgcs/images/bgc_intro_hu_f0edb9cb1296086d.png","permalink":"/p/big-slice-bgcs/","title":"使用BiG-SLiCE高效聚类大规模BGCs"},{"content":"Introduction 抗生素耐药性是对人类健康和疾病临床治疗日益严重的全球性威胁。在过去十年中，已在所有环境中检测到抗生素抗性基因(ARG)，包括自然、工程和临床及栖息地。包括抗生素的临床使用在内的人为活动，被广泛认为是ARGs传播的主要驱动力。很早之前也写过一篇介绍抗生素，ARG以及相应生信分析方法的文章，这里想要介绍一下几篇全球尺度的ARG相关研究，他们已经整理好的数据还可以作为自己研究数据的背景参考。\nARG的全球健康风险评估 这是一篇2022年发表在NC上的文章《Assessment of global health risk of antibiotic resistance genes》，研究者使用4572个宏基因组数据集来揭示2561个ARG及其宿主在全球栖息地的分布和传播。他们实施了一个框架，通过考虑四个指标（人类可及性、流动性、人类致病性和临床可用性）来定量评估每个ARG和样本的健康风险。有23.78%的ARGs对健康构成威胁，尤其是那些具有多重耐药性的ARGs。\n这篇NC用来鉴定ARG的方法是RGI工具+CRAD数据库跑reads，应该是比较常见的做法，文章也提供了所有sample的metadata以及鉴定出来的ARG丰度表，都在https://figshare.com/articles/dataset/Supplementary_Tables/19189652里，可以搞下来和自己的数据比较。\nARG分布的全球模式 研究者用4572个宏基因组样本展示ARG分布全球模式，样本源于空气、水生、陆地、工程、人类和其他宿主六类栖息地。从中依据综合抗生素研究数据库确定2561个ARG，可抵抗24种药物类别抗生素，2401个仅对一种药物耐药，160个对多种药物耐药，25个ARG在超75%样本中被发现，近一半ARGs在不同栖息地共享，表明人为活动对ARGs全球传播很关键。\n人为活动影响ARGs传播方面，按总体人口密度将采样点分两组，高强度活动区域ARG总丰度和特定抗性基因显著更高，不同ARGs与人为活动相关性不同影响其对人类健康风险，后续从人类可及性、流动性、人类致病性和临床可用性四个指标评估ARGs健康风险。\n在ARGs的人类可及性上，检查人类与其他三个主要栖息地共享的ARG，建筑环境与人类栖息地共享最多，多数为多药和β - 内酰胺类药物抗性，确定人类栖息地中ARG的平均丰度和流行率后计算人类可及性，发现只有一小部分ARGs对人类高度可及并有潜在风险。\n对于ARG宿主和移动遗传元件（MGEs）在不同栖息地的分布，实施严格质量标准提高ARGs宿主识别准确性，确定7555个MAG为ARG宿主，个体ARGs宿主在不同生境差异显著，多数宿主特定于一个栖息地，人工和人类相关栖息地宿主不如自然栖息地多样，可能是人为活动选择性压力所致 。\nARG的健康风险评估 研究者分析ARGs特征以确定其人类可及性、流动性和人类致病性，进而评估其从环境转移到人类并推动耐药病原体进化的潜力，还通过系统评估ARGs对人类健康的风险确定其临床相关性。全球抗生素使用数据显示青霉素和头孢菌素这两种β - 内酰胺类抗生素使用最多，在检测到的2561个ARG中，对临床可用抗生素耐药性的基因占比较大。\n研究者用四个计算指标（人类可及性、流动性、人类致病性和临床可用性）评估每个ARG的整体健康风险，除临床可用性外其他指标仅涵盖约一半ARG ，计算风险指数RI = HA × MO × HP × CA 。结果表明抗生素使用增加了ARGs对人类健康的风险并可能导致临床感染治疗失败，属于Q1的ARG数量显著多于其他等级，Q3和Q4的ARGs很少被病原体基因组携带，证明了健康风险评估工作的有效性。基于四个主要栖息地（水生、陆地、工程、与人类相关）发现与人类相关的栖息地构成抗生素耐药性的最高风险 。\n城市微生物群落和ARG的全球宏基因组图谱 《A global metagenomic map of urban microbiomes and antimicrobial resistance》，这是一项关于全球公共室内环境（公共交通工具）微生物图谱的重要研究，于2021年发表在Cell上。\n研究呈现了一个全球地图集，涵盖60个城市公共交通系统的4728个宏基因组样本，是全球首个系统性城市微生物生态系统目录。该图谱包含注释的微生物菌株地理空间信息、功能特征、抗菌素耐药性标记及遗传元素，有10928种病毒、1302种细菌、2种古菌以及838532种未在参考数据库发现的CRISPR序列。研究发现4246种已知城市微生物，97%的样本中有31种不同于人类共生生物的物种；不同城市抗菌素耐药性基因的类型和密度差异明显；城市因气候和地理差异呈现出独特的微生物分类特征。这些结果构成高分辨率全球宏基因组图谱，有助于发现生物体和基因，凸显公共卫生和法医应用潜力，还为城市抗菌素耐药性负担提供了新的视角。\n城市微生物群特征 研究者调查全球城市环境微生物种类分布，发现分类群流行率双峰分布，据此定义亚核心组、外围组和真正核心类群，确定1145种微生物构成亚核心城市微生物群、31种为真正核心微生物群，亚核心群主要是细菌，全球城市常见三个细菌门为变形杆菌、放线杆菌和厚壁菌门。\n虽几乎所有样本都有核心城市微生物群，但城市间在分类和定位上有差异，计算Jaccard距离并使用UMAP降维可视化，发现亚群大致对应气候而非地表类型，功能代谢剖面有地理空间差异，时间可能影响分类变化。MAVRIC分析表明城市是影响分类组成的最重要因素，其次是地区，对分类数据进行PCA分析，两个显著主成分与城市气候有关，样本相似性有邻域效应。\n全球范围内，多数样品含放线菌门、拟杆菌门、厚壁菌门和变形菌门，不同大陆相对丰度有别，功能途径在各大陆间更稳定，抗菌素耐药性种类因大陆而异。比较样本分类剖面和功能剖面距离，分类图谱平均Jensen-Shannon divergence高于功能。\n创建GeoDNA和MetaGraph用于搜索原始序列，训练随机森林分类器预测样本来源，对培训集中未出现的城市特征预测表明城市特异性分类特征可预测样本来源，且城市特有的分类群分布不均，制定分数反映分类群在城市中的流行程度，其分布呈区域和城市双峰分布 。\nARG形成了不同的clsuter 抗生素多样性和AMR的量化是全球抗生素管理的关键，仅从基因序列预测抗生素耐药性有挑战，检测准确性取决于抗生素类别。作为全球城市环境中抗生素耐药性调查的第一步，研究者用MegaRES本体和比对软件将reads映射到已知抗生素耐药性基因，用20类抗生素耐药基因的RPKM量化其相对丰度，2210份样本中部分序列与AMR基因对齐，但无一致的AMR基因核心集。\n常见抗生素耐药基因类别有大环内酯类等，其中MLS仅在部分样本中发现，还量化了耐药基因的可能机制，常见三种耐药机制在一些样本中未发现。抗生素耐药基因丰度普遍低于功能基因，但一些样本含众多不同AMR基因序列，高AMR多样性集群在城市中分布不均，不同城市情况有差异。\n检测到AMR基因的病例平均深度表明整体分布不受读取深度显著影响，训练随机森林模型预测城市分类，其准确率优于随机概率但远低于分类预测器，因AMR基因更具移动性，可能代表较弱的城市特异性特征。此前研究表明质粒可携带大量AMR基因，生态竞争可致同一样本多个类群产生耐药性，在城市环境中研究较少。\n研究者鉴定相同样本中出现的AMR基因簇，测量基因对间Jaccard距离并聚类，发现三个大基因群和许多小基因群，这些集群常由多抗性类别基因组成且大型集群基因更多。对数据集中所有抗性基因集进行稀疏分析（泛抗性组），发现其与被检测物种发现率相似，呈现开放斜率，未来分析可能发现更多抗性基因。此外，AMR基因在地理位置相近样本中表现出邻域效应，同一城市样本的AMR基因组间Jaccard距离随距离增大而增大，总体影响微弱但显著 。\n土壤ARG的全球生物地理学及预测 这是2022年发表在Science Advances上的《Global biogeography and projection of soil antibiotic resistance genes》，该研究生成了一张全球土壤抗生素抗性基因丰度图，其中确定的微生物宿主、农业活动和人为因素解释了印度、东亚、西欧和美国的抗生素抗性基因热点。研究者的结果突显了来自携带抗生素抗性基因的土壤临床病原体的健康威胁，并确定了在全球范围内控制土壤抗生素抗性的重点地区。\n这篇文章用的也是比较常用的软件ARG-OAP跑的reads，应该也是可以方便整合自己的数据的。\n土壤ARG的空间格局 研究者的1088个土壤观测结果显示，共有23种抗生素抗性基因类型和558个亚型。样本中平均有12.42种基因类型和49.24个亚型，多为编码多重耐药性、MLS、万古霉素和膦胺霉素的基因，最常检测到的亚型是mexF 。抗生素抗性基因归一化丰度平均为121.20 ppm，主要由多重耐药性基因主导。\n通过PERMANOVA分析，不同栖息地抗生素抗性基因组成存在显著差异，农业栖息地丰度较高，不同大陆间也有明显差异，澳大利亚最丰富，且从低纬度到极地丰度呈增加趋势。研究者鉴定出9种可移动遗传元件类型和157个亚型，有助于土壤抗生素抗性基因的存在和持久性。其总归一化丰度平均为55.26 ppm，转座酶占主导。抗生素抗性基因归一化丰度与多种可移动遗传元件显著相关。\n土壤微生物归一化丰度平均为232,179.53 ppm，细菌是主导分类群，变形菌门在门水平上占优，放线菌门次之 。研究者鉴定出携带抗生素抗性基因或可移动遗传元件的微生物占总物种的20.97%，但归一化丰度仅1.36%。这些微生物宿主涵盖多个分类层级，其组成与土壤微生物群落组成有差异，在各分类水平上都有不同表现，且抗生素耐药微生物组中一些物种是多重耐药基因和转座酶的核心宿主，抗生素抗性基因及其微生物宿主、可移动遗传元件及其微生物宿主之间均呈正相关 。\n土壤ARG的地理驱动因素 为研究土壤抗生素抗性基因丰度空间模式的地理机制，研究者将潜在环境约束整合到16个主成分中，抗生素抗性基因丰度变异性主要受与人类活动相关主成分（57.52%）控制，代表人类输入、畜牧业和农业污染的贡献，气候和植被（17.18%）及土壤养分（7.07%）主成分贡献较小，且气候和植被因素影响相互关联。\n分析表明抗生素抗性基因丰度与多数人为因素呈正向关联，如畜牧业生产随其丰度增加而显著增加，土壤养分增加在中等范围内会提高丰度，气候参数影响较复杂，温度降低丰度减少，降水增加丰度增加。\n通过结构方程模型检查地理属性对抗生素抗性基因归一化丰度的因果效应，发现其影响通过微生物因素介导，人为因素引入携带相关基因和元件的微生物间接提高丰度，气候变量也通过土壤养分等多种因素间接影响。\n研究者利用169个空间协变量，基于四种机器学习算法预测土壤抗生素抗性基因归一化丰度，经优化后随机森林最优，构建了0.083°分辨率的归一化丰度图谱，显示西欧、东亚、南亚和美国东部等地丰度最高，高纬度地区也有较高丰度，与纬度梯度一致，应用变异系数量化不确定性，在西伯利亚等地显示较高不确定性，但模型表现稳健。\nReferences Zhang, Z. et al. Assessment of global health risk of antibiotic resistance genes. Nat. Commun. 13, 1553 (2022). Danko, D. et al. A global metagenomic map of urban microbiomes and antimicrobial resistance. Cell 184, 3376-3393.e17 (2021). Zheng, D. et al. Global biogeography and projection of soil antibiotic resistance genes. Sci. Adv. 8, eabq8015 (2022). ","date":"2025-02-27T00:00:00Z","image":"/p/global-arg/images/global1_hu_ce047fe4cd684104.png","permalink":"/p/global-arg/","title":"全球尺度的抗生素耐药基因（ARG）研究"},{"content":"Introduction 次级代谢产物（Secondary Metabolites）是微生物在生长过程中产生的非必需化合物，尽管对微生物自身的生长发育并非不可或缺，却在生态和生理功能中扮演着重要角色。这些化合物在医药、生物技术和农业领域具有广泛的应用潜力。它们的合成由生物合成基因簇（Biosynthetic Gene Clusters, BGCs）编码，这些基因簇共同指导次级代谢产物的生物合成。随着宏基因组学技术的发展，研究人员能够直接从环境样本中研究BGCs，发现了许多编码全新化学结构的未知基因簇。\n上次介绍过一下生物合成基因簇家族（GCF）相关的Big-Fam数据库，但它的源数据来自培养的微生物基因组或存放在公共存储库中的MAG的数据。而且它不提供相应数据的下载，上传还是AntiSmash的id，想要跟自己宏基因组产生的大量BGCs比较不太可能。\n本文介绍一个比较新的名为BGC Atlas的网络资源（https://bgc-atlas.cs.uni-tuebingen.de），它为探索和分析宏基因组中的BGC多样性提供了便捷的工具。该工具最近发表在了NAR上：\nCaner Bağcı, et.al, BGC Atlas: a web resource for exploring the global chemical diversity encoded in bacterial genomes, Nucleic Acids Research, Volume 53, Issue D1, 6 January 2025, Pages D618–D624, https://doi.org/10.1093/nar/gkae953\nBGC Atlas从公开数据集中识别并聚类BGCs，提供了一个集中化的数据库和网络界面，支持基于元数据的BGC和基因簇家族（Gene Cluster Families, GCFs）的探索。通过对MGnify平台上超过35,000个数据集的分析，BGC Atlas识别了近180万个BGCs，并将其聚类为GCFs。分析结果显示，核糖体合成并经翻译后修饰的肽类（RiPPs）是最丰富的化合物类别，且大多数GCFs表现出高度的环境特异性。\nDatabase 数据收集与预处理 研究者从公共数据库MGnify收集了宏基因组数据集及其对应的元数据。这些数据集涵盖了海洋、土壤、人体相关及其他环境样本。对于每个样本，研究者获取了FASTA格式的组装contigs以及描述样本环境和生物学背景的元数据（上图）。\nBGC识别 使用antiSMASH（版本7.0.0）识别BGCs，参数设置为--clusterhmmer --tigrfam --asf --cc-mibig --cb-subclusters --cb-knownclusters --pfam2go --rre --tfbs --genefinding-tool prodigal-m --allow-long-headers。antiSMASH提供了全面的注释信息，包括次级代谢产物类型、预测的化学结构和功能域，并构建了antiSMASH-DB用于存储和比较BGCs。\nBGC聚类 使用BiG-SLiCE（版本2.0.0）将BGCs聚类为基因簇家族（GCFs），基于序列相似性和域结构进行分组，形成非冗余的GCFs集合（上图）。聚类过程分为两步：\n初始聚类：对antiSMASH标注为完整的BGCs进行聚类，距离阈值为0.4，确保核心簇定义明确。 部分BGCs分配：将antiSMASH标注为“on contig edge”的部分BGCs和MIBiG数据库中的已知化合物分配到预定义的簇中，距离阈值同样为0.4，保留最佳匹配结果。 数据库与网络界面 BGC识别和聚类结果存储在PostgreSQL数据库中，支持复杂查询和高效数据管理。研究者还开发了BGC Atlas的网络界面，基于node.js、express、pug、leaflet和bootstrap构建，提供以下功能：\nBGC和GCF探索：浏览BGCs、查看详细注释及其在不同环境中的分布。 元数据整合：将BGC数据与环境元数据结合，支持生态和进化分析。 查询功能：用户可输入BGC序列，使用BiG-SLiCE查询模式在数据库中搜索相似簇，结果以表格形式展示输入BGC与最接近GCF的距离。 BGC Atlas 提供了多种视图和功能，用于探索宏基因组样本、BGCs 和 GCFs。所有视图均支持基于自由文本或元数据特征的搜索和过滤。通过“Filter”菜单，用户可以使用布尔逻辑组合多个条件进行查询，例如搜索来自“Arctic”（地理位置特征）环境的“Marine”（生物群落特征）BGCs。\nSamples 视图：展示所有分析样本及其元数据特征，用户可通过antiSMASH界面进一步探索这些样本。 BGCs 视图：显示数据库中所有BGCs的表格，支持过滤功能以进行更具体的查询。 GCFs 视图：展示所有GCFs的表格，选择特定GCF后，“BGCs”视图将仅显示该GCF的成员BGCs。 这种设计使用户能够在不同视图之间切换，结合详细注释和分布信息，深入比较分析BGCs及其所属GCFs，并通过元数据探索其生态学意义（上图）。\nResult BGC结构类别的分布 研究者对MGnify的35,486个数据集进行了初步分析，发现了约185万个BGCs，分布于多种环境样本中。其中，绝大多数（88.7%）BGCs被antiSMASH标注为“on contig edge”，表明它们的不完整性，这主要是由于宏基因组测序通常产生较短的contigs。尽管如此，超过一半（51.7%）的BGCs长度仍超过5 kb，完整BGCs的中位长度约为21 kb。\n在分析的BGCs中，核糖体合成并经翻译后修饰的肽类（RiPPs）占比最高（52.3%），其中环内酯自诱导物是最常见的产物类型（16.5%）。RiPPs的高比例可能与数据库中宿主相关样本的过度代表性有关。多项研究表明，RiPPs是人类微生物组中最常见的BGC类别，特别是在乳酸菌基因组中，其占比可高达76%。其他显著的结构类别包括萜类、非核糖体肽和聚酮类，这些类别共同构成了宏基因组中观察到的化学多样性。研究者还发现，不同生物群落中产物类别的分布存在显著差异。例如，萜类主要存在于陆地环境样本中，而RiPPs在宿主相关样本中最为丰富。\n基因簇家族（GCFs）的栖息地特异性 聚类分析显示，GCFs表现出显著的栖息地特异性，表明某些BGCs适应了特定的环境条件。总体而言，76%的GCFs（至少包含5个BGC成员）仅存在于一种特定栖息地中，这强调了微生物次级代谢的生态专一性。\n在MGnify生物群落分类的第一层级（宿主相关、环境、工程和混合）中，几乎所有GCFs都局限于某一特定类别。这种高度特异性在第二层级（如宿主相关样本中的人类、哺乳动物和鸟类）中依然存在，表明大多数GCFs对特定宿主类型具有专一性。在第三层级（如人类样本中的消化系统与皮肤），这种趋势继续延续，表明GCF特异性甚至延伸到宿主体内的不同部位。然而，随着分类的细化，栖息地特异性逐渐减弱。例如，在第四层级（如人类消化系统中的大肠与后肠），GCFs的专一性下降，表明某些GCFs虽然适应了更广泛的环境（如人类消化系统），但也可能存在于更细分的生态位中。\n在环境样本中也观察到了类似的模式。这些样本在第一层级被广泛分类，而在第二层级（如水生与陆地）中，大多数GCFs仍然高度特异性于这些不同的环境类型。在第三层级（如水生样本中的淡水与海洋），GCFs仍然主要特异性于特定的水生栖息地。然而，到了第四层级（如淡水样本中的地下水、静水与流水），栖息地特异性开始减弱，表明某些GCFs虽然适应了更广泛的水生环境，但也可能存在于更狭窄的亚栖息地中。\n对某些GCFs的详细分析揭示了显著的栖息地特异性模式。例如，GCF2487（一种萜类生产簇）仅在全球的河口样本中发现，凸显了其对该特定环境的适应性。另一方面，GCF12495（一种长度约50 kb的非核糖体肽合成酶BGC家族）仅在来自欧洲、东南亚和北美的哺乳动物粪便样本中被发现。这些特异性BGCs的生态作用表明，微生物可能采用了特定的适应策略以在其各自环境中繁衍生息。\nReference Caner Bağcı, Matin Nuhamunada, Hemant Goyat, Casimir Ladanyi, Ludek Sehnal, Kai Blin, Satria A Kautsar, Azat Tagirdzhanov, Alexey Gurevich, Shrikant Mantri, Christian von Mering, Daniel Udwary, Marnix H Medema, Tilmann Weber, Nadine Ziemert, BGC Atlas: a web resource for exploring the global chemical diversity encoded in bacterial genomes, Nucleic Acids Research, Volume 53, Issue D1, 6 January 2025, Pages D618–D624, https://doi.org/10.1093/nar/gkae953\n","date":"2025-02-26T00:00:00Z","image":"/p/bgc-atlas/images/bgc_atlas_hu_e67fd961d5af35af.png","permalink":"/p/bgc-atlas/","title":"BGC Atlas助力宏基因组中生物合成基因簇的发现与分析"},{"content":"Introduction 在微生物组学研究中，基因组binning（分箱，即将测序数据中的reads或contigs分类到不同的基因组中）是一个关键步骤。发表于2018年的MetaWRAP一直没有重大更新，这篇文章将介绍一个较新的binning流程：BASALT及其具体使用方法。\nBASALT （Binning Across a Series of AssembLies Toolkit）是一个高效的基因组binning工具，旨在处理复杂的微生物组数据，特别是在多个组装（assemblies）之间进行binning时表现出色。它通过整合多个组装结果，提高了binning的准确性和完整性，尤其适用于处理高度复杂的微生物群落数据。\nBASALT的文章于2024年发表于Nature Communications，软件主页：https://github.com/EMBL-PKU/BASALT。以下是BASALT的主要工作流程模块：\n功能模块 BASALT由四个模块组成：自动分箱（Automated Binning）、分箱选择（Bin Selection）、优化（Refinement）和缺口填充（Gap Filling）。以下是各模块的详细工作流程：\n自动分箱模块\n首先，通过多个分箱工具（每个工具使用不同的阈值）将组装的contigs分类到不同的bin中，生成初始的binsets。接着，通过识别contig ID，将包含相似contig的bin合并为混合bin（hybrid bins）。然后，基于平均核苷酸一致性（ANI）对这些混合binsets进行分组，并通过覆盖度估计（coverage estimation）识别每组中的核心序列（Core sequence identification, CSI），用于比较组内每对bin中的内部序列（inliers）。随后，使用神经网络算法识别冗余bin，并保留非冗余bin用于后续的离群值去除（Outlier removal, OR）。\n分箱选择模块\n在优化模块中，结合四核苷酸频率（Tetranucleotide Frequency, TNF）和覆盖度相关系数（Coverage Correlation Coefficient, CCC），通过多维内部四分位距（Multidimensional Internal Quartile Range, IQR）检测来识别离群序列（outlier sequences）。接着，通过序列检索步骤（sequence retrieval），利用双端测序（Pair-End, PE）或长读长追踪（Long-Read Tracking）将未分箱的内部序列（un-binned inliers）从短读长（SR）和长读长（LR）contig池中连接并重新迭代，从而生成优化后的bin。成功映射到优化bin的reads会进一步进行抛光（polishing），生成抛光后的bin。\n优化模块\n在优化模块的最后一步，通过受限的重叠-布局-一致性程序（restrained Overlap–Layout–Consensus program, rOLC），将优化/抛光后的bin与相应的冗余bin进行重叠，然后在短读长（SRS）和长读长（LRS）数据的基础上进行重新组装。重新组装的bin会进一步抛光，并经过另一轮rOLC处理，最终生成最终的bin-set。\n缺口填充模块\n在缺口填充模块中，长读长测序数据（+LRS）可以用于补充和完善bin中的缺口区域，进一步提高bin的完整性和准确性。\n效果评估 利用CAMI数据集评估BASALT的性能 采用Critical Assessment of Metagenome Interpretation （CAMI）中的CAMI-high数据。使用二代+三代数据混装产生的组装文件，BASALT可以恢复其中的392个满足完整度 ≥ 50，污染度 ≤ 10的MAGs。经过基因组选择、优化和空缺填补每一个模块处理后，所产生的MAGs无论从完整度（Completeness）、污染度（Contamination）和总质量（完整度-5*污染度）上都有很大的提升。\n与其他主流软件的比较 在MAGs（宏基因组组装基因组）的评估中，采用了更为严格的质量标准，即质量值（完整度 - 5 × 污染度）≥ 50。通过对比VAMB、DASTool、metaWRAP和BASALT四个软件的处理结果，发现BASALT的表现显著优于其他工具。具体而言，BASALT比VAMB、DASTool和metaWRAP分别多获得了63.7%、61.5%和33.3%的MAGs，其中包括69个独有的MAGs（图a）。\n在四个软件共同获得的168个MAGs中，BASALT生成的基因组质量也显著高于其他软件（图b）。两两比较的结果进一步显示，BASALT生成的MAGs质量普遍优于其他工具。具体来说，BASALT生成的质量更好的MAGs数量分别是VAMB的9.6倍、DASTool的14.6倍和metaWRAP的6.1倍（图c）。\n此外，在高质量MAGs（质量值 \u0026gt; 90）的获取方面，BASALT的表现同样突出。与VAMB、DASTool和metaWRAP相比，BASALT获得的高质量MAGs数量分别是它们的2.28倍、3.59倍和2.02倍（图d）。\n真实数据集评估 除了测试数据集外，作者团队还选用了十个真实数据集，包括SRS（短读长测序）、SRS+LRS（短读长+长读长测序）以及LRS（HiFi长读长测序）数据，涵盖了盐湖沉积物、人类肠道、海水、南极土壤、活性污泥（AS）、鸡肠道、羊肠道、热泉、厌氧反应器（AD）等多种环境类型。以高度复杂的盐湖沉积物微生物群落样本为例（仅使用二代测序数据），BASALT比metaWRAP多获得了30%的MAGs，尤其在恢复低丰度MAGs方面表现出显著优势（图a）。在功能注释分析中，BASALT比metaWRAP多获得了47.6%的非冗余开放式阅读框（ORF）序列（图b），使得BASALT恢复的MAGs在功能模块上更加完整（图c）。\n从盐湖沉积物样品中，BASALT共获得了557个MAGs，涵盖了54个门；而metaWRAP仅识别了392个MAGs，涵盖45个门，且这些门均被BASALT检测到（图5）。此外，BASALT独特地识别出了metaWRAP未能发现的9个门，其中包括21个纲水平上的细菌分支和2个目水平上的古菌分支（红色高亮分支）。这些独特的分支为挖掘复杂环境中未被探索的微生物及其功能元件提供了重要线索，进一步拓展了对微生物多样性和功能潜力的理解。\n使用方法 安装 由于需要安装许多依赖项，推荐使用conda安装和管理BASALT，命令耗时较长，需要耐心等待：\n1 2 3 4 5 # 我这里安装到~/biosoft/目录 cd ~/biosoft/ git clone https://github.com/EMBL-PKU/BASALT.git cd BASALT conda env create -n BASALT --file basalt_env.yml 然后要授权BASALT脚本。一般来说conda BASALT环境位于conda安装的子目录envs中。\n1 chmod -R 777 ~/miniconda3/envs/BASALT/bin/* 然后下载神经网络训练模型，可以直接用1脚本下载，如果网络不好可以手动下载（或者在浏览器下载好再ftp上传到服务器）：\n1 2 3 4 5 6 7 8 9 # 1.脚本下载训练模型 python BASALT_models_download.py # 2.手动下载训练模型 wget https://figshare.com/ndownloader/files/41093033 mv 41093033 BASALT.zip mv BASALT.zip ~/.cache cd ~/.cache unzip BASALT.zip 后续一般会用到checkM，所以也最好按照上一篇文章下载配置一下相应数据库：\n1 2 # 设置CheckM数据存储位置 checkm data setRoot ~/db/checkm 除上述conda方法外，还可以使用脚本直接安装或是利用singularity运行等方法，可参考https://github.com/EMBL-PKU/BASALT。\n测试数据 作者团队准备了测试文件以测试BASALT是否成功安装并且可以顺利运行。从https://figshare.com/articles/dataset/BASALT_demo_files/22323424下载测试文件（共三个：Data.tar.gz、Final_bestbinset.tar.gz、basalt.sh），然后执行下面的命令运行程序（该过程耗时大约六小时）：\n1 2 3 4 unzip 22323424.zip tar zxvf Data.tar.gz cd Data/ BASALT -a assembly.fa -s sample1.R1.fq,sample1.R2.fq -l sample1.nanopore.fq -t 16 -m 300 命令参数 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 用法: BASALT [-h] [-a ASSEMBLIES] [-s SR_DATASETS] [-l LONG_DATASETS] [-hf HIFI_DATASETS] [-c HI_C_DATASET] [-t THREADS] [-m RAM] [-e EXTRA_BINNER] [-qc QUALITY_CHECK] [--min-cpn MIN_COMPLETENESS] [--max-ctn MAX_CONTAMINATION] [--mode RUNNING_MODE] [--module FUNCTIONAL_MODULE] [--autopara AUTOBINING_PARAMETERS] [--refinepara REFINEMENT_PARAMTER] -h, --help 显示帮助信息并退出。 -a ASSEMBLIES, --assemblies ASSEMBLIES 组装序列文件列表，例如：`as1.fa,as2.fa`。 -s SR_DATASETS, --shortreads SR_DATASETS 双端测序数据列表，例如： `r1_1.fq,r1_2.fq/r2_1.fq,r2_2.fq`（双端数据需使用`/`分隔）。 注意，这里不是随便什么路径，要求一定要在同一个文件夹下。 -l LONG_DATASETS, --longreads LONG_DATASETS 包含ONT和PacBio长读长数据（不包括HiFi数据）。 例如：`lr1.fq,lr2.fq`。 -hf HIFI_DATASETS, --hifi HIFI_DATASETS HiFi测序数据，例如：`hf1.fq,hf2.fq`。 -c HI_C_DATASET, --HIC HI_C_DATASET Hi-C测序数据列表，例如：`hc1.fq,hc2.fq`。 -t THREADS, --threads THREADS 线程数，例如：`64`。 -m RAM, --ram RAM 内存大小，最低建议`32G`。 -e EXTRA_BINNER, --extra_binner EXTRA_BINNER 额外的分箱工具： `m`：MetaBinner `v`：Vamb 例如：`-e m`表示在默认使用MetaBAT2、MaxBin2和CONCOCT的基础上，额外使用MetaBinner进行分箱。 -qc QUALITY_CHECK, --quality-check QUALITY_CHECK 选择CheckM版本，默认`checkm`，可指定`checkm2`，例如： `-qc checkm2`用于质量检查。 --min-cpn MIN_COMPLETENESS 过滤保留bin的最小完整度（默认`35`）。 --max-ctn MAX_CONTAMINATION 过滤保留bin的最大污染度（默认`20`）。 --mode RUNNING_MODE 运行模式： `new`：新建项目 `continue`：继续运行 例如：`--mode continue` / `--mode new`。 --module FUNCTIONAL_MODULE 运行的功能模块（默认运行所有模块）： `autobinning`：自动分箱 `refinement`：分箱优化 `reassembly`：重新组装 例如：`--module reassembly` 仅运行重新组装模块。 --autopara AUTOBINING_PARAMETERS 自动分箱模式： `more-sensitive`（默认） `sensitive` `quick` 例如：`--autopara sensitive`。 --refinepara REFINEMENT_PARAMTER 分箱优化参数： `deep`（默认） `quick` 例如：`--refinepara quick`。 BASALT支持单一组装文件或多组装文件进行binning；在样品的物种非常相似，但群落中物种丰度不同的情况下，如时间序列样品，多组装文件可大幅度提高binning的效果，但也可能会导致运算时间过长，但作者推荐用多组装文件模式进行分箱分析。如果运算资源不足，推荐使用多组数据进行合并组装的组装文件进行后续的分箱分析。\n单独使用二代测序数据进行 binning 及修正，比较常用 1 BASALT -a as1.fa,as2.fa,as3.fa -s ds1_r1.fq,d1_r2.fq/d2_r1.fq,d2_r2.fq -t 60 -m 250 使用二代测序数据及三代测序数据进行 binning 及修正 1 BASALT -a as1.fa,as2.fa,as3.fa -s ds1_r1.fq,d1_r2.fq/d2_r1.fq,d2_r2.fq -l lr1.fq,lr2.fq -t 60 -m 250 使用 HiFi 数据及二代测序数据进行 binning 及修正 1 BASALT -a as1.fa -hf hifi1.fq -s ds1_r1.fq,d1_r2.fq -t 60 -m 250 使用 BASALT 进行基因组的获取，并融合已有的基因组数据 1 BASALT -a as1.fa,as2.fa,as3.fa -s ds1_r1.fq,d1_r2.fq/d2_r1.fq,d2_r2.fq -d m_binset -t 60 -m 250 使用 BASALT 进行外源数据基因组的去冗余 (a) 数据输入（Data feeding）\n1 BASALT -s sample1.R1.fq,sample1.R2.fq/sample2.R1.fq,sample2.R2.fq -d mbin,dbin -t 60 -m 250 该命令会生成 Date_feeded 文件夹，其中包含：\n修改 index 后的组装文件，如 500_mbin.fa 基因组文件夹，如 500_mbin.fa_BestBinsSet 覆盖率文件，如 Coverage_matrix_for_binning_500_mbin.fa.txt 修改格式后的 reads 文件 (b) 基因组去冗余（De-replication）\n1 2 3 4 BASALT -b 500_mbin.fa_BestBinsSet,501_dbin.fa_BestBinsSet \\ -c Coverage_matrix_for_binning_500_mbin.fa.txt,Coverage_matrix_for_binning_501_mbin.fa.txt \\ -a 500_mbin.fa,501_mbin.fa \\ -s sample1.R1.fq,sample1.R2.fq/sample2.R1.fq,sample2.R2.fq -t 60 该命令输入多个基因组文件夹、组装文件、reads 和覆盖率文件，最终生成去冗余后的基因组文件夹 BestBinset。\n使用 BASALT 进行基因组的修正 1 2 3 4 BASALT -r BestBinset \\ -c Coverage_matrix_for_binning_500_mbin.fa.txt,Coverage_matrix_for_binning_501_mbin.fa.txt \\ -a 500_mbin.fa,501_mbin.fa \\ -s PE_r1_sample1.R1.fq,PE_r2_sample1.R2.fq/PE_r1_sample2.R1.fq,PE_r2_sample2.R2.fq -t 60 该命令会生成 BestBinset_outlier_refined 文件夹，存储优化后的基因组。\n具体示例 项目背景 在鸟类生长的不同阶段，采集了若干种鸟类的粪便样本，通过宏基因组二代测序分析它们的微生物组。每个样本根据鸟类不同的生长周期进行了采集，并使用 metaspades 软件对数据进行单个样本的组装。在得到单个样本的组装结果后，进一步对同种鸟类在同一生长周期的多个平行样本的数据进行合并组装，以便获取更丰富的群落信息，辅助后续的分箱处理。\n组装策略 单个样本组装：使用 metaspades 对每个鸟类在不同生长周期的粪便样本进行单样本组装。 多样本合并组装：将同一生长周期、同种鸟类的多个平行样本进行合并组装，以提高组装的完整性和准确性。 分箱处理：在完成组装后，进行基于二代测序数据的分箱，获取更准确的基因组信息。 以A鸟样本为例\n样本数据：\nA类鸟阶段1样本：\nsampleA_s1_1_R1.fq, sampleA_s1_1_R2.fq sampleA_s1_2_R1.fq, sampleA_s1_2_R2.fq sampleA_s1_3_R1.fq, sampleA_s1_3_R2.fq A类鸟阶段2样本：\nsampleA_s2_1_R1.fq, sampleA_s2_1_R2.fq sampleA_s2_2_R1.fq, sampleA_s2_2_R2.fq sampleA_s2_3_R1.fq, sampleA_s2_3_R2.fq A类鸟阶段3样本：\nsampleA_s3_1_R1.fq, sampleA_s3_1_R2.fq sampleA_s3_2_R1.fq, sampleA_s3_2_R2.fq sampleA_s3_3_R1.fq, sampleA_s3_3_R2.fq 组装结果：\n阶段1单样品组装结果： sampleA_s1_1_assembly.fa, sampleA_s1_2_assembly.fa, sampleA_s1_3_assembly.fa 阶段2单样品组装结果： sampleA_s2_1_assembly.fa, sampleA_s2_2_assembly.fa, sampleA_s2_3_assembly.fa 阶段3单样品组装结果： sampleA_s3_1_assembly.fa, sampleA_s3_2_assembly.fa, sampleA_s3_3_assembly.fa 阶段1多样品合并组装结果： sampleA_s1_assembly.fa 阶段2多样品合并组装结果： sampleA_s2_assembly.fa 阶段3多样品合并组装结果： sampleA_s3_assembly.fa 分箱命令：\n阶段1样品分箱命令： 1 2 3 BASALT -a sampleA_s1_assembly.fa, sampleA_s1_1_assembly.fa,sampleA_s1_2_assembly.fa,sampleA_s1_3_assembly.fa \\ -s sampleA_s1_1_R1.fq,sampleA_s1_1_R2.fq/sampleA_s1_2_R1.fq,sampleA_s1_2_R2.fq/sampleA_s1_3_R1.fq,sampleA_s1_3_R2.fq \\ -t 60 -m 250 注意事项 输入输出 BASALT的程序输入 -a,-s等参数不是任意文件的路径，而是要把这些文件放置到脚本运行同一文件夹下，因为\u0026rsquo;/\u0026lsquo;已经被用作文件之间的分隔符了。并且BASALT还不能设定输出路径，在输出时候自动将结果及重要过程文件输出至当前工作路径下，建议用户将需要分析的文件单独建立文件夹存放和运行BASALT，以免重复输出覆盖原有结果。用起来有点麻烦。\n运行速度 在使用单个组装文件时，BASALT的完整流程耗时通常比metaWRAP长，尤其随着样品复杂度的增加，耗时差异会更加显著。然而，文章中也提到，即便不运行gap filling模块，BASALT在基因组质量和数量上通常优于metaWRAP。实际上，在多个组装文件输入模式下，BASALT的效率反而高于metaWRAP，因为BASALT仅需运行一次，且其单独组装、合并组装和去冗余的流程有助于大大提高非冗余基因组的产出。如果用户对基因组的深度挖掘需求不高，且需要加速分箱过程，以下几种策略可能会有所帮助：\n使用MetaBAT2 + Semibin2作为初始Binners：这可以显著加快auto-binning的过程。 只运行auto-binning、bin selection和refinement模块：跳过gap filling模块可以有效减少运行时间。 仅使用合并组装文件：在同时输入多个样品时，使用单一的合并组装文件（例如：sampleA1A2A3_assembly.fa）可以减少auto-binning的计算时间，但也可能会减少基因组的产出量。 References Qiu, Z., Yuan, L., Lian, CA. et al. BASALT refines binning from metagenomic data and increases resolution of genome-resolved metagenomic analysis. Nat Commun 15, 2179 (2024). https://doi.org/10.1038/s41467-024-46539-7 https://github.com/EMBL-PKU/BASALT https://mp.weixin.qq.com/s/TlxaiQGjoiE3c0Onqatu8A ","date":"2025-02-18T00:00:00Z","image":"/p/binning3/images/workflow_hu_6cddfa5cd6ddc464.png","permalink":"/p/binning3/","title":"宏基因组分箱（binning）｜3. BASALT优化binning流程"},{"content":"Introduction 上次记录了一下qiime2的扩增子分析流程。但是实际使用时，在最后一步物种注释时卡住了，如果使用常用的feature-classifier方法，我尝试使用unite数据库鉴定了100条ITS序列，居然用了半个小时！尴尬的是，我有整整10万条ASV序列，这得跑到猴年马月。我想到做宏基因组时，千万级数量的reads用kraken做物种注释也不需要这么久，肯定有快的方法的。\n然后发现Kraken用于16S已经有文章了： Lu, J., Salzberg, S.L. Ultrafast and accurate 16S rRNA microbial community analysis using Kraken 2. Microbiome 8, 124 (2020). https://doi.org/10.1186/s40168-020-00900-2\nKraken 2现在支持16S rRNA数据库，可以直接与QIIME和类似系统进行比较。Kraken 2通过其独特的无对齐算法，能够在极短的时间内完成大量序列的分类，并且支持多线程处理，显著提升了分析效率。此外，Kraken 2还结合了Bracken工具，能够更精确地估计物种的相对丰度，尤其是在处理复杂微生物群落时表现出色。\n但是Kraken2要用在ITS上的话目前是官方没有支持的，需要手动构建相应数据库，这个折腾了一会，具体方法放在后面了。\nKraken效果 速度快 Kraken 2在速度上的表现非常突出。根据Lu和Salzberg的研究，Kraken 2在生成16S rRNA数据库时，比QIIME 2快得多。例如，使用单线程时，Kraken 2生成Greengenes数据库仅需9分钟，而QIIME 2则需要78分钟。对于更大的SILVA数据库，Kraken 2仅需34分钟，而QIIME 2则需要超过58小时。在分类速度上，Kraken 2同样表现出色，单线程下仅需1分钟即可完成一个样本的分类，而QIIME 2则需要35分钟（使用16线程时）。对于大规模数据分析，Kraken 2的速度优势尤为明显，能够显著缩短分析时间。\n更精确 Kraken 2不仅在速度上占优，其分类精度也优于QIIME 2。研究显示，Kraken 2在分类16S rRNA序列时，能够更准确地识别物种，尤其是在处理复杂微生物群落时。Bracken工具进一步提升了Kraken 2的精度，能够更准确地估计物种的相对丰度。通过重新分配Kraken 2在属或更高分类水平上的分类结果，Bracken能够将分类结果细化到种水平，从而提供更精确的物种丰度估计。此外，Kraken 2的每读长分类功能使其能够为每个读长提供详细的分类信息，进一步提高了分析的准确性。\n总的来说，Kraken 2和Bracken的组合为16S rRNA数据分析提供了一个快速、高效且精确的解决方案，特别适合处理大规模微生物群落数据。\nKraken-16S Kraken2是直接支持16S常用的三大数据库的(greengenes，rdp，silva)，用起来也非常简单：\n1 2 3 4 5 6 7 8 9 10 11 12 #直接构建数据库，TYPE可选greengenes，rdp，silva kraken2-build --db $DBNAME --special TYPE #构建完成后就可以鉴定了，内存够的话，1min内都有结果 kraken2 rep-seqs/dna-sequences.fasta --db $DBNAME --out kraken_output --threads 4 --report kraken_report.txt -c 0.05 #可以借助taxonkit得到类似qiime2标准注释文件 cut -f3 kraken_output \u0026gt;tmpid taxonkit lineage tmpid --data-dir $DBNAME/taxonomy/|taxonkit reformat --data-dir $DBNAME/taxonomy/ -P \u0026gt;tmpres paste kraken_output tmpres |cut -f2,8\u0026gt;kraken_taxonomy rm tmpid tmpres Kraken-ITS ITS一般用Unite数据库注释，但这个kraken2不支持，我尝试将Unite数据库整理为greengenes的格式，然后用build_gg_taxonomy.pl生成names.dmp, nodes.dmp, seqid2taxid并建立kraken数据库，最后进行ITS序列鉴定是可行的。\n具体步骤如下：\nUnite官网下载fasta文件，https://unite.ut.ee/repository.php ，点击General FASTA release下载解压，我用的是sh_general_release_dynamic_all_04.04.2024.fasta文件。\n运行以下命令建立数据库，注意split_fasta.py和build_gg_taxonomy.pl在后面，记得拷贝过去用。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 # 手动构建目录结构 mkdir ~/db/kraken_unite/ pushd ~/db/kraken_unite/ mkdir -p data taxonomy library pushd data # 用split_fasta.py把unite数据库提供的fasta格式整理为greengenes的 GG_VERSION=unite_all_04.04.2024 ./split_fasta.py -i ../sh_general_release_dynamic_all_04.04.2024.fasta -o ${GG_VERSION} # 用build_gg_taxonomy.pl进一步生成names.dmp, nodes.dmp, seqid2taxid perl ../build_gg_taxonomy.pl \u0026#34;${GG_VERSION}_taxonomy.txt\u0026#34; popd mv data/names.dmp data/nodes.dmp taxonomy/ mv data/seqid2taxid.map . mv \u0026#34;data/${GG_VERSION}.fa\u0026#34; library/unite.fna popd # 用kraken2-build构建用于注释的数据库 kraken2-build --db ~/db/kraken_unite --build --threads 4 鉴定获得output文件 1 2 #1秒出结果 kraken2 rep-seqs/dna-sequences.fasta --db ~/db/kraken_unite/ --out kraken_output --threads 4 --report kraken_report.txt -c 0.05 借助taxonkit获取标准注释文件，taxonkit这软件也很好用。 1 2 3 4 5 cut -f3 kraken_output \u0026gt;tmpid taxonkit lineage tmpid --data-dir ~/db/kraken_unite/taxonomy/|taxonkit reformat --data-dir ~/db/kraken_unite/taxonomy/ -P \u0026gt;tmpres paste kraken_output tmpres |cut -f2,8\u0026gt;kraken_taxonomy rm tmpid tmpres 最后的结果就是类似下面的形式：\n1 2 3 0229a5c7f887dad960b40a0505cf9776\tk__Fungi;p__Ascomycota;c__Saccharomycetes;o__Saccharomycetales;f__Saccharomycetales_fam_Incertae_sedis;g__Candida;s__Candida Candida_albicans f88d9001e10f6d37672514972e6a199e\tk__Fungi;p__Ascomycota;c__Saccharomycetes;o__Saccharomycetales;f__Saccharomycetales_fam_Incertae_sedis;g__Candida;s__Candida Candida_albicans c3519270e269b92d3577ed450032bbc4\tk__Fungi;p__Ascomycota;c__Eurotiomycetes;o__Eurotiales;f__Aspergillaceae;g__Penicillium;s__ 补充脚本信息：\n1.split_fasta.py：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 #!/share/home/jianglab/pengchen/miniconda3/bin/python3.9 import argparse def process_fasta(input_file, unite_fa, unite_taxonomy): with open(input_file, \u0026#39;r\u0026#39;) as infile, open(unite_fa, \u0026#39;w\u0026#39;) as fa_out, open(unite_taxonomy, \u0026#39;w\u0026#39;) as tax_out: for line in infile: if line.startswith(\u0026#39;\u0026gt;\u0026#39;): # Extract information from the header header = line.strip() parts = header.split(\u0026#39;|\u0026#39;) accession = parts[1] taxonomy = parts[-1] formatted_taxonomy = taxonomy.replace(\u0026#39;;\u0026#39;, \u0026#39;; \u0026#39;).replace(\u0026#39; \u0026#39;, \u0026#39;\u0026#39;).replace(\u0026#39;;\u0026#39;, \u0026#39;; \u0026#39;) # Write to unite.fa fa_out.write(f\u0026#34;\u0026gt;{accession}\\n\u0026#34;) # Write to unite_taxonomy.txt tax_out.write(f\u0026#34;{accession}\\t{formatted_taxonomy}\\n\u0026#34;) else: # Write sequence lines to unite.fa fa_out.write(line) def main(): parser = argparse.ArgumentParser(description=\u0026#34;Process a fasta file to generate unite.fa and unite_taxonomy.txt.\u0026#34;) parser.add_argument(\u0026#34;-i\u0026#34;, required=True, help=\u0026#34;Input fasta file\u0026#34;) parser.add_argument(\u0026#34;-o\u0026#34;, required=True, help=\u0026#34;Output prefix for unite.fa and unite_taxonomy.txt\u0026#34;) args = parser.parse_args() input_file = args.i output_prefix = args.o unite_fa = f\u0026#34;{output_prefix}.fa\u0026#34; unite_taxonomy = f\u0026#34;{output_prefix}_taxonomy.txt\u0026#34; process_fasta(input_file, unite_fa, unite_taxonomy) if __name__ == \u0026#34;__main__\u0026#34;: main() 2.build_gg_taxonomy.pl : https://github.com/DerrickWood/kraken2/blob/master/scripts/build_gg_taxonomy.pl\n3.taxonkit: https://github.com/shenwei356/taxonkit\nReferences Lu, J., Salzberg, S.L. Ultrafast and accurate 16S rRNA microbial community analysis using Kraken 2. Microbiome 8, 124 (2020). https://doi.org/10.1186/s40168-020-00900-2 https://github.com/DerrickWood/kraken2/wiki/Manual#custom-databases https://github.com/DerrickWood/kraken2/issues/97 ","date":"2025-01-14T00:00:00Z","image":"/p/kraken-16s-its/images/k16s1_hu_268e43eaf6d0efdc.png","permalink":"/p/kraken-16s-its/","title":"使用Kraken进行16S/ITS物种注释（超快）"},{"content":"Introduction 生物合成基因簇 (BGC) 的计算分析通过快速研究微生物基因组序列内的次级代谢潜力，彻底改变了天然产物的发现。将同源 BGC 分组为基因簇家族 (GCF) 有助于绘制其结构和分类多样性，并通过对已知功能的 BGC 进行去重复，提供对假定 BGC 新颖性的见解。\n通过将从当前可用的基因组和 MAG 中鉴定出的大规模全球 BGC 集合作为数据源，BiG-FAM 提供了可探索的微生物次生代谢多样性“图集”，以浏览和搜索跨类群的生物合成多样性。 BiG-FAM 有助于查询假定的 BGC，以便根据公开数据与其他已知和预测的 BGC 的关系，快速找到它们在多样性图上的位置，并更好地了解它们的新颖性或（可能的）功能。\nBiG-FAM数据库（2020年）基于从多个公开可用来源获取的 1,225,071 个 BGC 的 GCF 聚类。这项大规模分析是使用 BiG-SLiCE 软件 和任意聚类阈值 (T=900.0) 进行的，结果构建了 29,955 个 GCF 模型，每个模型代表不同的蛋白质结构域和序列特征BGC。\n这个数据库一直没有更新，而最近几年又是宏基因组测序井喷的时候，里面的GCF数量肯定远低于现在已经发现的GCF，但稍微用一下做参考还是可以的（或者有想法可以自己跑一下更多公开数据说不定也是一篇NAR）\nBiG-FAM数据库在线访问：https://bigfam.bioinformatics.nl\n数据库特征 超过120万个BGC的GCF数据 BiG-FAM数据库包含29,955个通过BiG-SLiCE 1.0版本计算的GCF，这些数据源自1,225,071个BGC的集合。这些BGC通过antiSMASH v5.1.1从188,622个微生物基因组（包括细菌、真菌和古菌基因组）以及20,584个MAG中预测得到，并补充了来自MIBiG 2.0数据库的实验验证BGC。所有基因组的完整列表及其BGC计数和分类信息见补充表。这些BGC及其对应的GCF涵盖了广泛的生物合成类别和分类群，提供了对微生物次级代谢多样性的全面覆盖。\n数据库内容的无缝探索 基于BiG-SLiCE 1.0.0生成的核心SQLite3数据存储，作者使用Python Flask库构建了一个功能齐全的Web服务器。为了实现更流畅的浏览体验，特别是在计算密集型的网页中，作者额外实现了一层缓存存储，用于预取复杂SQL查询。此外，这种设置还实现了轻量级的“搜索和过滤”功能，使用户能够根据特定的分类群、来源数据集类型、生物合成类别或蛋白质域来查找BGC或GCF。\n用户提交BGC的快速GCF定位 使用BiG-SLiCE的一个主要优势在于，每个GCF的共享BGC特征被总结在与底层BGC相同的基于欧几里得距离的特征矩阵中，形成GCF模型。这使得BGC到GCF的线性匹配成为可能，从而可以在几秒钟内将新测序的BGC定位到预计算的生物合成多样性全球图谱中。为了便于使用这一功能，BiG-FAM集成了一个基于Web的“查询”提交系统，用户可以直接提交通过antiSMASH预测的BGC进行GCF分析。生成的BGC到GCF匹配结果将揭示查询BGC的近缘和远缘关系，帮助研究其新颖性、与其他BGC的关系，以及跨分类群的分布和进化。\n直接链接到BGC和基因组数据库 尽管BiG-FAM存储并展示了许多与BGC相关的有用信息，但它并非旨在成为一个BGC数据库，因此不包含与GCF无直接关联的信息。为了支持需要这些数据的用户，BiG-FAM存储了来自MIBiG和antiSMASH数据库的BGC元数据链接。这些交叉链接可用于获取更多信息，例如BGC产物的核心结构。此外，每个BGC的摘要页面还提供了原始基因组来源的链接，用户也可以从GCF页面下载合并的URL列表。\n应用示例 探索Ranthipeptide BGC的多样性 Ranthipeptides（曾被称为“SCIFF肽”）是一类核糖体合成并经翻译后修饰的肽（RiPPs），主要存在于梭菌纲（Clostridia）中，尽管GC含量分析表明其生物合成基因可能通过水平转移传播到其他分类群。近期研究表明，这些肽在群体水平调控中发挥重要作用，例如通过群体感应机制。在作者先前绘制120万个BGC全球多样性的研究中，作者捕获了6,800个推定的ranthipeptide BGC，这些BGC在前体肽侧翼的基因邻域表现出多样性。为了探索这种多样性，作者可以使用BiG-FAM的“GCF搜索”功能，并以该BGC类的两个标志性结构域（AS-TIGR03973和Radical_SAM）作为查询条件。搜索结果显示了79个GCF，每个GCF代表了不同的BGC分布模式及其分类学来源。通过点击每个GCF的详情页面链接，可以获取其分类来源、核苷酸长度、计算半径以及GCF内BGC共享的生物合成特征。此外，所有BGC的概览及其序列链接可以以TSV格式下载。多基因比较可视化功能还提供了ranthipeptide前体基因侧翼基因邻域多样性的整合视图。\n对新测序链霉菌株的GCF分析 最近，一株从突尼斯薰衣草根际土壤中分离的新链霉菌——Streptomyces tunisialbus的基因组草图被发布。为了展示BiG-FAM如何用于评估新测序BGC的生物合成新颖性并捕捉其远缘关系，作者从ENA下载了该基因组的组装数据，并将其上传至antiSMASH Web服务器，获得了一个唯一的任务ID。该ID可直接用于在BiG-FAM中进行GCF分析。对36个antiSMASH预测的BGC的完整分析在不到一分钟内完成，生成了最佳BGC-to-GCF匹配对的汇总表。其中一个有趣的BGC是来自“Region 15.1”的完整46.5 kb Type-I PKS基因簇，其在ClusterBlast和KnownClusterBlast结果中与公共数据库的基因簇匹配率较低。GCF分析结果显示，该BGC仅与一个单例GCF有显著匹配，进一步检查发现该GCF源自同一基因组的NCBI提交条目。这表明该PKS BGC代表了一种新型BGC，因为它与其他基因组中的GCF成员没有密切关系。通过“追踪”查询BGC的生物合成结构域，可以分析与数百至数千个远缘BGC的关系，展示基因之间的结构域架构相似性。\nReference Satria A Kautsar, Kai Blin, Simon Shaw, Tilmann Weber, Marnix H Medema, BiG-FAM: the biosynthetic gene cluster families database, Nucleic Acids Research, Volume 49, Issue D1, 8 January 2021, Pages D490–D497, https://doi.org/10.1093/nar/gkaa812\n","date":"2025-01-08T00:00:00Z","image":"/p/gcf-big-fam/images/Screenshot%202025-01-08%20at%2011.53.28_hu_a2ceb9aedcd0dcf0.png","permalink":"/p/gcf-big-fam/","title":"生物合成基因簇家族（GCF）数据库 BiG-FAM"},{"content":"生信研究中，树的生成和可视化是我们经常会遇到的问题，（鉴于有有些工具要收费，有些工具使用麻烦），最近（一年前）和LYE共同开发了一个用于分类树生成和可视化的在线网站iPhylo。不仅可以方便的生成物种树，还可以有化学树和自定义层级树，得到的树也可以无缝衔接到可视化部分，用起来还是非常流畅的，并且全部免费。最近这篇文章也正式上线Briefings in Bioinformatics了。\n文章：Y. Li*, C. Peng*, F. Chi, Z. Huang, M. Yuan, X. Zhou, C. Jiang#, The iPhylo suite: an interactive platform for building and annotating biological and chemical taxonomic trees. Briefings Bioinf. 26, bbae679 (2025). https://doi.org/10.1093/bib/bbae679.\niPhylo网址：https://iPhylo.net\niPhylo全面教程：https://asa12138.github.io/iPhylo_tutorial/\nIntroduction iPhylo是一套综合的自动化和交互式平台，用于生物和化学分类学分析。 它包括Tree和Visual两个基于web的模块，用于构建和注释生物和化学分类树；以及一个独立的命令行界面(CLI)模块，用于本地使用和部署到高性能计算集群上。\n此外，iPhylo的可视化模块完全用R实现，允许用户本地保存进度并修改底层R代码。最后，iPhylo的CLI模块将分析扩展到所有层次关系数据。 总之，iPhylo提供了一个集成的交互式框架，用于深入分析生物和化学特征及其他方面的分类学。\niPhylo套件服务器采用用户友好的界面，包括但不限于导航主页、构建树、注释仪表板和检查页面。主页展示了一系列引人入胜的动态效果，介绍了网站的独特特点和功能。构建树和注释仪表板页面采用直观而实用的表单布局。检查页面采用拖动选择器将分支和节点转换为结构化数据，便于探索树的内容。还有专门的教程帮助页面和展示示例的画廊页面。\nGenerate tree iPhylo Tree模块是一个在线网络应用，用于从生物物种或化合物中构建分类树。该过程包括以下步骤：\n输入：用户提供生物物种的一组名称或分类学标识符（TaxID），或者对于化合物，提供InChIKey、InChI或SMILES。 分类查询：将输入特征与iPhylo Tree数据库进行查询，包括生物和化学两个部分。这些数据库定期更新，包含来自NCBI分类数据库和各种化学数据库的信息。 构建树：采用面向对象的方法，将查询的分类数据转换为n元树对象。构建过程从一个空结构开始，逐渐合并分类数据。 生成输出：采用深度优先后序遍历算法遍历树对象，将拓扑结构保留为Newick格式。iPhylo利用BioPython中的phylo包将Newick字符串转换为其他所需格式（Nexus、PhyloXML），并提供树的ASCII表示和PDF可视化。 生成的生物分类树包括标准级别，如域、界、门、纲、目、科、属和种。类似地，化学分类树从界到亚族进行组织。\niPhylo Tree提供了额外的功能，如在指定级别过滤树，用户可以使用“|subtree”运算符提取特定的clade（例如，Primates|subtree或Hydroxyindoles|subtree）。\nCLI 命令行 iPhylo CLI是基于Web的iPhylo Tree的扩展。iPhylo CLI包括四个模块，即1）phylo tree模块，2）chemical tree模块，3）chemical online模块和4）csv2tree模块。\niPhylo tree模块和chemical tree模块提供与在线iPhylo Tree相同的功能，但在本地运行。值得注意的是，独家的在线chemical模块允许从ClassyFire API检索化学信息，包括经过处理的化合物及其在ClassyFire数据库中存储的相应分类数据。通过这个在线模块，可以查询超过7000万个化合物，这个数字还在不断增长。这一功能显著增强了化学分类分析的能力。此外，csv2tree模块使用户能够直接从CSV文件创建自定义的树。\niPhylo CLI专为效率设计。在第一次运行时，该工具下载必要的数据库资源，随后的运行将在脱机本地模式下进行。这种设计确保了快速执行，非常适合部署在高性能计算集群上。\nVisualization iPhylo Visual是一个交互式在线工具，旨在简化iPhylo模块生成的基于树状结构的显示、注释和检查，包括但不限于系统发育和化学分类树。\niPhylo Visual通过采用与数据框兼容的格式，简化了对分类树进行注释的过程，用户可以在一个数据框中封装所有‘叶子’注释所需的信息，另一个数据框用于‘节点’注释。在数据框中，行对应树叶子或节点，列代表具体特征。用户可以通过提供的在线表格查看器高效导航和管理这些上传的数据框，具有排序和检索功能。这种设计避免了上传多个注释文件，并且直接兼容R。\niPhylo Visual利用ggtree和ggtreeExtra的全部图形功能来可视化、操作和注释树状结构数据。之前也介绍过直接用R代码绘图的内容：R绘制系统发育树的基本用法,进阶使用，整体使用逻辑类似，就是在线网站可能对于不熟悉代码的人来说更方便一些。\niPhylo Visual提供了“Basic feature”、“Leaf annotation”、“Node annotation”和“Legend”标签以进行注释控制。\n其中，“Basic feature”标签提供了各种布局选项，用于树的基本布局，表示树结构的简单形状。用户可以从circular, inward circular, daylight (an unrooted tree layout), rectangular, slanted, ellipse, roundrect中选择布局。用户可以在注释过程中在这些布局之间切换，注释的特征会自动适应新布局。\n此外，用户可以通过滑块和调色板方便地定制树枝粗细、颜色、角度等特征。\n“Leaf Annotation”标签管理与树叶相关的注释track，包括tree leaves, encompassing bars, tiles, boxes, violins, tip points, and tip labels。\n“Node Annotation”标签处理与内部节点和分支相关的注释track，包括strips, clade branch colors, clade backgrounds, and node labels。此外，“Legend”标签允许用户调整画布大小和每个注释层的图例。\niPhylo Visual强调通过session文件轻松导出和复现树的可视化结果。独特的导出“.iPhylo”文件包含生成iPhylo树所需的所有关键数据。session文件非常紧凑，对于包含1000个物种的注释树，大小仅为30kB。所有树注释session都可以保存到本地计算机并从中上传，使用户能够在保持对原始数据的控制的同时微调复杂的树。此外，session文件可以促进合作注释项目。\niPhylo Visual为树提供了不同的图像导出格式，即PNG、PDF和JPEG。\n重要的是，iPhylo Visual的“Export Code”功能一键导出可视化和注释树的所有原始数据和绘图代码。包括树文件、注释表、以JSON文件记录的详细注释参数以及用于可视化数据的R脚本。通过在本地运行此脚本，用户可以复制在iPhylo Visual中看到的树可视化。精通R编程的高级用户还可以通过修改代码进一步定制树。\nExample iPhylo网站的Gallery and Demo部分提供了很多示例树图，可以直接点击绘图，导入自己的数据做参考。\niPhylo套件与用户创建的层次关系数据库以及自定义树结构兼容，就是说我们可以画任意自定义层级的树图。比如我们把常用统计方法的层次关系以CSV格式组织，通过iPhylo进行处理，生成了一棵常见统计方法的树，然后在iPhylo Visual中进行了可视化：\n还可以画两棵树的连接关系：\nSummary iPhylo套件致力于提供一个快速而便捷的解决方案，以解决现有用于生物和化学分类分析的工具存在的问题。该套件遵循几个原则：1）跨平台兼容性，支持Web和命令行服务，适用于Windows、Mac OS和Linux。2）集成性，通过在不切换平台的情况下无缝整合构建、可视化和注释的整个工作流程，减少错误的可能性。3）可定制性，提供广泛的定制选项，扩展了对所有层次关系数据库的支持。采用数据框格式进行注释，以减少用户的输入需求。此外，用户可以下载和上传构建树的session，并访问底层的R绘图代码进行进一步修改。\n此外，其他数据库如GTDB等，也为未来的扩展提供了机会。iPhylo套件的发展计划整合不仅限于生物和化学领域更广泛的数据库。\n","date":"2025-01-02T00:00:00Z","image":"/p/iphylo/images/iphy_hu_6b9eac75906ebac9.png","permalink":"/p/iphylo/","title":"iPhylo 生成并绘制优美的分类树（物种+化学）"},{"content":"Introduction 我学习微生物组分析的过程是从shot-gun 宏基因组数据分析开始的，反而没怎么做过相对更早更成熟的扩增子测序的上游分析😂，最近刚好有需求，还是自己学习并搭建一下自己用的比较舒服的流程吧。\n扩增子（Amplicon）分析是研究微生物群落组成与功能的核心方法之一，特别是在生态学、医学和环境科学领域。通过对目标基因区域（如16S rRNA、18S rRNA、ITS）的特异性扩增与测序，扩增子分析能够高效揭示样本中微生物的多样性和群落结构。相比宏基因组测序，扩增子分析具有成本低、处理流程简化等优势，适用于大规模样本研究。\n扩增子分析的核心原理是通过聚合酶链式反应 (PCR) 技术，对目标微生物基因片段进行特异性扩增和测序，以解析微生物群落组成及其多样性。通常选择的目标片段为具有保守区域和高变异区域的基因，如细菌的16S rRNA基因、真菌的ITS区等。保守区域用作引物设计的靶点，高变异区域用于区分不同物种。\n具体步骤包括：\nDNA 提取：从样本中提取总 DNA。 目标基因扩增：使用特异性引物扩增目标区域。 高通量测序：测序得到大量扩增子的序列数据。 生物信息学分析：对序列进行过滤、聚类、注释，获得物种分类和功能信息。 这种方法的优势在于其高灵敏度和特异性，可以快速揭示微生物多样性并进行定量分析。\n细菌 细菌核糖体RNA (rRNA) 包括 5S rRNA (120bp)、16S rRNA (~1540bp) 和 23S rRNA (~2900bp)。\n5S rRNA: 序列短，遗传信息量有限，无法用于分类鉴定。 23S rRNA: 序列过长，突变率高，不适用于远缘种类分析。 16S rRNA: 稳定性高、拷贝数多，约占细菌RNA总量的80%，基因中包含10个保守区和9个高变异区，适合细菌分类标准。V3-V4 区因特异性和数据库支持最佳，常用于多样性分析。 真核生物 真核微生物的 rRNA 包括 5.8S、18S 和 28S rRNA，其中 18S rRNA 常用于多样性分析。\n18S rRNA: 基因序列包括保守区和可变区 (V1-V9, 无 V6)。可变区反映物种差异，V4 区因分类效果佳、数据库支持丰富，是分析和注释的最佳选择。 真菌 ITS (内源转录间隔区) 位于真菌 18S、5.8S 和 28S rRNA 基因之间，由 ITS1 和 ITS2 组成，分别长约 350 bp 和 400 bp。\n保守性: 基因片段在种内稳定，种间差异显著，适用于细粒度分类。 灵活性: 容易分析和扩增，广泛用于真菌种属和菌株系统发育研究。 古菌 古菌生活于极端环境，是生命极限的代表。通过引物设计，16S rRNA 的 V4V5 区是古菌多样性研究的核心区域。\nIllumina MiSeq: 519F/915R 适用于 V4V5 扩增。 Roche 454: 344F/915R 表现更佳。\n古菌研究揭示了其独特的生物特征，促进了极端生态学和生物系统学的发展。 Qiime2 QIIME 2 (Quantitative Insights Into Microbial Ecology 2) 是一个功能强大的微生物组数据分析平台，专为从原始 DNA 序列到可解释的生物学结论的全过程而设计。它是 QIIME 的升级版本，具有更高的灵活性、可扩展性和可重复性。\n网站：https://qiime2.org/\n详细教程：https://docs.qiime2.org/\n主要特点：\n模块化架构：\nQIIME 2 使用插件系统，支持不同的分析任务（如数据导入、质量控制、OTU/ASV 分类、可视化等）。 常用插件包括 dada2（去噪）、feature-classifier（分类）、diversity（多样性分析）。 可重复性：\n分析工作流被记录在 .qza 和 .qzv 文件中，包含完整的元数据和参数信息。 易于分享和复现研究结果。 交互式可视化：\n支持交互式的结果可视化（如多样性分析、特征分类）。 可在 QIIME 2 View 网站上直接查看 .qzv 文件。 广泛支持的数据类型：\n支持多种数据输入格式，如 FASTQ、BIOM。 可处理单端或双端序列，以及扩增子、宏基因组、宏转录组数据。 强大的社区和生态系统：\nQIIME 2 拥有活跃的用户社区和丰富的文档支持。 易于与其他工具（如 R、Python、QIIME 1、PICRUSt）集成。 QIIME 2 的分析过程通常包括以下步骤：\n数据导入：\n将原始数据（如 FASTQ 文件）导入为 QIIME 2 的 .qza 格式。 质量控制与去噪：\n使用插件如 DADA2 或 Deblur 进行序列修剪、去噪和去冗余。 特征表构建：\n生成 ASV 表（或 OTU 表）和代表性序列。 序列分类：\n利用分类器（如 SILVA、Greengenes、UNITE）对特征序列进行物种注释。 多样性分析：\n计算 α 多样性（物种丰度）和 β 多样性（样本间差异），并进行统计分析。 可视化：\n生成图形化结果，如 PCA 图、丰度热图、分类饼图等。 优点：\n高度可扩展，支持多种微生物组分析。 工作流透明，方便重复分析和结果共享。 插件生态丰富，可根据需要选择不同的工具。 缺点：\n学习曲线较陡，需熟悉命令行操作。 对计算资源需求较高，处理大规模数据可能较慢。 QIIME 2 是现代微生物组研究的核心工具之一，尤其适合大规模扩增子数据的处理和分析。安装的话尽量用conda直接装下整个环境，然后整个Qiime2分析平台太多太复杂了，像多样性分析，可视化等步骤都可以后续在R语言里更灵活地实现，没必要一定用Qiime2。我们明确一下我们的输入和输出目标（获得feature-table，feature的物种注释结果，feature的系统发育树基本就够了），这里只用下面最关键的几个步骤就行：\nInput data 测序公司一般返回的是按照每个样本拆分好的双端fq文件，或者单端fq文件，或者已经做了简单质控和拼接后的单个fq文件（可以当作单端fq文件），我们从这里开始进行分析。\nmetadata.tsv的话是我们的实验设计（第一列SampleID，可以有一些实验分组的列），想搞的话可以搞一个，后续基于Qiime可视化的话可以用上，没有的话也没关系。\n双端fq文件 需要先准备一个一个制表符分隔的（即 .tsv）文本文件manifest。第一列定义样本 ID，而第二列（和可选的第三列）定义正向（和可选反向）读取的绝对文件路径：\n1 2 3 4 5 sample-id forward-absolute-filepath reverse-absolute-filepath sample-1 $PWD/some/filepath/sample1_R1.fastq.gz $PWD/some/filepath/sample1_R2.fastq.gz sample-2 $PWD/some/filepath/sample2_R1.fastq.gz $PWD/some/filepath/sample2_R2.fastq.gz sample-3 $PWD/some/filepath/sample3_R1.fastq.gz $PWD/some/filepath/sample3_R2.fastq.gz sample-4 $PWD/some/filepath/sample4_R1.fastq.gz $PWD/some/filepath/sample4_R2.fastq.gz 然后数据导入qiime2，这里假设reads格式为双端33格式（PairedEndFastqManifestPhred33V2）\n1 2 3 4 5 qiime tools import \\ --type \u0026#39;SampleData[PairedEndSequencesWithQuality]\u0026#39; \\ --input-path manifest \\ --output-path demux.qza \\ --input-format PairedEndFastqManifestPhred33V2 单端fq文件 同样需要准备manifest文件：\n1 2 3 sample-id absolute-filepath sample-1 $PWD/some/filepath/sample1_R1.fastq sample-2 $PWD/some/filepath/sample2_R1.fastq 然后数据导入qiime2，这里假设reads格式为单端33格式（SingleEndFastqManifestPhred33V2）\n1 2 3 4 5 qiime tools import \\ --type \u0026#39;SampleData[PairedEndSequencesWithQuality]\u0026#39; \\ --input-path manifest \\ --output-path demux.qza \\ --input-format SingleEndFastqManifestPhred33V2 其他类型 其他类型数据的导入方式可以参考https://docs.qiime2.org/2024.10/tutorials/importing/，主要是未拆分的fq文件，就是说所有样本都在一个fq文件里，但是不同样本具有不同的barcode可以用来区分。\n这种的话需要新建一个muxed-se-barcode-in-seq文件夹，把多样本的一个fq文件和对应metadata文件放在文件夹里，metadata其中包含一列用于 FASTQ 解复用（demultiplexing）的每个样本barcode（或两列双索引条形码）\n1 2 3 4 qiime tools import \\ --type MultiplexedPairedEndBarcodeInSequence \\ --input-path muxed-pe-barcode-in-seq \\ --output-path multiplexed-seqs.qza ASV/OTU ASV（Amplicon Sequence Variant）和 OTU（Operational Taxonomic Unit）是微生物组研究中用于表征样本中微生物分类单元的两个核心概念。具体可以参考师姐以前写的介绍https://www.jianshu.com/p/f31581bbfb80。\n1. OTU\n定义：OTU 是通过对扩增子序列进行聚类后定义的分类单元。通常基于序列间的相似性（如 97% 或 99% 相似性）将序列归为同一 OTU。 特点： 常用聚类方法如 UCLUST、VSEARCH、USEARCH。 需要参考数据库或 de novo 聚类（无参考）。 OTU 表可能存在冗余（因聚类误差导致部分不一致）。 2. ASV\n定义：ASV 是通过严格的去噪算法（如 DADA2 或 Deblur）精确定义的单个核苷酸级别变异的序列单元。 特点： 不依赖相似性阈值，直接基于序列精确变异。 生成的序列表更加真实和精细，减少了因聚类导致的信息丢失。 去除了测序误差，保留了真实生物学变异。 特性 ASV OTU 定义 精确的序列变异单位 相似性聚类的单位 分析方法 去噪算法（DADA2、Deblur） 聚类算法（VSEARCH、UCLUST） 分辨率 核苷酸级别 依赖设定的相似性阈值（如 97%） 误差处理 去噪模型精准去除测序误差 聚类可能保留部分测序误差 对数据质量要求 较高 较低 ASV 是现代扩增子分析的主流方法，其精确性和可比较性显著优于 OTU。OTU 在一些特定场景仍有使用价值，但逐渐被 ASV 所取代。\nASV 在 QIIME 2 中，去噪（denoising）是重要步骤，用于去除测序误差并生成高分辨率的 ASV（Amplicon Sequence Variants）。目前支持两种主流的去噪方法：DADA2 和 Deblur。DADA2 使用基于错误模型的算法，通过学习测序误差分布，精确校正序列错误并去除嵌合体；它适合于单端和双端数据，能够直接输出无错误的 ASV 表。Deblur 则是基于参考序列的去噪方法，通过对序列进行截断和归一化操作，快速去除低质量序列及噪音，适合质量已优化的单端数据。两者均能高效生成高分辨率的 ASV，但 DADA2 更注重错误校正，而 Deblur 在速度上更具优势。\n1 2 3 4 5 6 7 8 9 10 11 12 # 选择1，DADA2，不一定要trim和trunc，看自己数据，这里是单端数据，双端稍微改一下参数 qiime dada2 denoise-single \\ --i-demultiplexed-seqs demux.qza \\ --p-trim-left 0 \\ --p-trunc-len 120 \\ --o-representative-sequences rep-seqs-dada2.qza \\ --o-table table-dada2.qza \\ --o-denoising-stats stats-dada2.qza # 改名，放入主流程 mv rep-seqs-dada2.qza rep-seqs.qza mv table-dada2.qza table.qza 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 # 选择2，deblur，不一定要trim和trunc，看自己数据，这里是单端数据，双端稍微改一下参数 qiime quality-filter q-score \\ --i-demux demux.qza \\ --o-filtered-sequences demux-filtered.qza \\ --o-filter-stats demux-filter-stats.qza qiime deblur denoise-16S \\ --i-demultiplexed-seqs demux-filtered.qza \\ --p-trim-length 120 \\ --o-representative-sequences rep-seqs-deblur.qza \\ --o-table table-deblur.qza \\ --p-sample-stats \\ --o-stats deblur-stats.qza # 改名，放入主流程 mv rep-seqs-deblur.qza rep-seqs.qza mv table-deblur.qza table.qza OTU 在 QIIME 2 中，序列聚类用于根据相似性对扩增子序列进行分组，生成 OTU（Operational Taxonomic Units） 表。目前支持三种主要聚类策略：De novo 聚类 完全基于样本序列间的相似性，无需参考数据库，适合研究未被充分表征的微生物群落；封闭引用聚类 仅将序列与参考数据库进行比对，未匹配的序列会被丢弃，适合标准化分析和与已有数据的比较；开放引用聚类 则结合两者优势，先对序列与参考数据库比对，再对未匹配序列进行 de novo 聚类，适合兼顾探索性研究和数据库参考分析的场景。注意，优先使用ASV吧。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 # 如果input数据是fq文件，需要先想办法质控后转化为fasta文件， # 可以参考https://docs.qiime2.org/2019.1/tutorials/read-joining/ # 因为OTU聚类需要输入fasta文件 qiime tools import \\ --input-path seqs.fna \\ --output-path seqs.qza \\ --type \u0026#39;SampleData[Sequences]\u0026#39; # 导入数据后，第一步可以使用 dereplicate-sequences 命令去重复。 qiime vsearch dereplicate-sequences \\ --i-sequences seqs.qza \\ --o-dereplicated-table table.qza \\ --o-dereplicated-sequences rep-seqs.qza # 选择1，De novo clustering qiime vsearch cluster-features-de-novo \\ --i-table table.qza \\ --i-sequences rep-seqs.qza \\ --p-perc-identity 0.99 \\ --o-clustered-table table-dn-99.qza \\ --o-clustered-sequences rep-seqs-dn-99.qza # 选择2，Closed-reference clustering qiime vsearch cluster-features-closed-reference \\ --i-table table.qza \\ --i-sequences rep-seqs.qza \\ --i-reference-sequences 85_otus.qza \\ --p-perc-identity 0.85 \\ --o-clustered-table table-cr-85.qza \\ --o-clustered-sequences rep-seqs-cr-85.qza \\ --o-unmatched-sequences unmatched-cr-85.qza # 选择3，Open-reference clustering qiime vsearch cluster-features-open-reference \\ --i-table table.qza \\ --i-sequences rep-seqs.qza \\ --i-reference-sequences 85_otus.qza \\ --p-perc-identity 0.85 \\ --o-clustered-table table-or-85.qza \\ --o-clustered-sequences rep-seqs-or-85.qza \\ --o-new-reference-sequences new-ref-seqs-or-85.qza 筛选处理 试了下如果这一步产生的ASV太多的话，后续建树（fasttree预估20多天）和物种注释（2天还没完）要非常久，可以稍微对table进行筛选。\n例如，当过滤样本时，可以使用它来过滤总频率是样本频率分布中的异常值的样本。在许多16S调查中，某些样本只能获得很少（可能是数十）的序列，这可能是由于样本生物量较低导致DNA提取率较低。在这种情况下，用户可能希望根据样本的最小总频率（即，在此示例中为样本获得的序列总数）来删除样本。这可以通过如下方式实现（在本例中，总频率小于1500的样本将被过滤）。\n1 2 3 4 qiime feature-table filter-samples \\ --i-table table.qza \\ --p-min-frequency 1500 \\ --o-filtered-table sample-frequency-filtered-table.qza 此过滤器可以应用于特征轴以从表中删除低丰度特征。例如，您可以删除总丰度（所有样本的总和）小于 10 的所有特征，如下所示。\n1 2 3 4 qiime feature-table filter-features \\ --i-table table.qza \\ --p-min-frequency 10 \\ --o-filtered-table feature-frequency-filtered-table.qza 基于偶然性的过滤用于根据样本包含的特征数量从表中过滤样本，或者根据观察到的样本数量从表中过滤特征。\n1 2 3 4 qiime feature-table filter-features \\ --i-table table.qza \\ --p-min-samples 2 \\ --o-filtered-table sample-contingency-filtered-table.qza 1 2 3 4 qiime feature-table filter-samples \\ --i-table table.qza \\ --p-min-features 10 \\ --o-filtered-table feature-contingency-filtered-table.qza 建树 1 2 3 4 5 6 7 ### 构建进化树，可以用来展示物种，也可以计算后续的基于发育距离的alpha和beta多样性 qiime phylogeny align-to-tree-mafft-fasttree \\ --i-sequences rep-seqs.qza \\ --o-alignment aligned-rep-seqs.qza \\ --o-masked-alignment masked-aligned-rep-seqs.qza \\ --o-tree unrooted-tree.qza \\ --o-rooted-tree rooted-tree.qza 然后还可以做一个简单的summary和可视化：\n1 2 3 4 5 6 7 qiime feature-table summarize \\ --i-table table.qza \\ --o-visualization table.qzv \\ --m-sample-metadata-file metadata.tsv qiime feature-table tabulate-seqs \\ --i-data rep-seqs.qza \\ --o-visualization rep-seqs.qzv 这些qzv文件都可以直接拖动到https://view.qiime2.org/网站来查看可视化结果。\n物种注释 数据库注释 常用的扩增子数据库上次介绍过了，涉及到16S rRNA基因的序列数据库时，有三个主要的数据库是常用的：Greengenes、SILVA 和 RDP。UNITE数据库是用于真菌鉴定和多样性检测的主要marker基因数据库。具体信息每个数据库主页都有写，我们拿来用的话关键就是两个文件，一个是数据库提供的序列fasta文件，另一个是这些序列对应的taxonomy文件。\n拿一个UNITE数据库做例子（用来真菌ITS比较多的），先去官网https://unite.ut.ee/repository.php找到对应的资源下载（注意版本号等信息）。\n读入数据库：\n1 2 3 4 5 6 7 8 9 10 11 # 导入参考序列 qiime tools import \\ --type FeatureData[Sequence] \\ --input-path sh_refs_qiime_ver9_99_s_all_25.07.2023.fasta \\ --output-path unite-ver9-seqs_99_25.07.2023.qza # 导入物种分类信息 qiime tools import \\ --type FeatureData[Taxonomy] \\ --input-path sh_taxonomy_qiime_ver9_99_s_all_25.07.2023.txt \\ --output-path unite-ver9-taxonomy_99_25.07.2023.qza \\ --input-format HeaderlessTSVTaxonomyFormat 注释的话，在 QIIME 2 中，feature-classifier 插件提供多种方法用于扩增子序列的分类注释，帮助识别微生物物种或更高分类级别。常用方法包括：朴素贝叶斯（Naive bayes）分类器，利用预训练的参考数据库（如 Silva 或 Greengenes）对序列进行概率性分类，是最常用的分类方法；vsearch-based consensus 分类，通过与参考数据库的序列比对，基于相似性得出共识分类，适合精确匹配需求；BLAST+ 分类，使用 BLAST 算法与参考序列比对，能够提供灵活的匹配控制。此外，还支持训练自定义分类器，适用于特定研究需求。各方法在速度、灵敏度和对参考数据库的依赖上各有优劣，用户可根据数据特点和研究目标灵活选择。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 # 选择1，朴素贝叶斯分类器 # 注意，首先要有训练好的分类器qza文件才能用，可以参考下一节训练分类器 qiime feature-classifier classify-sklearn \\ --i-classifier unite-ver9-99-classifier-25.07.2023.qza \\ --i-reads rep-seqs.qza \\ --o-classification taxonomy.qza # 选择2，vsearch qiime feature-classifier classify-consensus-vsearch \\ --i-query rep-seqs.qza \\ --i-reference-reads unite-ver9-seqs_99_25.07.2023.qza \\ --i-reference-taxonomy unite-ver9-taxonomy_99_25.07.2023.qza \\ --o-classification taxonomy_vsearch.qza # 选择3，blast qiime feature-classifier classify-consensus-blast \\ --i-query rep-seqs.qza \\ --i-reference-reads unite-ver9-seqs_99_25.07.2023.qza \\ --i-reference-taxonomy unite-ver9-taxonomy_99_25.07.2023.qza \\ --o-classification taxonomy_blast.qza 简单画个物种堆积柱形图，后续导出数据再R里画也行。上面几种方法的物种注释结果有差异，在合适情况下还是选最常用的第一个吧。\n1 2 3 4 5 6 7 8 9 10 11 # 可视化物种注释 qiime metadata tabulate \\ --m-input-file taxonomy.qza \\ --o-visualization taxonomy.qzv # 堆叠柱状图展示 qiime taxa barplot \\ --i-table table.qza \\ --i-taxonomy taxonomy.qza \\ --m-metadata-file metadata.txt \\ --o-visualization taxa-bar-plots.qzv 训练分类器 注意，这个步骤一般需要较大内存（看数据库，UNITE这个我消耗了100G左右内存），运行时间也比较久，10多个小时\n1 2 3 4 qiime feature-classifier fit-classifier-naive-bayes \\ --i-reference-reads unite-ver9-seqs_99_25.07.2023.qza \\ --i-reference-taxonomy unite-ver9-taxonomy_99_25.07.2023.qza \\ --o-classifier unite-ver9-99-classifier-25.07.2023.qza 所以尽可能可以去找别人训练好的结果（因为序列是一样的，拿来用就行，但是要注意是在跟你同版本的Qiime2环境下训练的，不然可能用不了）\n这里整理了一些下载路径，可以尝试用用，毕竟不一定每个人都有足够的内存和时间来跑这个分类器：\nUNITE (ITS)：https://github.com/colinbrislawn/unite-train/releases Greengenes (16S rRNA)：http://ftp.microbio.me/greengenes_release/2022.10/sklearn-1.4.2-compatible-nb-classifiers/ Silva (16S/18S rRNA): https://anw-sh.github.io/silva-138_classifiers/ RDP (16S/28S rRNA): https://sourceforge.net/projects/rdp-classifier/ Kraken物种注释 Qiime2注释可真慢呀😂，赶紧找了Kraken的替代方法，见使用Kraken进行16S/ITS物种注释（超快）\nExport data qza，qzv文件是Qiime2的标准格式，还是导出成普通的文本文件（表格等）用来后续别的平台分析吧：\n1 2 3 4 5 6 7 8 9 10 11 12 # 导出feature丰度表 qiime tools export \\ --input-path feature-table.qza \\ --output-path exported-feature-table # 导出序列，在rep-seqs文件夹下 qiime tools export \\ --input-path rep-seqs.qza \\ --output-path rep-seqs # 导出系统发育树 qiime tools export \\ --input-path unrooted-tree.qza \\ --output-path exported-tree 功能预测 16S测序的一大缺点就是只能的到物种信息，缺乏功能信息，使用PICRUSt软件进行16S功能预测分析（预测，稍微弥补这一缺点）。 2018年推出了全新版本的PICRUSt，即PICRUSt2https://github.com/picrust/picrust2。\nPICRUSt2 (Phylogenetic Investigation of Communities by Reconstruction of Unobserved States)是一款基于标记基因序列来预测功能丰度的软件。\n“功能”通常指的是基因家族，如KEGG同源基因，预测通常基于16S rRNA基因测序数据，但也可以使用其他标记基因。\n1 2 3 4 5 # 选择1. 使用 bioconda 安装 PICRUSt2 环境 conda create -n picrust2 -c bioconda -c conda-forge picrust2 #input就是我们上面导出来的otu.fasta和otu_table.txt picrust2_pipeline.py -s otu.fasta -i otu_table.txt -o picrust2_result -p 4 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 # 选择2. 安装q2 picrust2插件（前面提到qiime2的一个特点是插件化，这里刚好可以试试，注意安装对于Qiime2版本的） conda install q2-picrust2 \\ -c conda-forge \\ -c bioconda \\ -c picrust # 跑整个流程 qiime picrust2 full-pipeline \\ --i-table feature-table.qza \\ --i-seq rep-seqs.qza \\ --output-dir q2-picrust2_output \\ --p-placement-tool sepp \\ --p-threads 1 \\ --p-hsp-method pic \\ --p-max-nsti 2 \\ --verbose q2-picrust2_output 中的这些输出文件是：\nec_metagenome.qza - EC 宏基因组预测（行是 EC 编号，列是样本）。 ko_metagenome.qza - KO 宏基因组预测（行是 KO，列是样本）。 Pathway_abundance.qza - MetaCyc 途径丰度预测（行是Pathway，列是样本）。 1 2 3 4 # 导出功能丰度表 qiime tools export \\ --input-path q2-picrust2_output/pathway_abundance.qza \\ --output-path pathabun_exported 这样，整个扩增子上游就差不多了，得到了feature丰度表，feature的物种注释信息，预测的功能丰度表，后续分析就类似宏基因组的部分操作了。\nReferences https://docs.qiime2.org/2024.10/ https://www.jianshu.com/p/f31581bbfb80 Evan Bolyen, Jai Ram Rideout, et al. 2019. Reproducible, interactive, scalable and extensible microbiome data science using QIIME 2. Nature Biotechnology 37: 852-857. https://doi.org/10.1038/s41587-019-0209-9 Douglas, G.M., Maffei, V.J., Zaneveld, J.R. et al. PICRUSt2 for prediction of metagenome functions. Nat Biotechnol 38, 685–688 (2020). https://doi.org/10.1038/s41587-020-0548-6 https://github.com/YongxinLiu/EasyAmplicon ","date":"2024-12-23T00:00:00Z","image":"/p/amplicon-workflow/images/16s_hu_cc5969a292eaa055.webp","permalink":"/p/amplicon-workflow/","title":"扩增子(Amplicon)数据分析流程|Qiime2"},{"content":"Introduction KEGG（Kyoto Encyclopedia of Genes and Genomes）是一个广泛使用的生物信息学数据库，用于研究基因组、代谢组、信号通路和生物化学反应等方面的信息。之前也写过推文详细介绍过KEGG数据库和API，但最近又有一些重要的更新，并在NAR上发表：\nMinoru Kanehisa, Miho Furumichi, Yoko Sato, Yuriko Matsuura, Mari Ishiguro-Watanabe, KEGG: biological systems database as a model of the real world, Nucleic Acids Research, 2024;, gkae909, https://doi.org/10.1093/nar/gkae909\nKEGG (https://www.kegg.jp/) 是一个用于分析生物系统的数据库资源，主要包含分子相互作用与反应网络的通路图（Pathway maps）。KEGG Orthology (KO) 系统通过 KO 标识将基因和蛋白与通路图及分子网络关联，实现基因组和宏基因组的系统功能解析。KO 还用于物种组内保守基因和基因单元的分析，支持通过分类学映射和基因组序列保守性分析。此外，KEGG 开发了 VOG 数据集（病毒同源群），为跨物种的基因序列比较和多物种生物过程的全局视图构建提供支持。\nKEGG更新 VOG (virus ortholog group) VOG（病毒同源群）是通过与KO注释相同的资源计算生成的数据集。KEGG中的所有基因组都会通过SSEARCH程序进行SSDB（序列相似性数据库）计算，涵盖氨基酸序列（编码蛋白基因）和核苷酸序列（RNA基因）。对于每个基因，会生成一个基于物种的相似性邻居列表，并以GFIT表格形式展示，这也是KO注释的基础数据集。在SSDB计算中，vg（病毒基因）类别作为一个单一物种处理，病毒基因之间的相似关系会显示在平行GFIT表中。相似性度量采用修改后的同一性评分，其中重叠区域的身份评分由SSEARCH给出，并根据最小值 min(1, overlap*2/(aalen1 + aalen2)) 加权。所有病毒蛋白的平行GFIT表按表格大小降序处理，通过启发式方法有效地执行单链聚类（single linkage clustering）来生成VOG。实际上，生成了三个VOG数据集，修改后的同一性阈值分别为30%、50%和70%，每个VOG都分配了一个六位数编号，分别以3、5和7开头。这些编号不是稳定的，可能会随着GENES vg类别（来自RefSeq）的更新而变化。此外，所有细胞生物（KEGG物种）的蛋白质会与这三个数据集进行比较，查看是否属于某个VOG。\n目前VOG数据集的统计信息可以在KEGG病毒页面查看（https://www.kegg.jp/kegg/genome/virus.html）。在使用30%的阈值时，约90%的病毒蛋白属于大小为2或更大的VOG。最大VOG包含了8%的病毒蛋白，而其他组的规模则较小，每组含有0.7%或更少的蛋白。来自RefSeq的大多数病毒蛋白为噬菌体蛋白（80%），最大VOG也以噬菌体蛋白为主（93%）。根据RefSeq注释，最大VOG中的三分之一为假设蛋白，最常见的注释术语是HNH内切酶。当包括细胞生物时，大约5%的5000万个蛋白质与病毒蛋白质有相似性。\n优化基因顺序比对 基因组比对通常通过比对两组核苷酸序列完成，而这里的方法是将基因组视为由KOs（K编号）或VOGs（VOG编号）表示的基因序列进行比对。由于53%的细胞生物基因和90%的病毒基因分别被分配到KOs和VOGs，这种方法有效简化了基因顺序比对问题。利用Goad和Kanehisa开发的动态规划算法，该工具可发现两个基因组中局部相似基因顺序，避免负分值路径并结合正向与反向路径的逻辑产品修剪。工具已整合至KEGG Syntax工具集中。\n该工具在KEGG Syntax工具集中提供，用于比较两个基因组。其功能包括通过动态规划算法找到局部基因顺序相似的区域。比对输出显示两基因组的基因标识符和匹配的K编号，中间使用符号“\u0026lt;”表示互补链。此外，工具支持两种方向（正向和反向）比对，当基因重复时，会合并为单元并标注重复次数。例如，人类和小鼠基因组比较中，显示了嗅觉受体基因（K04257）在不同重复数下的匹配情况，以及后续基因顺序在基因组图谱中的位置。\n通路图的分类映射 KEGG数据库使用NCBI分类法对细胞生物和病毒进行分类，其中不同版本的分类树作为多个Brite层次文件实现。细胞生物的默认文件（br08611）是根据固定的分类等级：门、纲、目、科、属和种，对三到四个字母的KEGG生物体代码进行分类。病毒的默认文件（br08621）是根据固定的分类等级：域、王国、门、纲、目、科、属和种，对vtax标识符进行分类。\n分类映射是将KOs（K编号）、模块（M编号）和VOGs的基因组内容映射到KEGG分类文件的过程。结果通过KEGG分类浏览器显示，这是一个专用的Brite层次查看工具。该浏览器具有缩放功能，可以更改分类等级的底层。此外，最近引入了分类映射的另一种显示方式，即通过简要视图展示每个分类类别中映射的生物或病毒数量。\nKEGG通路图的原始概念是手动创建通用的通路图，其中节点由KOs表示，然后通过将KOs转换为特定的基因ID来为每个生物体调整，最终得到特定于生物的通路图。通用（参考）通路图可以应用于一组生物体，而不仅仅是单个生物体，甚至可以应用于多个生物体组。图3展示了新的氮循环通路图（map01310），其本质上与现有的氮代谢通路图（map00910）相同，但更侧重于化学化合物作为生物地球化学循环的转化过程，以及不同生物体群在特定转化过程中的作用。生物体群的参与通过七个KEGG模块的分类映射来表示，每个模块与特定的转化过程相关联。在路径查看器中，选择模块（如氮固定模块M00175）后，相关模块将以红色段显示。\nKO人工矫正 KEGG生物体的数量目前正以每月约80个的速度增加。为了应对这种加速增长，KEGG的KO分配注释流程已进行了简化。首先，新的基因组中的蛋白编码基因通过BLAST与一个小型参考序列数据集进行比对，该数据集与BlastKOALA服务器提供的数据集相同。其次，蛋白质和RNA编码基因通过SSEARCH与整个GENES数据集进行比对，并使用新的KOALA程序进行自动注释。除了基于计算的基因组注释外，还会通过创建序列组来执行手动KO注释，尤其是在新KO定义或现有KO修改时。GENES注释的整体一致性每天都会进行检查，并为人工干预提供额外的候选项和可能的误注释。\n疾病相关的网络 KEGG MEDICUS 是一个实用资源，将 KEGG 的健康信息类别与日本和美国已上市药物的药品标签整合，通过分配 D 编号标识符进行连接。日本的药品标签来源于 JAPIC（日本药品信息中心），并被整合到 KEGG Oracle 数据库中。美国食品药品监督管理局（FDA）的国家药品代码（NDC）目录用于与 DailyMed 数据库链接，以获取美国的药品标签。与 KEGG 的其他三大类别（分别为细胞、机体和生物圈层面上的分子系统）不同，健康信息类别专注于建模人类分子系统，特别是与人类疾病相关的扰动系统。\n在 NETWORK 数据库中，网络变异图展示了参考分子网络如何受到人类基因变异、病毒等因素的扰动，扰动如何与特定疾病相关，以及有哪些药物和靶标可用。网络变异图已经应用于多个代谢和信号网络，且大多数与 KEGG 路径图相关联。因此，越来越多的 DISEASE 数据库条目与网络变异图相关联，目前约 30% 的条目展示了网络与疾病的关联。\n","date":"2024-12-20T00:00:00Z","image":"/p/kegg-2024-12/images/gkae909fig3_hu_6818ce8d24bd3630.jpeg","permalink":"/p/kegg-2024-12/","title":"KEGG更新（2024.12）|作为现实世界模型的生物系统数据库"},{"content":"Introduction 上次已经介绍了巨型病毒的一些基本内容，也讲到了不依赖培养的方法是从环境样本中发现巨型病毒基因组成的不可或缺的工具。可以通过基因组解析宏基因组学来从环境序列数据中获取 NCLDV 基因组并进行深入研究如功能基因，宿主，进化等等。这次介绍一些基于宏基因组的巨型病毒研究：\n全球宏基因组学揭示巨型病毒多样性和宿主相互作用 作者利用快速增加的公开宏基因组数据，从全球采样点重建了 2,074 个 NCLDV 基因组。这导致系统发育多样性增加了 11 倍，功能多样性也相应增加了 10 倍。使用宏基因组数据对来自大型和巨型病毒的 58,023 个主要衣壳蛋白进行分析，揭示了这些病毒的全球分布模式和世界性本质。 所发现的病毒基因组编码了多种在光合作用和不同底物运输过程中具有推定作用的蛋白质，表明宿主重编程可能是 NCLDV 中的常见策略。此外，水平基因转移的推论将病毒谱系与不同的真核宿主联系起来。作者预计在此描述的 NCLDV 的全球多样性将使巨型病毒（与大多数主要真核生物谱系相关）成为地球生物群落生态系统中的重要参与者。\n作者使用了多步宏基因组数据挖掘、分箱和迭代过滤流程，从 8,535 个公开可用的宏基因组中恢复了代表 2,074 个假定 NCLDV 群体的基因组，置于综合微生物基因组和微生物组 (IMG/M) 数据库。核质病毒直系同源基因（NCVOG）的组装大小、GC含量、编码密度和拷贝数与之前描述的NCLDV基因组相当，支持将这些基因组分类为巨型病毒宏基因组组装基因组（GVMAG）。使用依赖于保守 NCVOG 的方法，作者估计了基因组完整性和污染，从而对 773 个高质量、989 个中等质量和 312 个低质量 GVMAG 进行了分类，符合 MIUViG 建议。\n使用 GVMAG 增强现有的 NCLDV 系统发育框架大大增加了该病毒目的多样性（上图a）。由此产生的系统发育树从 205 个病毒基因组扩展到 2,279 个病毒基因组，与之前识别的 20 个属相比，这些病毒基因组现在可以分为 100 个潜在属或亚科水平的单系进化枝，跨越 10 个临时超进化枝。这意味着 NCLDV 的系统发育多样性增加了 11 倍。值得注意的是，新病毒基因组的添加并没有改变 NCLDV 树的基本拓扑结构，而是改变了现有群体（尤其是拟病毒科）对总病毒多样性的贡献。此外，谱系特异性模式中保守的 NCVOG 的存在强化了该病毒群具有共同进化起源的假设。现有分类框架内出现了没有分离株代表的新病毒群（即宏基因组巨型病毒谱系（MGVL））。为了进一步加深对 NCLDV 环境分布模式的了解，作者对所有公共宏基因组数据集的主要衣壳蛋白 (MCP) 进行了调查。作者鉴定了超过 58,000 个该蛋白质的拷贝，其中 67% 可以归属于病毒谱系（上图b）。\n病毒感染对其真核宿主的有害影响是众所周知的；然而，最近的一些研究表明，NCLDV 也可能补充其宿主的新陈代谢，例如，通过编码吸收氮等营养物质的转运蛋白或发酵基因。扩展这些初步发现，作者的数据表明，所有 NCLDV 超进化枝的不同谱系都编码在光合作用、不同底物运输过程、光驱动质子泵和视网膜色素中具有潜在作用的酶（上图）。代谢重编程是指细菌病毒从宿主获取基因并维持它们以支持宿主新陈代谢的一种常见现象。结果表明，以类似的方式，NCLDV 介导的宿主重编程可能是增加病毒繁殖力的重要策略，同时使受感染的真核宿主细胞具有短期竞争优势，特别是在营养有限的条件下。\n宿主基因的摄取是 NCLDVs进化中的常见机制。使用 HGT 分析，作者将假定的宿主分配给不同的 NCLDV 谱系。对可能经历 HGT 的 2,040 个基因的分析提供了 50 个病毒谱系与 32 组推定真核宿主的连锁信息（上图）。值得注意的是，包含分离病毒基因组的 23 个病毒谱系中有 17 个可以通过 HGT 连接到经过实验验证的天然宿主，例如大多数感染藻类的病毒和感染后生动物的子囊病毒、纳毛病毒和痘病毒，以及将克洛斯新病毒连接到动质体。作者的分析进一步证实棘阿米巴是潘多拉病毒、海象鼠病毒、水母病毒、马赛病毒和巨拟病毒的宿主。值得注意的是，作者的分析没有揭示与人类宿主的联系。作者预计，随着宿主基因组采样的改进，特别是未充分探索的原生生物和藻类的基因组，通过 HGT 进行的宿主关联将产生更全面的 NCLDV 宿主范围和进化历史图景。\n来自地球生态系统的巨型噬菌体进化枝 噬菌体通常具有较小的基因组，并且依赖于其细菌宿主进行复制。在这里，作者对来自不同生态系统的 DNA 进行了测序，发现了数百个长度超过 200 kb 的噬菌体基因组，其中包括 735 kb 的基因组，据作者所知，这是迄今为止描述的最大的噬菌体基因组。手动整理了 35 个基因组以完成（圆形且无间隙）。扩展的遗传库包括多种先前未描述的 CRISPR-Cas 系统、转移 RNA (tRNA)、tRNA 合成酶、tRNA 修饰酶、翻译起始和延伸因子以及核糖体蛋白。噬菌体的 CRISPR-Cas 系统具有沉默宿主转录因子和翻译基因的能力，可能作为更大的相互作用网络的一部分，拦截翻译以将生物合成重定向到噬菌体编码的功能。此外，一些噬菌体可能会重新利用细菌 CRISPR-Cas 系统来消除竞争噬菌体。作者从系统发育上定义了来自人类和其他动物微生物组以及海洋、湖泊、沉积物、土壤和建筑环境的巨型噬菌体的主要进化枝。作者的结论是，巨大噬菌体的大量基因库反映了保守的生物策略，并且噬菌体分布在广泛的细菌宿主范围和地球生态系统中。\n2017 年，仅发表了 93 个基因组长度超过 200 kb 的分离噬菌体。对整个群落 DNA 进行测序可以发现噬菌体衍生的片段；然而，由于碎片化，大基因组仍然可以逃脱检测。最近，根据宏基因组数据集手动整理完成的基因组，描述了人类和动物相关巨噬细胞的一个新分支9。这一发现促使作者对微生物群落进行更全面的分析，以评估具有大基因组的噬菌体的流行率、多样性和生态系统分布。此前，基因组超过 200 kb 的噬菌体被称为“jumbophages”，或者基因组超过 500 kb 的噬菌体被称为megaphages。由于这里重建的集合跨越了两个尺寸范围，作者将它们简单地称为“巨大噬菌体”。上图概述了作者的方法和主要发现。这项研究扩展了作者对噬菌体生物多样性的理解，并揭示了各种生态系统，其中噬菌体的基因组大小可与小细胞细菌相媲美。作者假设这些噬菌体已经进化出一种独特的“生命”策略，其中涉及在复制其巨大基因组时对宿主生物学进行广泛的拦截和增强。\n作者重建了 351 个噬菌体序列、6 个类质粒序列和 4 个未知分类序列。排除了被推断为质粒的其他序列，仅保留编码 CRISPR-Cas 位点的序列。由于 CRISPR-Cas 位点的存在，作者纳入了 3 个长度≤200 kb 的噬菌体序列。与噬菌体的分类一致，作者鉴定了多种噬菌体相关基因，包括参与裂解和编码结构蛋白的基因，并记录了噬菌体的其他预期基因组特征。一些预测的蛋白质很大，长度可达 7,694 个氨基酸；有些被暂时注释为结构蛋白。总共有 175 个噬菌体序列被环化，其中 35 个是手动完成的，在某些情况下通过解析复杂的重复区域，揭示其编码的蛋白质（方法和补充表 1）。大约 30% 的基因组显示出明显的 GC 偏差，表明存在双向复制，30% 的基因组具有表明单向复制的模式13。4 个最大的完整、手动管理和环化的噬菌体基因组长度分别为 634、636、642 和 735 kb，据作者所知，它们是迄今为止报道的最大的噬菌体基因组（2020年）。\n一个有趣的问题与具有巨大基因组的噬菌体的进化历史有关。也就是说，它们是否是正常大小噬菌体进化枝内最近基因组扩张的结果，或者大量基因是否是一种既定的、持久的策略。为了研究这一点，作者使用公共数据库中的序列作为背景，构建了大终止酶亚基蛋白（上图）和主要衣壳蛋白的系统发育树。噬菌体基因组中的许多序列在高引导支持下聚集在一起，从而定义了进化枝。对数据库序列的基因组大小信息的分析表明，属于这些进化枝的公共序列来自基因组长度至少为 120 kb 的噬菌体。最大的进化枝，在这里被称为 Mahaphage（Maha 在梵文中是巨大的意思），包括作者所有最大的基因组以及来自人类和动物微生物组的 540-552 kb Lak 基因组。作者还发现了另外九个大型噬菌体簇，并在本文的一些作者的语言中使用“巨大”一词来指代它们。大噬菌体始终被分组为进化枝的事实表明，大的基因组大小是一个相对稳定的特征。在每个进化枝内，噬菌体都是从各种环境类型中采样的，这表明这些巨大噬菌体及其宿主在整个生态系统中的多样化。\n为了确定细菌宿主系统发育与噬菌体进化枝的相关程度，作者使用 CRISPR 间隔区从相同或相关样本中的细菌以及正常宿主相关噬菌体基因的系统发育中鉴定了一些噬菌体宿主。作者还测试了噬菌体基因库的细菌分类学隶属关系的预测值，发现在每种情况下，CRISPR 间隔区靶向和系统发育都与门级分类学特征一致。因此，作者使用分类学特征来预测许多噬菌体的细菌宿主门（补充表4）。结果确定了厚壁菌门和变形菌门作为宿主的重要性。与其他环境相比，人类和动物肠道中厚壁菌门感染的巨型噬菌体的患病率较高，这反映了微生物组的潜在宿主组成。值得注意的是，长度超过 634 kb 的 5 个基因组均来自预计会在拟杆菌门中复制的噬菌体，Lak 噬菌体也是如此，并且全部聚集在 Mahaphage 进化枝内。总体而言，系统发育上分组的噬菌体预计会在同一门的细菌中复制。\n噬菌体基因组编码的蛋白质预计定位于细菌膜或细胞表面。许多噬菌体具有参与嘌呤和嘧啶的从头生物合成以及核酸和核糖核酸以及核苷酸磷酸化状态的相互转化的基因。这些基因组与具有非常小细胞和假定共生生活方式的细菌的基因组非常相似。 值得注意的是，许多噬菌体的基因具有预测的转录和翻译功能。完整的噬菌体基因组编码多达 67 个 tRNA，其序列与其宿主的序列不同。一般来说，每个基因组的 tRNA 数量随着基因组长度的增加而增加。巨大的噬菌体每个基因组有多达 15 个 tRNA 合成酶，它们也与其宿主的合成酶不同但相关。噬菌体可以利用这些蛋白质为它们自己的 tRNA 变体装载来自宿主的氨基酸。基因组的一个子集具有用于 tRNA 修饰和连接被宿主防御切割的 tRNA 的基因。 许多噬菌体携带与宿主翻译的拦截和重定向有关的基因。这些基因包括起始因子IF1和IF3，以及核糖体蛋白S4、S1、S21和L7/L12（核糖体蛋白最近才在噬菌体中报道17（上图））。 rpS1 和 rpS21 对于细菌中的翻译起始都很重要，这使得它们可能有助于劫持宿主核糖体。对 rpS21 蛋白的进一步分析揭示了 N 末端延伸，富含对 RNA 结合很重要的碱性和芳香残基。作者预测这些噬菌体核糖体蛋白会替代宿主蛋白，并且它们的延伸有助于竞争性核糖体结合或噬菌体 mRNA 的优先启动。\n作者鉴定了噬菌体中大多数主要的 CRISPR-Cas 系统类型，包括基于 Cas9 的 II 型、最近描述的 V-I23 型、V-U 型系统的新变体24 和 V-F 型系统的新亚型。 II 类系统（II 型和 V 型）此前尚未在噬菌体中报道过。大多数噬菌体效应核酸酶（用于干扰）具有保守的催化残基，这意味着它们具有功能。 与具有 CRISPR 系统的噬菌体案例相比，几乎所有噬菌体 CRISPR 系统都缺乏间隔区获取机制（Cas1、Cas2 和 Cas4），并且许多系统缺乏可识别的干扰基因。例如，两个相关的噬菌体具有 I-C 型变体系统，该系统缺乏 Cas1 和 Cas2，并具有解旋酶蛋白而不是 Cas3。这些噬菌体还有第二个系统，其中包含新的候选 V 型效应蛋白 CasΦ (Cas12j)，其长度约为 750 个氨基酸（图 4 和补充表 1），出现在 CRISPR 阵列附近。\n在某些情况下，缺乏干扰和间隔区整合基因的噬菌体与宿主具有相似的CRISPR重复序列，因此可能使用宿主的Cas蛋白。或者，缺乏效应核酸酶的系统可能会抑制靶序列的转录而不发生裂解。此外，间隔重复引导RNA可能具有类似RNA干扰的机制来沉默宿主CRISPR系统或它们可以杂交的核酸。噬菌体编码的 CRISPR 阵列通常很紧凑，该范围远小于原核基因组中常见的范围。一些噬菌体间隔区针对其他噬菌体的核心结构和调节基因。因此，噬菌体显然增强了宿主的免疫库，以防止竞争性噬菌体的感染。\n一些感染假单胞菌的大型噬菌体编码抗 CRISPRs (Acrs) 和蛋白质，这些蛋白质组装成核样区室，将其复制基因组与宿主防御和其他细菌系统隔离开来。作者鉴定了巨大噬菌体基因组中编码的蛋白质，这些蛋白质与 AcrVA5、AcrVA2、AcrIIA7 和 AcrIIA11 聚集在一起，并且可能具有 Acrs 的功能。作者还鉴定了微管蛋白同源物 (PhuZ) 和蛋白质，它们可产生蛋白质噬菌体“细胞核”。最近表明噬菌体核可以通过物理阻止 CRISPR-Cas 系统的降解来保护噬菌体基因组免受宿主防御。\n全球巨型病毒的基因组进化动态和病毒细胞代谢 真核巨型病毒的发现改变了作者对病毒复杂性极限的理解，但其编码代谢多样性的程度仍不清楚。在这里，作者从全球环境中生成了 501 个核胞质大 DNA 病毒 (NCLDV) 的宏基因组组装基因组，并分析了它们的编码功能能力。作者报告了广泛分布的巨型病毒中代谢基因的显著多样性，包括许多与营养吸收、光捕获和氮代谢有关的基因。令人惊讶的是，许多 NCLDV 编码糖酵解和 TCA 循环的成分，这表明它们可以重新编程宿主中心碳代谢的基本方面。 作者对 NCLDV 代谢基因及其细胞同源物的系统发育分析揭示了病毒序列不同的聚类，形成不同的分支，表明这些基因是病毒特异性的，并且是在遥远的过去获得的。总的来说，作者的研究结果表明，巨型病毒编码复杂的代谢能力，其进化历史很大程度上独立于细胞生命，强烈暗示它们是全球生物地球化学循环的重要驱动因素。\n为了解决有关环境中 NCLDV 的基因组多样性、进化关系和病毒细胞代谢的关键问题，作者开发了一个工作流程，从公开的宏基因组数据中生成 NCLDV 的宏基因组组装基因组 (MAG)。作者调查了 1545 个宏基因组，并从大小范围为 100 至 1400 kbp 的单个样本中生成了 501 个新型 NCLDV MAG。作者的工作流程包括去除可能源自细胞生物或噬菌体的重叠群的步骤，以及最大限度地减少每个 MAG 中可能的菌株异质性。为了确保作者的 NCLDV MAG 代表几乎完整的基因组，作者只保留了至少包含 5 个关键 NCLDV 标记基因中的 4 个的 MAG，这些基因已知在这些病毒中高度保守11，并且总长度 \u0026gt; 100Kbp。大多数 MAG 是从海洋和淡水环境中产生的（分别为 444 和 36），但作者还在生物反应器、废水处理厂、油田和土壤样本的宏基因组中发现了 21 个。\n作者使用先前用于这些病毒系统发育分析的 5 个高度保守的基因，构建了 NCLDV MAG 的多位点系统发育树以及 121 个参考基因组（上图）。大多数 MAG 属于 Mimiviridae 和 Phycodnaviridae 家族（分别为 350 和 126），但作者还在 Iridoviridae、Asfarviridae、Marseillviridae和 Pithoviridae中鉴定了新基因组。作者的研究中对大量拟病毒科成员的鉴定与之前的分析一致，表明该科在海洋系统中具有高度多样性。 作者的系统发育表明，藻类DNA病毒科是多系的，并且至少由两个不同的单系群组成，其中一个是拟拟病毒科的姐妹群（称为晚期藻类DNA病毒科，108个MAG），另一个是拟拟病毒科-晚期藻类DNA病毒科分支的基础分支（称为“晚期藻类DNA病毒科”）早期藻类DNA病毒科，18 MAG）。尽管最近的一项研究报告了另一种拓扑结构，其中 Asfarviridae 也属于这个更广泛的组，但先前已根据串联标记基因系统发育提出了藻类DNA病毒科和拟菌病毒科组合的单系性。除了系统发育之外，作者还评估了 NCLDV 基因组之间的成对平均氨基酸同一性 (AAI)，以评估基因组差异。 AAI 值提供的结果与作者的系统发育分析基本一致，并显示科内 AAI 值范围为 26% 至 100%（上图b），突出显示即使是同一科内的 NCLDV 基因组之间也存在显著的序列差异。\n为了评估 NCLDV 家族中蛋白质家族的多样性，作者计算了 MAG 和 126 个参考基因组之间的直系同源群 (OG)，从而得到 81,411 个 OG。其中，只有 21,927 个 (27%) 与 EggNOG、Pfam、TigrFam 和 VOG 数据库中已知的蛋白质家族具有可检测的同源性，这凸显了在其他研究中观察到的 NCLDV 基因组中存在大量新基因。此外，55,692 (68%) 的 OG 仅存在于一个 NCLDV 基因组（单例 OG）中，总体而言，蛋白质家族成员的程度分布仅揭示了少数广泛共享的蛋白质家族（上图a、b），与一般 dsDNA 病毒所显示的结果一致。为了可视化 NCLDV 中的基因共享模式，作者构建了一个二分网络，其中可以表示基因组和 OG（上图 c）。 对该网络的分析主要揭示了科级聚类，拟菌病毒科以及早期和晚期藻类DNA病毒科彼此靠近，而皮托病毒科、马氏病毒科和痘病毒科分别聚类。有趣的是，虽然潘多拉病毒是早期藻类DNA病毒科分支的成员，但它们独立聚集在一个小子网络中，表明该组中特别大的基因组和新颖的基因组库与所有其他NCLDV不同。这些模式表明，NCLDV 中的基因组内容部分是由进化历史决定的，但基因组内容的大规模增加或减少可能会在短时间内发生，类似于潘多拉病毒中发生的情况。这表明，在漫长的进化时间尺度上，NCLDV 的基因组进化是由垂直遗传和 LGT 混合形成的，在许多方面至少在质量上与细菌和古细菌相似。\n引人注目的是，许多 NCLDV 基因组编码参与中心碳代谢的基因，包括大多数糖酵解、糖异生、TCA 循环和乙醛酸分流酶（上图4a）。中心碳代谢通常被认为是细胞生命的基本特征，因此值得注意的是，巨型病毒累积地编码了这些途径的几乎每一步。这些基因在拟菌病毒分支 1、9 和 16 中特别丰富，但其中一些基因也存在于几种藻DNA病毒科成员中。糖酵解酶甘油醛-3-磷酸脱氢酶 (G3P)、磷酸甘油酸变位酶 (PGM) 和磷酸甘油酸激酶 (PGK)，以及 TCA 循环酶乌头酸酶和琥珀酸脱氢酶 (SDH) 特别普遍。此外，作者在 16 个 MAG 中发现了一个编码糖酵解酶 G3P 和 PGK 的融合基因，它们执行糖酵解中的相邻步骤，代表了以前在细胞谱系中未报道过的独特结构域结构。 有趣的是，在许多 MAG 中，TCA 循环基因共定位于病毒重叠群上，这表明这些基因在感染过程中可能存在共同调节（上图c）。值得注意的是，一种 NCLDV MAG (ERX552257.96) 编码了糖酵解 10 个步骤中的 7 个步骤（上图d），这突显了一些巨型病毒可以从宿主中实现高度的代谢独立性。病毒编码不同中央代谢途径的这些成分，这一事实强调了它们通过操纵细胞内碳通量从根本上重新编程病毒细胞代谢的潜力。\n病毒历来被视为细胞生命的附属品，因此它们对生物地球化学循环的影响在很大程度上是通过它们对宿主死亡率的影响来看待的，而不是通过它们本身的任何直接代谢活动来看待。作者在这项研究中揭示的 NCLDV 基因组中编码的大量细胞代谢基因揭示了另一种观点，即病毒特异性酶在塑造病毒细胞生理学方面具有直接作用。在全球水生环境中的病毒感染范围内，这提出了病毒酶本身可以大幅改变全球生物地球化学通量的可能性。此外，病毒代谢基因独特的进化谱系表明 NCLDV 是代谢创新的独特驱动力，这与传统观点形成鲜明对比，传统观点认为它们只是细胞基因的偶尔扒手，而不是事实上的进化创新者。总而言之，这些发现表明，正如微生物被认为是塑造全球生物地球化学循环的引擎一样，病毒也应该与它们的细胞对应物一起被视为具有自身编码生理学的代谢流代理。\nReferences Schulz, F., Roux, S., Paez-Espino, D. et al. Giant virus diversity and host interactions through global metagenomics. Nature 578, 432–436 (2020). https://doi.org/10.1038/s41586-020-1957-x Al-Shayeb, B., Sachdeva, R., Chen, LX. et al. Clades of huge phages from across Earth’s ecosystems. Nature 578, 425–431 (2020). https://doi.org/10.1038/s41586-020-2007-4 Moniruzzaman, M., Martinez-Gutierrez, C.A., Weinheimer, A.R. et al. Dynamic genome evolution and complex virocell metabolism of globally-distributed giant viruses. Nat Commun 11, 1710 (2020). https://doi.org/10.1038/s41467-020-15507-2 ","date":"2024-12-02T00:00:00Z","image":"/p/giant-virus-res/images/gvmags2_hu_1b91ce2873bd94a5.png","permalink":"/p/giant-virus-res/","title":"一些基于宏基因组的巨型病毒研究"},{"content":"Introduction 大型和巨型病毒是双链 DNA 病毒的一部分，即核质大DNA病毒 (NCLDV, nucleocytoplasmic large DNA viruses)，构成病毒门 Nucleocytoviricota。 该门的病毒感染多种真核宿主，从已知最小的单细胞领鞭毛虫到多细胞动物。 NCLDV 通常在宿主细胞质中构建的所谓病毒工厂中复制，或使用宿主细胞核复制，有时组装其后代。这些病毒的标志性特征是基因组范围从 70 kb 到 2.5 Mb 不等，病毒粒子长度可达 2 μm 以上。\n“巨型病毒”一词最初是在 20 世纪 90 年代创造的，当时感染藻类的病毒明显具有异常大的基因组，此外，在 2000 年代初期，第一个基因组在兆碱基范围内的病毒被发现；最初的光学显微镜观察得出这样的假设：其颗粒对应于变形虫革兰氏阳性细菌病原体。更详细的超微结构分析揭示了典型的二十面体形状的病毒粒子，并且基因组测序产生了 1.2 Mb 的病毒基因组。 这种病毒被命名为“mimivirus”，是“微生物模仿病毒”的缩写，代表了病毒圈中意想不到的新颖性，不仅因为其特殊的颗粒和基因组大小，而且还因为它包含多个具有可能作用的基因，因此具有编码潜力蛋白质生物合成。 自从巨型病毒被发现以来，它们的编码潜力充满了惊喜，并且细胞生命标志基因的存在导致了这样的假设：这些病毒可能代表生命的神秘第四域。同样有趣的是，人们发现更小的病毒（所谓的病毒噬菌体）可以感染一些仅具有细胞质感染周期的 NCLDV；噬病毒体寄生并有时杀死宿主。还发现了第三个伙伴，称为“transpoviron”，它对应于 7kb 双链 DNA 附加体，能够使用巨型病毒和噬病毒体颗粒作为载体进行繁殖。\n十多年来，巨型病毒主要通过基于培养的方法进行研究，直到最近，病毒学追随微生物基因组学的脚步，应用不依赖培养的宏基因组学以无与伦比的速度研究这些病毒的进化多样性和代谢潜力。 研究者探索了大量的实验数据，这些数据揭示了对巨型病毒生物学的许多见解，特别是它们的病毒颗粒结构和独特的感染策略。研究者通过整合最新的基于序列的研究来建立这些知识，这些研究扩展了 NCLDV 多样性、生物地理学、编码潜力和假定的宿主范围。此外，研究者讨论了令人信服的证据，表明巨型病毒基因组中存在多种细胞标志基因，使病毒能够重新编程宿主代谢，并且巨型病毒遗传物质整合到宿主基因组中可能会影响真核细胞的生物学和进化。\n通过分离发现巨型病毒 最早发现的 NCLDV 是痘病毒科，其中包括天花的病原体，是 130 多年前在显微镜下看到的第一个病毒颗粒。感染小球藻绿藻的大型病毒在 20 世纪 80 年代被分离出来。痘苗病毒（一种痘病毒）和草履虫小球藻病毒 1 (PBCV1) 的第一个基因组分别于 20 世纪 90 年代初和 1999 年进行了测序。 此后不久，对痘病毒科的其他基因组进行了测序（图 1），其大小范围从 120 kb 到 360 kb。 随后，发现了感染动物的其他病毒，包括子囊病毒科、虹彩病毒科和阿斯法病毒科的成员，并对它们的基因组进行了测序。这些类群中的病毒基因组相对较小（最多 220kb），最近发现的与虾相关的小核病毒科病毒的基因组更小（70-80kb）。 除了感染动物的 NCLDV 外，2000 年代初期，在各种真核藻类中也检测到了多种 NCLDV，包括叶绿藻、附着藻、深海藻、褐藻和甲藻。这些与藻类相关的 NCLDV 被分类为 Phycodnaviridae 和 Mesomimiviridae，尽管它们的大部分基因组约为 200–500 kb，但 Tetraselmis 病毒和 Prymnesium kappa 病毒 RF01 的基因组为 668 kb和 1.4 Mb。\n图 1：核质病毒门中依赖于培养和不依赖于培养的重要发现的时间线。 堆叠柱状图表示每年在NCBI GenBank数据库中发布或可用的核质病毒门（Nucleocytoviricota）成员的病毒分离基因组（蓝色；左y轴）和巨型病毒宏基因组组装基因组（GVMAGs；红色；左y轴）的数量（x轴为年份）。实心圆点表示病毒分离基因组和GVMAGs的组装大小（右y轴）。重要的基于培养的事件以绿色星星标注：(1) 首次分离巨型病毒（Paramecium bursaria chlorella virus 1）。(2) 通过阿米巴共培养分离出mimivirus。(3) 与其宿主Cafeteria roenbergensis一起分离巨型病毒。(4) 分离出基因组大小达2.5 Mb的瓶状pandoravirus。(5) 通过与阿米巴共培养，从一块3万年前的冰芯中恢复出pithovirus。(6) 通过与Vermamoeba vermiformis共培养分离出faustovirus。(7) 分离出Bodo saltans virus，这是Klosneuvirinae亚科中首个具有原生宿主（动力鞭毛虫）的分离成员。(8) 从阿米巴中分离出tupanvirus，目前是基于衣壳直径和长度最大的巨型病毒。(9) 从阿米巴中分离出medusavirus，代表核质病毒门中的一个新的分化谱系。 重要的基因组和宏基因组事件以黄色星星标注：(1) 核质病毒门成员的首批基因组被测序：Vaccinia virus (1a) 和 Paramecium bursaria chlorella virus 1 (1b)。(2) 测序了第一个基因组大小超过1 Mb的巨型病毒：Acanthamoeba polyphaga mimivirus。(3) 首次从南极洲有机湖恢复出GVMAGs。(4) 基于从环境序列数据中恢复的GVMAGs提出了病毒亚科Klosneuvirinae。(5) 利用单细胞基因组学从海洋领鞭毛虫中发现了Choanovirus。(6) 首次大规模全球宏基因组研究，恢复了超过2000个GVMAGs，实现了系统发育多样性增加11倍和功能多样性扩展10倍。(7) 在宿主染色体中检测到完整的巨型病毒基因组整合。\n继 2003 年发现拟菌病毒之后，其他具有较大病毒粒子和基因组超过 500 kb 的 NCLDV 也被发现可以感染异养原生生物（主要是变形虫动物门的成员）。十多年来，棘阿米巴菌株主要用作共培养新病毒的宿主，导致经常分离出能够感染这种单细胞宿主的密切相关的巨型病毒。 棘阿米巴属已被证明是许多 Megamimivirinae 和 Marseilleviridae 特别合适的宿主。因此，来自这些分类群的病毒是目前最常培养的 NCLDV 之一，公共数据库中有 30 多个基因组序列，包括新的 Megamimivirinae 谱系 tupanvirus 和 cotonvirus。共培养方法取得了广泛的成功，并且还从不同的 NCLDV 分支中恢复了分离株，促进了 Pithoviruses、Pandoraviruses、molliviruses 和 medusaviruses 的组织和命名。 最近，使用替代宿主，如 Vermamoeba spp.，得到了几种新的 faustovirus 分离株、orpheovirus、pacmanvirus 和 kaumoebavirus 的共同培养——它们都是 Pithovirus、marseillevirus 和 Asfarvirus 的远亲。 新开发的基于高通量共培养的方法使用高内涵筛选显微镜，已被证明是发现和分离巨型病毒的宝贵工具。然而，共培养受到巨型病毒宿主特异性的限制；一些 NCLDV 谱系只能感染特定宿主，例如某些棘阿米巴物种，而其他谱系可能更加通用，表现出更广泛的宿主范围 。考虑到真核生物，特别是微真核生物的巨大多样性，通过分离回收的巨型病毒很可能只反映了野外现存 NCLDV 谱系的一小部分。\n病毒体结构和感染策略 具有核质感染周期的病毒 Chloroviruses是第一个被称为“巨型病毒”的病毒，因为它们具有直径为 190 nm 的大二十面体病毒粒子（T 号 169）（图 2）和高达 370 kb 的基因组。 特别是，PBCV1被广泛研究；它的衣壳有一些从一些衣壳延伸出来的外部纤维，并且在一个顶点存在一个尖峰状结构，以锚定在宿主细胞上（图2）。衣壳被病毒编码的糖基化机器合成的不寻常的寡糖糖基化；该寡糖与主要衣壳蛋白 (MCP；Vp54) 中的非典型序列片段中的天冬酰胺进行 N 连接。 外衣壳层覆盖单个脂质膜，这对于感染性至关重要。Chloroviruses通过使用包装在病毒粒子中的病毒编码酶在细胞壁上创建一个洞，将其基因组传递到藻类宿主中。然后病毒内膜与宿主质膜融合，形成基因组和一些病毒蛋白进入细胞的通道。由于病毒不编码 RNA 聚合酶，因此传入的基因组必须在病毒粒子在细胞质中组装之前在宿主细胞核内转录。病毒粒子在宿主细胞裂解后释放。\n图2：巨型病毒感染机制和病毒体结构。 A | 巨型病毒通过附着于宿主细胞膜进入宿主细胞，随后通过内吞作用（a）或衣壳开启后的膜融合（b）实现入侵。随后，巨型病毒的转录过程在细胞质或病毒工厂中启动（c；紫色箭头），或在宿主细胞核中启动（d；绿色箭头）。在细胞质病毒工厂的外围，基因组复制和新病毒颗粒的组装随之发生（e），或者新合成的病毒颗粒分散在一个大的细胞质病毒工厂中（f）。最后，病毒颗粒通过宿主细胞裂解（g）、含病毒颗粒的液泡与宿主细胞膜融合（h）或膜包裹的病毒颗粒通过胞吐作用（i）被释放。小彩色圆点表示病毒基因组和病毒蛋白。B| 部分巨型病毒的感染策略。C| 镶嵌在树脂中的非二十面体病毒超薄切片的透射电子显微图。D| 使用冷冻电子显微镜解析的分离巨型病毒结构。注意mimivirus的蓝色星门结构。C和D部分的比例尺为100nm。\n缩写：AaV（Aureococcus anophagefferens病毒），CroV（Cafeteria roenbergensis病毒），OtV（Ostreococcus tauri病毒），PBCV1（Paramecium bursaria chlorella病毒1）。\n其他感染藻类的核质病毒由小病毒颗粒组成。核质病毒门中最小的成员是病毒颗粒直径约为 120 nm 且基因组长达 410 kb 的病毒。体积小对于金牛骨球菌Ostreococcus tauri的感染和复制至关重要，金牛骨球菌是最小的自由生活真核生物之一，细胞大小仅为 0.8μm。病毒感染后，基因组被释放到细胞核中，并且几乎立即开始复制。数小时内，新病毒粒子在细胞质中组装，不到 24 小时，宿主裂解发生。在此期间，宿主细胞核、线粒体和叶绿体保持完整。\n具有核质感染周期的较大病毒是变形虫感染的潘多拉病毒pandoraviruses，其双耳瓶形状的病毒体长度可达 1 µm，直径达 500 nm（图 2），基因组可达 2.5 Mb。厚皮层内至少有一层脂质膜，该皮层由三层组成，其中一层由纤维素制成。颗粒通过吞噬作用被吸收，顶端的小孔状结构打开，使内膜与吞噬体膜融合；这导致基因组和必需的蛋白质被递送到宿主细胞质中。尽管潘多拉病毒编码RNA聚合酶，但该酶并未包装在衣壳中，因此，感染病毒依赖宿主细胞进行病毒基因的早期转录。在细胞核内建立的病毒工厂（图 2），新的病毒粒子开始从顶端组装，脂质囊泡被招募到病毒工厂用于病毒粒子组装。新生病毒粒子通过细胞裂解释放，或者如果病毒位于液泡内，则通过与质膜的膜融合的胞吐作用释放。\nMolliviruses 具有较小尺寸（约 650 nm）的卵形病毒粒子和 650 kb 的基因组（图 2）；它们与潘多拉病毒有 16% 的基因相同，但三分之二的基因是 ORFans。衣壳似乎被不同长度的原纤维所包围，并且它们呈现出类似于潘多拉病毒的膜内衬外皮。 它们的感染周期也与潘多拉病毒相似，不同之处在于 DNA 似乎被预先包装在细丝中，这些细丝在被加载到成熟的病毒粒子中之前在病毒工厂中积累。通过低温电子显微镜 (cryo-EM)广泛分析了病毒颗粒组装中涉及的膜重塑。\n美杜莎病毒Medusaviruses也是棘阿米巴感染病毒。它们的二十面体病毒粒子直径为 260 nm，被从每个衣壳延伸出的球形头尖刺覆盖，并具有包围衣壳内部的脂质膜。通过冷冻电镜确定了低分辨率结构，其返回的 T 值为 277。美杜莎病毒病毒粒子从宿主中进入和离开的机制尚未确定。摄入宿主细胞质后，其 DNA 在宿主细胞核中复制，病毒粒子在细胞质中组装（图 2）。\n仅具有胞质感染周期的病毒 继 PBCV1 之后，研究最多的第二个病毒是感染阿米巴原虫的拟菌病毒mimivirus。约 700 nm 的病毒体由直径约 500 nm 的二十面体衣壳组成，基因组为 1.2 Mb。细菌型糖由病毒编码的糖基化机制合成，是装饰衣壳周围拟病毒原纤维的复杂 70 kDa 和 25 kDa 多糖结构的组成部分。拟菌病毒衣壳的低分辨率结构已被确定（图2），详细的原子力显微镜提供了对病毒粒子组成的更多见解，进一步强调了衣壳的复杂性。有两层内部脂质膜，一层位于衣壳内，另一层位于核仁区室中，其中包含基因组和数百种蛋白质，包括 RNA 聚合酶和转录成熟机器。有人提出，类核中的非结构蛋白是启动病毒感染周期、保护病毒体免受氧化应激和进行早期转录所必需的。初步数据表明，基因组组织在直径为 30 nm 的螺旋核衣壳中，其中包含 GMC 氧化还原酶，该酶也构成衣壳的糖基化原纤维。折叠的基因组排列在核衣壳的外壳上，留下一个可以容纳大蛋白质（包括 RNA 聚合酶）的中央通道。拟菌病毒通过其糖基化原纤维粘附在宿主细胞膜上后触发吞噬作用进入宿主。一旦进入液泡，二十面体一个顶点的特定结构（星门）就会打开，衣壳下的膜被拉出并与液泡膜融合，从而允许类核转移到宿主细胞质中。与拟菌病毒科的其他已知成员类似，拟菌病毒在其宿主的细胞质中复制（图2）。早期转录开始使用病毒编码的转录机制，该机制最初仍局限于类核中。由于活跃的转录和复制而积累的核酸导致病毒工厂的大小增加，新合成的病毒颗粒开始在其外围出芽，回收来自内质网或高尔基体的宿主细胞膜。在将基因组加载到类核中之后，病毒颗粒成熟的最后一步是将原纤维层添加到衣壳中，细胞裂解后释放出数百个新合成的病毒颗粒。\n与拟菌病毒相关的几种病毒具有相似的感染周期，但病毒体较小。其中包括 Cafeteria roenbergensis 病毒，它具有直径 300 nm 的二十面体衣壳（图 2），衣壳下面有一层脂质膜。其感染模式尚不完全清楚，但与拟菌病毒类似，已观察到细胞质中的核仁结构和细胞外空衣壳，支持衣壳的外部开口，然后内膜与细胞膜融合，从而允许将类核转移到宿主细胞质中。病毒粒子含有约 150 种蛋白质，它们要么构成二十面体衣壳，要么是启动感染周期所必需的。新生病毒体在感染后期聚集并通过细胞裂解释放。通过冷冻电镜测定的复杂衣壳结构对应于 T 数 499，并为衣壳组装提供了新模型。\n拟菌病毒科的另一个成员是博多萨尔坦病毒Bodo saltans virus，它具有类似的二十面体衣壳，直径为 300 纳米。它的衣壳似乎由两层蛋白质层组成，周围环绕着 40 纳米长的原纤维。衣壳的一个顶点存在可能的星门状结构，并且有两层膜，一层位于外部蛋白质壳内，另一层位于包含基因组的核样区室内部。感染周期与拟菌病毒相似，只是宿主的核基因组似乎被降解了。病毒工厂在细胞后极发育，填充了三分之二的细胞空间，将细胞核和细胞器推到一边。脂质囊泡被招募用于病毒粒子组装，该组装发生在病毒工厂的一侧，成熟的病毒粒子在基因组加载后分离并迁移到细胞的后极。细胞裂解后，病毒粒子通过在宿主膜上的囊泡中出芽而释放（图2）。\n感染藻类的一些最大的病毒属于拟病毒科，所有这些病毒都具有二十面体衣壳，尺寸范围从无噬金球菌病毒的 150 nm（图 2）到最近描述的 Prymnesium kappa 病毒的 370 nm。 这些病毒还在宿主细胞质中构建病毒工厂，但尚不清楚转录机制是否被加载到衣壳中，从而实现完全细胞质的感染循环。\n在核质病毒门中发现的最大的病毒体是 Pithovirus 和 cedratvirus 的病毒体（图 2），它们具有非常大的双耳瓶形衣壳，长度可达 2 µm，宽度可达 600 nm，包裹基因组高达 685kb（表1）。衣壳由软木塞结构（Corks）封闭——Pithovirus有一个（图 2）， cedratvirus两个——这些软木塞结构是由组织成蜂窝状阵列的蛋白质制成的。尽管病毒体形态与潘多拉病毒非常相似，但外皮不同，似乎由平行条带组成，没有纤维素；衣壳似乎覆盖有短而稀疏的原纤维。与其他变形虫感染病毒一样，感染周期通过吞噬作用进行，然后衣壳打开并与吞噬体进行膜融合。对于pithovirus和cedratvirus，病毒粒子中装载的RNA聚合酶在细胞质中开始早期转录，并且宿主细胞核在整个感染周期中保持完整。在成熟过程中，外皮和木塞的储存库在宿主细胞质中积累，并用于构建新的双耳瓶形状的病毒体。然后，新生病毒体通过胞吐作用或细胞裂解离开宿主细胞。\n除了拟菌病毒科之外，还有一些较小的阿米巴感染病毒，例如马赛病毒科的成员，其具有直径约 250 纳米的二十面体病毒体（图 2）。最近研究以不同的分辨率显示了该家族两个成员的衣壳结构，揭示了 T 数 309 和复杂的衣壳结构以及许多次要衣壳蛋白。 墨尔本病毒Melbournevirus和马赛病毒科Marseilleviridae的其他成员被吞噬作用吞噬，然后在液泡膜消失后失去二十面体外观，变成球形。 与 Megamimivirinae 类似，它们的基因组保留在细胞质中；然而，RNA 聚合酶并未加载到病毒粒子中。相反，核蛋白被招募到早期病毒工厂，包括执行早期转录的宿主 RNA 聚合酶。细胞核的外观在感染早期发生变化，并通过病毒感染引发的仍未知的机制而发生渗漏。感染 1 小时后，细胞核完整性恢复，病毒编码的 RNA 聚合酶执行中间和晚期转录，二十面体颗粒在病毒工厂内组装（图 2A）。 马赛病毒科病毒编码组蛋白双联体，形成核小体，将基因组包装成病毒体。成熟的衣壳可以聚集在大囊泡中，细胞裂解导致单个病毒体和充满液泡的释放。 正如这些例子所表明的那样，巨型病毒的结构及其感染机制并没有共同的蓝图；这些特征在巨型病毒谱系之间有所不同，并且可能是由宿主生物体决定的。实验表征的巨型病毒的宿主范围仅限于少数变形虫和藻类谱系，仅代表真核生物多样性的一小部分。因此，预计当新病毒与其天然宿主一起被捕获时，将会揭示更多不寻常的病毒颗粒和感染策略。\n不依赖培养的基因组学 序列推断的巨型病毒的流行率和多样性 通过巨病毒的分离和培养，在巨病毒生物学和多样性方面取得了许多重要发现。然而，此类方法受到满足实验室环境中最佳生长要求的限制，并且通常仅限于裂解病毒。事实证明，不依赖培养的方法是从环境样本中发现巨型病毒基因组成的不可或缺的工具。\n在宏基因组学的早期，基于单标记基因的调查显示，藻类DNA病毒科和拟病毒科的几种病毒存在于塔拉海洋和马尾藻海探险期间收集的各种海洋宏基因组中，并且这些病毒的光层比真核生物更丰富。在后续研究中，这些调查的数据提出了这样的假设：海洋中的巨型病毒比任何细胞生物体都更加多样化。随后，对 NCLDV 主要衣壳蛋白 (MCP) 的大规模分析（其中在地球生物群落中发现了 50,000 多种此类蛋白质）揭示了巨型病毒的全球传播，包括在陆地生态系统中。\n能够发现新型 NCLDV 的其他方法包括单病毒或单细胞基因组学和微型宏基因组学。首先，从海洋样本中分选病毒颗粒，能够检测到先前发现与藻类 Ostreococcus spp 有关的病毒。和球形棕囊藻。这种方法对几个所谓的巨型病毒单扩增基因组进行了测序，其中最大的是属于拟病毒科的 813 kb 基因组，编码元半胱天冬酶，该酶可能使宿主细胞自催化细胞死亡。单细胞方法，包括单个真核细胞的分选和基因组扩增，也被用来鉴定与海洋领鞭毛虫相关的五种巨型病毒并进行基因组测序；与所有其他 NCLDV 基因组的比较基因组学表明，以相似的营养模式（包括宿主栖息地和生活方式）感染宿主的病毒表现出不同的遗传特征。此外，对单个森林土壤样本的小型宏基因组学分析（方框 1）导致富集和发现了 15 种不同的巨型病毒宏基因组组装基因组 (MAG)，其中包括 Klosneuvirinae 的几个成员，这突显了巨型病毒在土壤尚未开发的多样性。\n从环境序列数据中获取 NCLDV 基因组的最成功方法是基因组解析宏基因组学。自 2000 年代初以来，这种方法已成为从复杂环境样本中恢复细菌和古细菌基因组的常见做法，但又过了近十年，第一个巨型病毒 MAG (GVMAG) 才出现在公共数据库中（图 1）。尤等人重建了第一个 GVMAG，作为他们对南极洲有机湖宏基因组中的病毒噬菌体进行研究的副产品。 几年后，从美国黄石国家公园黄石湖的环境序列数据中检索到了另外四个可能与藻类相关的 GVMAG；人们发现它们与藻DNA病毒科和拟病毒科病毒科有关，并与同一样本中共存的噬病毒体共享一些基因。 当从宏基因组数据中恢复出拟南芥病毒科亚科（即 Klosneuvirinae）的成员时，用于发现巨型病毒基因组中心序列信息的独立于培养的方法获得了关注。事实上，这些病毒是在来自四个不同大陆的淡水和污水样本的宏基因组中发现的，这一事实表明，这一新的巨型病毒群是世界性的。 随后在深海中发现了 20 多个 GVMAG，其中 15 个属于 Pithoviridae，这表明类 Pithovirus 病毒在海洋中的流行率惊人地高，随后在收集的样本中发现了其他可能与藻类相关来自中国上海滴水湖的淡水巨型病毒。当从不同生物群落收集的数千个样本分析生成的宏基因组数据集中提取了 2,000 多个 GVMAG 时，独立于培养的病毒基因组学和发现方法的独特优势变得最为明显。 此后不久，又重建了主要来自海洋系统的另外 500 个 GVMAG。将 GVMAG 添加到 Nucleocytoviricota 物种树中导致系统发育多样性增加十倍以上，并实现了 Nucleocytoviricota 分类框架的全面更新，其中 Mesomimiviridae 占观察到的三分之一以上多样性（图 3）。新谱系的添加还导致核病毒泛基因组的大小大幅增加，该基因组现在包含超过 900,000 个蛋白质。这转化为广泛扩展的功能基因库，不仅为巨型病毒如何与其宿主和环境相互作用提供了许多新的见解，而且还产生了关于其进化作用的令人信服的新假设。\n图 3：通过宏基因组学扩展 Nucleocytoviricota 系统发育多样性。 显示了核质病毒的两个物种树：内部树说明了基于病毒分离株基因组的核质病毒多样性，外部倒转树突出了通过源自培养独立测序方法的基因组扩展物种多样性（黑色分支）。病毒分离株的分支根据分类群的隶属关系进行着色，并推断出外树的扩展多样性。彩色条带显示目级分类，彩色圆圈表示所选巨型病毒的系统发育位置，这些将在文本中进一步讨论。树根为痘病毒科。物种树改编自核质病毒谱系的分类框架。 AaV, Aureococcus anophagefferens virus; CroV, Cafeteria roenbergensis virus; PBCV1, Paramecium bursaria chlorella virus 1。\n探索巨型病毒的宿主 基因组解析的宏基因组学能够发现数千个病毒基因组，其中许多代表与通过分离或共培养恢复的病毒不同的谱系（图3）。然而，从宏基因组中回收的巨型病毒通常缺乏宿主生物体的信息。克服这一限制的方法是检测同一样本中同时存在的病毒和潜在的真核宿主。此外，病毒及其宿主之间遗传物质的水平转移是一种常见现象，并且可以双向进行，并且对可能通过最近的水平基因转移（HGT）获得的病毒基因进行分析可能会识别宿主生物体。在巨型病毒宏基因组学的早期，基于读段图谱的共现分析显示，一些海洋样本中病毒序列的存在与真核卵菌的序列呈正相关，但尚未发现NCLDV与真核卵菌的序列存在相关性。 在另一项研究中，宏转录组数据的共表达分析揭示了无噬金球菌病毒Aureococcus anophagefferens virus与其藻类宿主之间的紧密联系，并且还表明同一样本中存在的其他拟病毒科可能与金球菌属相关。这种方法还将藻藻DNA病毒科和拟病毒科成员与多种海洋微真核生物联系起来，包括领鞭毛虫、原生藻菌、硅藻、甲藻和尾虫。\n在另一项研究中，通过病毒和真核 PolB 编码基因以及真核 18S rRNA 基因高变 V9 区域的共现分析暗示了病毒与宿主的关系。然后将该方法应用于塔拉海洋探险期间收集的一套全面的海洋宏基因组，揭示了属于 Alveolata、Opisthokonta、Rhizaria 和 Stramenopiles 的特定微真核生物与不同的 NCLDV 谱系共存。在一项类似的研究中，在拟病毒科病毒和作为其潜在宿主的海洋金藻植物之间检测到强烈的共现信号。随后对 GVMAG 与金藻基因组和转录组之间假定的 HGT 事件的检测为这种宿主-病毒关系提供了进一步的支持。对 2,000 多个 NCLDV 基因组中存在的 HGT 候选基因（其中大部分是来自全球不同采样点的 MAG）进行的系统分析揭示了数千个可能通过最近的 HGT 引入宿主染色体或源自宿主的基因。基于这些结果，有可能提出 NCLDV 与所有主要真核生物门成员之间的联系。尽管大多数这些预测的宿主尚未被发现被巨型病毒感染，但通过最近的 HGT 事件成功预测了 20 多个先前分离的病毒与宿主关系，强调了这种基于序列推断的宏基因组组装病毒方法的有效性基因组（图 4）。\n图 4：经过实验验证和计算预测的核细胞病毒宿主范围。 显示了通过与天然宿主分离、共培养、单细胞分选和基于计算机水平基因转移的预测而鉴定的宿主谱系。彩色框的黑色轮廓表明经过实验验证的相互作用也已通过计算预测。叶绿体包括链藻门（该组包括一些绿藻）和绿藻门（该组包括大多数绿藻）。 CroV 亚科，拟病毒科中的病毒亚科水平进化枝，包含 Cafeteria roenbergensis 病毒； HaV 科，藻类病毒目中的科级进化枝，含有赤潮异形病毒； TSAR，Telonemia-Stramenopiles-Alveolata-Rhizaria 超群。\n尽管基于序列的计算宿主预测提供了一种扩大假定 NCLDV 宿主范围的方法，但这些方法存在一些潜在的挑战和偏差。例如，共现分析依赖于足够的宿主基因组覆盖率来检测宏基因组数据，而 HGT 分析需要宿主基因组序列的可用性。此外，很难从以前的宿主中检测出古老的 HGT。 NCLDV 基因整合到宿主基因组中的分析的另一个限制是所用数据库的质量。例如，GVMAG 在公共数据库中被发现被错误注释为细菌、古细菌或真核生物，这阻碍了使用自动化工具进行正确的 HGT 检测。尽管存在一些局限性，扩大宏基因组衍生的 NCLDV 的假定宿主范围为假定宿主的靶向采样、病毒与宿主共同进化的研究以及确定病毒编码功能以靶向调节宿主代谢提供了基础。然后可以推断病毒及其宿主的基于序列的推论，以评估这种相互作用对全球生态系统的影响。\n从 HGT 到内生化 病毒与其宿主之间的 HGT 是一种常见现象，一些巨型病毒甚至可以将其整个基因组整合到宿主染色体中（图 4）。这种所谓的内生化是大多数真核病毒观察到的一种机制。 NCLDV 基因阵列偶尔会在真核生物基因组中发现，特别是在藻类、植物和变形虫中。 最近对已发表的真核生物基因组和转录组的一项调查显示，66 种不同的真核生物中存在巨型病毒基因，包括几种棘阿米巴物种、鞭毛虫、纤毛虫、原生藻菌、卵菌、真菌、节肢动物和各种单细胞和多细胞藻类（图 4）。 然而，对于许多真核生物来说，尚未观察到巨型病毒感染。\nNCLDV 基因的整合通常表现为高度宿主特异性，在一种真核物种中检测到的病毒基因与在密切相关物种中发现的病毒基因无关。在整合的基因中，有 NCLDV 标志基因，这些基因在某些情况下分散在整个宿主染色体上，而在其他情况下，共同定位在由 100 多个基因组成的岛屿中。拟病毒科的一些成员的完整病毒基因组的整合已被描述；例如，20 多年前，Ectocarpus siliculosus 病毒很可能通过使用整合酶整合到其褐藻宿主中。 相关的球形棕囊藻病毒是一种溶原性病毒，可引起持续感染，这与许多其他已知的NCLDV谱系形成鲜明对比，这些谱系是基于裂解阿米巴宿主而成功分离的。对现有藻类基因组和转录组数据的分析揭示了整个巨型病毒基因组整合到真核宿主染色体中的其他例子。一些区域编码超过 1,500 个病毒基因，占绿藻宿主基因的 10%。一些检测到的病毒基因被注释为在碳水化合物代谢、染色质重塑、信号转导、能量产生和翻译中发挥作用的酶。\n目前尚不清楚整合的巨型病毒是否处于休眠状态，对宿主没有任何好处或只有很少的好处，或者宿主细胞是否受益于某些可能提供或微调代谢能力的病毒基因。另一个悬而未决的问题是，整合病毒基因组中是否存在编码机制，可以在转录和翻译一些整合病毒基因后重新激活感染。随后，在宿主复制过程中释放巨型病毒遗传物质并有效传播到新宿主。如果病毒感染没有重新激活，巨型病毒基因会随着时间的推移而衰减，导致重排和假基因化，并使它们的检测变得更具挑战性或不可能。巨型病毒内生化主要是通过分析真核分离基因组发现的，但研究者预计真核生物基因组解析的宏基因组学将进一步促进发现这种现象的许多其他例子。未来对巨型病毒基因整合的研究有望为内生化如何塑造并继续塑造真核生物的进化和生态学提供一些答案。\n宿主的重编程及其对宿主群体的影响 感染后，病毒会对其宿主细胞进行重新编程，并将其转变为支持病毒复制的所谓病毒细胞。与感染细菌的病毒（包括大型病毒）噬菌体类似，巨型病毒似乎向宿主贡献基因，以增强和/或调节宿主细胞的代谢能力（图5）。\n第一个描述的例子是病毒编码的乙酰透明质酸合酶，由小球藻病毒编码，使其藻类宿主能够合成乙酰透明质酸。此外，还发现小球藻病毒编码的活性钾通道在感染过程中整合到宿主膜中。另一个例子是金牛座球菌病毒中源自宿主的氮转运蛋白，它在绿藻宿主感染期间表达。实验表征提供的证据表明，这种转运蛋白可能会增加宿主细胞对氮的吸收。其他研究揭示了 Tetraselmis 病毒基因组中发酵基因的存在，可能对营养有限的海洋系统中宿主的代谢产生影响。对巨型病毒分离株和 MAG 的调查揭示了细胞色素 P450 单加氧酶基因的广泛存在，可能促进或调节复杂的代谢过程，例如甾醇和其他脂肪酸的合成。对霍科病毒独特的细胞色素 P450 进行的宏基因组实验表征并未揭示重组病毒细胞色素 P450 代谢的任何甾醇。\n最近研究在 NCLDV 基因组中发现了真核肌动蛋白（“viractins”）和肌球蛋白（“virmyosins”）的远距离同源物，表明这些病毒影响细胞结构、运动性和细胞内运输过程；然而，还需要进一步的功能验证。此外，一种与 Mesomimiviridae 相关的巨型病毒感染异养领鞭毛虫，被发现编码 1 型视紫质以及合成所需色素 β-胡萝卜素的途径。 NCLDV 视紫红质的宏基因组实验表征表明，假定的视紫红质可能起到质子泵的作用，从光中产生能量。在南极洲有机湖的 GVMAG 中发现了一种系统发育独特的 NCLDV 视紫红质，该蛋白质的实验表征表明，它可能充当光门控五聚离子通道，可能影响宿主细胞的离子稳态和趋光性。\n此外，通过全局宏基因组学，预测编码各种底物运输过程、通过光产生能量（视紫红质和参与光合作用的基因）、碳固定和糖酵解的基因常见于隶属于核质病毒不同谱系的GVMAG（图5)。更详细的系统发育分析表明，一些编码铁、磷酸盐、镁和铵转运蛋白的辅助代谢基因起源于真核宿主，并且可能最近通过 HGT被巨型病毒获得。然而，编码几种视紫红质、琥珀酸氢化酶、乌头酸酶和甘油醛3-磷酸脱氢酶的其他基因显示出一种模式，表明祖先宿主之一具有病毒起源或共同进化起源。总而言之，代谢基因在不同的 NCLDV 谱系中广泛存在，这意味着增强宿主代谢能力可能是 NCLDV 比最初假设更常用的策略。然而，目前缺乏大多数这些基因和途径的功能和活性及其对宿主细胞的影响的实验证据，需要进一步的实验研究。\n代谢重编程对宿主种群结构和动态有直接影响。一个引人注目的例子是世界性的海洋石藻，它形成大量的水华，在全球碳和硫循环中发挥着关键作用。Emiliania huxleyi种群受到球石病毒Emiliania huxleyi viru的持续性但最终裂解性感染。一旦诱导溶解，就会导致藻华终止，大量方解石和营养物质沉积到海洋中，从而增加海洋溶解有机物池。重要的是，病毒感染不仅会导致宿主裂解，还会通过重新连接宿主生理机能，特别是糖的周转以及脂肪酸和脂质的合成来促进病毒复制。人们对宿主群体如何受到通过基因组解析宏基因组学恢复的巨型病毒的影响知之甚少，但考虑到这些病毒的预测宿主，可以想象，类似的原理无处不在，并且正在积极塑造生物群落和生物地球化学循环。\n图 5：巨病毒衍生病毒细胞的预测代谢重编程以及巨病毒感染对宿主群体的后果。 一个假设的病毒细胞模型展示了不同巨型病毒在感染宿主过程中可能具备的代谢功能，这些功能基于巨型病毒基因组中辅助代谢基因的存在。更深的红色阴影表示某些功能已通过实验数据得到支持，例如：由Paramecium bursaria chlorella virus 1（PBCV1）编码的钾通道、由Ostreococcus tauri病毒编码的铵转运蛋白、由Choanovirus编码的光驱动质子泵以及从南极Organic Lake Phycodnavirus（OLPV）的宏基因组组装基因组中发现的光门控离子通道。此外，还特别指出Tetraselmis病毒编码的发酵基因。TCA表示三羧酸循环。 a. 尚未在天然病毒宿主系统中进行实验验证。 b. 目前没有这些基因功能的实验证据。\n巨型病毒基因组编码细胞生命的标志基因 在巨型病毒基因组中发现的最有趣的特征之一是细胞生命的标志基因，例如 tRNA 和参与蛋白质生物合成的基因。这种现象首先是在对拟菌病毒基因组进行测序时描述的。随后的分析揭示了病毒编码的细胞基因在细菌和真核生物之间的系统发育位置，表明其起源很古老。在其他巨型病毒基因组中发现了具有类似深分支模式的其他细胞标志基因，并导致了这样的假设：巨型病毒可能代表生命的第四个域，或者是由还原进化衍生的高度退化的真核细胞的残余物。随后使用更复杂的系统发育模型表明，其中许多基因很可能是从不同的真核宿主获得的。其中一些基因可能代表来自未被发现的真核宿主的古代转移。这一发现为巨型病毒可能是由较小病毒进化而来的假设提供了证据。\n然而，其他研究报告了细胞生物体的一些管家基因和其他代谢基因的替代拓扑，包括视紫红质和细胞色素 P450。还有人提出，这些基因可能从祖先巨型病毒转移到过去的真核宿主，甚至原真核生物，这凸显了巨型病毒在真核细胞进化中潜在的不可或缺的作用。此外，一些可能作为真核核心代谢一部分的基因可能是在巨型病毒遗传物质整合到古代真核细胞基因组中时引入的，进一步塑造了真核进化。在新发现的巨型病毒基因组中，已多次记录到氨酰 tRNA 合成酶 (aaRS) 和真核翻译因子基因的存在。\n事实上，从宏基因组数据中已经报道了克洛斯新病毒中几乎完整的 20 个 aaRS 集。不久之后，分离出两种图潘病毒tupanviruses，其基因组含有全套 aaRS 和 tRNA7，随后描述了第一个克洛斯新病毒亚科分离株，其中一个也含有全套 aaRS145。特别是在克洛斯新病毒亚科中，具有谱系特异性进化历史的 aaRS 的存在为这些基因源自不同的真核宿主提供了额外的支持。目前，完整aaRS基因组的存在仅限于拟病毒科成员，并且有关巨型病毒aaRS在宿主相互作用中的作用的信息有限；然而，有些已经过实验研究并且确实具有功能。甚至有一些实验证据表明，这些基因在使巨型病毒减少对宿主机器的依赖方面具有潜在作用，例如，在响应病毒感染或其他不利条件而关闭宿主翻译期间。另一方面，通过提供额外的aaRS拷贝以支持宿主翻译来增强病毒翻译的可疑作用尚未得到证实。细胞生命的其他标志基因包括编码四种核心组蛋白的基因以及预计参与能量产生的巨型病毒基因。最近的一项研究报道了马西潘多拉病毒病毒粒子的活跃膜电位以及三羧酸循环基因的几个远程同源物的表达。尽管编码功能最近被认为只存在于细胞生物体中，但目前没有证据表明巨型病毒在没有宿主来源的核糖体或不依赖于宿主的能量产生的情况下进行蛋白质翻译。\nConclusions 近 20 年的巨型病毒分离已经产生了代表高度多样化谱系的病毒分离株。对这些病毒生物学的补充详细研究揭示了病毒体结构和感染策略的许多重要细节。很明显，病毒粒子的大小和结构存在明显差异，尽管这些病毒进入和退出宿主细胞的方式有一些相似之处，但大多数巨型病毒采用不同的策略在宿主细胞内复制和利用宿主细胞。病毒分离株的测序发现了已知最大和最小的核质病毒基因组。\n独立于培养的方法加速了核质病毒门中新巨型病毒和其他大型病毒基因组序列的发现，为它们的系统发育多样性和功能潜力提供了新的见解。宏基因组学还表明，这些病毒几乎可以在地球上的任何地方找到，与不同的真核生物有关，并且可能通过代谢重编程改变宿主的生理机能，最终改变环境中宿主群落的结构和功能。与此同时，基于宏基因组数据集中 NCLDV 标志基因的估计表明，迄今为止仅发现了巨型病毒基因组的一小部分，并且巨型病毒的多样性可能远远大于细菌，至少在海洋中。将巨型病毒掺入环境样本中的受控宏基因组分箱实验表明，给定样本中存在的许多巨型病毒的基因组片段可能仍低于检测限，这凸显了超深度宏基因组测序或有针对性的分离工作的必要性。此外，人们对检测与已知病毒相似的巨型病毒存在强烈偏见，因为用于从宏基因组中识别病毒的工具严重依赖于在测序的 NCLDV 基因组中观察到的特征，例如大量保守基因。然而，巨型病毒基因组表现出广泛的可塑性，使得同一进化枝内的病毒迅速分化，并且共享的基因很少。\n最近 NCLDV 多样性的一个令人震惊的例子是 yaravirus，它是与其本地阿米巴宿主分离的，但在公共宏基因组数据集中没有检测到密切相关的序列。由于其 90% 以上的基因与公共数据库中的基因缺乏相似性，并且缺乏大多数病毒标志基因，因此将其在 NCLDV 中的定位很困难，并且其在核质病毒中的定位目前仍在争论中。此外，最近的一份预印本描述了基于基因组解析的宏基因组发现了来自海洋系统的 Proculviricetes 和 Mirusviricetes，这可能是 Nucleocytoviricota 中两个类水平的新谱系，缺乏大多数典型的病毒标志基因。总而言之，通过培养和非培养方法观察到的核质病毒中病毒的过度基因新颖性，进一步强调了许多巨型病毒可能隐藏在人们的视线中。\n其他概念 巨型病毒之所以被称为“巨型”，是因为它们违反了“可过滤性”的特性，自 1892 年分离出烟草花叶病病毒以来，“可过滤性”一直被用来将病毒与其他微生物分开。当今已知的巨型病毒（尚待其他病毒）很可能被忽视，因为人们过早地认为所有病毒都足够小，可以通过标准的消毒过滤器。与这一信念相一致的是，第一个巨型病毒（称为拟菌病毒，拟菌病毒科的原型）的病毒性质在十多年来一直被误认为是寄生细菌之后，直到 2003 年才被人们认识。因此，根据病毒颗粒（病毒颗粒）的大小（最小尺寸\u0026gt;250 nm），病毒被归类为“巨型”病毒，这使得它们可以通过标准光学显微镜看到。尽管巨型病毒的颗粒大小和基因组大小之间没有严格的相关性，但大于 400kb 的基因组有时被用作定义巨型病毒的替代阈值。\n病毒工厂：病毒在受感染宿主细胞的细胞质中发育的瞬时细胞器，巨型病毒在其中进行复制和组装。\nT数：三角剖分 (triangulation，T) 数描述了二十面体每个面的结构单元数，并计算为两个相邻五重顶点之间距离的平方。\n软木塞结构：一些病毒体的独特结构；就 Pithovirus 而言，软木塞位于病毒颗粒的顶端，由排列成六角形蜂窝状阵列、间隔 15 nm 的条纹组成。\nReferences Schulz, F., Abergel, C. \u0026amp; Woyke, T. Giant virus biology and diversity in the era of genome-resolved metagenomics. Nat Rev Microbiol 20, 721–736 (2022). https://doi.org/10.1038/s41579-022-00754-5 Abergel, Chantal et al. Giant viruses. Current Biology, Volume 30, Issue 19, R1108 - R1110 https://www.americanscientist.org/article/giant-viruses Frederik Schulz et al. ,Giant viruses with an expanded complement of translation system components.Science356,82-85(2017).DOI:10.1126/science.aal4657 Menon T. Athira, Swapna P. Antony, The Tiny Giants: Overview of Giant Viruses, Ecological Genetics and Genomics, Volume 29, 2023, https://doi.org/10.1016/j.egg.2023.100210 ","date":"2024-12-02T00:00:00Z","image":"/p/giant-virus/images/gv2_hu_e147c119fb0fcca9.png","permalink":"/p/giant-virus/","title":"巨型病毒(Giant virus)生物学和多样性研究"},{"content":"Introduction 对于微生物研究，虽然平时我们用的都是正式的拉丁学名，但有时我们还是需要查阅一些相关生物的正式中文名称（有时候还需要大批量的转换），方便做中文的展示或者写中文论文使用。\n目前常用的方法有：\n直接谷歌查找，运气好的话可以找到知名物种的中文名称。 参考中文文献中的译名，如知网、百度学术等。 使用一些专业的菌种库检索，如CICC菌种平台。 查找专业书籍，如《细菌名称双解及分类词典》 个人觉得比较好用的一个网站是中国典型培养物保藏中心的原核微生物名称翻译及分类查询网站(http://cctcc.whu.edu.cn/portal/dictionary/index)：\n这个网站的描述是：\n依据2011年化学工业出版社正式出版的《细菌名称双解及分类词典》以及由原主编组织翻译的2011-2020年间增加和修订的合格发表原核生物的学名。 在此网站不仅可以查询获得原核生物的中文名称，还包括了原核生物的分类地位、曾用名、变更信息、词源以及相关文献出处等信息。 原核生物的汉译名延用已有通用名称并充分尊重命名人的意愿根据发表的词源信息进行翻译。其中的地名参照《世界地名翻译大辞典》和《欧路词典》。 每年会更新一次，但是由于某些原核生物名称分类地位不断变化, 因此, 本网站中的信息仅供读者参考,欲了解准确信息,请及时査阅 “IJSB”或“IJSEM”杂志以及LPSN网站（https://lpsn.dsmz.de/）。 查询起来很方便：\n拉丁名翻译为中文 中文名翻译为拉丁名 批量快速转换 如果需要大量的转换，一个一个查起来就比较费劲了，所以我也整理了一下数据库中的中文名-拉丁名对应关系，写了一个函数帮助批量的转换，放在pctax包里了。同样的，所有翻译结果仅供参考！\n1 2 3 # 下载更新一下最新版 # install.packages(\u0026#34;devtools\u0026#34;) devtools::install_github(\u0026#34;Asa12138/pctax\u0026#34;) 1 2 library(pctax) convert_taxon_name(c(\u0026#34;Escherichia coli\u0026#34;, \u0026#34;Clostridioides difficile\u0026#34;, \u0026#34;Chryseobacterium ureilyticum\u0026#34;, \u0026#34;Mycolicibacterium hippocampi\u0026#34;)) 1 2 3 4 ## Escherichia coli Clostridioides difficile ## \u0026#34;大肠埃希氏菌\u0026#34; \u0026#34;艰难拟梭菌\u0026#34; ## Chryseobacterium ureilyticum Mycolicibacterium hippocampi ## \u0026#34;解脲金黄杆菌\u0026#34; \u0026#34;海马分枝菌酸小杆菌\u0026#34; 1 2 # 支持中文搜索，可以打开模糊匹配 convert_taxon_name(c(\u0026#34;白色盐湖杆菌\u0026#34;,\u0026#34;乳酸乳球菌\u0026#34;,\u0026#34;大肠弯曲杆菌\u0026#34;,\u0026#34;新月柄杆菌\u0026#34;),mode = \u0026#34;chinese_to_latin\u0026#34;,fuzzy = TRUE) 1 2 3 4 ## 白色盐湖杆菌 乳酸乳球菌 大肠弯曲杆菌 ## \u0026#34;Salilacibacter albus\u0026#34; \u0026#34;Lactococcus lactis\u0026#34; \u0026#34;Campylobacter coli\u0026#34; ## 新月柄杆菌 ## \u0026#34;Caulobacter crescentus\u0026#34; 微生物命名规则 顺便学习一下微生物相关的一些命名规则吧：\n微生物学命名遵循国际生物命名规则，主要包括国际细菌命名法规（ICNP）和国际植物命名法规（ICN, 真菌属于此范畴）。\n1. 基本命名原则 a. 双名法 微生物的学名一般由属名（genus）和种加词（specific epithet）组成。 属名首字母大写，种加词小写，均采用斜体书写。 示例: Escherichia coli（大肠杆菌）。 b. 学名的唯一性 每一个物种的名称应在全球范围内唯一，避免歧义。 新物种的命名需要经过严格审查并正式发表。 c. 拉丁化 名称通常采用拉丁文或拉丁化的词汇，表示分类、特性、发现地或纪念发现者。 示例: Streptococcus（链球菌），“strepto-”表示链状结构。 d. 语言通用性 学名以拉丁文为基础，不因语言或地区的变化而改变。 2. 微生物分类层级 微生物命名的层级结构从高到低依次为：\n域（Domain）: 如 Bacteria（细菌域）、Archaea（古菌域）。 界（Kingdom）: 较少用于微生物。 门（Phylum）: 后缀通常为 -ota。 示例: Acidobacteriota（酸杆菌门）。 纲（Class）: 后缀通常为 -ia。 示例: Gammaproteobacteria（γ-变形菌纲）。 目（Order）: 后缀通常为 -ales。 示例: Enterobacterales（肠杆菌目）。 科（Family）: 后缀通常为 -aceae。 示例: Enterobacteriaceae（肠杆菌科）。 属（Genus）: 通常由一个单词构成，首字母大写。 示例: Escherichia（埃希菌属）。 种（Species）: 由属名和种加词构成，具体描述物种。 示例: Escherichia coli（大肠杆菌）。 亚种（Subspecies）: 必须附加在种名之后，用于表示下一级分类。 3. 命名规则细节 a. 正式描述 新物种必须在公认的学术期刊（《国际系统细菌学杂志》(IJSB)或《国际系统与进化微生物学杂志》(IJSEM)）上正式发表，发表在IJSB或IJSEM以外刊物的新名称和(或)新组合须在IJSB或IJSEM上合格化(validation)。 描述中应包括物种的特征、分类依据及模式标本。 b. 模式菌株 每个新命名的物种必须提供一个模式菌株（Type strain），作为该物种的标准参考。 模式菌株应保存在两个独立的公共菌种保藏机构中。 c. 同义名与名称修订 如果发现物种的分类或命名有误，可以提出修订。 原有的名称会作为同义名（Synonym）记录。 4. 特殊情况 a. 暂定名称 一些未能充分描述的物种会以“Candidatus”表示，表示该分类是候选状态。 示例: Candidatus Liberibacter asiaticus。 b. 名称变更 随着分类学研究的进展，物种可能会被重新分类或更名，旧名会标注为“basionym”（基名）。 c. 不确定分类 在名称后加问号（?）表示分类不确定。 示例: Escherichia coli?。 d. 其他写法 属名重复出现，可缩写如：E.coli （大肠杆菌）； 只确定属名，未确定种名的某一株细菌，如Salmonella sp.； 只确定属名，未确定种名的若干菌株，如Salmonella spp.； 亚种用subsp. 或者ssp.（subspecies）表示Pasteurella multocida subsp. 5. 中文命名规范 中文名称通常根据拉丁学名的含义翻译而来。 属名: 通常为一个字或短语，如“大肠杆菌”（Escherichia coli）。 种加词: 描述特性或发现地的词汇，如“金黄色葡萄球菌”（Staphylococcus aureus），“aureus”是形容词，意思是“金黄色的”。 通过遵守命名规则，微生物的分类体系能保持全球统一，也有助于科研成果的准确交流与传播。\nReferences http://cctcc.whu.edu.cn/portal/dictionary/mic_notice 国际细菌命名法规（ICNP） LPSN: https://lpsn.dsmz.de NCBI Taxonomy: https://www.ncbi.nlm.nih.gov/taxonomy IJSEM: https://www.microbiologyresearch.org/content/journal/ijsem 微生物学命名的表示方法-《华侨大学学报（自然科学版）》 ","date":"2024-11-20T00:00:00Z","image":"/p/latin_name/images/R-C_hu_1d8b204f6c93e4d8.jpeg","permalink":"/p/latin_name/","title":"微生物学名-中文名称转换（可批量）"},{"content":"Introduction 整个太阳系的绝大多数区域，包括地球环境，都以极端温度为特征。值得注意的是，地球生物圈约 80% 的区域周期性或永久寒冷，温度低于 5°C。因此可以认为低温地区是地球上主要的“极端”环境。 这些环境已被称为嗜冷生物或冷适应生物的多种生物成功定殖，主要包括细菌、古菌、酵母菌、蓝藻和原生生物等微生物。嗜冷微生物通过一系列结构和功能适应，克服低温带来的生存限制，使其能够在这种特殊环境中繁衍生息。\n自1887年首次发现冷栖生物以来，研究者通过生理学、微生物学和分子生物学等方法研究了它们的适应性、生物地理分布及生态角色。近年来，基因组学、转录组学、蛋白质组学和宏基因组等“组学”技术进一步揭示了其独特的适应机制和关键功能，为冷生态系统的微生物群落结构和功能提供了更全面的视角。\n低温环境不仅带来热能降低的问题，还伴随着溶剂粘度增加、氧气及活性氧物质溶解度增加、渗透压增强、冰冻、干燥等多重物理化学限制，同时这些环境通常还具有营养缺乏、高盐、氧化应激等压力。例如，深海和冰下环境的微生物还要承受高压，而高海拔和极地环境则会面临光照极端变化。因此，嗜冷微生物需要多种协同适应策略来应对复杂的环境压力。\n嗜冷微生物的低温适应机制包括一系列生理和结构上的精妙适应，这些适应往往具有多功能性，可应对多种环境压力。每种微生物根据其特定需求和环境条件，采用不同的组合策略，而不是使用所有可能的适应工具（表1）。\n生物产物 提出的冷适应功能 膜脂肪酸：不饱和脂肪酸，长链多不饱和脂肪酸 (LC-PUFA) 不饱和脂肪酸：维持膜流动性；长链多不饱和脂肪酸 (LC-PUFA)：维持膜流动性？ 膜色素：类胡萝卜素 维持膜流动性？抗冻保护？ 兼容溶质 渗透保护：抵御冰冻引起的渗透应激；干燥保护：抵御冰冻引起的干燥；降低冰点；降低胶态玻璃转变温度；稳定蛋白质和膜 抗冻蛋白 冰晶生长抑制（热滞后效应）；冰再结晶抑制；膜稳定性？冰附着？ 促冰核蛋白 细胞外冰晶核化；防止/减少损害性细胞内冰形成；小冰晶形成？释放结晶潜热？ 细胞外聚合物 冰晶生长抑制；渗透保护：抵御冰冻引起的渗透应激；干燥保护：抵御冰冻引起的干燥；冰再结晶抑制 生物表面活性剂 冰再结晶抑制？渗透保护？ 冷适应酶 维持适当的代谢通量 分子伴侣蛋白 促进蛋白质折叠和稳定性；解构RNA/DNA二级结构 储存化合物：聚羟基烷酸酯，青藻素 克服碳和氮吸收缺陷 细胞被膜 细胞膜及其各种组件发挥着提供形状、支撑和保护以及调节物质进出细胞的运动的关键功能。它保护细胞免受周围环境的影响并抵抗膨胀压力；作为半透膜发挥营养吸收、产物输出和溶质运输的作用；并参与细胞分裂、传感、信号传导和粘附。低温会对细胞膜的特性和功能产生不利影响，导致膜流动性、渗透性和扩散率降低，此外还会降低嵌入蛋白质的流动性和功能，增加膨胀压力，甚至因冰形成和/或冻结而导致物理细胞破裂。虽然细胞膜的冷适应特征早已为人所知，但其他包膜成分、外膜、肽聚糖层甚至外部细胞涂层的适应策略现在也开始被了解。\n细胞膜 冷适应微生物通过“膜黏度调节”机制，通过改变脂肪酸组成来适应低温。具体来说，它们会增加膜中不饱和脂肪酸、短链、支链或顺式异构脂肪酸的含量，从而降低膜的相变温度，维持膜的流动性和功能。这一策略反映在许多嗜冷微生物基因组中，通常富含脂肪酸合成、去饱和酶及其他参与膜生物合成的基因，帮助细胞在低温下维持正常功能。此外，某些嗜冷微生物上调膜运输蛋白的表达，补偿低温引起的扩散和运输速度下降。\n关于长链多不饱和脂肪酸（LC-PUFAs），虽然它们有助于维持膜流动性，但其主要作用可能在于抗氧化保护。LC-PUFAs如EPA、DHA和ARA在冷水生物中含量较高，尤其在低温下生成更多，能够在膜表面形成疏水屏障，减少活性氧进入细胞。除了抗氧化，它们在膜蛋白的稳定、细胞分裂等方面也有潜在功能。\n膜色素 色素，特别是类胡萝卜素，在调节细胞膜流动性方面也可能具有作用。嗜冷微生物常产生色素，如从冰芯、冰川、海洋表层水和高海拔土壤中分离的样本中均观察到了色素生成。研究发现，一些极地类胡萝卜素在低温下生成量增加，可能通过平衡不饱和脂肪酸的流动性作用来稳定膜。然而，一些研究发现低温下某些极地细菌的色素含量反而减少，说明色素作用可能因环境而异。\n这些色素在低温适应中可能具有多种功能，包括光保护（与其他分子如苔藓氨基酸一起抵御强光和紫外线）、抗氧化（对抗低温环境中的活性氧）、光捕获（光合微生物）以及抗菌。同时，它们还可能作为冷冻保护剂，增强冻融循环的耐受性。由于这些多重功能，色素水平的变化在不同环境中可能有所不同，因此需要进一步研究其在冷适应微生物中的确切作用和机制。\n细胞壁 相较于细胞膜，细胞壁其他成分的冷适应研究相对较少，但最近的一些研究揭示了可能的适应策略。对于细胞壁的适应性变化，一些嗜冷细菌在低温下显示出肽聚糖生物合成基因的上调以及肽聚糖层的增厚。这种增强的肽聚糖层可以形成更强的物理屏障，有助于保护嗜冷菌在冰晶形成、冻融循环或渗透压升高时不受损伤。例如，Planococcus halocryophilus Or1在外细胞表面展现出厚化的外层，这种特有的结构由肽聚糖、碳酸钙和胆碱的疏水性外壳组成，提供了额外的保护。\n对于革兰氏阴性细菌的细胞壁外膜，冷适应特征主要表现为脂多糖（LPS）结构的变化。研究表明，许多嗜冷菌在低温下产生的LPS为粗糙型（即缺少特异性O链成分），且其链长较短。尽管仅有少数嗜冷菌的LPS结构已被分析，但这种LPS的变化可能有助于在低温下增加外膜的灵活性和稳定性。此外，与细胞膜相似，LPS中的脂质A成分表现出较高的短链和/或不饱和脂肪酸含量，增强了膜的流动性。而核心寡糖部分的高负电荷则有助于捕获冷环境中常见的二价阳离子。\n与其他细胞包膜成分的研究一致，转录组分析显示，在低温下，LPS生物合成相关基因（主要是糖基转移酶）和外膜蛋白的基因表达上调。例如，突变某些核心LPS糖基转移酶基因会降低南极细菌在低温下的生长能力，这进一步证明了LPS结构在低温适应中的关键作用。\n冷冻保护 零度以下的温度会导致结冰，从而导致冷冻损伤、渗透压、脱水甚至细胞破裂和死亡。在自然环境中，与细胞外部相比，细胞内部结冰的开始通常延迟，因为前者体积较小且密集且高度拥挤。当温度高速下降时，确实会发生细胞内冰晶的形成，这通常对细胞是致命的，但在自然环境中，冷却通常相对缓慢，因此冰的形成主要局限于细胞外空间（Fonseca et al. 2016） ）。细胞外冰的形成可导致物理破坏性膜破裂，其发生是在排除溶质并除去可用液态水的情况下发生的。这导致细胞外溶质浓度升高并引起细胞内/外渗透压失衡。反过来，这会导致与细胞内部渗透收缩和脱水相关的压力，不仅对细胞功能和存活产生负面影响，而且还会阻止细胞内冰的形成，并导致非晶态无定形（胶体玻璃态）状态，从而抑制细胞新陈代谢（Fonseca 等人，2016）。此外，在相对较高的零度以下温度下，在经历冻融循环的部分冷冻环境中以及在温度波动期间，细胞还可能受到有害的冰再结晶应力，这是一种热力学驱动的过程，导致冰晶聚结和大的、以较小的晶体为代价来致命地破坏冰晶（Bar Dolev 等人，2016b）。\n兼容溶质 兼容溶质是低分子量、无毒的有机渗透调节物质，许多嗜冷微生物的基因组中包含大量的兼容溶质合成、摄取和降解基因，常见的兼容溶质包括甜菜碱、海藻糖、甘油、蔗糖、肌氨酸、甘露醇和山梨醇等。这些溶质在低温环境中可积累至摩尔浓度，有助于恢复渗透平衡，从而抵消冻融过程中因水分流失和细胞收缩带来的影响。此外，兼容溶质可以降低溶液的冰点，并显著降低细胞质的胶体玻璃转变温度（Tg），例如，在细菌细胞中添加甘油可将细胞质的Tg降低达30°C，同时提高解冻后的存活率。\n除了渗透平衡的调节外，兼容溶质还可通过自由基清除作用，在低温下保护蛋白质和膜结构。它们能够避免蛋白质聚集，增强蛋白质折叠稳定性，可能是由于其对蛋白质表面的优先排斥作用或水分捕获效应，促进蛋白质的稳定和结构紧致。\n冰结合蛋白：抗冻蛋白 抗冻蛋白（AFPs），也称为冰结构蛋白或热滞后蛋白，是一种具有非胶体特性的生物抗冻剂，能够结合冰晶并抑制冰的生长和再结晶。这类蛋白最早在南极鱼类的血液中发现，现已在多种细菌、真菌、硅藻、植物、昆虫和甲壳类动物中被发现。自然界中存在多种结构多样的AFPs，通常带有糖基化或脂质修饰，分子量从约2至50 kDa不等。例如，南极细菌Marinomonas primoryensis中存在一种多结构域的冰黏附蛋白，分子量高达1.5 MDa。AFPs通过不可逆地结合特定的冰晶面，阻止次级成核事件，导致冰晶形成独特的形态。由于Kelvin效应，AFPs的吸附导致冰晶表面局部弯曲，从而阻碍冰的进一步生长，形成热滞后（TH）效应，即冻结点低于融解平衡点，生成的热滞后区域内冰晶生长被抑制。\nTH活动的温度范围从0.1°C到13°C不等，并且在加入其他AFPs、溶质和离子时可增强。AFPs还是有效的冰再结晶抑制剂（IRI），常以亚微摩尔浓度即能发挥比TH更强的效果。这种IRI作用通常是许多嗜冷微生物分泌AFPs的主要功能，例如南极藻类和冰川冰细菌中的AFPs能有效稳定盐水口袋，维持细胞周围的液态环境。此外，AFPs还可能通过其膜稳定和结构保护作用维持细胞膜的完整性，并可能帮助附着在冰面上，使细胞更好地接近光合区的氧气和营养物质。\n冰结合蛋白：冰成核蛋白 冰成核蛋白（INPs）是一类大分子膜结合蛋白，能促进冰的形成。它们通过在接近零度以下的高温环境中引发异质性冰结晶，被认为通过提供模板来使水分子按冰状结构有序排列，从而稳定水分子（Lorv et al. 2014; Pandey et al. 2016; Pummer et al. 2015）。这种作用降低了冰形成的活化能，使冰可以在-2°C左右开始结晶（Li et al. 1997）。INPs由多种生物产生，通常以大的胞外重复多聚体形式存在，且更大的复合体表现出更高的成核活性（Bar Dolev et al. 2016a）。\n在嗜冷微生物中，INPs被认为通过引导冰的成核至胞外空间来抵御低温损伤（Lorv et al. 2014），从而避免在细胞内形成具有潜在致命破坏力的冰晶。INPs还促进了胞外小冰晶的形成，相较于大冰晶对细胞的损害更小。此外，冰结晶过程中释放的潜热也有助于防止温度的进一步下降（Pummer et al. 2015）。除了在冷适应中的作用，INPs在一些植物病原体中也起到营养挖掘的作用，通过诱发植物的冻害破坏细胞，进而获取植物内部的养分。\n细胞外聚合物 胞外聚合物物质（EPS）是一类多功能的高分子生物聚合物复合物，由各种生物体分泌到其局部环境中。EPS具有复杂多样的结构，主要由碳水化合物（均一或非均一多糖）构成，但也包含蛋白质和较少量的核酸、脂类、酚类和腐殖质。EPS由多种生物产生，可以附着在细胞表面，也可以释放到周围环境中，形成水合凝胶。这些凝胶在生物膜的形成以及细胞环境的物理、化学和生物特性调节中起着重要作用。它们具有多种功能，包括细胞黏附、养分吸收，还在渗透保护、活性氧清除、胞外蛋白保护及抗冻保护等方面发挥重要作用。有关详细综述，请参考Deming和Young (2017)及Ewert和Deming (2013)等文献。\n在冷适应方面，宏基因组研究已在南极和北极冰架池中发现了大量EPS合成相关基因（Varin et al. 2012），且研究发现，冷适应细菌在低温甚至冰点以下会产生高浓度的EPS（Caruso et al. 2018; Feng et al. 2014; Marx et al. 2009; Mykytczuk et al. 2013）。EPS水合凝胶基质被认为通过在细胞周围形成保护性外壳以充当溶质扩散屏障，并物理阻止冰的形成，从而在低温下保护细胞（Caruso et al. 2018; Deming和Young 2017; Ewert和Deming 2013; Krembs et al. 2011）。这种扩散屏障限制了冰冻诱导的渗透压应激和干燥损伤。此外，EPS的凝胶状状态降低了冰成核的自由能，而溶质排斥至周围液相中则抑制了冰晶的生长，从而保护细胞免受冰损伤，并增加了可居住的液态空间。有趣的是，最近研究表明，冷适应生物产生的EPS具有类似抗冻蛋白（AFP）一样的冰结合功能和冰重结晶抑制（IRI）活性（Casillo et al. 2017a）。相比其他冷适应机制，EPS的研究尚不充分，其在应对低温中的重要作用才刚开始被揭示，未来的研究将有助于更好地理解EPS在冷适应中的多种相互关联的生理和生态功能及其与成分和结构的关系。\n生物表面活性剂 生物表面活性剂是微生物来源的表面活性两亲化合物，可降低液体、固体和气体之间的表面和界面张力。通常，与生物乳化剂例如EPS相比，它们具有低分子量，生物乳化剂往往具有高分子量，并且可以由糖、氨基酸、脂肪酸和/或官能团例如羧酸组成。它们是结构多样的化合物，但最常见的是糖脂（鼠李糖脂、槐糖脂、海藻糖脂和甘露糖赤藓糖醇脂等）、脂肽（表面活性素、伊图林、风霉素、粘胶素等）、磷脂、脂肪酸和中性脂类。在自然界中，它们被认为在增强难溶性疏水底物的生物利用度、调节生物膜结构和表面附着/分离、细菌发病机制和群体感应以及充当抗菌剂和抗真菌剂方面发挥作用。关于冷适应，从南极酵母中分离出的糖脂生物表面活性剂被证明具有 IRI 活性（Kitamoto 等人，2001 年），而生物表面活性剂也被认为具有渗透调节剂的作用（Perfumo 等人，2018 年）。有趣的是，尽管生物表面活性剂的生产似乎在适应寒冷的生物体中广泛存在（Gesheva et al. 2010; Malavenda et al. 2015; Perfumo et al. 2018; Vollú et al. 2014），但调查其在寒冷适应中潜在作用的研究却很少。显然需要进一步的研究来阐明这些化合物是否构成细胞适应寒冷的工具包的一部分，并阐明它们在其中的确切作用和作用机制。\n酶 低温环境下，冷适应微生物面临的主要挑战之一是低温对反应速率的不利影响。根据阿伦尼乌斯定律，所有反应（包括酶促反应）都受温度影响，温度的降低会导致反应速率呈指数下降（Arrhenius 1889）。事实上，对于大多数未适应的酶，从37°C降低到0°C会导致活性降低16–80倍。相比之下，大多数嗜冷生物产生的酶适应其环境，能够在寒冷的栖息地中保持高特异性活性，以维持适当的代谢速率（Collins et al. 2002a；Collins and Gerday 2017；Fields et al. 2015；Gerday 2013；Santiago et al. 2016；Siddiqui 2015）。\n除少数例外（如Oswald et al. 2014；Roulling et al. 2016），大多数研究的冷适应酶在低至中等温度下表现出较高的催化活性，最佳活性温度较低，且相比中温和嗜热同源酶，其稳定性较差。这些“冷酶”通过减少活化焓（ΔH*）来降低活化能（ΔG*）和反应的温度依赖性，这意味着在催化循环中断裂的焓相互作用数量和/或强度减少（Lonhienne et al. 2000）。此外，较低的负值活化熵（ΔS*）暗示着活化过程中的重排更大，同时在活化过程中热容变化更负，这表明地态具有更高的热容和更多的振动模式（Arcus et al. 2016）；而较高的Km值则暗示底物亲和力较低。这些特征共同说明了嗜冷酶的酶-底物复合物（ES）呈现出不稳定的状态，具有更高的自由能，从而导致观察到的较低ΔG*和增强的催化速率。\n多项研究利用多种技术调查了嗜冷酶中这种结构不稳定或柔性。值得注意的是，蛋白质的柔性是一种复杂的参数，难以测量。深入的比较研究以表征蛋白质运动的特定幅度、时间框架、涉及区域和温度依赖性将是必要的，且NMR等强有力的技术对更好地理解这一参数至关重要。尽管存在当前的限制，目前普遍接受的观点是，嗜冷酶确实显示出更高的结构柔性，且通过增加特定区域（如催化位点附近）或整个蛋白质的柔性或弹性来克服低温的挑战。这种柔性使得所需的构象变化在低能量成本下得以进行，但也导致稳定性降低。在结构水平上，这种增加的柔性主要通过减少和/或减弱稳定性相互作用（如氢键、盐桥、芳香相互作用、二硫键、离子结合位点等）或减弱疏水核心来实现。此外，还报道了低脯氨酸含量、环状区域甘氨酸含量增加及疏水残基的更高暴露度等特征。这些修饰允许在低温下增加所需的柔性，但也导致嗜冷酶普遍具有较低的稳定性（Collins和Gerday 2017）。重要的是，研究发现不同的酶可能采用不同的结构适应策略，每种酶根据其特性、环境和需求使用独特或组合的修饰方式。\n分子伴侣 蛋白质和RNA/DNA伴侣蛋白分别促进蛋白质和RNA/DNA的高效折叠，在抗击蛋白质错误折叠和聚集、以及低温下稳定RNA和DNA二级结构方面发挥重要作用。DNA和RNA伴侣蛋白对维持高效的转录、翻译和DNA复制至关重要。它们作为冷休克反应的一部分，在中温和嗜热微生物中短暂产生，但在嗜冷生物中常常持续过表达或在低温下上调（Lim et al. 2000）。与冷适应微生物中的蛋白质伴侣蛋白有关的研究表明，存在持续过表达、生产冷适应变体以及与此相对的未过表达和低温抑制等现象（Ferrer et al. 2003；Godin-Roulling et al. 2015）。\n值得注意的是，尽管蛋白质错误折叠和沉淀在低温下通常会大大减少，主要是由于疏水相互作用的减弱，但在温度范围较低的条件下，蛋白质还面临着另一个现象：冷变性（Collins and Gerday 2017；Romero-Romero et al. 2011）。冷变性被认为是由于低温下的优先水合作用和疏水性及离子相互作用的减弱，令人感兴趣的是，嗜冷酶可能比其高温适应的同源酶更容易发生这种情况（D’Amico et al. 2003）。然而，冷变性的潜在机制仍未完全明了，未来的研究应关注这一问题。\n代谢调整 近期利用现代组学方法，如基因组学、转录组学和蛋白质组学的研究揭示了多种冷适应微生物的共同特征（参见例如Tribelli和Lopez（2018）中的最新综述）。特别是，研究表明低温下有多种代谢调整，包括主要代谢途径的下调，以及用简化或替代的次级代谢途径进行替代，还有储备化合物的积累和代谢。氧化代谢过程，特别是糖酵解、磷酸戊糖途径、TCA循环和/或电子传递链，以及涉及金属离子和钼红酶代谢的途径，在一些嗜冷生物中被报告在低温下被下调（Medigue et al. 2005; Piette et al. 2011; Tribelli et al. 2015）。虽然这一现象尚未完全理解，但研究表明它们被替代为替代/简化途径，如草酰乙酸、甲基乙二醛或2-甲基柠檬酸循环、乙醇氧化途径、醋酸代谢或丙酰-CoA分解代谢（Ayala-del-Río et al. 2010; Tribelli和Lopez 2018），实际使用的替代途径依赖于微生物及其生态位。这样的代谢重编程策略可能通过避免产生ROS的途径来减轻低温固有的氧化应激，同时可能对能量节约和长期生存具有重要作用。\n筛选研究表明，冷栖息地中聚羟基烷酸酯（PHA）生产者的含量较高（Ciesielski et al. 2014; Goh和Tan 2012; Pärnänen et al. 2015），许多嗜冷生物能够积累和降解PHA（López et al. 2009; Methé et al. 2005; Ting et al. 2010）和/或类氰藻肽（Duchaud et al. 2007; Methé et al. 2005; Vollmers et al. 2013）化合物。这些化合物可以作为细胞内的碳、氮、还原当量和能量的动态储备，并被认为在克服低温对碳和氮吸收的挑战中起着重要作用。然而，也有研究提出PHA在抗冻保护、抗氧化应激、维持细胞的氧化还原平衡和细胞运动性方面的功能（Methé et al. 2005; Tribelli和Lopez 2018）。\n参考文献 Collins, T., Margesin, R. Psychrophilic lifestyles: mechanisms of adaptation and biotechnological tools. Appl Microbiol Biotechnol 103, 2857–2871 (2019). https://doi.org/10.1007/s00253-019-09659-5 Goyal, D., Swaroop, S., Prakash, O., Pandey, J. (2022). Survival Strategies in Cold-Adapted Microorganisms. In: Goel, R., Soni, R., Suyal, D.C., Khan, M. (eds) Survival Strategies in Cold-adapted Microorganisms. Springer, Singapore. https://doi.org/10.1007/978-981-16-2625-8_8 Corsaro, M.M., Casillo, A., Parrilli, E., Tutino, M.L. (2017). Molecular Structure of Lipopolysaccharides of Cold-Adapted Bacteria. In: Margesin, R. (eds) Psychrophiles: From Biodiversity to Biotechnology. Springer, Cham. https://doi.org/10.1007/978-3-319-57057-0_13 Choudhary, P., Bhatt, S. \u0026amp; Chatterjee, S. From freezing to functioning: cellular strategies of cold-adapted bacteria for surviving in extreme environments. Arch Microbiol 206, 329 (2024). https://doi.org/10.1007/s00203-024-04058-5 ","date":"2024-11-07T00:00:00Z","image":"/p/psychrophilic/images/cold-adaption_hu_db0287e8853a48b3.png","permalink":"/p/psychrophilic/","title":"微生物的低温适应/抗寒机制研究"},{"content":"极地环境病毒组 文献：Rahlff, J., Westmeijer, G., Weissenbach, J. et al. Surface microlayer-mediated virome dissemination in the Central Arctic. Microbiome 12, 218 (2024). https://doi.org/10.1186/s40168-024-01902-0\n摘要 背景： 水生病毒在塑造微生物群落中起着关键作用。在极地环境中，病毒面临着诸多挑战，如宿主资源有限和环境条件恶劣。然而，由于这些生态系统的访问受限，作者对病毒的多样性、丰度、适应性及宿主相互作用的了解仍然有限。\n结果： 为弥补这一知识空白，研究者研究了来自中央北极和格林兰北部大气近水生生态系统的病毒。病毒-宿主分析的水样采集自约60厘米深度和亚毫米表面微层（SML），样本采集是在极地夏季的2021年“同步极地调查”（Synoptic Arctic Survey）期间进行的，地点为破冰船Oden。水样来自融水池和开阔水域，经过大小分级过滤后，进行了基因组解析的宏基因组学和培养研究。融水池中的原核生物多样性显著低于开阔水域。 融水池的主要微生物为黄杆菌属（Flavobacterium sp.）和Aquiluna属（后者基因组较小，仅为1.2 Mb，并具有通过磷酸乙酰转移酶-乙酸激酶途径生成ATP的代谢潜力）。融水池的病毒多样性在宿主部分（0.2–5 µm）上明显低于开阔水域。在1154个病毒操作分类单元（vOTUs）中，约三分之二被预测为噬菌体，其中17.2%编码有辅助代谢基因（AMGs），这些基因具有代谢功能。一些AMGs如甘油-3-磷酸胞苷转移酶和冰结合蛋白可能为宿主提供抗冻保护。前噬菌体常与SML基因组相关，且从北极SML菌株Leeuwenhoekiella aequorea Arc30中诱导了两个活跃的前噬菌体。 研究者还发现，与约60厘米深度相比，SML中的vOTU丰度与该vOTU在五个不同北极站点的分布呈更强的正相关。\n结论： 研究结果表明，病毒采用复杂的策略以适应极端、宿主有限的环境。此外，研究者的观察结果表明，海气界面是中央北极病毒分布的重要平台。\n关键结果 格陵兰冰原巨型病毒 摘要 背景： 冰川和冰原上的深色雪和冰川冰藻有助于加速融化。对这些藻类的生物控制，特别是病毒的作用，仍然知之甚少。巨型病毒属于核质大 DNA 病毒 (NCLDV) 超群（核细胞病毒门），种类繁多，分布于全球。众所周知，NCLDV 会感染海洋和淡水环境中的真核细胞，从而对这些生态系统中的藻类种群提供生物控制。然而，关于陆地冰冷栖息地 NCLDV 的多样性和生态系统功能的信息非常有限。\n结果： 在这项研究中，作者首次研究了巨型病毒及其在冰雪栖息地中的宿主联系，例如冰石、黑冰、冰芯、红雪和绿雪，以及五种人工培养的绿藻雪藻的基因组组装。几乎所有样本中都存在巨型病毒标记基因；从红雪和雪藻基因组组合中回收的丰度最高，其次是绿雪和深色冰。这些含有 NCLDV 标记基因的 GrIS 栖息地中的各种活跃藻类和原生生物表明，感染可能发生在一系列真核宿主上。来自红色和绿色雪的宏基因组数据包含来自Imitervirales、Asfuvirales和Algavirales目的巨型病毒宏基因组组装基因组的证据。\n结论： 作者的研究强调了格陵兰冰盖冰雪样本中 NCLDV 家族的特征。在红雪样本中发现巨型病毒宏基因组组装基因组（GVMAG），并首次在雪藻培养基因组组装中鉴定出相关NCLDV标记基因；暗示 NCLDV 和雪藻之间存在关系。宏转录组病毒基因也与宏基因组序列对齐，表明 NCLDV 是微生物群落的活跃组成部分，并且是真核藻类和原生生物成员的潜在“自上而下”控制。这项研究揭示了在以藻类为主的各种冰川栖息地中前所未有地存在着多样化的 NCLDV 群落。\n关键结果 方法 巨型病毒宏基因组组装基因组（GVMAG）是通过使用\u0026gt;=5000个碱基对重叠群与MetaBAT2（v2.12.1）[83]进行分箱而创建的。使用 ViralRecall (v2) [57] 分析生成的 bin 中的 NCLDV 标记基因，如果它们具有 5 个或更多标记基因、基因组大于 100 kbp 以及在其他 NCLDV 基因组中的分类位置，则被视为 GVMAG [51]。 CoverM (v 0.6.1) (https://github.com/wwood/CoverM) 用于评估所有 57 个生成的组件和环境样本读数（18 个宏基因组、19 个宏转录组和 1 个宏病毒组）之间的读数招募。 GVMAG 功能注释通过 InterPro [84] 和 GVOG [50] 进行评估。\nViralRecall was used to identify NCLDV-like sequences and viral-like regions in all the metagenome, metatranscriptomes, metavirome, and pure algal culture. Options used were as follows: -db marker -c. The “marker” option was used to only search against 10 NCLDV marker genes, encoding for factors for maturation of the viral capsid (MCPs), packaging ATPase (A32), DNA polymerase elongation subunit family B (PolB), D5-like helicase-primase (D5), mRNA-capping enzyme (mRNAc), RNA polymerase large and small subunit (RNApl, RNAps), DNA or RNA helicases of superfamily II (RNR, SFII), and poxvirus late transcription factor VLTF3 like (VLTF3). All resulting hits with an e-value less than e^-10 were used further. These genes are universal NCLDV marker genes and hence are routinely assessed for identification of signatures of NCLDVs in different ecosystems [51]. PolB is the only marker gene typically found as single copy and is therefore used for phylogenetic placement within known NCLDV families [57].\nViralRecall 用于识别所有宏基因组、宏转录组、宏病毒组和纯藻类培养物中的 NCLDV 样序列和病毒样区域。使用的选项如下：-db 标记-c。 “标记”选项仅用于搜索 10 个 NCLDV 标记基因，编码病毒衣壳 (MCP) 成熟因子、包装 ATP 酶 (A32)、DNA 聚合酶延伸亚基家族 B (PolB)、D5 样解旋酶 -引物酶 (D5)、mRNA 加帽酶 (mRNAc)、RNA 聚合酶大亚基和小亚基（RNApl、RNAps）、超家族 II 的 DNA 或 RNA 解旋酶（RNR、SFII）和痘病毒晚期转录因子 VLTF3 样（VLTF3）。所有 e 值小于 e^-10 的结果命中均被进一步使用。这些基因是通用的 NCLDV 标记基因，因此经常进行评估，以识别不同生态系统中 NCLDV 的特征 [51]。 PolB 是唯一通常以单拷贝形式发现的标记基因，因此用于已知 NCLDV 家族中的系统发育定位 [57]。\n为了确认病毒样区域属于 NCLDV 家族，使用了针对 NCBI nr 的blastp 函数，并针对由 ViralRecall 分类为可能的 NCLDV 基因的每个序列验证了 50 个最高命中。当 NCLDV 结果位于前 10 名命中之内时，该基因被视为来自 NCLDV。通过 NCBI nr 验证之前和之后，通过对 e 值截止值为 1×10−10 的标记基因求和并归一化到总文库大小，计算每个样本中 10 个 NCLDV 核心基因的总丰度。选择病毒标记基因相对存在率最高的 19 个环境样本中的 4 个（MG3、MG8、MG12 和 MG28；图 2）进行更深度的重新测序，以提供更高的测序覆盖率并增加组装 GVMAG。\nViralRecall使用： https://github.com/faylward/viralrecall\n1 2 3 4 5 6 7 8 9 10 git clone https://github.com/faylward/viralrecall.git cd viralrecall #发现deepbgc环境基本满足，主要是prodigal和hmmer conda activate deepbgc #下载数据库 wget -O hmm.tar.gz https://zenodo.org/records/12666277/files/hmm.tar.gz?download=1 tar -xvzf hmm.tar.gz #测试 python viralrecall.py -i examples/arm29B.fna -p test_outdir -t 2 -f GVMAGs 外部核细胞病毒基因组是从之前发表的研究中下载的 [50, 91]。所有 1171 个外部基因组和我们的 10 个 GVMAG 使用 ncldv_markersearch.py进行比对（最后更新于 2022 年 4 月 21 日，github.com/faylward/ncldv_markersearch）。使用 IQ-TREE 和 LG+F+I+G4 模型以及 -B 超快 1000 个引导程序构建最大似然系统发育树 [90]。系统发育分配是根据以前的文献[51]进行的。\nhttps://journals.plos.org/plosbiology/article?id=10.1371/journal.pbio.3001430 A phylogenomic framework for charting the diversity and evolution of giant viruses\nhttps://zenodo.org/records/6382754#.Y-Pxw-zML0s ，1175个Representative giant virus genomes。\n核细胞病毒门的大型 DNA 病毒最近已成为全球生态系统的重要成员，挑战了病毒复杂性的传统观点。最近报道了该门的许多成员无法分类到已建立的科中，目前强烈需要这些病毒的强大的系统发育和分类学框架。在这里，我们报告了核细胞病毒门的全面系统发育分析，提出了一组巨型病毒直系同源群（GVOG）以及基准参考系统发育，并描绘了该门内的分层分类学。我们表明，大多数核细胞病毒多样性可分为 6 个目、32 个科和 344 个属，大大扩展了目前公认的这些病毒的分类等级数量。我们将我们的结果整合到所有病毒都采用的分类法中，为核细胞病毒多样性、进化和环境分布的研究建立一个统一的框架。\nncldv_markersearch 用于识别 Nucleocytoviricota 中的系统发育标记基因并生成串联比对的工具。\n该脚本将根据一组 10 个精心策划的隐马尔可夫模型搜索蛋白质文件，以查找核胞质大 DNA 病毒 (NCLDV) 中普遍存在的蛋白质家族。命中相同 HMM、与该 HMM 形成非重叠比对、并且位于同一重叠群上某个确定的邻近范围内的蛋白质将连接在一起并作为单个氨基酸序列输出。这有助于对具有分裂基因的 NCLDV 进行系统发育分析。\n1 2 3 4 5 git clone https://github.com/faylward/ncldv_markersearch.git cd ncldv_markersearch #发现deepbgc环境基本满足，主要是prodigal和hmmer conda activate deepbgc python ncldv_markersearch.py -i test_input -n test_run -t 4 ","date":"2024-11-07T00:00:00Z","permalink":"/p/env-virus/","title":"近期的一些环境病毒组研究（2024.10）"},{"content":"Introduction 我们平时在做科研的时候，经常会遇到需要整理文献信息的情况。比如，我们需要查找某个领域的最新论文，或者是了解一个作者的发文情况等等。\n一般情况下，我们会通过搜索引擎来查找相关的文献，然后逐一查看。但手动的话一般很难快速整理成表，所以我在这里简单介绍几个R包，可以帮助我们快速整理文献信息:\nscholar Google Scholar 可能是了解一位作者最好的途径了（如果他有账号的话，因为这里的list一般比较全。但由于没有ORCID一类的标识符，也可能出现不是该作者的文章）。scholar包提供从 Google Scholar 中提取引文数据的功能。还提供了方便的函数来比较多个学者并预测未来的 H 指数值。\n1 2 3 4 5 6 # from CRAN install.packages(\u0026#34;scholar\u0026#34;) # from GitHub if(!requireNamespace(\u0026#39;remotes\u0026#39;)) install.packages(\u0026#34;remotes\u0026#34;) remotes::install_github(\u0026#39;YuLab-SMU/scholar\u0026#39;) 注意使用这个包需要我们本来就能上Google Scholar（代理一下），然后记得在R环境里也设置一下：\n1 2 3 4 5 # install.packages(\u0026#34;r.proxy\u0026#34;) r.proxy::proxy() #打开代理 # r.proxy::noproxy() #不用的话可以关掉 获取作者的profile 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 library(scholar) ## Define the id for Richard Feynman，这个id可以在Google Scholar中找到，看网址中的user=XXXXXXXXX id \u0026lt;- \u0026#39;B7vSqZsAAAAJ\u0026#39; ## Get his profile l \u0026lt;- get_profile(id) print(l[2:7]) ## $name ## [1] \u0026#34;Richard Feynman\u0026#34; ## ## $affiliation ## [1] \u0026#34;California Institute of Technology\u0026#34; ## ## $total_cites ## [1] 127275 ## ## $h_index ## [1] 62 ## ## $i10_index ## [1] 100 ## ## $fields ## [1] \u0026#34;quantum mechanics\u0026#34; \u0026#34;quantum electrodynamics\u0026#34; 获取作者的文章列表 1 2 3 pubdf=get_publications(id) nrow(pubdf) ## [1] 157 注意这里的文章信息并不多，只有标题、作者列表、期刊、发表年、引用量等。而且，作者列表里如果人名太多太长，就会出现\u0026quot;\u0026hellip;\u0026ldquo;的省略😂，我们可以进一步处理：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 # 比如pubdf$author[33] # \u0026#34;RP Feynman, RB Leighton, M Sands, CA Heras, R Gómez, E Oelker, ...\u0026#34; for (i in 1:nrow(pubdf)){ if (grepl(\u0026#34;...\u0026#34;, pubdf$author[i],fixed = TRUE)) { pubdf$author[i] \u0026lt;- get_complete_authors(id,pubdf$pubid[i]) } } # 处理好之后： # \u0026#34;RP Feynman, RB Leighton, M Sands, CA Heras, R Gómez, E Oelker, H Espinosa\u0026#34; # 获取作者排名（根据姓查询的，比如这里就是用Feynman，有重名的话保留靠前的排名）： author_pos=scholar::author_position(pubdf$author,l$name) pubdf=cbind(pubdf,author_pos) 这里的Position_Normalized基本可以确定0是第一作者，1是最后一个通讯作者了，但是共一共通讯需要自己去手动看看。\n引用次数可视化 1 2 3 4 5 6 7 8 9 #作者年份被引信息 scholar::get_citation_history(id)-\u0026gt;citation_history #某一篇文章年份被引信息 scholar::get_article_cite_history(id,pubdf$pubid[1])-\u0026gt;article_cite_history ggplot(citation_history,aes(x=year,y=cites)) + ggh4x::geom_pointpath()+ labs(title=\u0026#34;Feynman\u0026#39;s Citation History\u0026#34;,x=\u0026#34;Year\u0026#34;,y=\u0026#34;Citations\u0026#34;)+ theme_classic() 作者比较 1 2 3 4 5 6 7 #比较Feynman和Hawking的文章引用 compare_scholars(c(\u0026#39;B7vSqZsAAAAJ\u0026#39;, \u0026#39;qj74uXkAAAAJ\u0026#39;))-\u0026gt;compare_result ggplot(compare_result,aes(x=year,y=cites,color=name)) + ggh4x::geom_pointpath()+ labs(title=\u0026#34;Feynman and Hawking\u0026#39;s Citation History\u0026#34;,x=\u0026#34;Year\u0026#34;,y=\u0026#34;Citations\u0026#34;)+ theme_classic() 1 2 3 4 5 6 7 #用职业生涯比较累计量 compare_scholar_careers(c(\u0026#39;B7vSqZsAAAAJ\u0026#39;, \u0026#39;qj74uXkAAAAJ\u0026#39;))-\u0026gt;compare_career_result ggplot(compare_career_result,aes(x=career_year,y=cites,color=name)) + ggh4x::geom_pointpath()+ labs(title=\u0026#34;Feynman and Hawking\u0026#39;s Citation History\u0026#34;,x=\u0026#34;Career year\u0026#34;,y=\u0026#34;Citations\u0026#34;)+ theme_classic() 作者的co-author网络 1 2 coauthor_network \u0026lt;- get_coauthors(\u0026#34;amYIKXQAAAAJ\u0026amp;hl\u0026#34;, n_coauthors = 7) plot_coauthors(coauthor_network) 预测未来的h指数值 1 2 3 ## Predict h-index of original method author, Daniel Acuna id \u0026lt;- \u0026#39;GAi23ssAAAAJ\u0026#39; predict_h_index(id) rcrossref DOI (Digital Object Identifier) 是一种唯一的、永久的数字标识符，用于标记学术文章、图书、数据集等数字内容，确保即使资源位置变化，用户仍能访问。DOI由国际DOI基金会管理，广泛用于出版和学术界。\nCrossref 是一家非营利组织，负责为出版物分配和管理DOI。它通过与出版商合作，使学术资源能够通过DOI轻松发现和引用。Crossref 提供的服务帮助提升了学术成果的可追溯性和引用率。\nrcrossref 是一款 R 语言包，其核心功能是与 CrossRef 平台进行交互，实现对全球数千万条文献记录的快速查询和处理。通过该包，用户可以方便地获取论文的DOI（数字对象唯一标识符）、作者信息、出版年份等详细元数据，甚至进行文本和数据挖掘服务。\n1 2 3 4 # from CRAN install.packages(\u0026#34;rcrossref\u0026#34;) # from GitHub remotes::install_github(\u0026#34;ropensci/rcrossref\u0026#34;) 通过DOI获取文章信息 如果我们有文章的DOI，可以通过rcrossref包获取文章的元数据，这是最方便的。\n1 2 3 4 5 6 library(rcrossref) cr_works(dois=\u0026#39;10.1063/1.3593378\u0026#39;)-\u0026gt;doi_res #批量查询也是可以的 cr_works(dois=c(\u0026#39;10.1007/12080.1874-1746\u0026#39;,\u0026#39;10.1007/10452.1573-5125\u0026#39;, \u0026#39;10.1111/(issn)1442-9993\u0026#39;),.progress = \u0026#34;text\u0026#34;)# 加上进度条 doi_res$data里面提供了非常详细的信息，包括作者列表、标题、出版年份、参考文献等，可以进一步整理表格。\n通过其他信息查询文章 官网提供了https://docs.ropensci.org/rcrossref/articles/crossref_filters.html，可以根据作者、关键词、出版时间等信息进行筛选。\n1 2 3 4 5 6 7 8 9 10 library(rcrossref) # 通过作者ORCID查询文章，但不是很准确，会少很多 cr_works(filter = list(orcid=\u0026#34;0000-0002-9449-7606\u0026#34;))-\u0026gt;orcid_res # 通过期刊+标题查询文章（比如我们之前谷歌学术的结果表格只有期刊+标题，一般没有DOI） res \u0026lt;- cr_works(query = \u0026#34;Interaction with the absorber as the mechanism of radiation\u0026#34;, flq = c(`query.container-title` = \u0026#39;Reviews of Modern Physics\u0026#39;)) # 这个可能会搜到很多结果，一般第一条是比较准确的，可以手动check一下： nrow(res$data) ## [1] 20 举个例子，我们需要将上面找到的谷歌学术列表中的文章表格添加DOI信息，可以用下列代码：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 library(rcrossref) pubdf2=get_publications(id) pubdf2$DOI=NA for (i in seq_len(nrow(pubdf2))){ results \u0026lt;- cr_works(query = pubdf2$title[i], filter = c(type = \u0026#34;journal-article\u0026#34;)) if(stringr::str_equal(pubdf2$title[i],results$data$title[1],ignore_case = T)){ # 如果第一篇文章标题和搜索结果标题完全一致，则添加DOI pubdf2$DOI[i]=results$data$doi[1] } else{ # 如果第一篇文章标题和搜索结果标题不完全一致，则需要手动选择 cat(pubdf2$title[i],\u0026#34;\\n\\n\u0026#34;,results$data$title[1]) flag \u0026lt;- readline(\u0026#34;yes/no(y/n)?\u0026#34;) if (tolower(flag) %in% c(\u0026#34;yes\u0026#34;, \u0026#34;y\u0026#34;)) { pubdf2$DOI[i]=results$data$doi[1] } } } PubMed相关R包 PubMed数据库是一个流行的数据库（但我用的比较少😂，基本上直接谷歌学术），有很多包可以用来查询PubMed数据库并挖掘，比如RISmed，pumed.mineR，easyPubMed等等。\nRISmed 这是一套从国家生物技术信息中心（NCBI）数据库（包括PubMed）中提取书目内容的工具。RISmed是RIS（用于研究信息系统，书目数据的通用标签格式）和PubMed的组合。\n1 2 3 4 5 6 7 8 9 10 11 12 library(RISmed) # 限定检索主题 search_topic\u0026lt;-\u0026#34;indoor air microbiome\u0026#34; search_query\u0026lt;-EUtilsSummary(search_topic,db=\u0026#34;pubmed\u0026#34;,type=\u0026#34;esearch\u0026#34;,mindate=2022,maxdate=2024) summary(search_query) # 获取摘要信息，经常有网络问题😂不如去网站检索再导出 records\u0026lt;- EUtilsGet(search_query@PMID,type=\u0026#34;efetch\u0026#34;,db=\u0026#34;pubmed\u0026#34;) # 获取作者信息 authors \u0026lt;- Author(records) easyPubMed EasyPubMed是Entrez编程实用程序的开源R接口，旨在允许在R环境中对PubMed进行程序化访问。该软件包适用于下载大量记录，并包含一系列功能来执行Entrez/PubMed查询响应的基本处理。该库支持XML或TXT（“ MEDLINE”）格式。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 library(easyPubMed) # 可以直接输入文章标题查找 fullti \u0026lt;- get_pubmed_ids_by_fulltitle( fulltitle = \u0026#34;Identification of hub genes and outcome in colon cancer based on bioinformatics analysis\u0026#34;, field = \u0026#34;[Title]\u0026#34;) # PMID fullti$IdList$Id ## [1] \u0026#34;30643458\u0026#34; # 转为DOI rcrossref::id_converter(fullti$IdList$Id) ## $status ## [1] \u0026#34;ok\u0026#34; ## ## $responseDate ## [1] \u0026#34;2024-10-14 02:56:51\u0026#34; ## ## $request ## [1] \u0026#34;tool=rcrossref;email=myrmecocystus%40gmail.com;ids=30643458;format=json\u0026#34; ## ## $records ## pmcid pmid doi versions ## 1 PMC6312054 30643458 10.2147/CMAR.S173240 PMC6312054.1, true bibliometrix BiblioMetrix软件包提供了一组用于文献计量学和科学计量学方面的定量研究的工具。\n文献计量学本身是科学，定量分析的主要工具。本质上，书目计量学是定量分析和统计数据的应用，例如期刊文章及其随附的引文数。现在，几乎所有科学领域都使用了对出版和引文数据的定量评估，以评估成长，成熟度，主要作者，概念图和智力图，科学界的趋势。\nBIBLIOMERTIC还用于研究绩效评估，尤其是在大学和政府实验室，以及决策者，研究总监和管理人员，信息专家和图书馆员以及学者本身。\nBiblioMetrix在分析的三个关键阶段支持学者：\n数据导入和转换为R格式； 出版数据集的文献计量分析； 构建和绘制矩阵，用于共同引用，耦合，协作和共同词分析。矩阵是用于执行网络分析，多个对应分析和任何其他数据减少技术的输入数据。 这个包的使用教程很多，比如参考https://blog.csdn.net/weixin_42487488/article/details/116379324。而且它提供一个shiny界面，不需要很多代码知识也可以方便使用。\n数据获取 一般使用自己检索或整理得到的bib文件，比如直接从web of science检索，export为BibTex；或者自己想去看的某个作者的文章列表。\n1 2 3 4 5 6 7 8 9 10 11 12 13 library(bibliometrix) file \u0026lt;- c(\u0026#34;https://www.bibliometrix.org/datasets/management1.txt\u0026#34;, \u0026#34;https://www.bibliometrix.org/datasets/management2.txt\u0026#34;) M \u0026lt;- convert2df(file = file, dbsource = \u0026#34;wos\u0026#34;, format = \u0026#34;plaintext\u0026#34;) ## ## Converting your wos collection into a bibliographic dataframe ## ## Done! ## ## ## Generating affiliation field tag AU_UN from C1: Done! 基本信息 1 2 3 results \u0026lt;- biblioAnalysis(M, sep = \u0026#34;;\u0026#34;) plot(x = results, k = 10, pause = FALSE) 可视化文献网络 展示国家科学合作：\n1 2 3 4 5 6 7 8 # Create a country collaboration network M \u0026lt;- metaTagExtraction(M, Field = \u0026#34;AU_CO\u0026#34;, sep = \u0026#34;;\u0026#34;) NetMatrix \u0026lt;- biblioNetwork(M, analysis = \u0026#34;collaboration\u0026#34;, network = \u0026#34;countries\u0026#34;, sep = \u0026#34;;\u0026#34;) # Plot the network net=networkPlot(NetMatrix, n = dim(NetMatrix)[1], Title = \u0026#34;Country Collaboration\u0026#34;, type = \u0026#34;circle\u0026#34;, size=TRUE, remove.multiple=FALSE,labelsize=0.8) 共同引用分析：\n1 2 3 4 5 6 7 # Create a co-citation network NetMatrix \u0026lt;- biblioNetwork(M, analysis = \u0026#34;co-citation\u0026#34;, network = \u0026#34;references\u0026#34;, n=30, sep = \u0026#34;;\u0026#34;) # Plot the network net=networkPlot(NetMatrix, Title = \u0026#34;Co-Citation Network\u0026#34;, type = \u0026#34;fruchterman\u0026#34;, size=T, remove.multiple=FALSE, labelsize=0.7,edgesize = 5) 关键词网络： 1 2 3 4 5 6 7 8 # Create keyword co-occurrences network NetMatrix \u0026lt;- biblioNetwork(M, analysis = \u0026#34;co-occurrences\u0026#34;, network = \u0026#34;keywords\u0026#34;, sep = \u0026#34;;\u0026#34;) # Plot the network net=networkPlot(NetMatrix, normalize=\u0026#34;association\u0026#34;, weighted=T, n = 30, Title = \u0026#34;Keyword Co-occurrences\u0026#34;, type = \u0026#34;fruchterman\u0026#34;, size=T,edgesize = 5,labelsize=0.7) Co-Word分析 共词分析的目的是使用书目集合中的词共现来映射框架的概念结构。 可以通过降维技术（例如多维标度（MDS）、对应分析（CA）或多对应分析（MCA））来执行分析。\n这里展示了一个使用函数 ConceptualStructure 的示例，该函数执行 CA 或 MCA 来绘制字段的概念结构，并使用 K 均值聚类来识别表达共同概念的文档簇。结果绘制在二维图上。\n1 2 3 4 5 # Conceptual Structure using keywords (method=\u0026#34;CA\u0026#34;) CS \u0026lt;- conceptualStructure(M,field=\u0026#34;ID\u0026#34;, method=\u0026#34;MCA\u0026#34;, minDegree=10, clust=5, stemming=FALSE, labelsize=15, documents=20, graph=FALSE) plot(CS$graph_terms) 其他需求 添加期刊影响因子 目前没有特别好的R包或函数来获取期刊的影响因子，之前scholar包 get_impactfactor函数也无法使用了。最好的方法还是自己去下载一下当年的JCR影响因子表格（很多公众号都可以获取），然后自己用R整合一下。我之前也也简单整理了一个IF大于2.4的部分期刊的表，下载链接：https://asa12138.github.io/FileList/JCR_IF_2024_bigger_than_2.4.csv。\n1 2 3 4 5 6 7 8 9 #获取IF readr::read_csv(\u0026#34;~/Documents/Others/JCRs/JCR_IF_2024_bigger_than_2.4.csv\u0026#34;)-\u0026gt;jcr_df pubdf2$IF=NA for (i in seq_len(nrow(pubdf2))){ tmp=which(stringr::str_equal(pubdf2$journal[i],jcr_df$`Journal name`,ignore_case = T)) if (length(tmp)\u0026gt;0) { pubdf2$IF[i]=jcr_df[tmp,3]%\u0026gt;%unlist() } } ","date":"2024-10-14T00:00:00Z","image":"/p/r-paper-list/index.en_files/figure-html/unnamed-chunk-19-1_hu_bae599dd4780c7f1.png","permalink":"/p/r-paper-list/","title":"R整理和分析文献信息"},{"content":"Introduction R语言是平时统计分析，科研绘图的利器，除了很多非常严肃标准的可视化外，还经常可以看到一些非常有趣的绘图R包，不得不佩服开发者们的创意。\n这里介绍一些我认为比较有趣的绘图R包：\nggCyberPunk ggplot画图也可以赛伯朋克，哈哈哈，这个包提供了非常好看的一个主题，绘制的线和面都有朦胧发光感，再加上代码风格字体。\n目前只能github安装：\n1 devtools::install_github(\u0026#34;delabj/ggCyberPunk\u0026#34;) 然后我们画一个折线图：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 library(tidyverse) library(ggCyberPunk) df = data.frame(A=c(1,4,4,6,7,5,1), B=c(4,3,5,7,5,6,7), Time=c(1,2,3,4,5,6,7)) %\u0026gt;% pivot_longer(cols = c(A,B),names_to = \u0026#34;group\u0026#34;, values_to = \u0026#34;count\u0026#34;) showtext::showtext_auto() sysfonts::font_add(\u0026#34;Aldrich\u0026#34;, system.file(\u0026#34;fonts\u0026#34;, \u0026#34;Aldrich/Aldrich-Regular.ttf\u0026#34;, package = \u0026#34;ggCyberPunk\u0026#34;)) df %\u0026gt;% ggplot(aes(x=Time, y = count, color = group, fill= group))+ geom_glowing_area()+ theme_cyberpunk()+ scale_color_cyberpunk()+ ggtitle(\u0026#34;geom_glowing_line()\u0026#34;, subtitle = \u0026#34;From ggCyberPunk\u0026#34;) gggibbous ggplot2的扩展包gggibbous提供了一个月亮的geom，月亮图可作为两组的饼图替代品。\n1 2 3 install.packages(\u0026#34;gggibbous\u0026#34;) #或 devtools::install_github(\u0026#34;mnbram/gggibbous\u0026#34;) 使用的话，geom_moon和geome_point类似：\n1 2 3 4 5 6 library(gggibbous) ggplot(data.frame(x = 1:5, y = 1, size = 2^(0:4)), aes(x, y, size = size)) + geom_moon() + geom_point(y = 2) + lims(x = c(0.5, 5.5), y = c(0.5, 2.5)) + scale_size(range = c(5, 10)) 当然，它还多一些美学特征，比如ratio 控制要绘制的月亮的比例。它必须介于 0（实际未绘制任何内容的“新月”）和 1（“满月”，即圆形）之间:\n1 2 3 4 5 ggplot(data.frame(x = 1:5, y = 0, ratio = 0:4 * 0.25), aes(x = x, y = y)) + geom_moon(aes(ratio = ratio), size = 20, fill = \u0026#34;black\u0026#34;) + geom_text(aes(y = y + 1, label = ratio)) + lims(x = c(0.5, 5.5), y = c(-1, 1.4)) + theme_void() right 接受一个布尔值，控制月亮是“渐盈”还是“渐亏”，即它是从右侧还是从左侧“填充”。 用两种颜色制作“完整”月亮的一种方法是对一种颜色使用 right = TRUE，对另一种颜色使用 right = FALSE，并具有互补比例。\n1 2 3 4 5 6 7 8 9 10 tidymoons \u0026lt;- data.frame( x = rep(1:3, 6), y = rep(rep(3:1, each = 3), 2), ratio = c(1:9 / 10, 9:1 / 10), right = rep(c(TRUE, FALSE), each = 9) ) ggplot(tidymoons) + geom_moon(aes(x, y, ratio = ratio, right = right, fill = right)) + lims(x = c(0.5, 3.5), y = c(0.5, 3.5)) 我们用moon形状绘制到地图上，展示二分组的一个情况：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 dmeladh_adj \u0026lt;- dmeladh dmeladh_adj$long \u0026lt;- dmeladh$Longitude + c( -2, 0, -2, 2, -3, 3, 3, 2, 3, 4, -2.5, -2.5, -1, -2, -2.5, -4, 2.5, 5, 6, 7, 2, -7, -5.5, -3, 0, -7, -2, 3, 5.5, 0.5, -1, -1.5, -3, 2) dmeladh_adj$lat \u0026lt;- dmeladh$Latitude + c( -2, 2, 0, 1, 0, 0, 0, 2, 0.5, -1, 1, -1.5, 2, 4, 1.5, 0, 2, 1, -1, -3, -2, 1, -1, -2, -3, -2, -4, -3, -1, 1.5, 2, 2, -2, 0) moonmap \u0026lt;- ggplot(dmeladh_adj, aes(long, lat)) + geom_polygon( data = map_data( \u0026#34;world\u0026#34;, region = \u0026#34;(Australia)|(Indonesia)|(Papua New Guinea)\u0026#34;), aes(group = group), fill = \u0026#34;gray80\u0026#34; ) + geom_segment(aes(xend = Longitude, yend = Latitude), color = \u0026#34;gray20\u0026#34;) + geom_point(aes(Longitude, Latitude), size = 0.75, color = \u0026#34;gray20\u0026#34;) + scale_size(range = c(4, 10)) + coord_map(xlim = c(110, 160), ylim = c(-45, -5)) + theme_void() + theme( legend.position = c(0.05, 0.05), legend.direction = \u0026#34;horizontal\u0026#34;, legend.justification = c(0, 0) ) moonmap + geom_moon( aes(ratio = AdhS / 100, size = N), right = FALSE, fill = \u0026#34;gold\u0026#34;, color = \u0026#34;gold\u0026#34;, key_glyph = draw_key_moon_left ) + geom_moon( aes(ratio = AdhF / 100, size = N), fill = \u0026#34;forestgreen\u0026#34;, color = \u0026#34;forestgreen\u0026#34; ) ggbrick ggbrick提供了一个有趣的geom_brick，用来绘制砖墙或者华夫饼图：\n1 2 3 install.packages(\u0026#34;ggbrick\u0026#34;) #或 devtools::install_github(\u0026#34;doehm/ggbrick\u0026#34;) 先画一个普通的柱形图：\n1 2 3 4 5 6 7 library(ggbrick) showtext::showtext_auto() df=data.frame(x=factor(strsplit(\u0026#34;努力搬砖\u0026#34;,\u0026#34;\u0026#34;)[[1]],strsplit(\u0026#34;努力搬砖\u0026#34;,\u0026#34;\u0026#34;)[[1]]),y=10*1:4) ggplot(df) + geom_brick0(aes(x, y), fill = \u0026#34;#BF8285\u0026#34;, bricks_per_layer = 2)+ theme_void()+ theme(axis.text.x = element_text(size = 20,face = \u0026#34;bold\u0026#34;)) 也可以用来画堆积柱形图：\n1 2 3 4 5 6 # basic usage mpg |\u0026gt; count(class, drv) |\u0026gt; ggplot() + geom_brick0(aes(class, n, fill = drv), bricks_per_layer = 2)+ scale_fill_manual(values = c(\u0026#34;#BF8285\u0026#34;, \u0026#34;#85BF82\u0026#34;,\u0026#34;grey\u0026#34;)) rphylopic rphylopic 包的目的是允许用户将生物体的轮廓添加到基础 R 和 ggplot2 中生成的绘图中。为此，它使用了 PhyloPic 网站提供的剪影。\n1 2 3 install.packages(\u0026#34;rphylopic\u0026#34;) #或 devtools::install_github(\u0026#34;palaeoverse/rphylopic\u0026#34;) PhyloPic 网站有非常多种类的动物剪影： rphylopic包可以查找物种学名，然后下载相应的剪影：\n1 2 3 4 5 6 7 8 9 10 11 library(rphylopic) #获取一个物种的单一图像uuid uuid \u0026lt;- get_uuid(name = \u0026#34;Canis lupus\u0026#34;, n = 1) # 获取该uuid的图像 img \u0026lt;- get_phylopic(uuid = uuid) # 但每个物种可能存在多个轮廓。 uuid \u0026lt;- get_uuid(name = \u0026#34;Canis lupus\u0026#34;, n = 5) #我该怎么选？！ #如果不看到图像本身很难，让我们使用： img \u0026lt;- pick_phylopic(name = \u0026#34;Canis lupus\u0026#34;, n = 5) 使用add_phylopic和geom_phylopic可以将剪影轮廓用于ggplot2：\n1 2 3 4 5 6 7 8 library(rphylopic) # Get image uuid \u0026lt;- get_uuid(name = \u0026#34;Iris\u0026#34;, n = 1) img \u0026lt;- get_phylopic(uuid = uuid) #在图后面画一个剪影 ggplot(iris) + add_phylopic(x = 6.1, y = 3.2, img = img, alpha = 0.2) + geom_point(aes(x = Sepal.Length, y = Sepal.Width)) 1 2 3 4 5 #将轮廓绘制为点 ggplot(iris) + geom_phylopic(aes(x = Sepal.Length, y = Sepal.Width), img = img, color = \u0026#34;purple\u0026#34;, height = 0.25) 如果你有更多有趣的R包推荐，欢迎在评论区留言。\n","date":"2024-10-12T00:00:00Z","image":"/p/r-vis-pkg/index.en_files/figure-html/unnamed-chunk-2-1_hu_5a3500859ff20c7a.png","permalink":"/p/r-vis-pkg/","title":"一些有趣的绘图R包"},{"content":"Introduction 官网：https://github.com/teunbrand/ggh4x/\nggh4x 包是 ggplot2 扩展包。它提供了一些实用函数，虽然这些函数并不完全符合“图形语法”的概念（它们可能有点hacky），但在调整ggplot绘图结果时仍然很有用。比如调整facet的大小、将多种美学映射到颜色以及指定facet的单独比例等等，下面介绍一些常用的功能：\n可以从 CRAN 安装最新稳定版本的 ggh4x，如下所示：\n1 install.packages(\u0026#34;ggh4x\u0026#34;) 或者可以使用以下命令从 GitHub 安装开发版本：\n1 2 # install.packages(\u0026#34;devtools\u0026#34;) devtools::install_github(\u0026#34;teunbrand/ggh4x\u0026#34;) 调整facets 扩展facets facet_wrap2和facet_grid2函数扩展了ggplot2的分面功能。即使当scales=“fixed”（默认）时，也可以使用axes参数在（部分或全部）内面绘制轴。此外，可以选择省略轴标签，但通过设置remove_labels参数保留内部面的轴刻度。\n1 2 3 4 5 6 7 8 library(ggh4x) library(scales) p \u0026lt;- ggplot(mpg, aes(displ, hwy, colour = as.factor(cyl))) + geom_point() + labs(x = \u0026#34;Engine displacement\u0026#34;, y = \u0026#34;Highway miles per gallon\u0026#34;) + guides(colour = \u0026#34;none\u0026#34;) p + facet_wrap2(vars(class), axes = \u0026#34;all\u0026#34;, remove_labels = \u0026#34;x\u0026#34;) 此外，facet_grid2() 还支持该包所谓的“独立”尺度。这缓解了 ggplot2::facet_grid() 的限制，即比例只能在布局的行和列之间自由，而允许比例在布局的行和列内自由。这保留了网格布局，但保留了包裹面中尺度的灵活性。请注意，在下图中，每个面板的 x 轴都是独立的。\n1 p + facet_grid2(vars(year), vars(drv), scales = \u0026#34;free_x\u0026#34;, independent = \u0026#34;x\u0026#34;) 嵌套facets ggh4x这个包因生成嵌套面而闻名；其中，如果外strip属于同一类别，则它们可以跨越内strip。 如果分面存在一些层次关系，这可能特别有用。 在下面的示例中，根据叶子的长短对鸢尾花进行分类：\n1 2 3 4 5 6 7 8 9 10 11 12 new_iris \u0026lt;- transform( iris, Nester = ifelse(Species == \u0026#34;setosa\u0026#34;, \u0026#34;Short Leaves\u0026#34;, \u0026#34;Long Leaves\u0026#34;) ) iris_plot \u0026lt;- ggplot(new_iris, aes(Sepal.Width, Sepal.Length)) + geom_point() iris_plot + facet_nested(~ Nester + Species, nest_line = element_line(linetype = 2)) + theme(strip.background = element_blank(), ggh4x.facet.nestline = element_line(colour = \u0026#34;blue\u0026#34;)) 手动设计facets 为了实现对 ggplot2 方面的类似base-R的par(mar = c(2,2,1,1))控制级别，facet_manual() 被引入。与layout()函数一样，facet_manual()需要预先指定哪些面板放置在哪里。 这些被称为“手动”构面，因为它不会像网格和环绕构面那样根据可用数据动态生成布局。在上图中赋予layout()函数的矩阵现在可以用作手动方面的设计参数。\n1 2 3 # Setting up a design for a layout design \u0026lt;- matrix(c(1,2,3,2), 2, 2) p + facet_manual(vars(factor(drv)), design = design) 或者更灵活的设计：\n1 2 3 4 5 6 7 design \u0026lt;- \u0026#34; A## AB# #BC ##C \u0026#34; p + facet_manual(vars(drv), design = design) 细调strips ggh4x提供了主题化的 strips。这些 strips 还允许你根据每个标签或每层图形设置 strip.text.* 和 strip.background.* 的主题选项。background_x/y 和 text_x/y 参数可以接受一个包含 ggplot2 主题元素的列表。如果主题元素的数量与 strips 的数量不匹配，这些主题元素会使用 rep_len() 扩展，如下面的垂直 strips 所示。\n按照如下方式构建一个元素列表可能会有点麻烦：list(element_text(colour = \u0026quot;dodgerblue\u0026quot;, face = \u0026quot;bold\u0026quot;), element_text(colour = \u0026quot;limegreen\u0026quot;, face = \u0026quot;bold\u0026quot;))。为了简化操作，可以使用方便的函数来获得相同的结果，像这样：elem_list_text(colour = c(\u0026quot;dodgerblue\u0026quot;, \u0026quot;limegreen\u0026quot;), face = c(\u0026quot;bold\u0026quot;, \u0026quot;bold\u0026quot;))，这稍微简洁了一些。同样，也有 elem_list_rect() 函数可以对 element_rect() 执行类似操作。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 ridiculous_strips \u0026lt;- strip_themed( # Horizontal strips background_x = elem_list_rect(fill = c(\u0026#34;limegreen\u0026#34;, \u0026#34;dodgerblue\u0026#34;)), text_x = elem_list_text(colour = c(\u0026#34;dodgerblue\u0026#34;, \u0026#34;limegreen\u0026#34;), face = c(\u0026#34;bold\u0026#34;, \u0026#34;bold\u0026#34;)), by_layer_x = TRUE, # Vertical strips background_y = elem_list_rect( fill = c(\u0026#34;gold\u0026#34;, \u0026#34;tomato\u0026#34;, \u0026#34;deepskyblue\u0026#34;) ), text_y = elem_list_text(angle = c(0, 90)), by_layer_y = FALSE ) p + facet_grid2(class ~ drv + year, strip = ridiculous_strips) 调整scales 我们可能还希望对每个分面的坐标轴位置进行精确调整。为此，可以使用 facetted_pos_scales() 并结合 scales 列表来单独设置各个分面的刻度。通过这种方式可以为每个面板单独调整labels, breaks, limits, transformations，甚至轴guides。\nscales 列表按照分面的顺序排列，只要它们被设置为 \u0026ldquo;free\u0026rdquo;（自由缩放）。调整位置刻度适用于多种类型的分面，如 wrap、grid 和 nested，但需要在添加分面之后调用。如果不想让坐标轴自由缩放，可以使用 xlim() 和 ylim() 来固定坐标范围。不过，facetted_pos_scales() 函数要求分面的 scales 参数必须设置为 \u0026ldquo;free\u0026rdquo;，才能应用不同的刻度设置。\n1 2 3 4 5 6 7 8 9 10 11 scales \u0026lt;- list( scale_x_reverse(), scale_x_continuous(labels = scales::dollar, minor_breaks = c(2.5, 4.5)), scale_x_continuous(breaks = c(2.945, 6), limits = c(0, 10), guide = \u0026#34;axis_minor\u0026#34;) ) p + facet_wrap(vars(drv), scales = \u0026#34;free_x\u0026#34;) + facetted_pos_scales(x = scales) Panel大小 最后，我们还可以根据需要设置面板的大小。force_panelsizes() 函数允许你为行和列设置相对或绝对大小。该函数适用于遵循典型 ggplot2 规范的分面功能。这不仅包括 ggplot2 中的分面函数，还包括 ggforce 包中的函数、ggh4x 中的分面功能，甚至其他可能的包（但对 facet_manual() 来说是多余的）。值得注意的是，这个函数同样适用于 facet_null()，即每个图形的默认分面设置。\n1 2 3 4 5 6 7 8 9 lvls \u0026lt;- factor(c(\u0026#34;Points\u0026#34;, \u0026#34;Density\u0026#34;), c(\u0026#34;Points\u0026#34;, \u0026#34;Density\u0026#34;)) g \u0026lt;- ggplot(faithful) + geom_point(aes(waiting, eruptions), data = ~ cbind(.x, facet = lvls[1])) + geom_density(aes(y = eruptions), data = ~ cbind(faithful, facet = lvls[2])) + facet_grid(~ facet, scales = \u0026#34;free_x\u0026#34;) g + force_panelsizes(cols = c(1, 0.3), rows = c(0.5), respect = TRUE) 调整legend 多color scale 有时单一的颜色比例不足以描述数据。我之前的话用ggnewscale包来实现多种颜色scale，ggh4x提供了另一种策略。\n如果数据位于不同的图层中，你可以使用 scale_colour_multi() 将多个变量映射到颜色上。它的工作原理类似于 scale_colour_gradientn()，但你可以声明美学属性，并以向量化的方式提供其他参数，与美学属性的设置平行。\n在下面的示例中，给出一个包含颜色的 list()，其中第一个列表元素将成为第一个颜色比例的参数，第二个列表元素将用于第二个颜色比例，依此类推。其他只需要长度为一的参数可以作为向量输入。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 #为了绘制具有多种颜色scale的图，我们首先需要制作有具有另类aes图层 #我们将为每个物种选择一个色标。 #这将产生一些警告，因为ggplot2不知道如何处理另类aes。 g \u0026lt;- ggplot(iris, aes(Sepal.Width, Sepal.Length)) + geom_point(aes(SW = Sepal.Width), data = ~ subset(., Species == \u0026#34;setosa\u0026#34;)) + geom_point(aes(PL = Petal.Length), data = ~ subset(., Species == \u0026#34;versicolor\u0026#34;)) + geom_point(aes(PW = Petal.Width), data = ~ subset(., Species == \u0026#34;virginica\u0026#34;)) g \u0026lt;- g + scale_colour_multi( aesthetics = c(\u0026#34;SW\u0026#34;, \u0026#34;PL\u0026#34;, \u0026#34;PW\u0026#34;), name = list(\u0026#34;Blue\u0026#34;, \u0026#34;Pink\u0026#34;, \u0026#34;Orange\u0026#34;), colours = list( brewer_pal(palette = \u0026#34;YlGnBu\u0026#34;)(6), brewer_pal(palette = \u0026#34;RdPu\u0026#34;)(6), brewer_pal(palette = \u0026#34;YlOrRd\u0026#34;)(6) ), guide = guide_colorbar(barheight = unit(50, \u0026#34;pt\u0026#34;)) ) g 字符legend 说明颜色或填充美学的直接映射的一种简单但有效的方法是使用彩色文本。ggh4x可以通过设置guide =\u0026ldquo;stringlegend\u0026quot;作为颜色和填充比例的参数，或设置guides(colour =\u0026quot;stringlegend\u0026quot;)来完成此操作。\n1 2 3 ggplot(diamonds, aes(price, carat, colour = clarity)) + geom_point(shape = \u0026#34;.\u0026#34;) + scale_colour_brewer(palette = \u0026#34;Dark2\u0026#34;, guide = \u0026#34;stringlegend\u0026#34;) 1 2 3 4 5 p \u0026lt;- ggplot(mpg, aes(displ, hwy)) + geom_point(aes(colour = class)) p + guides(colour = guide_stringlegend(spacing.x = 0, spacing.y = 5, family = \u0026#34;mono\u0026#34;, ncol = 2)) 调整坐标轴 首先，假设我们已经熟悉了坐标轴的基础设置方法，比如x,y轴(line,ticks,text)位置和主题，第二坐标轴等等：\n1 2 3 4 5 6 7 8 9 ggplot(economics, aes(date)) + geom_line(aes(y = unemploy)) + geom_line(aes(y = pop / 30), colour = \u0026#34;red\u0026#34;) + scale_y_continuous( sec.axis = sec_axis( ~ .x * 30, name = \u0026#34;pop\u0026#34;, guide = guide_axis_colour(colour = \u0026#34;red\u0026#34;)) ) + theme(axis.line.y = element_line()) 截断坐标轴 截断轴并不是一个非常特殊的轴：它只是使轴线变短。默认情况下，它将轴线修剪到最外面的断裂位置。\n1 2 3 4 g \u0026lt;- ggplot(mtcars, aes(wt, mpg)) + geom_point() + theme(axis.line = element_line(colour = \u0026#34;black\u0026#34;)) g + guides(x = \u0026#34;axis_truncated\u0026#34;) 这个可以灵活应用：\n1 2 3 4 5 6 7 8 9 10 11 df \u0026lt;- data.frame(x = seq(-3, 3, length.out = 6), y = LETTERS[1:6]) ggplot(df, aes(x, y)) + geom_col() + scale_x_continuous( breaks = -3:0, guide = \u0026#34;axis_truncated\u0026#34;, sec.axis = dup_axis( breaks = 0:3, guide = \u0026#34;axis_truncated\u0026#34; ) ) + theme(axis.line.x = element_line()) 手动设置坐标轴 1 2 3 4 5 g + guides(y.sec = guide_axis_manual( breaks = unit(c(1, 3), \u0026#34;cm\u0026#34;), labels = expression(\u0026#34;treshold\u0026#34;^2, \u0026#34;annotation\u0026#34;[3]), label_colour = c(\u0026#34;red\u0026#34;, \u0026#34;blue\u0026#34;), label_size = c(8, 12) )) 设置ticks 在小中断所在的位置也可以放置刻度线。 次要刻度的长度由 ggh4x.axis.ticks.length.minor 主题元素控制，并使用 rel() 函数相对于主要刻度指定。\n1 2 3 g + guides(x = \u0026#34;axis_minor\u0026#34;) + theme(axis.ticks.length.x = unit(0.5, \u0026#34;cm\u0026#34;), ggh4x.axis.ticks.length.minor = rel(0.5)) 次要刻度的一个变化是为对数轴放置刻度。需要注意的是，这些在 log10 转换中效果最好。ticks现在有三种长度：主要长度、次要长度和所谓的“迷你”长度。与次要刻度一样，迷你刻度也是相对于主要刻度来定义的。\n1 2 3 4 5 6 7 pres \u0026lt;- ggplot(pressure, aes(temperature, pressure)) + geom_line() pres + scale_y_log10(guide = \u0026#34;axis_logticks\u0026#34;) + theme(axis.ticks.length.y = unit(0.5, \u0026#34;cm\u0026#34;), ggh4x.axis.ticks.length.minor = rel(0.5), ggh4x.axis.ticks.length.mini = rel(0.2)) 嵌套坐标轴 具有某种类别或交互作用的离散变量可以以嵌套方式布局。这可以方便地指示例如组成员身份。\n在下面的示例中，我们使用interaction()函数将项目的名称及其所属的组粘贴在一起，并使用\u0026rdquo;.\u0026ldquo;为分割。 Guide_axis_nested() 函数尝试分割“.”上的标签。用于区分项目及其组成员身份的符号。为了解决在排序项目时使用interaction() 和paste0() 带来的一些麻烦，ggh4x 提供了weave_factors() 便利函数，该函数尝试保留它们出现的因子级别的自然顺序。\n1 2 3 4 5 6 7 8 9 10 df \u0026lt;- data.frame( item = c(\u0026#34;Coffee\u0026#34;, \u0026#34;Tea\u0026#34;, \u0026#34;Apple\u0026#34;, \u0026#34;Pear\u0026#34;, \u0026#34;Car\u0026#34;), type = c(\u0026#34;Drink\u0026#34;, \u0026#34;Drink\u0026#34;, \u0026#34;Fruit\u0026#34;, \u0026#34;Fruit\u0026#34;, \u0026#34;\u0026#34;), amount = c(5, 1, 2, 3, 1), stringsAsFactors = FALSE ) ggplot(df, aes(interaction(item, type), amount)) + geom_col() + guides(x = \u0026#34;axis_nested\u0026#34;) 1 2 3 4 5 6 df$type2 \u0026lt;- c(rep(\u0026#34;Consumables\u0026#34;, 4), \u0026#34;Vehicle\u0026#34;) df$appletea \u0026lt;- c(\u0026#34;\u0026#34;, rep(\u0026#34;Ingredient of apple tea\u0026#34;, 2), rep(NA, 2)) ggplot(df, aes(weave_factors(item, type, appletea, type2), amount)) + geom_col() + guides(x = \u0026#34;axis_nested\u0026#34;) 内部坐标轴 对于某些图，我们可能有兴趣让图的轴与最低限制以外的其他值相交。要将轴放置在绘图面板内，我们可以使用 coord_axes_inside()。默认情况下，如果原点不在限制范围内，coord_axes_inside() 将尝试将轴放置在原点 (0, 0) 或最接近原点的点处。\n1 2 3 4 5 p \u0026lt;- ggplot(mpg, aes(displ - mean(displ), hwy - mean(hwy))) + geom_point() + theme(axis.line = element_line()) p +coord_axes_inside() ","date":"2024-10-09T00:00:00Z","image":"/p/ggh4x-ggplot2/images/README-facets-1_hu_99617bfe487f0196.png","permalink":"/p/ggh4x-ggplot2/","title":"ggh4x包拓展ggplot2绘图"},{"content":"Introduction 微生物群体中存在遗传异质性，新的遗传多态性可以通过突变迅速出现，其频率会因漂变、选择或链接选择而变化。在人类个体的微生物群系中，每天可能会产生数十亿到数万亿的新突变。这些差异可能具有临床意义，例如，肠杆菌科的抗生素抗性可能由仅三个点突变引起。\n传统方法通过分离和分析多个细胞来研究这些变异，现代则使用基因组解析宏基因组分析，从环境中提取和测序DNA，并通过计算工具组装和分箱这些DNA序列。虽然短读长测序无法准确确定群体中的完整单倍型，但这种技术可以同时分析微生物群体中的所有物种，识别基因变异及其频率，并衡量群体内的异质性。\ninStrain 是一种用于分析宏基因组中共存基因组群体的工具，于2021年发表在Nature Biotechnology上[1]。inStrain可进行高度准确的基因组比较、覆盖度、微多样性和连锁分析，以及通过基因定位和同义非同义识别进行灵敏的 SNP 检测。在与现有方法进行基准测试时，发现inStrain大大提高了基因组比较的准确性。\n软件主页：https://github.com/MrOlm/inStrain\n官方教程：https://instrain.readthedocs.io/en/latest/，很详细。\nInstallation inStrain的安装非常简单，通过conda或者pip都可以安装。\npip 1 $ pip install instrain 需要自己另外安装samtools即可，samtools很常用，大家一般都有。\nbioconda 1 $ conda install -c conda-forge -c bioconda -c defaults instrain From source 1 2 3 4 5 $ git clone https://github.com/MrOlm/instrain.git $ cd instrain $ pip install . Concepts \u0026amp; Glossary 重要概念 inStrain 及其生成的数据概述 InStrain 是一个用于微生物宏基因组分析的工具，能评估群落内生物体的存在、丰度及遗传异质性。\n当你对任何微生物基因组进行测序时，其实就对一群细胞进行了测序。这个群体可能是从培养瓶中的分离物中生长出来的近乎克隆的群体，或者是现实世界中高度异质性的群体，但该群体内始终存在真正的生物遗传异质性。每个细胞的每个位置都不具有相同的基因型。 InStrain 可以确定群落中生物体的存在/不存在，测量和询问微生物群体中的遗传异质性，并对不同样本中的生物体进行详细比较。\n它通过将宏基因组读数映射到代表性基因组上，计算核苷酸多样性、SNS、SNV、连锁、pN/pS、iRep等指标，分析种群间的遗传差异。InStrain 还可以高精度比较不同样本中的种群，提供每个样本中基因组覆盖率、popANI、conANI 及菌株间所有差异位点等信息。下图是workflow概述：\n使用代表性基因组 代表性基因组是被选择来代表某些类群的基因组，它们是基于 inStrain 的宏基因组分析的基本单位。比如想用 inStrain 研究一个群落的物种水平组成，他们会使用一组物种代表性基因组(SRG) 。代表性基因组也可以用于更具体的分类水平，需要确保它们真正代表它们想要的分类群，比其他常见方法有几个优点，包括能够将完整读段对与目标序列对齐、使用整个基因组来确定存在和不存在以及执行高分辨率比较等：\n代表性基因组的集合称为基因组数据库。基因组数据库可以从公共存储库下载，通过从头序列组装和分箱或两者的组合生成。重要的是要确保基因组数据库中的每个基因组与数据库中的其他基因组足够不同，以避免映射混乱，并且通过同时（竞争性）映射到基因组数据库中的所有基因组，可以显着减少错误映射的数量整体reads。\n挑选和评估代表性基因组 代表性基因组通常通过首先使用某个ANI阈值聚类一组基因组，然后选择每个簇中的一个基因组来代表该簇。一个好的代表性基因组应具有高质量、连续性、高基因内容相似性及与其代表的所有基因组具有相似的ANI。常用的dRep程序通过评分系统选择得分最高的基因组作为代表。\n运行inStrain profile会生成关于样本中每个代表性基因组的大量信息，可用于评估其与真实种群的匹配程度，如平均读长ANI、参考conANI、参考popANI及广度与预期广度的比较。\n基因组数据库的建立和评估 基因组数据库通常是通过使用程序 dRep 使用某些 ANI 阈值对一组基因组进行聚类来创建的。 dRep 文档描述了选择 ANI 阈值时需要考虑的一些注意事项。最常见的阈值是 95% ANI，它代表物种级聚类 (Olm mSystems 2020)，以及 98% ANI，这大约是建议的最严格阈值。使用这些阈值中的任何一个通常都是安全的选择，您选择的阈值取决于您想要执行分析的分辨率级别。这些阈值确保基因组彼此足够不同，但又不会太不同。\na) 确保基因组彼此不同\nb) 确保基因组彼此之间没有太大差异\nc) 确保样品中的所有微生物都具有适当的代表性基因组\n处理和减少错误映射读段 如上所述，使用 inStrain 建立基因组数据库的一个主要方面是减少映射到错误基因组的读数数量。当对一个群落进行宏基因组测序时，会从该群落的每个群体中生成读数。读数映射的目标是将每个读数分配给代表该读数起源的群体的基因组。当读段映射到的基因组不代表该读段起源的群体时，它就是错误映射的读段。当一个读段同样很好地映射到多个基因组（然后随机分配到一个或另一个基因组）或当来自远亲群体的读段映射到不适当的基因组时，可能会发生读段错误映射。\n通过竞争性映射减少读段错误映射\n通过调整 min_read_ani 减少读段错误映射\n通过调整 MapQ 减少读段错误映射\n检测宏基因组数据中的生物体 宏基因组分析的关键第一步是确定哪些代表性基因组“存在”或“不存在”（因此也确定它们代表的微生物种群）。这实际上比表面上看到的更复杂，主要是由于多重映射读段和错误映射读段造成的。上面讨论了这些现象的细节，但结果是，仅仅因为基因组具有映射到它的读数并不意味着该基因组实际上存在于样本中。\n许多研究根据覆盖范围或相对丰度等指标来确定存在/不存在。但这并不好，因为很容易出现大量错误映射的读段。有无数的例子表明基因组以 100 倍覆盖率和 2% 相对丰度被检测到，但在查看映射时发现所有读数都映射到基因组上的单个原噬菌体。这些指标的问题在于它们是全基因组平均值，因此它们无法解释大量读数映射到基因组小区域的情况。大多数人都会同意，仅检测到基因组上的原噬菌体或转座子不应视为该基因组“存在”，因此我们需要超出覆盖范围的指标和 2% 的相对丰度来确定存在/不存在。\n菌株水平比较和 popANI InStrain 能够在多个宏基因组样本中检测到的生物体之间进行详细、准确、微多样性感知的菌株水平比较。这是使用命令 inStrain 对已使用命令 inStrain profile 进行分析的多个样本进行比较来完成的。\n要理解为什么“微多样性感知”基因组比较很重要，请考虑以下事实：所有天然微生物种群都存在一定程度的基因组异质性。\n上图不同的颜色代表不同的个体，每片叶子代表一个单独的分离株。从这些数据中可以看出，虽然每个个体都有独特的微生物种群，但每个个体内部也存在很大的多样性（称为种内遗传变异（物种内）、患者内遗传变异（患者内部）或微多样性）。了解这一事实引出了一个问题：如何准确比较具有种内遗传变异的群体？一些常见的方法包括比较每个样本中的“平均”基因组（共有基因组）或比较多个单独的分离株。\nInStrain 使用上面描述的指标 popANI 执行微多样性感知比较，该指标也与更常见的基于共识的 ANI 指标 conANI 一起报告。一旦你（真正）理解了 popANI 和 conANI 的计算并不复杂，但描述可能很棘手，描述它的最简单方法是使用上面显示的示例。\n计算 conANI 和 popANI 的第一步是识别基因组中两个样本覆盖度≥5x 的所有位置。该数字报告为“compare_bases_count”，它描述了能够比较的碱基对 (bp) 的数量。接下来，inStrain 遍历这些可比较的碱基对中的每一个，并确定该位置是否存在 conANI 替换和/或该位置是否存在 popANI 替换。\n上图的左半部分描述了将导致 popANI 和 conANI 替换的条件。如果两个样本具有相同的主要等位基因（例如，两个样本中该位置最常见的碱基相同），则不会调用任何替换。如果样本具有不同的主要等位基因（例如样本 1 中最常见的碱基是 A，样本 2 中最常见的碱基是 C），则会调用 conANI 替换。如果两个样本（主要或次要）之间没有共享的等位基因，则将调用 popANI 替换。\n在上图右侧，我们看到了几个实际的例子。在顶行中，两个样本中没有相同的等位基因，因此该位点将同时算作 conANI SNP 和 popANI SNP。在第二行中，两个样本中的共有等位基因不同（左侧样本中为 G，右侧样本中为 T），因此将调用 conANI SNP。然而，样本确实共享一个等位基因（T 存在于两个样本中），因此这不会被视为 popANI 替代。在第三行中，两个样本具有相同的共有等位基因并且共享等位基因，因此不调用替换。在最后一行中，样本具有不同的共有等位基因（左侧为 G，右侧为 T），因此将调用 conANI 替换，但样本之间存在等位基因重叠（两个样本都有 G 和 T），因此将调用 popANI 替换不会被调用。\n一旦我们有了compare_bases_count、conANI SNP 的数量和popANI SNP 的数量，conANI 和popANI 的计算就很简单了。\n$$ popANI = ({compared bases count} - {popANI snps}) / {compared bases count} \\\\ conANI = ({compared bases count} - {conANI snps}) / {compared bases count} $$\n确定“相同”与“不同”菌株的阈值 一旦 inStrain 进行了菌株水平比较，就必须确定某个阈值来将微生物定义为“相同”或“不同”菌株。上图说明了一些用于定义微生物之间各种关系的常见 ANI 值（左上）、一些先前报告的原位微生物进化速率（左下）以及各种 ANI 阈值的分歧时间估计（左上）。右边是使用犬类分类学的类比。\n上图说明了如何使用宽松的 ANI 阈值来定义相对广泛的生物体群体，例如犬属或家犬种。亚种分类水平，在微生物世界中称为菌株，在狗世界中称为品种，描述了特定物种内的生物群体。微生物世界中的菌株定义并不一致，但显示了一些菌株 ANI 阈值示例。然而，菌株内部通常仍然存在一些变异。例如，虽然同一品种的狗彼此相似，但它们彼此并不相同。同样，基于 99% ANI 定义的同一菌株的微生物可能已经分化了大约 44,000 年（基于左下角粗体的原位突变率）。显然，已经分化了数万年的微生物彼此并不相同。因此，如果我们想知道样本是否与最近的微生物传播事件有关，我们需要一个超出典型菌株水平的极其严格的“相同”定义。\n为了识别与最近的传播事件相关的微生物，我们需要尽可能严格的 ANI 阈值。例如，99.9999% ANI 代表不到 10 年的分歧时间，可能是一个有用的指标。然而，宏基因组测序很混乱，在这种严格程度下工作时，我们需要考虑我们的检测极限。基准部分包含有关使用定义的微生物群落的 inStrain 检测限的数据。结论是，99.999% popANI 对于相同菌株来说是一个良好、高度严格的定义，其范围在宏基因组分析的检测。除了 popANI 之外，还必须考虑在比较的两个样本中具有足够覆盖度的基因组部分。该值（报告为percent_genome_compared）更多的是一个判断调用，但我们建议除了 popANI 阈值之外，还至少需要 25% 或 50%的percent_genome_compared。\n计算 popANI 时代表性基因组的重要性 InStrain 菌株水平比较基于代表性基因组的映射。为了使其正常工作，具有变异的读段必须能够映射到“–min_read_ani”阈值内的代表性基因组。请注意，默认情况下，inStrain 比较将使用 inStrain 配置文件命令期间选择的 \u0026ndash;min_read_ani。\n使用 inStrain 进行基于基因的功能分析 InStrain 不具备注释基因的能力。然而，inStrain确实能够深入分析样本中的所有基因，包括分析覆盖度、覆盖度变异、基因pN/pS、核苷酸多样性、个体SNV等。然后可以将这种基因级信息与基因注释结合起来执行稳健的功能分析。任何数据库都可用于此类分析，包括用于蛋白质结构域注释的 pFam、用于抗生素抗性基因注释的 ABRicate、用于一般蛋白质注释的 UniRef100 以及用于 CAZyme 注释的 dbCAN。\n减少inStrain资源使用 运行 inStrain 时要考虑的两个计算资源是给定的进程数 (-p) 和计算机上的 RAM 量。 使用 inStrain v1.3.3，在中等大小（1 Gbp 或更小）的 .bam 文件上运行 inStrain 通常需要不到一个小时（6 核），并使用大约 8Gb 的 RAM。 InStrain 还设计用于处理大型 .bam 文件。例如，运行具有 32 个内核的巨大 .bam 文件 (30 Gbp) 将需要大约 2 小时，并使用大约 128Gb 的 RAM。为 inStrain 提供的进程越多，它的运行速度就越快，但它使用的 RAM 也就越多。\n在日志文件夹中，InStrain 提供了大量关于它在哪里花费了时间以及在哪里使用了 RAM 的信息。\n要减少 RAM 使用，您可以尝试以下操作：\n使用 --skip_mm 标志。这不会在 mm 级别上分析事物，并且会将每个读段对视为完美映射。这对于大多数应用程序来说都是完美的 映射到基因组数据库时，请确保并使用 --database_mode 标志。这将做一些事情来尝试减少 RAM 使用。 使用更少的进程 (-p)。使用更多进程将使 inStrain 运行得更快，但同时也会使用更多 RAM。 术语表 简要介绍一下inStrain涉及到的一些术语，具体内容可查看https://instrain.readthedocs.io/en/latest/overview.html。\n平均核苷酸相似性 (ANI)：衡量两个基因组或.fasta文件之间的平均核苷酸距离。若两个基因组每100个碱基有一个不同，ANI为99%。\n共有ANI (conANI)：基于共有序列计算的ANI值，通常就是\u0026quot;ANI\u0026quot;。基因组的每个位置由最常见的等位基因表示，忽略次要等位基因。\n群体ANI (popANI)：一种新型ANI计算方法，考虑主要和次要等位基因。若两个群体在某位点共享任何等位基因，popANI不计为差异。\n物种代表基因组 (SRG)：表示单一微生物物种的代表基因组。\n基因组数据库：一组代表基因组，用于映射。\n核苷酸多样性（nucleotide diversity）：测量群体内的遗传多样性。计算方法是1减去每个碱基频率的平方和。\n微多样性（microdiversity）：指同一微生物种内的遗传变异。\n克隆性（clonality）：核苷酸多样性的相反值，这是旧版本程序中使用的已弃用术语。\n单核苷酸变异 (SNV)：群体中存在的单个核苷酸变化。\n单核苷酸替换 (SNS)：两个群体间的固定核苷酸差异。如果参考基因组在某个位置有“A”，但所有reads在该位置都有“C”，则这将是 SNS，（如果一半read有“A”，一半read有“C”，这是一个 SNV）。\n分歧位点：基因组中存在SNV或SNS的位点。\n单核苷酸多态性 (SNP)：因不同解释而避免使用，改用SNS、SNV等术语。\n连锁（linkage）：两个分歧位点共同遗传的可能性。\n覆盖度（coverage）：测序深度的度量。覆盖率计算为映射到某个区域的平均reads数。如果contig中一半的碱基有 5 个reads，另一半有 10 个reads，则contig的覆盖率为 7.5。\n广度（breadth）：某区域被测序read覆盖的程度。\n预期广度：在特定覆盖值下，read均匀分布时的预期广度。\n相对丰度：某基因组的read占总read的百分比。\nContig：连续的DNA序列。\nScaffold：可能包含未知长度间隙的DNA序列。\niRep：DNA提取时群体复制速度的度量，可以查看量化细菌生长动态。\n突变类型：描述核苷酸突变对蛋白质氨基酸序列的影响。N = 非同义突变（编码的氨基酸因突变而改变）。 S = 同义突变（编码的氨基酸不会因突变而改变；由于密码子冗余，应该为1/6 的随机次数）。 I = 基因间突变。 M = 具有多个改变的多等位基因 SNV（罕见）。\ndN/dS：评估基因突变倾向于同义突变还是非同义突变的比例。dN/dS 是根据相对于参考基因组的突变计算的。 dN/dS \u0026gt; 1 意味着偏向于 N 突变，表明该基因正在主动选择突变。 dN/dS \u0026lt; 1 表示偏向于 S 突变，表明该基因处于稳定选择状态，不会发生突变。 dN/dS = 1 意味着 N 和 S 突变以随机突变位置所预期的速率进行，可能表明该基因无功能。\npN/pS：与dN/dS相似，但基于多等位基因位点计算。\nfasta文件：包含DNA序列的文件。\nbam文件：包含映射到DNA序列的宏基因组read的文件。\nscaffold-to-bin文件：记录scaffold及其所属bin/基因组的文件。\n基因文件：包含所有基因序列的文件。\nmismapped read：错误映射到基因组的read。\nmulti-mapped read：同样匹配到多个位置的read。\ninStrain分析文件：通过inStrain profile命令创建的配置文件，包含程序的内部工作和输出数据。\n空模型：描述在Q30评分下，由随机突变误差引起的变异碱基支持的真实read数的概率。\n最大错配数 (mm)：一个read对可以拥有的最大错配数。\nMapQ评分：表示read与特定位置的对齐程度的评分。\nUsage 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 $ inStrain -h ...::: inStrain v1.3.2 :::... Matt Olm and Alex Crits-Christoph. MIT License. Banfield Lab, UC Berkeley. 2019 Choose one of the operations below for more detailed help. See https://instrain.readthedocs.io for documentation. Example: inStrain profile -h Workflows: profile -\u0026gt; Create an inStrain profile (microdiversity analysis) from a mapping. compare -\u0026gt; Compare multiple inStrain profiles (popANI, coverage_overlap, etc.) Single operations: profile_genes -\u0026gt; Calculate gene-level metrics on an inStrain profile [DEPRECATED; USE profile INSTEAD] genome_wide -\u0026gt; Calculate genome-level metrics on an inStrain profile quick_profile -\u0026gt; Quickly calculate coverage and breadth of a mapping using coverM filter_reads -\u0026gt; Commands related to filtering reads from .bam files plot -\u0026gt; Make figures from the results of \u0026#34;profile\u0026#34; or \u0026#34;compare\u0026#34; other -\u0026gt; Other miscellaneous operations Input 以下是生成 inStrain 输入文件的总结：\ninStrain 的主要输入：inStrain 的主要输入包括一个包含参考基因组序列的 fasta 文件和一个包含映射到这些序列的读段的 bam 文件。此外，可以选择提供一个基因 .fna 文件来计算基因水平的指标，或者提供一个 scaffold-to-bin 文件来在基因组水平上计算指标。\n准备 fasta 文件：fasta 文件包含用于映射读段的 contig 的 DNA 序列。选择合适的 fasta 文件（如共识/参考基因组）会影响 inStrain 结果的解释。常见的策略包括：\n使用 de novo 组装的基因组（推荐）：从待分析的宏基因组样本中组装基因组，进行差异覆盖分箱，去重并过滤低质量基因组，创建 scaffold-to-bin 文件，建立代表性基因组的 bowtie2 索引，并将读段映射到这些基因组上。 使用单一基因组的 fasta 文件：如果使用单个基因组，建议该基因组能够良好地代表样本中的某个生物体。在解析结果之前，建议检查 inStrain 生成的图表输出和 scaffold_info.tsv 输出文件，以确保有足够的覆盖度和覆盖范围。 使用宏基因组组装：可以将整个宏基因组组装传递给 inStrain，包括已分箱和未分箱的 contig。输出将包含每个 contig 的种群信息。为了按微生物基因组/物种进行分类，可以提供 scaffold-to-bin 文件。 准备 bam 文件：inStrain 主要设计用于配对末端 Illumina 读段测序，但通过调整运行时参数，也可以使用未配对的读段。建议使用 Bowtie2 来将读段映射到基因组。\n默认情况下，Bowtie2 的 -X 参数为 500（表示预期插入长度）。在某些情况下（如 2x250 bp 或插入片段较长的数据集），可以将该值增加至 -X 1000。 如果需要删除多重映射的读段，可以将最小 mapQ 分数设置为 2。 其他映射软件也可以生成用于 inStrain 的 bam 文件，但需要注意软件的设置，尤其是一些软件（如 BBmap 和 SNAP）在生成 bam 文件时使用 fasta 文件的 scaffold 描述，这可能会导致问题。可以使用 --use_full_fasta_header 标志来解决此问题。\n准备基因文件：可以使用 Prodigal 软件在 fasta 文件上运行，以生成包含基因信息的 .fna 文件。该 .fna 文件可以用于 inStrain profile 以获取基因水平的特征。\n准备 scaffold-to-bin 文件：运行 inStrain profile 后，大多数结果都是基于 scaffold 来呈现的。为了在基因组或基因水平上分析结果，可以使用多种方法告诉 inStrain 哪些 scaffold 属于哪个基因组：\n单个 fasta 文件：将所有单独的基因组连接成一个 fasta 文件并映射到该文件上。 scaffold-to-bin 文件：这是一个两列的文本文件，一列列出 scaffold 名称，另一列列出基因组 bin 名称。 无需指定：如果所有 scaffold 都属于同一个基因组，则运行 inStrain profile 时不使用任何 -s 选项，inStrain 会将所有 scaffold 的结果汇总在一起。 profile profile 是 inStrain 的核心命令，用于创建 inStrain 分析结果。\n输入和输出：inStrain profile 的输入为一个 fasta 文件和一个 bam 文件，输出为一个 IS_profile。\n读取过滤：首先，过滤 bam 文件中的所有读段，只保留那些映射质量足够高的读段。默认情况下，所有非成对的读段将被过滤掉，还会对每个读段对（而不是单个读段）应用一系列额外的过滤。用户可以通过命令行参数来调整具体的过滤条件。通常来说：\n读段对必须以正确的方向和预期的插入大小进行映射。可以通过命令行参数设置最小插入距离，最大插入距离是中位插入距离的倍数。例如，如果成对读段的中位插入大小为 500bp，默认情况下，所有插入大小超过 1500bp 的成对读段将被排除。 读段对必须有一个最低的 mapQ 分数。mapQ 分数用于表示映射中的错配数量以及映射的唯一性。如果读段同样映射到基因组的两个位置（多重映射读段），其 mapQ 分数将被设置为 2。 读段对的核苷酸同一性(ANI) 值必须高于某个最小值。例如，如果读段对的每个读段都是 100bp 且每个读段有一个错配，则该对的 ANI 将为 0.99。 微多样性指标计算：仅使用通过过滤的读段对，逐个 scaffold 计算一系列微多样性指标，包括：\n计算 scaffold 上每个位置的覆盖度。 计算覆盖度超过 min_cov 参数的每个位置的核苷酸多样性。 识别 SNS 和 SNV。作为不同位点被报告的标准是：1）该位置的碱基数超过 min_cov；2）变异碱基的读段百分比超过 min_freq；3）具有变异碱基的读段数超过该覆盖的零模型。 计算同一读段对上不同位点之间的连锁性。对于每个具有不同位点的成对读段，计算该位点与同一对中其他不同位点之间的连锁性。仅对至少有 MIN_SNP 读段的不同位点对进行此操作。 计算 scaffold 级别属性：包括整体覆盖度、覆盖广度、读段与参考基因组之间的平均核苷酸同一性（ANI）以及基于实际覆盖度的预期覆盖广度等。\n数据存储：最终，这些信息被存储为一个 IS_profile 对象，其中包括不同位点的位置、每个 scaffold 通过过滤的读段对数量及其他信息、SNV 对之间的连锁性等。\n1 2 3 4 5 6 7 8 9 mkdir bt2 bowtie2-build test_data/N5_271_010G1_scaffold_min1000.fa bt2/N5_271_010G1_scaffold_min1000.fa bowtie2 -p 4 -x bt2/N5_271_010G1_scaffold_min1000.fa -1 test_data/N5_271_010G1.R1.fastq.gz -2 \\ test_data/N5_271_010G1.R2.fastq.gz \u0026gt; N5_271_010G1_scaffold_min1000.fa-vs-N5_271_010G1.sam inStrain profile N5_271_010G1_scaffold_min1000.fa-vs-N5_271_010G1.sam \\ test_data/N5_271_010G1_scaffold_min1000.fa -o N5_271_010G1_scaffold_min1000.fa-vs-N5_271_010G1.IS \\ -p 4 -g test_data/N5_271_010G1_scaffold_min1000.fa.genes.fna -s test_data/N5_271_010G1.maxbin2.stb Output 详细解释查看：https://instrain.readthedocs.io/en/latest/example_output.html\nscaffold_info.tsv 这提供了有关样品中scaffold的基本信息，以及允许的最高读段同一性级别。\nscaffold：输入 .fasta 文件中序列的名称。\nlength：输入 .fasta 文件中序列的全长。\ncoverage：序列的平均覆盖深度。例如，如果一半的碱基被5个读长覆盖，另一半被10个读长覆盖，则覆盖深度为7.5。\nbreadth：序列中至少被一个读长覆盖的碱基百分比。breadth 为1表示所有碱基至少有一个读长覆盖。\nnucl_diversity：计算所有具有核苷酸多样性值的碱基的平均核苷酸多样性。如果仅一个碱基满足计算核苷酸多样性的最低覆盖率，则该序列的nucl_diversity为该碱基的核苷酸多样性。\ncoverage_median：序列中所有碱基的覆盖深度中位数，包括覆盖深度为0的碱基。\ncoverage_std：所有覆盖值的标准差。\ncoverage_SEM：所有覆盖值的平均值的标准误差。\nbreadth_minCov：序列中至少达到 min_cov 覆盖度的碱基百分比，例如具有核苷酸多样性值且满足调用SNVs的最小测序深度的碱基百分比。\nbreadth_expected：预期的breadth；根据给定的覆盖值，如果读长均匀分布在基因组上，这会告诉你应该期望的breadth。例如，覆盖深度为10x时，预期breadth将接近1。\nnucl_diversity_median：计算所有具有核苷酸多样性值的碱基的中位核苷酸多样性。\nnucl_diversity_rarefied：在至少有 --rarefied_coverage（默认50x）覆盖度的位置之间的平均核苷酸多样性，这些值通过随机子集化该位置的读长来计算。\nnucl_diversity_rarefied_median：稀释核苷酸多样性的中位数。\nbreadth_rarefied：序列中至少有 --rarefied_coverage 覆盖度的碱基百分比。\nconANI_reference：读段和参考基因组之间的 conANI。\npopANI_reference：读段和参考基因组之间的 popANI。\nSNS_count：在该序列上调用的SNS总数。\nSNV_count：在该序列上调用的SNV总数。\ndivergent_site_count：在该序列上调用的分歧位点总数。\nconsensus_divergent_sites：读段的共识等位基因与参考基因组不同的分歧位点总数，这些在 conANI_reference 计算中计为“差异”。\npopulation_divergent_sites：读段的任何等位基因（主要或次要）中没有参考基因组碱基的分歧位点总数，这些在 popANI_reference 计算中计为“差异”。\nmapping_info.tsv 这提供了映射到每个支架的读段数量的概述，以及有关其质量的一些基本指标。\nscaffold: 输入 .fasta 文件中的 scaffold 名称。对于第一行，它将显示为 all_scaffolds，表示所有行的总和。\npass_pairing_filter: 通过选择配对过滤器的读段数量（默认情况下只有配对读段才能通过此过滤器）。\nfiltered_pairs: 通过所有阈值的读段对数量。\nmedian_insert: 所有映射到此 scaffold 的读段对的中位插入距离。\nmean_PID: 所有映射到此 scaffold 的读段对的平均百分比 ID（与参考 .fasta 文件相比）。\npass_min_insert: 映射到此 scaffold 的读段对中，通过最小插入尺寸阈值的数量。\nunfiltered_reads: 映射到此 scaffold 的原始读段数量。\nunfiltered_pairs: 映射到此 scaffold 的原始读段对数量。inStrain 只使用配对读段。\npass_min_read_ani: 映射到此 scaffold 的读段对中，通过 min_read_ani 阈值的数量。\nfiltered_priority_reads: 通过所有其他过滤器的优先读段数量（仅当提供优先读段输入文件时才会非零）。\nunfiltered_singletons: 检测到的只有一个读段配对被映射的读段数量。\nmean_insert_distance: 所有映射到此 scaffold 的读段对的平均插入距离。插入大小从第一个读段的起点到第二个读段的终点计算（两个完全重叠的 50bp 读段的插入大小为 50bp）。\npass_min_mapq: 映射到此 scaffold 的读段对中，通过最小 mapQ 分数阈值的数量。\nmean_mismatches: 所有映射到此 scaffold 的读段对的平均错配数。\nmean_mapq_score: 所有映射到此 scaffold 的读段对的平均 mapQ 分数。\nunfiltered_priority_reads: 因为是优先读段输入文件的一部分而通过配对过滤器的读段数量（仅当提供优先读段输入文件时才会非零）。\npass_max_insert: 映射到此 scaffold 的读段对中，通过最大插入尺寸阈值的数量——即它们的插入尺寸小于 all_scaffolds 中位插入尺寸的 3 倍。插入大小从第一个读段的起点到第二个读段的终点计算（两个完全重叠的 50bp 读段的插入大小为 50bp）。\nfiltered_singletons: 检测到的只有一个读段配对被映射并通过过滤的读段数量。仅当过滤设置允许非配对读段时，才会非零。\nmean_pair_length: 所有映射到此 scaffold 的读段对的平均总长度。\nSNVs.tsv 这描述了在此映射中检测到的 SNV 和 SNS。虽然我们应该将这些突变称为分歧位点，但有时 SNV 也用于指代 SNV 和 SNS：\nscaffold: 包含该 SNV 的 scaffold。\nposition: SNV 的基因组位置。\nposition_coverage: 在该位置检测到的读段数量。\nallele_count: 超出背景水平的碱基数量（根据零假设模型）。allele_count 为 0 表示没有碱基被读段支持；为 1 表示只有一个碱基被读段支持；为 2 表示两个碱基被读段支持，等等。\nref_base: 在该位置参考 .fasta 文件中的碱基。\ncon_base: 共识碱基（由最多读段支持的碱基）。\nvar_base: 变异碱基；由第二多读段支持的碱基。\nref_freq: 支持参考碱基的读段比例。\ncon_freq: 支持共识碱基的读段比例。\nvar_freq: 支持变异碱基的读段比例。\nA, C, T, 和 G: 编码每种碱基的映射读段数量。\ngene: 如果包含基因文件，此列将指示 SNV 是否位于基因的编码序列中。\nmutation: 氨基酸变化的简写代码。如果是同义突变，格式为 S: + 位置；如果是非同义突变，格式为 N: + 旧氨基酸 + 位置 + 新氨基酸。注意，这里的氨基酸位置总是从基因组文件的左到右计算，不论是正链还是反链。\nmutation_type: 突变类型。N = 非同义，S = 同义，I = 基因间，M = 存在多个基因无法确定。\ncryptic: 如果 SNV 是隐藏性的，这意味着在使用较低读段错配阈值时检测到，但在更高的错配水平下检测不到。\nclass: 此变异位点的分类。选项有 SNS（allele_count 为 1，con_base 不等于 ref_base），SNV（allele_count \u0026gt; 1，con_base 等于 ref_base），con_SNV（allele_count \u0026gt; 1，con_base 不等于 ref_base，且 ref_base 存在于读段中），pop_SNV（allele_count \u0026gt; 1，con_base 不等于 ref_base，且 ref_base 不存在于读段中），DivergentSite（等位基因计数为 0），以及 AmbiguousReference（ref_base 不是 A、C、T 或 G）。\nlinkage.tsv 这描述了映射中在同一读段对上至少发现 min_snp 次的 SNP 对之间的关联。\n连锁主要用于确定生物体是否正在进行水平基因转移。它针对至少可以通过 min_snp 读段连接的 SNP 对进行计算。它基于每个 SNP 都有两个等位基因（例如，a A 和 b B）的假设。\nscaffold: 包含两个SNP的scaffold。 position_A: scaffold上第一个SNP的位置。 position_B: scaffold上第二个SNP的位置。 distance: 两个SNP之间的距离。 r2: r平方连锁度量，用于衡量连锁不平衡。 d_prime: d\u0026rsquo;连锁度量，用于衡量连锁不平衡。 r2_normalized, d_prime_normalized: 通过将读取对稀释到最小SNP数计算得到的标准化r平方和d\u0026rsquo;值。 allele_A: position_A处的一个碱基。 allele_a: position_A处的另一个碱基。 allele_B: position_B处的一个碱基。 allele_b: position_B处的另一个碱基。 countab: 具有allele_a和allele_b的读取对的数量。 countAb: 具有allele_A和allele_b的读取对的数量。 countaB: 具有allele_a和allele_B的读取对的数量。 countAB: 具有allele_A和allele_B的读取对的数量。 total: 具有position_A和position_B信息的读取对的总数。 gene_info.tsv 这描述了有关正在分析的基因的一些基本信息：\n以下是 inStrain 输出文件中各字段的中文描述：\nscaffold: 基因所在的scaffold。 gene: 被分析的基因名称。 gene_length: 基因的长度（以核苷酸为单位）。 breadth: 基因中至少有1倍覆盖度的碱基数量。 breadth_minCov: 基因中至少达到最小覆盖度（min_cov）的碱基数量。 nucl_diversity: 基因中所有具有核苷酸多样性值的碱基的平均核苷酸多样性。 start: 基因的起始位置（scaffold上的位置，0索引）。 end: 基因的结束位置（scaffold上的位置，0索引）。 direction: 基因的方向（基于prodigal调用）。若为-1，表示基因的编码方向与.fasta文件中表达的方向相反。 partial: 若为True，表示这是一个部分基因；根据Prodigal提供的记录描述中不包含partial=00。 dNdS_substitutions: 此基因中检测到的SNS的dN/dS值。如果没有检测到N和/或S取代，则为空。 pNpS_variants: 此基因中检测到的SNV的pN/pS值。如果没有检测到N和/或S SNV，则为空。 SNV_count: 此基因中检测到的SNV总数。 SNV_S_count: 此基因中检测到的同义SNV数量。 SNV_N_count: 此基因中检测到的非同义SNV数量。 SNS_count: 此基因中检测到的SNS总数。 SNS_S_count: 此基因中检测到的同义SNS数量。 SNS_N_count: 此基因中检测到的非同义SNS数量。 divergent_site_count: 此基因中检测到的不同位点数量。 genome_info.tsv 在逐个基因组的水平上描述上述许多指标，而不是逐个scaffold的水平：\ngenome：被分析的基因组名称。如果所有的 scaffolds 是一个单独的基因组，则显示为“all_scaffolds”。 coverage：该基因组所有 scaffolds 的平均覆盖深度。 breadth：该基因组所有 scaffolds 的覆盖广度。 nucl_diversity：该基因组所有 scaffolds 的平均核苷酸多样性。 length：该基因组在所有 scaffolds 上的总长度。 true_scaffolds：基于 scaffold-to-bin 文件，该基因组中存在的 scaffolds 数量。 detected_scaffolds：至少有一个读段对其进行映射的 scaffolds 数量。 coverage_median：基因组中所有碱基的覆盖深度的中位数。 coverage_std：所有覆盖值的标准差。 coverage_SEM：所有覆盖值的均值标准误（使用 scipy.stats.sem 计算）。 breadth_minCov：在 scaffold 上至少有 min_cov 覆盖的碱基百分比（例如，具有 nucl_diversity 值并满足最低测序深度以调用 SNVs 的碱基百分比）。 breadth_expected：如果读段在基因组上均匀分布，基于报告的覆盖值，您应该期望的覆盖广度。基于公式 breadth = -1.000 * e^(0.883 * coverage) + 1.000。这有助于确定 scaffold 是否实际存在于读段中，还是只是 scaffold 的一部分。如果您的覆盖为 10x，期望的广度将为 ~1。如果实际广度显著低于期望广度，这意味着读段仅映射到 scaffold 的特定区域（转座子、前噬菌体等）。 nucl_diversity_rarefied：在至少具有 \u0026ndash;rarefied_coverage（默认 50x）的位点之间的平均核苷酸多样性。这些值也通过随机子集化该位置的读段到 \u0026ndash;rarefied_coverage 读取来计算。 conANI_reference：读段与参考基因组之间的 conANI。 popANI_reference：读段与参考基因组之间的 popANI。 iRep：该基因组的 iRep 值（如果能够成功计算）。 iRep_GC_corrected：iRep 值是否经过 GC 偏差校正的真/假值。 linked_SNV_count：该基因组中可能连接的不同位点的数量。 SNV_distance_mean：连接的不同位点之间的平均距离。 r2_mean：连接的 SNVs 之间的平均 r2（有关 linkage.tsv 的更多信息请参见上述说明）。 d_prime_mean：连接的 SNVs 之间的平均 d prime（有关 linkage.tsv 的更多信息请参见上述说明）。 consensus_divergent_sites：在这些位点中，读段与参考基因组具有不同的一致性等位基因的总数。这些计入 conANI_reference 计算中的“差异”，而 breadth_minCov * length 计入分母。 population_divergent_sites：在这些位点中，读段没有任何等位基因（主要或次要）作为参考基因组的碱基的总数。这些计入 popANI_reference 计算中的“差异”，而 breadth_minCov * length 计入分母。 SNS_count：在该基因组上调用的 SNS 总数。 SNV_count：在该基因组上调用的 SNV 总数。 filtered_read_pair_count：通过过滤并映射到该基因组的读段对的总数。 reads_unfiltered_pairs：映射到该基因组的对数（过滤或未过滤）。 reads_mean_PID：映射到参考基因组的读段对的平均 ANI。 reads_unfiltered_reads：映射到该基因组的读段总数（过滤或未过滤）。 divergent_site_count：在该基因组上调用的不同位点的总数。 Plots InStrain 会画出一些默认的pdf图形：\nCoverage and breadth vs. read mismatches\n覆盖广度（蓝线）、覆盖深度（红线）和给定覆盖深度的预期覆盖广度（虚线蓝线）相对于映射读段的最低 ANI。覆盖深度持续增加，而覆盖广度达到平台期，表明参考基因组的所有区域并未出现在被映射的读段中。\nGenome-wide microdiversity metrics\nSNV 密度、覆盖率和核苷酸多样性。在核苷酸多样性和 SNV 密度的峰值处，覆盖率并没有增加，表明这些信号并非由读段错误映射导致。存在核苷酸多样性但无 SNV 密度的位点，是指存在多样性但不高到足以调用 SNV 的位置。\nRead-level ANI distribution\n映射到参考基因组时读段对 ANI 水平的分布；该图表明参考基因组与映射读段之间的差异超过 1%。\nMajor allele frequencies\n双等位基因 SNV 的主要等位基因频率分布（位点频率谱）。主要频率低于 50% 的等位基因是多等位基因位点的结果。缺乏明显的点状分布，表明存在不止几种不同的菌株。\nLinkage decay\nSNV 链接与 SNV 之间距离的关系；链接衰减是重组的常见信号。\nRead filtering plots\n显示在过滤过程中有多少读段被过滤掉的条形图。所有百分比基于成对读段的数量；要了解因非成对而被过滤掉的读段数量，可以比较顶部条形图和第二个顶部条形图。\nScaffold inspection plot (large)\n这是一个扩展版本的全基因组微多样性指标图，足够长，可以在 y 轴上读取 scaffold 名称。\nLinkage with SNP type (GENES REQUIRED)\n非同义 SNP 对以及所有 SNP 对的链接图。\nGene histograms (GENES REQUIRED)\n所有分析基因的值的直方图。\nCompare dendrograms (RUN ON COMPARE; NOT PROFILE)\n基于 popANI 和共享碱基对所有样本进行比较的树状图。\nReferences Olm, M.R., Crits-Christoph, A., Bouma-Gregson, K. et al. inStrain profiles population microdiversity from metagenomic data and sensitively detects shared microbial strains. Nat Biotechnol 39, 727–736 (2021). https://doi.org/10.1038/s41587-020-00797-0 ","date":"2024-09-01T00:00:00Z","image":"/p/instrain/images/OverviewFigure1_v1_hu_b3af78fb78c6a9fb.webp","permalink":"/p/instrain/","title":"使用InStrain进行宏基因组群体分析"},{"content":"Introduction 群体遗传学（Population Genetics）是研究在群体水平上基因频率的变化及其影响因素的学科。它结合了遗传学、进化生物学和统计学的方法来分析基因在群体中的分布和变化。\n群体（Population）指的是一组同一物种的个体，它们生活在同一地理区域内，并能够相互交配和繁殖。这个群体的个体共享一个共同的基因库（gene pool），即所有个体的基因及其等位基因的集合。\n群体有几个特征：\n物种一致性：群体中的所有个体属于同一个物种，意味着它们在生物学上能够相互交配并产生具有生殖能力的后代。\n地理相对性：群体通常指在特定地理区域内的个体集合，虽然不同群体之间可能会有基因交流（如迁移），但通常被认为是相对隔离的。\n基因库：群体内的个体共享一个基因库，这意味着在群体内部进行的所有交配，都会影响该群体的基因频率和遗传结构。\n交配能力：群体中的个体能够进行随机或非随机的交配，产生后代，从而使得群体的基因频率在世代之间发生变化。\n在群体遗传学研究中，群体的概念是基础，因为研究的主要目标是理解在不同条件下（如自然选择、基因漂变、基因流动、突变等），一个群体的基因频率和基因型频率是如何变化的。\n群体遗传学的研究帮助科学家理解进化过程、物种形成、群体间的遗传差异及其对环境变化的适应能力等。\nConcepts 以下是群体遗传学中一些相关概念的简要介绍：\nLocus（基因座）：指基因或DNA片段在染色体上的特定位置。基因座可以是一个特定基因的位置，也可以是任意DNA序列的位置。\nVariation/Mutation（变异/突变）：指基因或DNA序列中发生的变化。突变是引起变异的过程，是基因组中遗传信息的永久性改变。\nIndel（插入/缺失）：指DNA序列中发生的短片段插入或缺失变异。Indel可导致基因功能的变化，尤其是在编码区发生时。\nSNP（单核苷酸多态性）：指基因组中单个核苷酸的位置上的变异，是一种常见的遗传变异形式。\nAlleles（等位基因）：指位于同一基因座的不同版本或变体。一个基因座可以有多个等位基因。\nSV（结构变异，Structural Variation）：指基因组中涉及大片段DNA的变异，通常定义为长度大于50个碱基对的变异。SV包括多种类型的变异，如：\n缺失（Deletion）：基因组中一段DNA片段的丢失。 重复（Duplication）：一段DNA片段的重复。 倒位（Inversion）：一段DNA片段在基因组中的方向发生了反转。 易位（Translocation）：一段DNA片段从一个位置移动到另一个位置。 插入（Insertion）：一段新的DNA片段插入到基因组中。 CNV（拷贝数变异，Copy Number Variation）：属于结构变异的一种，指基因组中某段DNA序列的拷贝数发生了变化，导致这段序列的拷贝数多于或少于通常的两个拷贝。CNV可以包括：\n基因扩增（Gene Amplification）：某段DNA的拷贝数增加。 基因缺失（Gene Deletion）：某段DNA的拷贝数减少。 Haplotypes（单倍型）：指一组位于同一染色体上的紧密连锁的基因或遗传标记的组合，通常作为一个整体进行遗传。\nSelection（选择）：自然选择的过程，通过优先传递适应环境的基因，影响群体中基因频率的变化。\nPositive selection（正选择）：有利于有益突变的传播和保持。 Negative selection（负选择）：排除有害突变，维持群体基因组的稳定性。 Genetic drift（基因漂变）：群体中的等位基因频率由于随机抽样效应而发生的变化，尤其在小群体中更为显著。\n核苷酸多样性 (π) ：测量群体中任意两个个体的基因序列之间平均差异的程度。反映了群体的遗传多样性。\n非同义突变率与同义突变率的比值 (dN/dS) ： 非同义突变率（dN）是引起氨基酸序列变化的突变率，同义突变率（dS）是不引起氨基酸序列变化的突变率。dN/dS比值用于判断是否存在选择压力。\ndN/dS = 1：指非同义替代和同义替代发生的概率相等，通常表示该基因区域处于中性进化状态，即没有选择压力，仅靠随机突变率演化。 dN/dS \u0026lt; 1：指非同义替代的发生率低于同义替代，通常表示负选择（或净化选择，purifying selection）。在这种情况下，非同义突变可能对生物体不利或有害，因此被自然选择淘汰。 dN/dS \u0026gt; 1：指非同义替代的发生率高于同义替代，通常表示正选择（positive selection）。在这种情况下，非同义突变可能带来有利的适应性优势，因此被自然选择保留下来。 LD（连锁不平衡，Linkage Disequilibrium）：指在一个群体中，两个或多个位点上的等位基因频率之间存在统计学上的非随机关联。换句话说，在一个群体中，某些等位基因组合比随机预期的频率出现得更多或更少。\n完全连锁平衡（LD = 0）：两个等位基因之间的组合是随机的，意味着它们独立遗传。 完全连锁不平衡（LD = 1）：两个等位基因总是一起遗传，意味着它们之间存在强烈的关联。 Tajima\u0026rsquo;s D：是一个统计量，用于检测群体中核苷酸多样性和序列分化的异常，进而判断是否存在自然选择或其他进化力（如人口扩张、收缩等）。\nTajima\u0026rsquo;s D = 0：表示核苷酸多样性和序列分化之间的一致性，通常意味着该群体处于中性进化状态，即没有自然选择作用。 Tajima\u0026rsquo;s D \u0026gt; 0：表示观测到的核苷酸多样性较高，序列间的差异较少，可能表明存在平衡选择或群体结构（如两个或多个亚群体的混合）。 Tajima\u0026rsquo;s D \u0026lt; 0：表示观测到的核苷酸多样性较低，序列间的差异较大，可能表明存在正选择（有利突变的快速扩散）或人口扩张。 D\u0026rsquo;（D-系数）：衡量两个遗传位点间连锁不平衡（LD）程度的指标，取值范围从0到1。D\u0026rsquo; = 1 表示完全连锁，D\u0026rsquo; = 0 表示无连锁。\n重组率 (1-D\u0026rsquo;) ： 重组率用于衡量两个位点之间的重组频率。1-D\u0026rsquo;表示在连锁不平衡（LD）中，反映了重组事件的相对频率。\nDivergence（分歧）：描述不同种群或物种之间的基因差异程度，反映了进化过程中累积的遗传变化。\nMolecular clock（分子钟）：假设特定DNA序列的突变速率恒定，用于估计不同物种或种群间分歧时间的工具。\nFounder effect（奠基者效应）：小群体从大群体中分离出来形成新的群体时，因最初几个创始者的基因组成差异而导致的新群体基因频率变化。\nBottleneck effect（瓶颈效应）：指群体经历了急剧的数量减少后，存活个体的基因组成对整个群体基因频率产生显著影响，通常伴随遗传多样性的减少。\nHardy-Weinberg定律 Hardy-Weinberg定律（Hardy-Weinberg Law），又称为哈迪-温伯格平衡定律，是群体遗传学中的一个基本原则。它描述了在一个理想的随机交配的群体中，等位基因和基因型的频率在世代之间保持恒定的状态。这一定律是由英国数学家G.H. Hardy和德国医生Wilhelm Weinberg在1908年独立提出的。\nHardy-Weinberg定律的条件 Hardy-Weinberg定律成立的前提条件是：\n无突变：没有新的等位基因通过突变加入到群体中。 无自然选择：所有基因型的生存和繁殖成功率相等，没有选择压力。 无限大的群体：群体的大小足够大，以至于基因频率的变化不受随机基因漂变的影响。 随机交配：群体中的个体是随机交配的，没有任何形式的非随机交配（如近亲交配或择偶偏好）。 无基因流：没有来自其他群体的基因引入，也没有个体迁出群体。 Hardy-Weinberg定律的数学表达 假设在一个二倍体群体中，一个基因座有两个等位基因：A和a。我们定义：\np：等位基因A的频率（取值范围为0到1）。 q：等位基因a的频率（取值范围为0到1）。 根据等位基因频率的定义，有$p + q = 1$。\n根据Hardy-Weinberg定律，基因型频率（AA、Aa和aa）的平衡状态可以用等位基因频率来表示：\nAA的频率：$p^2$ Aa的频率：$2pq$ aa的频率：$q^2$ 这些频率之和也等于1：\n$ p^2 + 2pq + q^2 = 1 $\nHardy-Weinberg平衡的应用 检测选择压力：通过比较观测到的基因型频率和预期的Hardy-Weinberg平衡频率，可以检测是否存在自然选择或其他进化因素的作用。\n估算等位基因频率：利用基因型频率来估算等位基因频率，尤其在研究隐性遗传病的频率时。\n基因库的稳定性：在一定条件下，如果一个群体的基因库符合Hardy-Weinberg平衡，则可以认为该群体的基因库在无外部干扰情况下是稳定的。\n实际应用中的偏离 在现实中，许多群体不完全符合Hardy-Weinberg平衡条件，可能因为：\n自然选择：不同基因型具有不同的适应性。 小群体效应：基因漂变在小群体中更为显著。 非随机交配：如近亲交配或选择性交配。 基因流：来自其他群体的基因引入。 偏离Hardy-Weinberg平衡可以揭示关于群体演化过程的有价值的信息。\nVCF VCF（Variant Call Format 是一种用于存储和描述基因组变异（如SNP、插入、缺失等）的文本文件格式。VCF文件广泛用于基因组学研究，尤其是在分析和存储从基因组测序数据中识别出的变异时。\nVCF文件由**头部（Header）和数据区（Data section）**两部分组成。\n头部（Header） 头部部分以“#”开头，包含文件的元信息和描述变异的相关注释。常见的头部信息包括：\n文件格式版本：例如，##fileformat=VCFv4.2。\n样本信息：例如，##SAMPLE=\u0026lt;ID=Sample1,Description=\u0026quot;Sample description\u0026quot;\u0026gt;。\n参考基因组信息：例如，##reference=ftp://ftp.1000genomes.ebi.ac.uk/...。\n信息字段的描述：例如，##INFO=\u0026lt;ID=DP,Number=1,Type=Integer,Description=\u0026quot;Total Depth\u0026quot;\u0026gt;，描述变异的附加信息。\n格式字段的描述：例如，##FORMAT=\u0026lt;ID=GT,Number=1,Type=String,Description=\u0026quot;Genotype\u0026quot;\u0026gt;，描述样本格式信息。\n数据区（Data section） 数据区包含实际的变异信息，每行表示一个变异。数据区以一行以“#CHROM”开头的字段名称作为标题行，常见的字段有：\nCHROM：染色体号，表示变异所在的染色体。\nPOS：位置，表示变异在染色体上的位置（1-based）。\nID：变异的标识符（若无信息则为“.”）。\nREF：参考碱基或参考序列，表示参考基因组中该位置的碱基。\nALT：替代碱基或替代序列，表示变异后的碱基或序列。\nQUAL：变异的质量得分，通常为Phred质量分数。\nFILTER：变异的过滤信息，描述该变异是否通过了特定的质量过滤标准（如“PASS”表示通过）。\nINFO：附加信息字段，包含与变异相关的各类注释和统计信息。\nFORMAT：样本格式字段，描述以下各列样本数据的格式。\n样本数据：每个样本的变异信息，根据FORMAT字段中的描述显示具体数据，如基因型、覆盖度等。\n例子\n下面是一个简单的VCF文件示例：\n1 2 3 4 5 ##fileformat=VCFv4.2 ##source=Example #CHROM POS ID REF ALT QUAL FILTER INFO FORMAT Sample1 1 123456 rs123456 G A 50 PASS DP=100;AF=0.5 GT:DP 0/1:35 1 789101 . T C,G 99 PASS DP=200;AF=0.25,0.75 GT:DP:AD 1/2:60:10,20 在这个例子中：\n第一个变异在1号染色体的123456位点，参考碱基是G，替代为A，质量得分50，通过了过滤，附加信息显示总深度（DP）为100，等位基因频率（AF）为0.5，样本1的基因型（GT）是0/1，覆盖度（DP）是35。\n第二个变异在1号染色体的789101位点，参考碱基是T，替代为C和G（多等位基因变异），质量得分99，通过了过滤，附加信息显示总深度（DP）为200，等位基因频率（AF）分别为0.25和0.75，样本1的基因型（GT）是1/2，覆盖度（DP）是60，等位基因深度（AD）分别为10和20。\n使用场景\nVCF文件主要用于： - 基因组变异分析：存储和分析个体或群体的基因变异。 - 临床基因组学：用于个体的基因组测序数据分析，帮助检测可能的致病突变。 - 进化研究：比较不同物种或个体之间的基因组差异。 - 群体遗传学：研究群体中等位基因的分布和频率。\nVCF格式标准化且易于扩展，适合存储大规模基因组数据，并支持丰富的注释信息，是基因组学研究中的重要工具。\n","date":"2024-08-29T00:00:00Z","image":"/p/pop-genetic/images/hw-law_hu_ec248f47da51b771.png","permalink":"/p/pop-genetic/","title":"群体遗传学基础学习"},{"content":"https://www.cnblogs.com/meet/p/18057112\nhttps://packaging.python.org/en/latest/tutorials/packaging-projects/\n开发自己的Python库是一项非常有趣且有益的任务。以下是创建和发布Python库的步骤：\n1. 规划和准备 确定库的功能：首先确定你的库将要实现的功能，并明确其目标用户。 设计API：考虑如何设计库的接口，使其易于使用和理解。 2. 设置项目结构 创建一个项目目录，目录结构如下：\n1 2 3 4 5 6 7 8 9 10 11 12 your_library_name/ ├── your_library_name/ │ ├── __init__.py │ ├── module1.py │ ├── module2.py ├── tests/ │ ├── test_module1.py │ ├── test_module2.py ├── setup.py ├── README.md ├── LICENSE └── .gitignore your_library_name/: 主库代码的目录。 __init__.py: 使目录成为Python包，并可在其中导入模块。 tests/: 存放测试代码的目录。 setup.py: 用于库的配置和安装。 README.md: 项目的描述文件。 LICENSE: 开源协议文件。 3. 编写代码 模块开发：在your_library_name目录下编写各模块代码。 测试开发：在tests目录下编写测试代码，确保库功能的正确性。 4. 配置setup.py setup.py 是Python库的安装配置文件，典型的文件内容如下：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 from setuptools import setup, find_packages setup( name=\u0026#39;your_library_name\u0026#39;, version=\u0026#39;0.1\u0026#39;, packages=find_packages(), install_requires=[ # 列出依赖的包，如需使用 ], author=\u0026#39;Your Name\u0026#39;, author_email=\u0026#39;your.email@example.com\u0026#39;, description=\u0026#39;A brief description of your library\u0026#39;, long_description=open(\u0026#39;README.md\u0026#39;).read(), long_description_content_type=\u0026#39;text/markdown\u0026#39;, url=\u0026#39;https://github.com/yourusername/your_library_name\u0026#39;, # 代码仓库的URL license=\u0026#39;MIT\u0026#39;, classifiers=[ \u0026#39;Programming Language :: Python :: 3\u0026#39;, \u0026#39;License :: OSI Approved :: MIT License\u0026#39;, \u0026#39;Operating System :: OS Independent\u0026#39;, ], python_requires=\u0026#39;\u0026gt;=3.6\u0026#39;, ) 5. 编写README.md 介绍库的功能和使用方法。 示例代码：提供一些简单的示例代码，展示如何使用你的库。 6. 编写测试 使用unittest或pytest编写测试，确保库在各种情况下都能正常运行。 7. 版本控制 使用Git进行版本控制，并将代码托管在GitHub等平台上。 8. 发布到PyPI 注册PyPI账户：PyPI 是Python包的官方仓库。 生成发布包： 1 python setup.py sdist bdist_wheel 安装twine并上传： 1 2 pip install twine twine upload dist/* 9. 安装和使用库 发布后，你可以通过以下命令安装你的库： 1 pip install your_library_name 10. 维护和更新 定期更新和维护你的库，修复bug，添加新功能。 ","date":"2024-08-21T00:00:00Z","permalink":"/p/python-pkg/","title":"尝试开发一个自己的Python库"},{"content":"CQ师姐做的一个纸杯微塑料项目，非常有意思，揭示了日常生活中真实来源的孕期微塑料暴露，对生殖和代谢性能的影响和调控机制。我参与了其中的部分实验和分析，学习了养小鼠，灌胃，解剖和部分塑料的定性定量等实验，还画了一个小鼠解剖热图，收获颇丰。\nPaper Info 标题：Placental and fetal enrichment of microplastics from disposable paper cups: implications for metabolic and reproductive health during pregnancy 期刊：Journal of Hazardous Materials 发表时间：2024年8月15日 第一作者：陈琼 通讯作者：蒋超、陈琼 通讯单位：浙江大学生命科学研究院 链接：https://doi.org/10.1016/j.jhazmat.2024.135527 图片摘要 成果简介 近日，浙江大学生命科学研究院蒋超课题组在环境领域国际著名期刊Journal of Hazardous Materials上在线发表了题为\u0026quot;Placental and fetal enrichment of microplastics from disposable paper cups: implications for metabolic and reproductive health during pregnancy\u0026quot;的研究论文。该工作首次系统揭示了日常生活中真实来源的孕期微塑料暴露，对生殖和代谢性能的影响和调控机制。\n引言 微塑料(Microplastics, MPs；直径小于5毫米)已成为一种无处不在的环境污染物。人体可通过饮食、呼吸和皮肤接触等多种途径摄入MPs，导致其在多个组织中沉积。尽管MPs的潜在健康风险日益受到关注，但目前的研究仍存在诸多局限性，如仅关注合成的单一大小和性质的MPs，特别是在妊娠期间的影响尚未得到系统研究。\n图文导读 DPCs 中浓缩 MPs 的质量、尺寸分布和特征 图1. DPCs释放的MPs的特征:质量、粒径分布和性质。(A) MPs灌胃溶液。(B) 每次灌胃的MPs质量。(C) MPs代表性荧光复合图像。每个孔的图像由28张使用蒙太奇功能拍摄的图像组成。(D) 每次灌胃的MPs数量。(E) MPs粒径频率分布(蓝色)和累积分布(黄色)。垂直虚线表示平均粒径。(F) MPs粒径分布。(G) MPs的拉曼光谱分析图谱。(H) 从DPCs分离的内层塑料薄膜的热稳定性曲线。\n研究团队对五个知名品牌的DPCs进行了筛选,选择了一个释放MPs最多且颗粒最小的品牌进行深入研究。模拟人类日常DPCs使用水平,用热水冲泡纸杯并浓缩富集其中释放的MPs。值得注意的是,即使在最高剂量组中,MPs的质量仍在估计的人体暴露范围内,且相关物质(如重金属、阴离子和双酚A)的浓度均低于世界卫生组织(WHO)和美国环境保护署(USEPA)设定的安全阈值。研究团队创新性地使用BioTek Cytation 3技术对MPs进行了颗粒分布分析,结果显示各组MPs的粒径分布在6至154微米之间,且不同剂量组间的颗粒大小无显著差异。通过拉曼光谱和热稳定性分析,研究团队进一步确认这些MPs主要由聚苯乙烯组成。\nMPs 暴露导致母体生理变化和胎儿生长受限 图2. 孕鼠MPs暴露的实验设计及其对母鼠和胎儿的影响。(A) 总体实验设计。GD：妊娠天数。(B) 乳腺HE染色及腺泡占比的定量分析。每组中的N值分别为13（0 C）、11（1 C）、12（10 C）和11（100 C）。(C) 肝脏重量与体重比率。(D) 胎盘HE染色及迷宫区域的定量分析。(E) 胎鼠代表性图像。(F) 胎儿存活率。(G) 每窝胎儿的总重量。(H) 使用不同指标评估胎儿生长情况。\n研究团队模拟人类日常DPCs消费水平(相当于每天0、0.33、3.33和33.3个DPCs),以剂量梯度口服灌胃的方式处理孕鼠,分析其对生殖系统的潜在毒性影响。实验结果显示,MPs暴露导致母鼠乳腺腺泡发育受损,表现为腺泡占比降低。同时,肝脏与体重的比率呈现剂量相关增加的趋势,暗示可能出现肝肥大。在胎儿方面,MPs暴露导致胎盘迷宫区面积减小,可能影响胎盘功能。此外,胎儿存活率降低,活产胎儿的总重量减轻,个体生长指标也受到影响。研究指出,MPs暴露可能通过影响母体生理状态,如诱发肝肥大,进而间接影响胎儿的发育和生长。值得注意的是,这些影响呈现出明显的剂量依赖性,即暴露剂量越高,影响越显著。这项研究揭示了MPs暴露对孕期健康的潜在风险,为理解环境污染物对生殖健康的影响提供了重要依据。\n胎儿-母体组织中 MPs 的组织特异性粒径分布与受损表型相关 图3. 胎儿-母体组织中 MPs 组织特异性粒径分布与受损表型相关。(A) 不同组织中MPs的归一化数量。(B) MPs累积在小鼠解剖图示意图；彩色渐变表示不同组织中MPs的密度变化。(C) 100 C组中不同类型组织中积累的MPs。(D) 100 C组中MPs的大小分布。(E和F) 组织沉积的MPs对乳腺腺泡比例(E)和胎盘迷宫区域(F)的贡献比例。\n研究团队分析了孕鼠12种不同组织和胎鼠中MPs的粒径分布及其对受损表型的贡献。结果显示，除海马和肺部外，MPs在各组织中的沉积量与暴露剂量呈明显的剂量-响应关系。血液中MPs含量最低，表明MPs可能被其他组织吸收。在最高剂量组(100 C)中，盲肠内容物中MPs数量最高，达356,769 ± 101,087个/克。胎儿(190,436 ± 99,103个/克)、胎盘(171,573 ± 92,071个/克)、肾脏、脾脏、肺和心脏也显示出显著的MPs沉积。\n不同生物组织中MPs的大小存在显著差异，在100 C组中，55.16%到90.73%的MPs粒径小于10微米。值得注意的是，研究发现胎儿和胎盘中的MPs数量和粒径分布没有显著差异，表明胎盘对MPs并没有明显的过滤作用，MPs可以直接通过胎盘进入胎儿体内。大脑组织中检测到的MPs最小，可能与血脑屏障有关。拉曼光谱分析确认了这些颗粒与摄入的MPs相似。\n多元回归模型表明，各组织中积累的MPs可解释12.4%～35.4%的受损表型。例如，乳腺组织中的MPs沉积对乳腺腺泡比例的降低贡献了12.4%的解释度。血液、小脑、肝脏和大脑皮层中的MPs共同解释了35.4%的胎盘迷宫区变化，其中血液中的MPs贡献最大。这些发现揭示了MPs在体内的组织特异性分布可能对多个器官系统产生影响，特别是对胎儿发育构成潜在风险。\nMPs 暴露引起的微生物组功能紊乱 图4. 微生物组成与功能变化的分析。(A) 微生物多样性呈现，外环表示每个物种的丰度。饼图详细展示了微生物群体的总体相对丰度。(B) 物种水平上的PCoA分析，箱线图显示显著性 (C) 棒棒糖图展示暴露剂量依赖性显著富集的属。(D) 网络图表明Alistipes属（随MPs暴露增加；橙色）和Romboutsia属（随MPs暴露减少；绿色）的丰度变化。(E) 棒棒糖图展示不同功能类别中显著富集的代谢途径。(F) PWY6285（脂肪酸生物合成；随MPs暴露增加）和PWY5833（葡萄糖生物合成；随MPs暴露减少）的网络图。\n研究团队对各组盲肠内容物进行了宏基因组测序分析，探讨MPs暴露对肠道微生物组的影响及其潜在作用机制。结果显示，不同暴露组在Bray-Curtis距离的主坐标分析(PCoA)中表现出明显分离，尤其是10 C组（相当于每天3.3杯）最为显著。使用课题组前期开发的广义报告得分分析（GRSA）方法，观察到盲肠微生物组从厚壁菌门向拟杆菌门的剂量相关转变。Alistipes属（与炎症和癌症相关）随MPs暴露增加，而Romboutsia属（与肠道稳态相关）则减少。在代谢功能方面，微生物脂肪酸的生物合成途径显著增强，而碳水化合物、氨基酸和核苷酸的代谢途径则下降。\n值得注意的是，中等剂量暴露水平（10C组）的微生物组成发生了显著变化，特别是厚壁菌门中参与代谢和免疫调节的属。这包括Parabacteroides、Oscillibacter和Dysosmobacter的增加，以及Turicibacter和Ligilactobacillus的减少。在功能通路方面，10 C组中脂肪酸合成途径显著上调，而氨基酸、核苷酸和能量代谢的生物合成途径则显著下调。特别是腺苷和鸟苷脱氧核糖核苷酸从头生物合成途径的显著下降，表明蛋白质和DNA核苷酸合成系统性下降。这些发现表明，即使是适度使用一次性纸杯，也可能导致肠道微生物组成和功能的显著变化，进而影响宿主的代谢和免疫功能。\nMPs 暴露导致组织特异性转录组畸变，具有潜在的健康影响 图5. 血液、胎盘和乳腺组织的转录组功能变化的分析。(A) 各组织显著变化的KEGG通路Venn图。(B) 血液中显著变化的KEGG通路。(C) 血液基因-功能整合Maptree，展示功能类别、KEGG通路和基因对应关系。(D) 胎盘中显著变化的KEGG通路 (E) 胎盘基因-功能整合Maptree。(F) 10C组与0C组对比的胎盘基因-功能整合Maptree。\n由于MPs在体内呈现组织特异性分布，研究人员推测这可能会导致组织特异性的基因表达改变。为探究MPs暴露对母鼠、胎儿和后代潜在的影响，研究团队对母鼠全血、乳腺组织和胎盘开展了转录组分析。\n分析结果显示，在母体血液样本中，多个通路呈现剂量依赖性增加，包括神经退行性疾病、病毒感染、核糖体功能、非酒精性脂肪肝、心肌收缩、氧化磷酸化和氧化应激等途径。与此同时，免疫和炎症相关途径则随剂量依赖性降低。胎盘组织中观察到许多与血液相似的功能变化，如上调的神经退行性疾病、病毒感染、核糖体功能和氧化磷酸化等通路。同时，研究也发现了一些胎盘特异性的变化，如N-糖基化合成的上调，这可能与生殖并发症有关，包括先兆子痫、宫内生长受限和流产风险增加。在乳腺组织中，研究团队观察到感染和免疫相关途径上调，而代谢和能量产生相关途径下调。\n值得注意的是，在中等暴露水平（10C组，相当于每天3.3杯）下，各组织均出现了显著的基因表达改变。特别是在胎盘中，复制和修复相关通路下调，而移植排斥和宿主抗移植物病相关通路上调，这可能暗示着流产风险的增加。这些发现揭示了MPs暴露可能通过影响多个组织的基因表达，对母体和胎儿健康产生广泛的影响。即使是适度的暴露水平也可能引起显著的分子水平变化，这强调了进一步研究MPs长期暴露对健康影响的必要性。\n基因基准剂量模型分析表明怀孕小鼠每日安全剂量为2-4 DPCs 图6. 来源于DPCs的MPs暴露BMDL评估。(A) 盲肠微生物、血液、胎盘和乳腺组织的分子标志物。(B) 使用组织特异性生物标志物评估BMDL。\n在毒理学和健康风险评估的背景下，建立关于DPCs的安全暴露阈值具有重要的实际生活指导意义。为此，研究团队结合MPs暴露后显著改变的表型数据和组织特异性生物标志物，计算了基准剂量下限（BMDL）。\n研究结果显示，尽管生理终点通常具有较高的安全限制（范围在每日15至38杯之间），但盲肠微生物组和基因标志物则指示出更低的安全限制，即每日2至4杯。这一发现突显了将分子水平终点纳入BMDL评估的重要性和敏感性。具体而言，研究发现多个组织特异性基因与炎症、神经退行性疾病和胎儿发育相关，这些基因对MPs暴露呈现剂量响应。例如，盲肠中Alistipes onderdonkii和Alistipes communis的增加与炎症和癌症风险相关。在血液、胎盘和乳腺组织中，Ptk2b、Uba52、Hbq1a、Anxa5、Ddx19b、Pycr1、Nqo2、Clec5a和Rpl26-ps6等基因标志物的变化表明，MPs暴露可能导致神经活动受损、DNA损伤修复能力下降、胎盘稳态受损以及氧化损伤和炎症增加等风险。\n小结 本研究首次系统揭示了在被普遍认为无害的DPCs消费水平下，MPs在孕鼠体内的组织特异性积累以及对代谢和生殖的毒性影响。研究发现除盲肠外，胎盘和幼鼠是微塑料富集最高的器官组织，且两者之间微塑料的含量和大小分布相差无几，提示胎盘在富集微塑料的同时，并没有明显的过滤作用，无法保护幼鼠免于微塑料暴露损伤。研究还发现，即使是每天3.3杯的适度消耗量，也可能对健康产生显著影响。这一发现尤为重要，因为这个消耗量不仅在一般人群的日常使用范围内，也在BMD评估的安全边际范围内。\n研究结果表明，MPs暴露可能对胎儿发育、盲肠微生物群、免疫健康、神经系统、代谢和生殖功能产生不利影响。这些发现可能具有广泛的人类健康意义，特别是对孕妇等高风险人群。这项研究强调了需要进一步评估和应对这些潜在健康危害的重要性。研究结果呼吁制定相应的食品安全法规，特别是针对孕妇等高风险人群。同时，这项研究也为未来探索环境污染物对人类健康长期影响的研究提供了重要的参考框架。\n陈琼博士为论文的第一作者，蒋超研究员、陈琼博士为论文的共同通讯作者。参与该研究的还有蒋超实验室的博士生彭晨、谢儒雯、魏昕，本科生徐浩腾、古丽米热·依力汗、沈跃然，西湖大学博士生苏卓杰，以及叶存奇研究员和其博士生杨森。研究课题受中国博士后科学基金和浙江大学生命科学研究院启动资金等项目资助。\n作者简介 通讯作者：蒋超，现任浙江大学生命科学研究院研究员、博导，兼聘浙江大学附属第一医院。长期致力于环境空气暴露组、微生物组、微生物进化、精准医学研究以及相关的分子实验和生信分析方法开发及应用。以通讯或一作在国际知名期刊Cell、Nature、Nature Protocols、Cell Reports、iMeta、ES\u0026amp;T、Journal of Hazardous Materials、Briefings in Bioinformatics、Cell Discovery、mSystems、STOTEN等杂志发表多篇研究论文，获得国内外专利若干。主持国自然专项等项目。任iMeta、iMetaomics、Scientific Reports、Current Microbiology、Bio-protocols副主编、The Innovation Life编委。\n第一作者兼共同通讯作者：陈琼，博士后，2019年博士毕业于浙江大学，研究方向为沙漠生态修复、微塑料暴露、环境空气暴露组、精准医学以及软件开发等。已在国际知名期刊Cell Discovery、Journal of Hazardous Materials、Nutrients、The Journal of Nutrition、Journal of Agricultural and Food Chemistry、Briefings in Bioinformatics等杂志发表多篇研究论文。长期担任Environmental Health Perspective、Current Microbiology、Journal of Food Science、Journal of Health and Pollution等杂志审稿人。\n","date":"2024-08-16T00:00:00Z","image":"/p/jhm/images/graphical_abstract_hu_a4f106c885aba0f5.png","permalink":"/p/jhm/","title":"浙江大学蒋超实验室在JHM发文揭示日常使用量的一次性纸杯释放的微塑料或可能影响孕期健康"},{"content":"Zotero 7.0 beta 版已经测试好久了，最近终于正式上线了。官方说Zotero 7是Zotero发布18年来最大的一次更新，它在设计、性能和功能性上都有了显著的提升。\n如果你已经在使用Zotero，可以通过Zotero内部的“帮助”菜单下的“检查更新\u0026hellip;”来升级。 Windows用户建议安装64位Zotero以获得最佳性能。Apple Silicon Mac的用户在从Zotero 6进行应用内升级后，Zotero 7会继续在Rosetta下运行，重新启动后将获得原生性能。\n官网下载：https://www.zotero.org/\n下面介绍一些新功能和好用插件。\n新功能 设计改版 Zotero 7带来了全新的现代化设计，虽然是重新设计，但依然保留了老用户熟悉的界面。\n新的项目面板： 项目面板是此次改动的重要部分之一，原来的水平标签（如信息、标签、笔记等）被折叠的垂直区域和侧边导航栏取代。这种设计允许在不影响使用性的情况下显示更多信息。此外，插件也可以更方便地创建专属的自定义信息或操作区域。 新的可自定义标题栏可以显示标题、标题/作者/日期，甚至是选择的引用格式的参考文献条目，且在信息部分折叠时，标题栏依然可见。\n暗黑模式： Zotero 7的设计中加入了全新的暗黑模式，确保每个部分都在暗黑模式下表现出色。此外，PDF和EPUB内容的基础暗黑模式支持也已经实现，未来还会有更多高级渲染选项。如果需要查看文档的原始状态，可以在阅读器的视图菜单中关闭内容的暗黑模式。 界面密度选择： Zotero 7现在提供两种界面密度选项：紧凑和舒适。紧凑模式类似于之前的密度，而舒适模式则是新的默认设置，适合新用户或较小的文献库用户，提供了更舒适的使用体验。\n新的应用图标： 为了配合全新的外观，Zotero 7还设计了一个全新的应用图标。\n自定义文件重命名 之前我是用第三方插件 zotfile 来完成附件重命名的，现在 Zotero 7已经原生支持了（zotfile插件也不能用了😂）。\n在“设置-常规-文件重命名“里面修改：\n默认命名格式是{{ firstCreator suffix=\u0026quot; - \u0026quot; }}{{ year suffix=\u0026quot; - \u0026quot; }}{{ title truncate=\u0026quot;100\u0026quot; }}\n我比较喜欢“年份-期刊-标题”的形式，所以可以参考官方说明修改为： {{ year suffix=\u0026quot; - \u0026quot; }}{{ journalAbbreviation suffix=\u0026quot; - \u0026quot; }}{{ title truncate=\u0026quot;100\u0026quot; }}\n智能参考弹窗 这个我觉得很牛，很好用。\n现在，悬停在引用或内部链接上时，会自动弹出显示相关参考文献或图表的窗口，不必再来回跳转查找参考内容。\n性能提升 Zotero 7在整体性能上有了显著提升，并支持Apple Silicon Mac、64位Windows和Windows on ARM，确保在最新硬件上的流畅运行。\n这个我感受了一下，不好说进步有多少。我是Mac air M2版本的，之前Zotero 6打开7-8个pdf经常会内存不足，要求我强制退出，现在Zotero 7基本不会，但是内存确实还是占了3-4GB。\n改进的阅读器 Zotero 7的内置PDF阅读器进行了重大升级，现在它不再仅仅是PDF阅读器，还支持EPUB格式。\nEPUB支持：EPUB是目前最流行的电子书格式，许多人更喜欢它的阅读体验。EPUB文档现在可以像PDF一样在Zotero的内置阅读器中打开，可以进行标注并将这些标注添加到笔记中。Zotero还可以自动检索大多数EPUB的元数据，并创建父项目。\n网页快照：Zotero保存的网页快照现在可以在新的阅读器中自动打开，使得标注网页变得和标注PDF一样方便。\n新的标注类型 Zotero 7支持创建墨迹、下划线和文本标注。墨迹标注已经在iOS上支持，现在也可以在桌面应用中使用（在触摸屏PC或手写笔设备上表现最佳）。下划线标注与高亮类似，文本标注则允许直接在页面上添加文本。\n更智能的引用 Zotero 7的引用过程变得更快且更直观。引用对话框会自动建议列表中选择的项目或在阅读器中打开的文档。引用你正在查看的内容现在只需点击“添加/编辑引用”并按Enter即可。\n这个是挺需要的功能，不然每次还要多一步搜索。\n其他 收藏夹搜索： 你可以在任意文献库中快速找到需要的收藏夹并跳转到它，无需手离键盘。\n标签菜单： 查看所有标签的垂直列表，输入关键字快速过滤列表，并快速跳转到指定标签。还可以直接从菜单中关闭或重新排列标签。\n附件预览： 在项目面板中直接预览PDF、EPUB、快照和图片，无需打开阅读器。\n回收站中的收藏夹和搜索： 被删除的收藏夹和搜索现在会被移到回收站中。如果不小心删除了收藏夹，可以轻松从回收站恢复，所有项目和子收藏夹都会保留。\n“文献库和收藏夹”列表： 项目面板中新增了一个部分，显示当前项目所在的所有收藏夹和文献库。\n自定义文件重命名： Zotero一直以来都支持自动重命名文件，现在你可以根据更多选项自定义文件名规则，确保文件名包含所有需要的信息。\n提高的可访问性： Zotero 7大大提升了对屏幕阅读器用户的可访问性，并改进了整个应用的键盘导航。未来还会有更多无障碍功能的改进。\n改进的插件架构： Zotero 7引入了新的插件架构，支持无缝加载/卸载插件，并内置了常见集成点（项目列表列、项目面板部分、设置面板等）的支持，使得插件更容易编写，并且在Zotero更新时更稳定。\n插件 Zotero 用户的活跃社区开发了各种插件来提供增强功能、新功能以及与其他程序的接口。 注意有些6.0里的插件在7.0里都失效了，需要重新安装或者寻找替代品。\n官方列表：https://www.zotero.org/support/plugins，不全，可以去github搜索更多插件，或者用下面的Zotero-Addons查找。\nZotero-Addons 这是一个用于在 Zotero 7 内浏览和安装插件的 Zotero 7 插件（用插件来管理插件）。\n安装后右上角就会出现“插件市场”的图标了，点击它就可以浏览和安装其他插件了（根据star数量排序，看看有哪些大家喜欢的）。\nTranslate for Zotero 读文献有时候还是需要借助翻译的。 Zotero PDF Translate是由@windingwind 开发的，用于文献管理软件Zotero的翻译插件。它完全开源、免费，主要功能有：\n划词翻译（自动/手动） 标题、摘要翻译与源文本/翻译结果显示切换 批注翻译（自动/手动） 支持15+种翻译服务与4+种字典服务 自定义翻译侧栏UI，支持同时使用多种翻译引擎 Better BibTex for Zotero Better BibTex是一款Zotero的插件，它可以自动生成BibTeX格式的参考文献，并自动更新到文献管理器中。我经常用Rmarkdown写东西，Rstudio和Zotero的连接需要Better BibTex。Latex论文写作时应该也要用到。\nJasminum 有些时候还是要看一些中文文献的，Jasminum是一个Zotero 中文插件，旨在提升 Zotero 中文用户的使用体验。主要功能有：\n中文期刊附件（PDF/CAJ）的元数据抓取，支持添加PDF/CAJ时自动抓取元数据功能 集成 Zotero 中文社区转换器的下载与更新功能 为知网学位论文PDF添加章节书签（依赖于PDFtk） 更新中文文献引用次数，核心期刊信息 合并/拆分姓，名，识别文献条目语言，下载知网附件，统一日期格式等 Zotero Reference Zotero Reference可以将文章中的参考文献展示在侧边栏，方便查阅参考文献。\nLinter for zotero 可以规范化/格式化条目的元数据（字段数据）。可以全部选中跑一遍Lint并修复。\nSciPDF Sci-Hub 应该不用多介绍。\n此插件利用了 Zotero 内自带的 PDF resolvers方案，将 Sci-Hub 的 resolver 自动填入 extensions.zotero.findPDFs.resolvers 字段，以实现在zotero内从sci-hub下载pdf。\n其他 Better Notes for Zotero，用的人非常多的一个笔记插件，不过我做笔记太懒了😂。 Awesome GPT，GPT帮忙读文献，可惜我没有API。 Ethereal Style，享受阅读文献的乐趣，但是可能会卡顿。 Actions and Tags，可以使用自定义脚本自动化您的工作流程！ ","date":"2024-08-15T00:00:00Z","image":"/p/zotero-7-0/images/library_hu_417ea8e412eadfdd.png","permalink":"/p/zotero-7-0/","title":"Zotero 7.0正式版，大更新！"},{"content":"Introduction 在微生物群落的研究中，分类和注释数量庞大的未培养古细菌和细菌病毒一直是一个难题，主要原因是缺乏统一的分类框架。\n目前，用于病毒分类的多种基于基因组的方法已经被提出，主要集中在细菌、古细菌和真核生物病毒的分类上。\n蛋白序列比较：早期方法使用完整基因组的蛋白序列进行配对比较，生成“噬菌体蛋白质树”。但因“镶嵌性”特征影响分类界限，这一方法未被广泛采用。\n共享基因的比例：另一些方法则基于共享基因的比例和同源基因的百分比定义病毒分类。然而，由于病毒进化模式变化大，这些方法未能有效处理所有已知的病毒群体。\nGBDP：基于基因组Blast距离的系统发育算法，如VICTOR工具，结合系统发育和聚类方法进行病毒分类。该方法的可扩展性有限，且对缺乏参考基因组的病毒分类效果有限。\n基因共享网络：基于病毒基因组间共享的蛋白质簇（PCs）构建的基因共享网络，已被证明与ICTV认可的分类基本一致。vConTACT v.1.0应用该方法实现了75%的一致性，并在全球海洋、淡水和土壤研究中用于大规模病毒分类。\n尽管这些方法各有优缺点，但基因共享网络逐渐成为病毒分类的重要工具，尤其在缺乏参考基因组的情况下发挥了关键作用。\nvConTACT2 vConTACT v.2.0 提供了一种可扩展的网络化解决方案，通过分析全基因组共享的基因模式，结合层次聚类和置信评分，实现病毒分类。它不仅能够成功复现已有的病毒分类，还可以高效处理大型宏基因组数据集，成为病毒分类的强大工具，适用于各种环境中的病毒研究。文章于2019年发表在Nature Biotechnology上[1]。\n在网络为基础的基因组分类算法中，相关的基因组通过多个边紧密连接。vConTACT v.2.0使用了一种新的两步聚类算法，以提高分类的准确性和鲁棒性。首先，基于蛋白质簇（PC）的马尔可夫聚类算法 (MCL) 被用于初步分类。然后，使用ClusterONE替代MCL以定义病毒簇（VC），并通过层次聚类进一步细分网络问题区域。此外，v.2.0 引入了拓扑和分类基础的置信度分数，以帮助识别和优化分类任务。 软件主页：https://github.com/Hocnonsense/vcontact2\n注意：由于资助结束，vConTACT2 不再被积极开发，尽管作者仍在修复错误并解决出现的其他问题。\n安装 1 2 3 4 # 注意使用python3.7而不是直接指定python=3，现在python版本太新了会出问题 conda create --name vContact2 python=3.7 source activate vContact2 conda install -y -c bioconda vcontact2 mcl blast diamond 再安装一下依赖的cluster_one：\n1 2 3 4 5 # 下载聚类软件，移动到conda/bin路径 (可使用win下载代替) wget -c http://www.paccanarolab.org/static_content/clusterone/cluster_one-1.0.jar java -jar cluster_one-1.0.jar -h chmod +x ./cluster_one-1.0.jar mv ./cluster_one-1.0.jar ~/miniconda3/bin/ 不然会报错：ERROR:vcontact2: Could not find ClusterONE java file.\nvContact2自带数据库，在~/miniconda3/envs/vContact2/lib/python3.7/site-packages/vcontact2/data/目录下。\n运行 主要参数： -r RAW_PROTEINS, \u0026ndash;raw-proteins RAW_PROTEINS：输入FASTA格式的蛋白质文件。如果同时提供--proteins-fn，vConTACT将从蛋白质簇(PC)生成前开始处理。 \u0026ndash;rel-mode {BLASTP, Diamond, MMSeqs2}：选择用于创建蛋白质相似性边文件的方法。默认使用Diamond。 -b BLAST_FP, \u0026ndash;blast-fp BLAST_FP：输入BLAST结果文件(CSV或TSV格式)，用于生成蛋白质簇。提供此选项时，将从PC生成步骤开始。 -p PROTEINS_FP, \u0026ndash;proteins-fp PROTEINS_FP：提供一个文件，将蛋白质名称与基因组名称链接。如果提供了--blast-fp，则从PC生成步骤开始。 \u0026ndash;db {None, ProkaryoticViralRefSeq85-ICTV, \u0026hellip;}：选择参考数据库用于去新蛋白质簇生成。默认使用ProkaryoticViralRefSeq85-ICTV。 \u0026ndash;pcs-mode {ClusterONE, MCL}：选择用于蛋白质簇生成的算法，默认为MCL。 \u0026ndash;vcs-mode {ClusterONE, MCL}：选择用于病毒簇生成的算法，默认为ClusterONE。 \u0026ndash;c1-bin CLUSTER_ONE：指定ClusterONE可执行文件的路径。 \u0026ndash;blastp-bin BLASTP_FP：指定BLASTP可执行文件的路径。 \u0026ndash;diamond-bin DIAMOND_FP：指定DIAMOND可执行文件的路径。 -o OUTPUT_DIR, \u0026ndash;output-dir OUTPUT_DIR：指定输出目录，默认vContact_Output。 -t THREADS, \u0026ndash;threads THREADS：设置使用的CPU数量，默认32个。 输入形式： FASTA格式的氨基酸文件。 1 2 3 4 5 6 7 8 9 10 \u0026gt;ref|NP_039777.1| ORF B-251 [Sulfolobus spindle-shaped virus 1] MVRNMKMKKSNEWLWLGTKIINAHKTNGFESAIIFGKQGTGKTTYALKVAKEVYQRLGHE PDKAWELALDSLFFELKDALRIMKIFRQNDRTIPIIIFDDAGIWLQKYLWYKEEMIKFYR IYNIIRNIVSGVIFTTPSPNDIAFYVREKGWKLIMITRNGRQPDGTPKAVAKIAVNKITI IKGKITNKMKWRTVDDYTVKLPDWVYKEYVERRKVYEEKLLEELDEVLDSDNKTENPSNP SLLTKIDDVTR \u0026gt;ref|NP_039778.1| ORF D-335 [Sulfolobus spindle-shaped virus 1] MTKDKTRYKYGDYILRERKGRYYVYKLEYENGEVKERYVGPLADVVESYLKMKLGVVGDT PLQADPPGFEPGTSGSGGGKEGTERRKIALVANLRQYATDGNIKAFYDYLMNERGISEKT AKDYINAISKPYKETRDAQKAYRLFARFLASRNIIHDEFADKILKAVKVKKANADIYIPT 一个“基因到基因组”的映射文件，采用tsv（制表符）或csv（逗号）分隔格式。 1 2 3 4 5 6 7 8 9 10 protein_id,contig_id,keywords ref|NP_039777.1|,Sulfolobus spindle-shaped virus 1,ORF B-251 ref|NP_039778.1|,Sulfolobus spindle-shaped virus 1,ORF D-335 ref|NP_039779.1|,Sulfolobus spindle-shaped virus 1,ORF E-54 ref|NP_039780.1|,Sulfolobus spindle-shaped virus 1,ORF F-92 ref|NP_039781.1|,Sulfolobus spindle-shaped virus 1,ORF D-244 ref|NP_039782.1|,Sulfolobus spindle-shaped virus 1,ORF E-178 ref|NP_039783.1|,Sulfolobus spindle-shaped virus 1,ORF F-93 ref|NP_039784.1|,Sulfolobus spindle-shaped virus 1,ORF E-51 ref|NP_039785.1|,Sulfolobus spindle-shaped virus 1,ORF E-96 测试数据： 1 2 3 4 5 6 git clone https://github.com/Hocnonsense/vcontact2.git cd vcontact2/test_data vcontact2 --raw-proteins test_data/VIRSorter_genomes.faa \\ --proteins-fp test_data/VIRSorter_genomes_g2g.csv \\ --db \u0026#39;ProkaryoticViralRefSeq211-Merged\u0026#39; \\ --output-dir vConTACT2_Results 运行时间还挺久的，输入文件有11个病毒contig，共433个gene。给了4核16G内存，结果跑了6485s，平均占用10.6GB内存。\n应该要给多一点线程。\n输出 vConTACT2 生成了很多输出文件，其中大多数是临时或中间文件，对一般用户没有用处。最重要的文件是网络和注释文件。\ngenome_by_genome_overview.csv 包含参考基因组的所有分类信息，以及所有聚类信息（初始 VC (VC_22)、精炼 VC (VC_22_1)）、置信度指标和杂项分数。\n一个重要的注意事项是，用户序列不包含分类信息。这意味着每个用户都需要找到他们感兴趣的基因组并检查参考基因组是否位于同一 VC 中。\n如果用户基因组与参考基因组位于同一 VC 子簇内，则用户基因组属于同一属的可能性非常高。 如果用户基因组与参考基因组位于同一 VC 但不在同一子簇中，则两个基因组很可能在大致属亚科水平上相关。 如果同一 VC 或 VC 子簇中没有参考基因组，那么它们很可能在属水平上根本不相关。也就是说它们有可能在更高的分类水平上相关（亚科、科、目）。 每列名称：\n1\tGenome\t基因组/序列名 2-4\tOrder/Family/Genus\t目/科/属 5\tpreVC\t初始病毒聚类 6\tVC Status\t病毒聚类状态 7\tVC\t病毒聚类 8\tVC Size\t病毒聚类数 9\tQuality\t质量值 10\tAdjusted P-value\t调整后的P值 11\tVC Avg Distance\t病毒聚类平均距离 12\tTopology Confidence Score\t拓扑学置信度 13\tGenus Confidence Score\t属级分类置信度 14-16\tVC Orders/Families/Genra\t病毒聚类目/科/属数 c1.ntw 包含高于显着性阈值的所有基因组对的源/目标/边缘权重信息，该显着性阈值由这两个基因组共享 N 个基因的概率确定。该文件中的最小值必须大于最小显着性阈值（默认值：1）。\n要在 Gephi 或 Cytoscape 中创建网络图形，用户需要将此文件导入到他们喜欢的程序中。 导入后，用户可以添加一个“注释文件” ，可以是genome_by_genome_overview.csv。 每个基因组的注释信息将被添加到网络中的每个节点/基因组。然后，用户可以通过注释文件中的任意属性对网络图形进行着色。\n注意：很多时候，用户会注意到他们的基因组连接到网络中的另一个（可能是参考）基因组，但这两个基因组不会位于同一个 VC 子簇中，甚至不会位于同一个 VC 中。这并不意味着它们没有相关性，只是意味着它们的基因共享比例不够大，无法属于同一属。他们在亚科或科层面上可能有很大的关联。\n可在https://dx.doi.org/10.17504/protocols.io.x5xfq7n找到详细的说明。\nPhaGCN2 PhaGCN2是一种可以快速分类病毒序列的工具，能够在科水平上进行分类，并支持所有科之间关系的可视化。文章于2022年发表在Briefings in Bioinformatics上[2]。\nPhaGCN2的性能与其他先进的病毒分类工具（如vConTACT2、CAT和VPF-Class）进行比较显示，PhaGCN2在病毒分类的精度和召回率上大大提高，并且显著增加了可分类病毒序列的数量。它将全球海洋病毒组数据库（Global Ocean Virome）中的可分类序列数量提高了四倍，并且能够对超过90%的肠道噬菌体数据库（Gut Phage Database）进行分类。PhaGCN2使得国际病毒分类委员会数据库（ICTV）的大规模、自动化扩展成为可能。\n软件主页：https://github.com/KennthShang/PhaGCN2.0\n安装 1 2 3 4 5 6 7 8 9 10 11 12 13 git clone https://github.com/KennthShang/PhaGCN2.0.git cd PhaGCN2.0 rm supplementary\\ file/ __pycache__/ pred/ final_prediction.csv -rf vi run_KnowledgeGraph.py # 把第169行注释掉，因为不需要再建一次数据库。 conda env create -f environment.yaml -n phagcn2 # 准备数据库 cd database tar -zxvf ALL_protein.tar.gz diamond makedb --in ALL_protein.fasta -d database.dmnd diamond blastp --sensitive -d database.dmnd -q ALL_protein.fasta -o database.self-diamond.tab awk \u0026#39;$1!=$2 {{print $1,$2,$11}}\u0026#39; database.self-diamond.tab \u0026gt; database.self-diamond.tab.abc cd .. 运行 1 2 3 4 5 6 7 8 9 $ python run_Speed_up.py -h usage: run_Speed_up.py [-h] [--contigs CONTIGS] [--len LEN] manual to this script optional arguments: -h, --help show this help message and exit --contigs CONTIGS --len LEN 该程序有两个参数：\n--contigs 是 contigs 文件的路径。 --len 是您要预测的重叠群的长度。正如我们的论文所示，随着重叠群长度的增加，查全率和查准率也会增加。我们建议您根据需要选择合适的长度。默认长度为 8000bp。支持的最短长度为1700bp。输出文件为final_prediction.csv。此 csv 文件中有三列：“contig_name、median_file_name、prediction”。 示例： 1 2 3 conda activate phagcn2 export MKL_SERVICE_FORCE_INTEL=1 #要设置一下这个 python run_Speed_up.py --contigs contigs.fa --len 8000 注意，该程序没有指定输出路程，会在当前目录生成，每次重跑会覆盖之前的内容😂，而且因为它的环境路径也不是绝对的，所以只能在PhaGCN2.0目录下跑，所以也不能同时跑多个任务，作者暂时也没有修改这个问题：https://github.com/KennthShang/PhaGCN2.0/issues/10。\n所以最好在运行该程序之前先切换到相应的输出目录（把运行文件全部拷贝到该目录），或者每次运行完把结果移动到输出目录。\n每次运行完把结果再移动到输出目录的策略还是有不足，会导致无法同时运行多个任务，所以选择前者。\n我们可以看一下run_Speed_up.py具体的几个步骤：\ndiamond，blastp 数据库准备，这里只需要运行一遍就好了，不知道为啥要放在run_Speed_up.py里每次都运行，至少还需要几十分钟呢。 把我们输入的contigs分割为每1000条序列一个子文件，过滤掉小于8000的序列，放在Split_files/下。 循环每个子文件： 把子文件mv到input/下，运行run_CNN.py，会用到CNN_Classifier/目录，得到Cyber_data/contig.F 运行run_KnowledgeGraph.py，生成中间文件single_contig/，all_proteins/，network/，输出到out/和Cyber_data/ 运行run_GCN.py，得到prediction.csv， 整理子文件输出，放在pred/，删除中间文件 合并所有子文件输出，运行run_network.py 所以还是选择自己写一个pipeline来跑吧，方便指定输出位置以及同时跑多个任务，不用run_Speed_up.py：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 #!/bin/bash # 打印帮助信息 usage() { echo \u0026#34;Usage: $0 -p \u0026lt;phaGCN_dir\u0026gt; -i \u0026lt;input_file\u0026gt; -o \u0026lt;output_dir\u0026gt;\u0026#34; exit 1 } # 解析命令行参数 while getopts \u0026#34;:p:i:o:\u0026#34; opt; do case \u0026#34;${opt}\u0026#34; in p) phaGCN_dir=${OPTARG} ;; i) input=${OPTARG} ;; o) output=${OPTARG} ;; *) usage ;; esac done # 检查是否提供了所有参数 if [ -z \u0026#34;${phaGCN_dir}\u0026#34; ] || [ -z \u0026#34;${input}\u0026#34; ] || [ -z \u0026#34;${output}\u0026#34; ]; then usage fi # 将路径转换为绝对路径 phaGCN_dir=$(cd \u0026#34;$(dirname \u0026#34;$phaGCN_dir\u0026#34;)\u0026#34; \u0026amp;\u0026amp; pwd)/$(basename \u0026#34;$phaGCN_dir\u0026#34;) input=$(cd \u0026#34;$(dirname \u0026#34;$input\u0026#34;)\u0026#34; \u0026amp;\u0026amp; pwd)/$(basename \u0026#34;$input\u0026#34;) output=$(cd \u0026#34;$(dirname \u0026#34;$output\u0026#34;)\u0026#34; \u0026amp;\u0026amp; pwd)/$(basename \u0026#34;$output\u0026#34;) # 检查输出目录是否存在且非空 if [ -d \u0026#34;$output\u0026#34; ] \u0026amp;\u0026amp; [ \u0026#34;$(ls -A $output)\u0026#34; ]; then echo \u0026#34;Error: Output directory $output already exists and is not empty.\u0026#34; exit 1 fi # 创建输出目录并进入 mkdir -p \u0026#34;$output\u0026#34; cd \u0026#34;$output\u0026#34; || exit # 复制 Python 脚本和 C 相关内容 cp \u0026#34;${phaGCN_dir}\u0026#34;/*.py ./ cp -r \u0026#34;${phaGCN_dir}/C\u0026#34;* ./ # 创建 database 目录的符号链接 ln -s \u0026#34;${phaGCN_dir}/database/\u0026#34; ./ # 创建 input 目录并复制输入文件 mkdir input/ cp \u0026#34;$input\u0026#34; input/ # 运行各个 Python 脚本 echo \u0026#34;Running CNN...\u0026#34; python run_CNN.py echo \u0026#34;Running KnowledgeGraph...\u0026#34; mkdir network python run_KnowledgeGraph.py echo \u0026#34;Running GCN...\u0026#34; python run_GCN.py echo \u0026#34;All tasks completed.\u0026#34; # 删除拷贝过来的脚本和目录 rm -rf *.py C* database 把上面内容拷贝到名为 run_phagcn的文件，注意修改~/biosoft/PhaGCN2.0为自己目录：\n1 2 3 4 vi run_phagcn chmod +x run_phagcn # 链接到环境变量目录 ln -s ~/biosoft/PhaGCN2.0/run_phagcn ~/miniconda3/envs/phagcn2/bin/ 这样就可以在任意目录运行该程序并指定输出了。\n1 2 3 4 cd ~/work/test/phagcn2_test # 注意input不要是contigs.fa，不然会覆盖 cp ~/biosoft/PhaGCN2.0/contigs.fa ./test_contigs.fa run_phagcn -p ~/biosoft/PhaGCN2.0/ -i test_contigs.fa -o ~/work/test/phagcn2_test/output 结果就是prediction.csv文件和network/phage_0.ntw文件，network/phage_0.ntw可以类似上述方法画一个网络图。\nReferences Bin Jang, H., Bolduc, B., Zablocki, O. et al. Taxonomic assignment of uncultivated prokaryotic virus genomes is enabled by gene-sharing networks. Nat Biotechnol 37, 632–639 (2019). https://doi.org/10.1038/s41587-019-0100-8 Jing-Zhe Jiang, Wen-Guang Yuan, Jiayu Shang, Ying-Hui Shi, Li-Ling Yang, Min Liu, Peng Zhu, Tao Jin, Yanni Sun, Li-Hong Yuan, Virus classification for viral genomic fragments using PhaGCN2, Briefings in Bioinformatics, 2022;, bbac505, https://doi.org/10.1093/bib/bbac505 ","date":"2024-08-14T00:00:00Z","image":"/p/vcontact2/images/PhaGCN2_hu_2c9347948e464f22.jpeg","permalink":"/p/vcontact2/","title":"使用PhaGCN2/vConTACT2进行病毒分类注释"},{"content":"什么是病毒？ 病毒是一种非常微小的、非细胞结构的病原体，它只能在宿主细胞内生长繁殖。与细菌不同，病毒本身没有完整的细胞结构，也无法进行独立的生命活动（如代谢、繁殖）。它们由遗传物质（DNA或RNA）和蛋白质外壳组成，少数病毒还带有脂质包膜。\n病毒的基本特征： 结构简单：病毒的结构通常包括核酸（DNA或RNA）和蛋白质外壳（称为衣壳）。有些病毒外面还有一层由宿主细胞膜衍生来的包膜。\n寄生性：病毒必须依赖宿主细胞才能复制。它们入侵宿主细胞后，将自身的遗传物质注入宿主细胞，并利用宿主的代谢系统进行复制。\n没有独立的生命活动：病毒不能独立进行代谢、运动、繁殖等生命活动，必须在宿主细胞内进行复制和增殖。\n特异性：病毒通常具有特异性，即它们只感染某些特定的宿主细胞。例如，某些病毒只感染植物，某些病毒只感染动物，还有些病毒专门感染细菌（称为噬菌体）。\n病毒的传播： 病毒可以通过多种途径传播，包括空气传播（如流感病毒）、体液传播（如艾滋病毒）、接触传播（如疱疹病毒）、蚊虫叮咬传播（如登革热病毒）等。\n病毒引发的疾病： 病毒可以引发多种疾病，包括感冒、流感、艾滋病、乙型肝炎、狂犬病、新冠肺炎等。治疗病毒感染通常需要抗病毒药物，而预防病毒感染常用疫苗。\n分类系统 病毒的分类主要依据以下几个方面：\n病毒颗粒的特性：如病毒的形状、大小、是否有包膜等。 抗原特性：指病毒表面蛋白的特性，这些蛋白决定了病毒与宿主细胞的相互作用。 生物特性：包括病毒的基因组类型（DNA或RNA）、复制方式、宿主范围等。 当前，只有一小部分的病毒得到了详细研究。来自人体的病毒样品中，有约20%的序列是未曾发现过的，而从环境（如海水、大洋沉积物等）中采集的病毒样品中，大部分序列都是全新的。这表明我们对病毒世界的了解还非常有限，未来的研究可能会发现更多新病毒，进一步丰富和复杂化现有的病毒分类系统。\nICTV病毒分类 ICTV于1966年建立了病毒分类的通用系统和统一的命名法则。这个系统是目前唯一一个被广泛接受的病毒分类标准。ICTV是国际微生物学联合会（International Union of Microbiological Societies, IUMS）下属的机构，负责发展、改进和维护这个病毒分类系统。\n官方网站：https://ictv.global/\n病毒分类的层次 ICTV的分类系统从最广泛的域（Realm）开始，逐步细化到种（Species）这个最低的分类单元。以下是各个层级及其对应的分类后缀： 域（Realm）：-viria 亚域（Subrealm）：-vira 界（Kingdom）：-viriae 亚界（Subkingdom）：-virites 门（Phylum）：-viricota 亚门（Subphylum）：-viricotina 纲（Class）：-viricetes 亚纲（Subclass）：-viricetidae 目（Order）：-virales 亚目（Suborder）：-virineae 科（Family）：-viridae 亚科（Subfamily）：-virinae 属（Genus）：-virus 亚属（Subgenus）：-virus 种（Species）：通常以[疾病]病毒的形式出现。 我们可以去官网下载文件后看看主要的门类，目前（2024.8.12）共有14,690种有命名的病毒：\n1 2 3 4 5 library(dplyr) ICTV=readxl::read_excel(\u0026#34;~/database/ICTV_Master_Species_List_2023_MSL39.v3.xlsx\u0026#34;,sheet = 2) ICTV=ICTV[,c(\u0026#34;Realm\u0026#34;,\u0026#34;Kingdom\u0026#34;,\u0026#34;Phylum\u0026#34;, \u0026#34;Class\u0026#34;, \u0026#34;Order\u0026#34;, \u0026#34;Family\u0026#34;, \u0026#34;Genus\u0026#34;, \u0026#34;Species\u0026#34;,\u0026#34;Genome Composition\u0026#34;)] count(ICTV,Realm,Kingdom,Phylum)%\u0026gt;%arrange(-n)%\u0026gt;%na.omit()%\u0026gt;%my_sankey() 以下是主要病毒域及其门类的介绍：\n以下是各个病毒域及其主要门类的详细介绍：\nA型DNA病毒域 (Adnaviria)\n特征：包含环状或线状双链DNA病毒，常感染古细菌，具有独特的DNA包装和复制机制。 齐利希病毒界 (Zilligvirae) 杆状病毒门 (Taleaviricota) 双链DNA病毒域 (Duplodnaviria)\n特征: 包含双链DNA病毒，具有独特的DNA包装和复制机制。 香港病毒界 (Heunggongvirae)： 衣壳病毒门 (Peploviricota)：具有二十面体衣壳和外膜，附有糖蛋白。 尾噬菌体门 (Uroviricota)：通过尾状结构将DNA注入宿主。 单链DNA病毒域 (Monodnaviria)\n特征：包含单链DNA病毒，通常感染真核生物。 洛布病毒界 (Loebvirae)： 霍夫奈病毒门 (Hofneiviricota) 桑格病毒界 (Sangervirae)： 菲克斯病毒门 (Phixviricota) 称徳病毒界 (Shotokuvirae)： 科萨特病毒门 (Cossaviricota) 单环编码病毒门 (Cressdnaviricota)：编码复制相关蛋白的环状单链DNA病毒。 特拉帕尼病毒界 (Trapavirae)： 嗜盐病毒门 (Saleviricota) 核糖病毒域 (Riboviria)\n特征：包含所有RNA病毒，具有单链正负链RNA基因组。 正RNA病毒界 (Orthornavirae)： 双链RNA病毒门 (Duplornaviricota) 光滑裸露病毒门 (Lenarviricota) 黄色病毒门 (Kitrinoviricota) 负核糖病毒门 (Negarnaviricota) 小RNA病毒超群门 (Pisuviricota) 副RNA病毒界 (Pararnavirae)： 酶录转逆病毒门 (Artverviricota) 核酶病毒域 (Ribozyviria)\n特征：包含单一属的病毒，具有环状RNA，类似核酶的功能。 主要门类：未列出具体门类。 多变DNA病毒域 (Varidnaviria)\n特征：包含多种DNA病毒，具有衣壳基因的广泛变化。 班福病毒界 (Bamfordvirae)： 核质病毒门 (Nucleocytoviricota) 质粒前体病毒门 (Preplasmiviricota) 海尔维蒂病毒界 (Helvetiavirae)： 分隔病毒门 (Dividoviricota) 巴尔的摩分类法 巴尔的摩分类法（Baltimore classification）是由美国生物学家戴维·巴尔的摩（David Baltimore）于1971年提出的一种病毒分类方法。与ICTV分类法基于病毒的结构和其他生物特性不同，巴尔的摩分类法主要依据病毒的基因组类型和病毒复制过程中的信使RNA（mRNA）合成方式进行分类。这个分类方法将病毒分为七大类，每一类对应一种特定的基因组类型和复制机制。\n巴尔的摩分类法的七大类： I类：双链DNA病毒（dsDNA）\n基因组：双链DNA。 mRNA合成：宿主细胞的RNA聚合酶直接转录mRNA。 代表病毒：腺病毒、疱疹病毒、痘病毒等。 II类：单链DNA病毒（ssDNA）\n基因组：单链DNA。 mRNA合成：单链DNA在宿主细胞中形成双链DNA，然后由宿主细胞的RNA聚合酶转录mRNA。 代表病毒：细小病毒等。 III类：双链RNA病毒（dsRNA）\n基因组：双链RNA。 mRNA合成：病毒自带的RNA依赖性RNA聚合酶将双链RNA中的一条链直接转录为mRNA。 代表病毒：轮状病毒等。 IV类：正义单链RNA病毒（(+)-ssRNA）\n基因组：正义单链RNA，即直接作为mRNA使用。 mRNA合成：基因组RNA本身就是mRNA，可以直接被翻译成蛋白质。 代表病毒：冠状病毒、脊髓灰质炎病毒、黄病毒等。 V类：负义单链RNA病毒（(-)-ssRNA）\n基因组：负义单链RNA。 mRNA合成：病毒自带的RNA依赖性RNA聚合酶将负义RNA转录为正义mRNA。 代表病毒：流感病毒、狂犬病毒、麻疹病毒等。 VI类：反转录RNA病毒（Retroviruses）\n基因组：正义单链RNA。 mRNA合成：病毒自带的逆转录酶将RNA逆转录为双链DNA，双链DNA整合到宿主基因组中，宿主细胞的RNA聚合酶再转录mRNA。 代表病毒：人类免疫缺陷病毒（HIV）等。 VII类：反转录DNA病毒（Pararetroviruses）\n基因组：部分双链DNA，带有缺口。 mRNA合成：缺口的双链DNA在宿主细胞内修复成为完整的双链DNA，由宿主的RNA聚合酶转录mRNA。部分mRNA通过逆转录形成DNA，并整合到宿主基因组中。 代表病毒：乙型肝炎病毒（HBV）等。 亚病毒因子 亚病毒因子是指比病毒更简单的病原体，包括类病毒、卫星病毒和朊病毒等。它们通常没有完整的病毒结构，缺乏自身复制所需的酶或结构蛋白，依赖宿主或协助病毒的机制进行繁殖。\n类病毒：由单一的环状RNA分子组成，感染植物。 卫星病毒：依赖辅助病毒进行复制。 朊病毒：异常折叠的蛋白质，能导致神经退行性疾病。 这些因子尽管简单，却可能导致严重的疾病。\n结构 病毒的形态和大小多种多样，大多数病毒直径在10至300纳米之间。某些丝状病毒长度可达1400纳米，但宽度只有约80纳米。病毒的形态主要有以下四种：\n螺旋形：核酸与蛋白质亚基形成螺旋状结构，如烟草花叶病毒。螺旋形病毒的长度取决于核酸的长度。\n正二十面体形：多见于动物病毒，结构为正二十面体，如腺病毒。这种结构具有对称性，可以最小化形成衣壳所需的能量。\n包膜型：包膜由宿主细胞膜改造形成，包裹在核衣壳外，如流感病毒。包膜使病毒能够通过细胞膜与宿主细胞融合，从而不必导致宿主细胞死亡。\n复合型：结构复杂，既非完全螺旋形也非完全正二十面体形，如有尾噬菌体和痘病毒。复合型病毒常有附加结构，如尾部或外壁，参与感染过程。\n病毒颗粒（病毒体）由蛋白质组成的衣壳和内部核酸组成。衣壳的形状由病毒基因组编码的蛋白质决定，通常可以自组装形成。某些病毒还有包膜，包膜内含有来自宿主细胞的脂质、糖类和病毒编码的膜蛋白。包膜型病毒的感染性依赖于包膜。病毒形态学研究通常通过电子显微镜和负染色技术进行观察。\n生命周期 病毒的生命周期分为六个主要阶段，各阶段间的差异取决于病毒类型，但总体流程相似：\n附着 (Attachment)：病毒通过其衣壳蛋白与宿主细胞表面的特定受体结合。这种结合决定了病毒的宿主范围，例如HIV特异性结合人类T细胞的CD4分子。\n穿入 (Penetration)：病毒通过受体介导的胞吞或膜融合进入宿主细胞。植物病毒通常通过伤口进入细胞，而噬菌体则通过注入DNA的方式感染细菌。\n脱壳 (Uncoating)：病毒的衣壳在宿主细胞内被酶降解，释放出病毒的核酸。\n合成 (Replication)：病毒基因组在宿主细胞内复制，并利用宿主的酶系统进行转录和蛋白质合成。在这一阶段，病毒的结构成分开始合成，病毒的复制也开始。\n组装 (Assembly)：新合成的病毒核酸与衣壳蛋白组装成新的病毒颗粒。DNA病毒通常在细胞核内组装，而RNA病毒则在细胞质中完成组装。\n释放 (Release)：无包膜病毒通过细胞裂解（lysis）释放，包膜病毒则通过出芽 (budding) 方式离开宿主细胞。在出芽过程中，病毒从宿主细胞膜中获取包膜，包膜上嵌有病毒的表面蛋白。\n病毒基因组的复制方式因其遗传物质的类型不同而有所差异：\nDNA病毒：大多数DNA病毒在宿主细胞核内复制。它们依赖宿主细胞的DNA和RNA合成机制，基因组需穿过核膜以控制这些工具。\nRNA病毒：RNA病毒在细胞质内复制，使用自身的RNA复制酶。其复制机制取决于RNA的极性和链数。\n反转录病毒：这些病毒利用反转录酶将RNA模板转化为DNA，或将DNA模板转化为RNA，并将生成的DNA整合入宿主基因组中。\n功能 病毒在环境生态和人类健康中扮演着复杂而重要的角色：\n环境生态方面 生态平衡：病毒可以通过感染和控制微生物种群，帮助维持生态系统的平衡。例如，噬菌体可以调节细菌的数量，从而影响微生物群落的结构和功能。\n物质循环：病毒在环境中可以促进物质循环。例如，海洋中的病毒感染细菌，导致细菌裂解，这释放出有机物质，供其他微生物利用，促进碳循环和营养物质的循环。\n遗传变异：病毒可以通过转导（转移遗传物质）促进基因水平的遗传变异，影响宿主的遗传组成和进化过程。\n对人类健康方面 疾病：病毒是许多传染病的病原体，如流感、感冒、艾滋病、肝炎等。它们通过感染宿主细胞，破坏正常的生理功能，引发疾病。\n免疫系统：某些病毒可以引发免疫反应，增强免疫系统的记忆功能。例如，疫苗接种就是利用病毒的无害部分来激发免疫反应，以保护个体免受未来的感染。\n基因治疗：病毒可以作为基因递送工具，将治疗性基因引入患者体内，用于治疗一些遗传性疾病。这些病毒通常经过工程化处理，使其不再引起疾病，同时具备高效的基因递送能力。\n肿瘤治疗：一些病毒具有选择性地感染和杀死癌细胞的能力，这为癌症治疗提供了新的方向。例如，工程化的溶瘤病毒可以专门攻击肿瘤细胞，同时减少对正常细胞的损伤。\n总的来说，病毒在生态系统中是关键的调节因子，对环境平衡和物质循环起着重要作用；在医学领域，虽然它们可能引起疾病，但也提供了治疗和基因工程的创新机会。\n","date":"2024-08-13T00:00:00Z","image":"/p/learn-virus/images/Virus_Baltimore_Classification_hu_f40dee417a36303f.png","permalink":"/p/learn-virus/","title":"病毒相关内容学习"},{"content":"Introduction 自己整理一些常用的功能基因预测/注释通用工具，因为数量较多，不会写的很仔细，对于每个单独的工具可以进一步找相关教程学习。\n基因结构鉴定工具 Prodigal 参考教程：一文读懂Prodigal教程\n介绍： Prodigal（Prokaryotic Dynamic Programming Gene-finding Algorithm）是一款用于原核生物基因预测的高效工具，广泛应用于基因组和宏基因组数据分析。\n安装：\n1 2 3 4 5 6 7 # 下载并解压源代码包： wget https://github.com/hyattpd/Prodigal/releases/download/v2.6.3/prodigal.linux chmod +x prodigal.linux sudo mv prodigal.linux /usr/local/bin/prodigal # 或者直接用 conda 安装： conda install prodigal 简单使用：\n基因组序列文件中预测基因： 1 prodigal -i input.fasta -o genes.gbk -a proteins.faa GeneMark 参考教程：\nGeneMark-ES GeneMarkS 介绍： GeneMark是一款通用的基因预测工具，适用于原核和真核生物，能够识别复杂的基因结构。\n安装：\n前往GeneMark官网（http://exon.gatech.edu/GeneMark/）下载相应的版本。\n解压并配置环境变量：\n1 2 tar -xzvf genemark.tar.gz export PATH=$PATH:/path/to/genemark 简单使用：\n对基因组序列文件进行基因预测： 1 gmhmmp -m MetaGeneMark_v1.mod -o genes.gff input.fasta Prokka 参考教程：基因注释Prokka\n介绍： Prokka 是一个快速的基因组功能注释工具，能够对细菌、古菌和病毒基因组进行注释。它集成了多个工具，用于基因预测和功能注释，输出标准化的注释结果。\n安装：\n1 conda install prokka 简单使用：\n对基因组序列进行注释： 1 prokka input.fasta --outdir annotation_output --prefix sample RNA鉴定工具 tRNAscan-SE 参考教程：tRNAscan-SE安装使用教程\n介绍： tRNAscan-SE 是一款广泛应用的tRNA基因预测工具，能够高效、准确地识别基因组中的tRNA基因。该工具结合了多个算法，以提高预测准确性。\n安装： 安装有点麻烦，需要仔细:\n下载并解压源代码包： 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 # 自己找一下最新版看看 wget http://trna.ucsc.edu/tRNAscan-SE.tar.gz tar -xzvf tRNAscan-SE.tar.gz cd tRNAscan-SE ./configure --prefix=$(pwd) make \u0026amp;\u0026amp; make install #需要调用infernal wget -c http://eddylab.org/infernal/infernal-1.1.2-linux-intel-gcc.tar.gz tar xzvf infernal-1.1.2-linux-intel-gcc.tar.gz cd infernal-1.1.2-linux-intel-gcc/ ./configure --prefix=$(pwd) make \u0026amp;\u0026amp; make install cp binaries/* bin # 添加bashrc echo \u0026#34;export PATH=$PATH:/path/to/tRNAscan-SE/bin\u0026#34; \u0026gt;\u0026gt; ~/.bashrc echo \u0026#34;export PERL5LIB=/path/to/tRNAscan-SE/lib:$PERL5LIB\u0026#34; \u0026gt;\u0026gt; ~/.bashrc source ~/.bashrc # 需要编辑/path/to/tRNAscan-SE/tRNAscan-SE.conf文件，下面这几行需要修改 bin_dir: /path/to/tRNAscan-SE/bin lib_dir: /path/to/tRNAscan-SE/lib infernal_dir: /path/to/infernal-1.1.2-linux-intel-gcc/bin 简单使用：\n对基因组序列进行tRNA基因预测： 1 tRNAscan-SE -o output.txt input.fasta ARAGORN 介绍： ARAGORN是一款用于快速和高效识别基因组序列中tRNA和tmRNA基因的工具。它的设计目的是在大规模基因组分析中提供精确的tRNA/tmRNA基因定位。\n安装：\nConda安装： 1 conda install -c bioconda aragorn 简单使用：\n识别tRNA和tmRNA基因： 1 aragorn -i input.fasta -o output.txt Barrnap 参考教程：Barrnap预测rRNA基因\n介绍： Barrnap是一款快速、小巧的rRNA基因预测工具，专为16S、23S和5S rRNA基因的检测而设计，适用于细菌和古菌。\n安装：\n1 2 3 4 5 6 7 wget https://github.com/tseemann/barrnap/archive/v0.9.tar.gz tar -xzvf v0.9.tar.gz cd barrnap-0.9 sudo cp bin/barrnap /usr/local/bin/ #或者conda安装： conda install -c bioconda -c conda-forge barrnap 简单使用：\n对基因组序列进行rRNA基因预测： 1 barrnap input.fasta \u0026gt; output.gff 比对软件 我们要对鉴定到的基因进行功能注释，有一些功能数据库具有配套的比对软件，但更多的数据库是只提供序列的，我们需要自己使用一些软件建库比对。\nBLAST 参考教程：BLAST教程\n介绍： BLAST（Basic Local Alignment Search Tool）是一个广泛使用的基因和蛋白质序列比对工具，能够快速地在数据库中查找与查询序列相似的序列。\n安装：\n1 2 3 4 5 6 7 8 wget ftp://ftp.ncbi.nlm.nih.gov/blast/executables/blast+/LATEST/ncbi-blast-*.tar.gz tar -xzvf ncbi-blast-*.tar.gz cd ncbi-blast-* # 配置环境变量： export PATH=$PATH:/path/to/ncbi-blast-*/bin # 或者conda安装： conda install -c bioconda blast 简单使用：\n创建本地数据库： 1 makeblastdb -in database.fasta -dbtype nucl -out mydb 进行序列比对： 1 blastn -query query.fasta -db mydb -out results.txt DIAMOND 参考教程：DIAMOND: 超快的蛋白序列比对软件\n介绍： DIAMOND是一个快速的蛋白质序列比对工具，设计用于比对大规模数据集，速度比BLAST快几个数量级。\n安装：\n1 2 3 4 5 wget https://github.com/bbuchfink/diamond/releases/download/v2.0.14/diamond-linux64.tar.gz tar -xzvf diamond-linux64.tar.gz # 或者conda安装 conda install -c bioconda diamond 简单使用：\n创建本地数据库： 1 diamond makedb --in database.fasta -d mydb 进行序列比对： 1 diamond blastp -d mydb -q query.fasta -o results.m8 MMseqs2 参考教程：MMseqs2蛋白质序列快速高效比对工具\n介绍： MMseqs2（Many-against-Many sequence searching）是一个快速高效的序列搜索和聚类工具，适用于大规模数据集，这个可以好好学习一下使用，因为速度算是非常快的。\n安装：\n1 2 3 4 wget https://mmseqs.com/latest/mmseqs-linux.tar.gz tar -xzvf mmseqs-linux.tar.gz # 或者conda安装 conda install -c conda-forge -c bioconda mmseqs2 简单使用：\n创建本地数据库： 1 mmseqs createdb input.fasta mydb 进行序列比对： 1 2 mmseqs search mydb query.fasta result tmp mmseqs convertalis mydb query.fasta result results.m8 在基因组和宏基因组研究中，除了BLAST、DIAMOND和MMseqs2等常用比对软件外，还有一些基于隐马尔可夫模型（HMM）的比对工具，这些工具能够提供更敏感和准确的比对，特别是对于蛋白质家族和结构域的检测。\n在基因组和宏基因组研究中，基因和功能注释的比对工具是不可或缺的。以下是一些常用的工具，包括HMM（隐马尔可夫模型）相关的比对软件：\nHMMER 参考教程：hmmer 简明教程\n介绍： HMMER是一款基于HMM的工具，适用于检测蛋白质家族和结构域。\n安装：\nConda安装： 1 conda install -c bioconda hmmer 简单使用：\n创建HMM模型： 1 hmmbuild mymodel.hmm myalignment.sto 进行HMM比对： 1 hmmsearch --tblout results.tbl mymodel.hmm query.fasta 功能数据库 KEGG 官网: KEGG 介绍: KEGG (Kyoto Encyclopedia of Genes and Genomes) 是一个综合数据库，提供有关基因组、化学物质和系统功能的信息。它包含了代谢通路、药物、疾病、代谢物等多种数据。KEGG 用于基因和代谢途径的注释，帮助研究人员理解生物体的复杂功能和相互作用。 eggNOG 官网: eggNOG 介绍: eggNOG (evolutionary genealogy of genes: Non-supervised Orthologous Groups) 是一个用于功能注释和进化学分类的数据库。它通过无监督的方式构建直系同源基因组群，提供高质量的功能预测和注释，广泛应用于基因功能研究和比较基因组学。 Pfam 官网: Pfam 介绍: Pfam 是一个蛋白质家族数据库，提供已知蛋白质结构域和功能位点的详细信息。每个结构域在数据库中都以隐马尔可夫模型（HMMs）的形式存储，Pfam 用于注释蛋白质序列，帮助研究人员理解蛋白质的结构和功能。 COG 官网: COG 介绍: COG (Clusters of Orthologous Groups) 数据库针对细菌和古菌，组织和分类了直系同源基因群。COG 提供了跨物种的基因和蛋白质功能注释，帮助研究者识别基因的保守性和功能演化。 InterPro 官网: InterPro 介绍: InterPro 是一个综合数据库，整合了多个蛋白质家族、结构域和功能位点的资源。它通过统一的注释标准，帮助研究人员分析和理解蛋白质序列的功能。 UniProt 官网: UniProt 介绍: UniProt 是一个全面的蛋白质序列和功能数据库。它提供了丰富的蛋白质信息，包括序列、功能注释、相互作用、结构等，广泛应用于生物信息学和系统生物学研究。 CAZy 官网: CAZy 介绍: CAZy (Carbohydrate-Active enZymes) 数据库专注于碳水化合物活性酶，包括糖苷水解酶、糖苷转移酶、多糖裂解酶等。CAZy 用于注释和分类这些酶，帮助研究人员理解碳水化合物代谢和功能。 MEROPS 官网: MEROPS 介绍: MEROPS 是一个肽酶和肽酶抑制剂的数据库。它分类和注释了各种肽酶及其抑制剂，提供了序列、功能和结构信息，帮助研究人员研究蛋白质降解和调控机制。 TIGRFAMs 官网: TIGRFAMs 介绍: TIGRFAMs 是一个用于功能和进化注释的蛋白质家族模型数据库。它基于 HMMs，为每个蛋白质家族提供详细的功能注释，广泛用于基因组和代谢途径的研究。 CARD 官网: CARD 介绍: CARD（The Comprehensive Antibiotic Resistance Database） 是经过严格筛选的、经过同行评审的耐药性决定因素和相关抗生素的集合，由抗生素耐药性本体论 (ARO) 和 AMR 基因检测模型组织而成。 mobileOG-db 官网: mobileOG-db 介绍: mobileOG-db 是一个用于注释移动基因组的数据库。它基于 HMMs，为每个移动基因组提供详细的功能注释，广泛用于基因组和代谢途径的研究。 ICEberg3 官网: ICEberg3 介绍: 整合和接合元件（ICE）是重要的移动遗传元件，在细菌进化中发挥着重要作用。它们可以整合到细菌染色体中并拥有完整的接合机制，从而实现细菌细胞之间的自我传播。通过促进不同货物基因的水平转移，ICE赋予宿主有益的特征，如抗生素抗性、发病机制、防御系统、金属抗性、化合物降解和共生，这对细菌多样性和适应有显着贡献。ICEberg 3.0 提供了三个主要增强功能：(i) 具有手动管理功能的新 ICE、IME 和 CIME 数据。 (ii) ICE 货运功能分类。 (iii) 将其重点扩展到涵盖人类微生物组中的 ICE。这些更新通过捕获 ICE 的不同功能和特征，能够有效地促进对细菌进化的理解。 PHASTEST 官网: PHASTEST 介绍: PHASTEST旨在支持细菌基因组和质粒中原噬菌体序列的快速识别、注释和可视化。 BacMet 官网: BacMet 介绍: BacMet 是一种易于使用的抗菌剂和金属抗性基因的生物信息学资源。 BacMet 由两个数据库组成：手动管理的基因数据库，具有经实验证实的抗性功能；基于与具有实验证实功能的基因的序列相似性的预测抗性基因的数据库。 mibPOPdb 官网: mibPOPdb 介绍: mibPOPdb 数据库是一个手动管理的综合资源，致力于持久性有机污染物 (POP) 研究的微生物生物修复。数据是从科学文献中系统地、手动地收集的。 元素循环 碳循环 碳循环是指碳在生物圈、大气圈、水圈和岩石圈中的循环过程。它通过光合作用、呼吸作用、分解和燃烧等途径，维持着地球上的碳平衡。碳循环的重要性在于它对气候变化和生态系统健康的影响。\n相关信息可以在KEGG找到大部分，甲烷循环部分具有数据库MCycDB\nNCycDB 官网: NCycDB 介绍: NCycDB 是一个专注于氮循环的基因和酶的数据库，包含与氮循环相关的功能基因信息。它有助于研究氮在生态系统中的转化过程，理解氮循环的分子机制。 PCycDB 官网: PCycDB 介绍: PCycDB 是一个关于磷循环的数据库，提供了磷循环相关基因和酶的信息。该数据库有助于研究磷的生物地球化学循环，了解磷在环境中的迁移和转化过程。 SCycDB 官网: SCycDB 介绍: SCycDB 专注于硫循环，包含硫循环相关的基因和酶信息。它帮助研究者理解硫在生态系统中的循环过程，分析硫的生物地球化学作用。 AsgeneDB 官网: AsgeneDB 介绍: AsgeneDB 是一个关于氨基酸循环的数据库，包含氨基酸循环相关的基因和酶信息。它有助于研究氨基酸在生态系统中的循环过程，理解氨基酸的生物地球化学作用。 FeGenie 官网: FeGenie 介绍: FeGenie 是一个关于铁循环的数据库，包含铁循环相关的基因和酶信息。它有助于研究铁在生态系统中的循环过程，理解铁的生物地球化学作用。 PlasticDB 官网: PlasticDB 介绍: PlasticDB 是一个关于塑料循环的数据库，包含塑料循环相关的基因和酶信息。它有助于研究塑料在生态系统中的循环过程，理解塑料的生物地球化学作用。 ","date":"2024-08-06T00:00:00Z","image":"/p/function-tools/images/mobileOG_hu_313dbd432cad146b.png","permalink":"/p/function-tools/","title":"功能基因预测/注释通用工具"},{"content":"Introduction CRISPR-Cas系统是微生物为免受噬菌体和外来遗传元件入侵进化而来的获得性免疫系统，在约45%的细菌和87%的古细菌基因组中都发现了CRISPR-Cas系统的存在，具体可以看之前写的CRISPR 相关学习。\n在噬菌体与宿主共进化的过程中，通过在宿主CRISPR-Cas系统的Protospacer seed sequence区域引入突变，降低了RNP复合物与靶标核酸的结合亲和力，从而逃避宿主CRISPR-Cas系统介导的免疫。宿主CRISPR-Cas系统具有不断获取新Spacer的能力，因此噬菌体进化出积极的反防御系统，通过与核酸序列无关的机制使CRISPR-Cas效应复合物失活。\n最初在铜绿假单胞菌的噬菌体中观察到了这种anti-CRISPR现象，尽管这些噬菌体携带与宿主Ⅰ-F型CRISPR-Cas系统Spacer序列匹配的靶标核酸，依然能成功侵染宿主并传播。Bondy-Denomy等研究者在这些噬菌体的基因组中发现了编码5个Acr蛋白（AcrⅠF1、AcrⅠF2、AcrⅠF3、AcrⅠF4和AcrⅠF5）的基因，这些蛋白能帮助噬菌体逃避Ⅰ-F型CRISPR-Cas系统的免疫。\n自2013年发现第一个Acr蛋白以来，已确认多种来源于病毒和质粒等移动遗传元件的Acr蛋白可抵御CRISPR-Cas系统的免疫。由于Acr蛋白在序列上相似性较低，因此无法通过氨基酸序列同源比对来预测新的Acr蛋白。\n当前预测和挖掘Acr蛋白的策略主要有三种：(1) 在序列保守的anti-CRISPR相关蛋白Aca周围进行预测；(2) 在携带内源CRISPR-Cas系统自靶向的宿主菌基因组上筛选；(3) 在能够抵御宿主CRISPR-Cas免疫活性的噬菌体基因组上鉴定。\n分类 目前已经发现了至少82种Acr蛋白，它们分别能够抑制Ⅰ、Ⅱ、Ⅲ、Ⅴ和Ⅵ型CRISPR-Cas系统的免疫活性。表1展示了这些发现，注意到目前还没有报道针对Ⅳ型CRISPR-Cas系统的Acr蛋白。研究表明，这些Acr蛋白大多通过与CRISPR-Cas复合物或Cas蛋白相互作用来抑制其免疫活性。\n除了Acr蛋白外，还有两种不同的噬菌体反CRISPR策略被发现可以对抗宿主CRISPR-Cas系统的免疫干扰。一种策略是噬菌体形成拟核结构来规避Ⅰ型CRISPR-Cas系统的免疫，另一种是利用噬菌体衍生的肽来抑制CRISPR-Cas9的免疫活性（见上图）。\nMendoza等人发现，铜绿假单胞菌噬菌体ΦKZ能够通过在其基因组周围形成蛋白质拟核屏障，逃避宿主细胞内多种CRISPR-Cas系统，包括Cas3、Cas9和Cas12a的免疫活性。类似地，Malone等人发现，沙雷氏菌噬菌体PCH45感染宿主后，形成的蛋白质包裹的拟核结构使其基因组DNA免受Ⅰ型CRISPR-Cas系统的靶向攻击，尽管Ⅲ-A型CRISPR-Cas系统仍可通过靶向释放到细胞质中的噬菌体mRNA来抑制其大量增殖。\n此外，噬菌体M13衣壳蛋白G8P的一个肽段G8PPD（G8P的外膜结构域）能够抑制链球菌CRISPR-Cas9系统的免疫活性。该外膜结构域的胞浆周结构能够与Cas9结合，阻止其装载sgRNA形成效应复合物，从而帮助噬菌体逃避CRISPR-Cas9的免疫反应。这种肽抑制CRISPR-Cas系统活性的机制类似于某些Acr蛋白。\n作用机制 已报道的Acr蛋白，分别以阻止crRNA装载、阻止靶标DNA/RNA的识别与结合、阻止靶标核酸的切割以及通过降解信号分子等方式发挥抵御CRISPR-Cas系统免疫活性的功能：\n阻止crRNA装载 AcrⅡC2是第一个报道的在核酸装载步骤抑制CRISPR-Cas系统免疫活性的anti-CRSIPR蛋白。AcrⅡC2通过与Cas9蛋白的BH结构域结合，阻止Cas9蛋白与crRNA结合形成效应复合体，进而保护靶标DNA不被降解。同样，有研究显示AcrⅡA16、17和19可能也是通过与ApoCas9蛋白的相互作用干扰了sgRNA的装载与稳定，从而抑制Ⅱ-A型CRISPR-Cas系统的活性。\n阻止靶标DNA/RNA的识别与结合 目前发现的anti-CRSIPR蛋白中，阻止CRISPR-Cas效应复合体识别和结合靶标核酸是其抑制CRISPR-Cas系统免疫活性的常见方式。例如，Ⅰ-D型CRISPR-Cas系统的AcrⅠD1蛋白以二聚体形式约束Cas10d大亚基，阻止其与外源DNA的结合。在Ⅰ-F型CRISPR-Cas系统中，AcrⅠF1和AcrⅠF2分别与Csy3亚基多聚体和Csy1-Csy2异二聚体互作，阻断CRISPR-Cas效应复合体与靶标DNA的结合，进而抑制靶标核酸的降解。AcrⅢB1是首个直接抑制Ⅲ型CRISPR-Cas系统核酸干涉活性的Acr蛋白，能有效阻止Ⅲ-B型CRISPR-Cas系统对病毒中/晚期基因的靶向免疫。\n阻止靶标核酸的切割 Acr蛋白抵御CRISPR-Cas系统免疫的第三种常见方式是直接抑制CRISPR-Cas效应复合体对外源靶标核酸的切割。其中，AcrⅠF3是第一个被发现能抑制CRISPR-Cas效应复合体核酸酶活性的Acr蛋白。AcrⅠF3以二聚体的形式结合到Cas3蛋白的关键结构域HD、Linker和CTD中，广泛的相互作用覆盖了Cas3蛋白的一个表面，并以ADP形式锁定Cas3，有效阻止了CRISPR-Cas效应复合体招募Cas3进行靶标DNA切割。此外，抑制Cas3靶向DNA降解也会阻碍新Spacer的获取。\n另外，AcrⅡA11能够特异性地与Cas9蛋白的一个保守结构域结合，并通过改变Cas9蛋白的引导和自身构象来抑制其对双链DNA的切割活性。这种直接作用于Cas蛋白的保守结构域是细菌和噬菌体在长期“军备竞赛”中进化的结果，可以在一定程度上防止CRISPR-Cas系统通过修饰和突变克服Acr蛋白的抑制。\n降解信号分子 AcrⅢ-1不直接改变Ⅲ型CRISPR-Cas效应复合体的结构和功能，而是通过降解靶向RNA后生成的环腺苷酸CA4信号分子来帮助病毒逃避Ⅲ型CRISPR-Cas系统的免疫干扰。这种策略表明AcrⅢ-1具有广泛的宿主适应性，在细菌和古菌中普遍存在。此外，Ⅵ-B型CRISPR-Cas系统中的Csx27是一种特殊的Cas蛋白，能减弱Cas13b-crRNA效应复合体对靶向干涉RNA的活性，这种负调节作用可能在微生物宿主的免疫防御中起重要作用。\n应用 细胞特异性控制：\n基于AcrIIA4的技术能够将Cas9的活性限制在特定细胞类型中，例如肝细胞和心肌细胞。这种方法通过引入特征性MicroRNAs来实现目标细胞的特异性调控，从而避免非目标细胞中的脱靶效应。 AAV载体与特异性miR-122结合：\n2019年的研究表明，通过使用Adenovirus-associated vector（AAV）与NmeCas9（来自Neisseria meningitidis）的联合递送，结合带有肝脏特异性miR-122结合位点的AcrIIC3，可以实现肝脏细胞中的基因编辑，同时抑制心肌细胞中的编辑。 生物传感器开发：\n利用Acr蛋白的特性开发的生物传感器可以用于检测CRISPR-Cas系统的活性。这些传感器在酿酒酵母中被成功构建，并且能够与荧光表达增强耦合，实现了对CRISPR-Cas系统的有效调控。 合成基因电路：\n基于Acr蛋白的合成基因电路可以在酿酒酵母中实现对CRISPR-Cas系统的精确调控。这些电路通过Acr蛋白介导的抗CRISPR表达和活性诱导方法，为基因组编辑提供了更多的控制手段。 生信鉴定方法 anti-CRISPRdb 可以直接跟现成的anti-CRISPR数据库比对。 anti-CRISPRdb （http://guolab.whu.edu.cn/anti-CRISPRdb/）存储了已知的一些anti-CRISPR蛋白序列，我们下载序列文件，使用blast或者diamond建库后，进行序列比对即可。\n1 2 3 4 5 6 7 wget -c http://guolab.whu.edu.cn/anti-CRISPRdb/dataset/proteinSequence_V2.2.faa # 下载的序列有一些空格，需要去除 awk \u0026#39;/^\u0026gt;/ {print; next} {gsub(\u0026#34; \u0026#34;, \u0026#34;\u0026#34;); print}\u0026#39; proteinSequence_V2.2.faa \u0026gt;proteinSequence_V2.2_rm_space.faa # 建库 ~/miniconda3/envs/func/bin/diamond makedb --in proteinSequence_V2.2_rm_space.faa --db proteinSequence_V2.2 # 比对 ~/miniconda3/envs/func/bin/diamond blastp --db ~/db/Anti-CRISPRdb/proteinSequence_V2.2 --query your_seq.faa --out your_seq.out --outfmt 6 --max-target-seqs 1 --threads 8 --evalue 1e-5 --quiet PreAcrs 一种新型机器学习集成预测器：PreAcrs[3]，用于直接从蛋白质序列中识别抗 CRISPR 蛋白质。使用三种特征和八种不同的机器学习算法来训练 PreAcrs。 PreAcrs 优于其他现有方法，并显着提高了识别抗 CRISPR 蛋白的预测准确性。\n源代码位于：https://github.com/Lyn-666/anti_CRISPR.git\nReferences PEI Chenchen, LI Yingjun. Origin, development, and application of anti-CRISPR[J]. Microbiology China, 2021, 48(9): 3353-3367. Na Xu, Yunxia Gong, Yanchun Shao, Shushan Gao, Shouwen Chen, Fusheng Chen. Research progress of CRISPR-Cas system and anti-CRISPR protein in microorganisms. Acta Microbiologica Sinica, 2021, 61(8): 2172-2191. PreAcrs: a machine learning framework for identifying anti-CRISPR proteins. https://doi.org/10.1186/s12859-022-04986-3 ","date":"2024-07-31T00:00:00Z","image":"/p/anti-crispr/images/acr_mechanism_hu_3a44c402ad9bb05d.jpg","permalink":"/p/anti-crispr/","title":"Anti-CRISPR 相关内容学习"},{"content":"Introduction 确定基因序列之间的系统发育关系是比较生物学研究的基础。它为理解地球上生命的进化和多样性提供了框架，并能够在生物体之间推断生物知识。鉴于此过程对生物研究多个领域的核心重要性，人们开发了一系列不同的软件工具，试图在给定用户提供的基因序列集的情况下识别这些关系。\n在基因组学和进化生物学中，直系同源、旁系同源和正交群是重要的概念：\n直系同源（Orthologs）： 直系同源基因是在不同物种中通过共同祖先的基因分裂而产生的。这类基因通常具有相似的功能，因为它们在不同物种间保留了原始基因的功能。 旁系同源（Paralogs）： 旁系同源基因是由于基因重复而在同一物种内形成的。这些基因可能会演化出不同的功能，因为它们不再受到相同的功能限制。 正交群（Orthogroups）： 正交群是一个集合，包含了来自不同物种的直系同源基因以及由它们衍生的旁系同源基因。正交群提供了一种组织基因的方式，以便于研究基因的功能和进化历史。 上图展示了一个关于人类、小鼠和鸡三种物种的基因树示例。直系同源基因是从两个物种的最后共同祖先（LCA）中单个基因后代的基因对（B）。它们可以被认为是两个物种之间的“等价基因”。正交群是这个概念的扩展，指的是来自多个物种共同祖先的单个基因后代的基因群（A）。在正交群中的基因可以是彼此的直系同源基因，也可以是旁系同源基因。\n树显示了基因的进化历史。首先，发生了一个物种分化事件，鸡的谱系与人类和小鼠的共同祖先分离。在人类和小鼠的共同祖先中，X处发生了基因重复事件，产生了Y和Z两个基因。当人类和小鼠分化时，它们各自继承了Y基因（变成了HuA和MoA）和Z基因（变成了HuB和MoB）。一般来说，我们可以通过它在一个物种中创建两个基因副本（如HuA和HuB）来识别基因重复事件。\n要区分基因是直系同源还是旁系同源，需要识别树中的基因重复事件。直系同源基因是在物种分化事件中分化的（如HuA和MoA），而旁系同源基因是在基因重复事件中分化的（如HuA和MoB，以及其他）。直系同源基因只在物种分化时分离，因此在两个物种之间，它们是最接近的基因。旁系同源基因则在共同祖先中的基因重复事件中分化，因此比直系同源基因之间的关系更远。旁系同源基因也可能存在于同一个物种内（如HuA和HuB）。\n鸡的基因与其他基因的分化发生在通向鸡的谱系与通向人类和鼠的谱系分离时。因此，鸡的基因ChC是人类中的HuA和HuB以及鼠中的MoA和MoB的直系同源基因。根据基因分化后的情况，直系同源基因可以是一对一关系（如HuA - MoA）、多对一关系（如HuA和HuB - ChC）或多对多关系（在此树中没有例子，但如果鸡中有一个重复，这种情况就会发生）。所有这些关系都可以通过OrthoFinder识别。\nOrthoFinder 是一个用于系统发育直系同源推断的软件程序，最新版于2019年发表于Genome Biology上[1]。\n软件主页：https://github.com/davidemms/OrthoFinder\n它将想要分析的物种的蛋白质组作为输入，并自动从中进行：\n推断的物种的直系群 推断出一套完整的有根基因树 推断有根物种树 使用基因树推断基因之间的所有直系同源关系 推断基因重复事件并将其交叉引用到基因和物种树上的相应节点 提供的物种的比较基因组学统计数据 除了大规模分析之外，它还可以用于在实验研究之前仔细检查各个直系同源关系。 与其他同源推理软件不同，OrthoFinder 使用基因树。这意味着可以检查其来源的基因树中的每个直系同源关系。基因树的使用提供了非常高的直向同源推理精度：\n尽管 OrthoFinder 使用更严格的、基于基因树的方法进行直向同源推理，但它的速度却令人难以置信！除此之外，它还比其他方法返回更多的比较基因组学数据（直系群、直向同源物、根基因树、基因重复事件等）\nUsage 安装 在Linux上安装OrthoFinder 可以通过Bioconda或直接从GitHub下载来安装OrthoFinder。以下是直接下载的说明，其他方法请参考教程。\n从GitHub下载最新版本：OrthoFinder Releases\n如果已安装Python及其numpy和scipy库，请下载 OrthoFinder_source.tar.gz。否则，请下载包含更多依赖的 OrthoFinder.tar.gz。\n在终端中，进入下载包的目录。\n解压文件：\n1 tar xzf OrthoFinder_source.tar.gz 或\n1 tar xzf OrthoFinder.tar.gz 添加环境变量：\n1 2 echo \u0026#39;export PATH=$PATH:/path/to/OrthoFinder/\u0026#39; \u0026gt;\u0026gt; ~/.bashrc source ~/.bashrc 测试OrthoFinder是否安装成功：\n1 orthofinder -h OrthoFinder是用Python编写的，但打包版本不需要在的计算机上安装Python。\nMac： 最简单的安装方式是使用Bioconda： 1 conda install orthofinder Windows： 最简单的运行方式是使用Windows Subsystem for Linux或Docker： 1 2 3 docker pull davidemms/orthofinder docker run -it --rm davidemms/orthofinder orthofinder -h docker run --ulimit nofile=1000000:1000000 -it --rm -v /full/path/to/fastas:/input:Z davidemms/orthofinder orthofinder -f /input 在Docker容器中运行OrthoFinder速度可能不如本地运行快。\n运行 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 # OrthoFinder 2.5.4 使用帮助 # 简单用法 # 完整分析: 对FASTA格式的蛋白质组进行全分析 orthofinder [选项] -f \u0026lt;目录\u0026gt; # 添加新物种并重新分析: 在之前的分析结果基础上添加新物种 orthofinder [选项] -f \u0026lt;新目录\u0026gt; -b \u0026lt;旧目录\u0026gt; # 选项 -t \u0026lt;int\u0026gt; # 并行序列搜索线程数 [默认=64] -a \u0026lt;int\u0026gt; # 并行分析线程数 -d # 输入为DNA序列 -M \u0026lt;txt\u0026gt; # 基因树推断方法 [默认=dendroblast] -S \u0026lt;txt\u0026gt; # 序列搜索程序 [默认=diamond] -A \u0026lt;txt\u0026gt; # MSA程序，需要`-M msa` [默认=mafft] -T \u0026lt;txt\u0026gt; # 树推断方法，需要`-M msa` [默认=fasttree] -s \u0026lt;file\u0026gt; # 用户指定的已生根的物种树 -I \u0026lt;int\u0026gt; # MCL膨胀参数 [默认=1.5] -x \u0026lt;file\u0026gt; # 输出OrthoXML格式的结果信息 -p \u0026lt;dir\u0026gt; # 将临时的pickle文件写入指定目录 -1 # 只执行单向序列搜索 -X # 不在序列ID中添加物种名称 -y # 在HOG的根下分离旁系同源群 -z # 不修剪MSA -n \u0026lt;txt\u0026gt; # 结果目录名后缀 -o \u0026lt;txt\u0026gt; # 非默认结果目录 -h # 打印帮助文本 # 工作流程停止选项 -op # 在准备输入文件后停止 -og # 在推断正交群后停止 -os # 在写入正交群序列文件后停止（需要`-M msa`） -oa # 在推断正交群的比对后停止（需要`-M msa`） -ot # 在推断正交群基因树后停止 # 工作流程重启命令 -b \u0026lt;dir\u0026gt; # 从预先计算的BLAST结果开始 -fg \u0026lt;dir\u0026gt; # 从预先计算的正交群开始 -ft \u0026lt;dir\u0026gt; # 从预先计算的基因树开始 # 许可证 # 根据GNU通用公共许可证（GPLv3）发布。详见License.md。 在示例数据类型上运行 OrthoFinder：\n1 orthofinder -f OrthoFinder/ExampleData 要在自己的数据集上运行，请将“OrthoFinder/ExampleData”替换为包含输入 fasta 文件的目录，每个物种一个文件。 OrthoFinder 将查找具有以下任意文件扩展名的输入 fasta 文件：.fa, .faa, .fasta, .fas, .pep\n运行过程如下：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 OrthoFinder version 2.5.4 Copyright (C) 2014 David Emms 2024-07-31 11:19:21 : Starting OrthoFinder 2.5.4 4 thread(s) for highly parallel tasks (BLAST searches etc.) 1 thread(s) for OrthoFinder algorithm Checking required programs are installed ---------------------------------------- Test can run \u0026#34;mcl -h\u0026#34; - ok Test can run \u0026#34;fastme -i /share/home/jianglab/pengchen/biosoft/OrthoFinder/ExampleData/ OrthoFinder/Results_Jul31/WorkingDirectory/SimpleTest.phy -o /share/home/jianglab/pengchen/biosoft/OrthoFinder/ExampleData/OrthoFinder/Results_Jul31/ WorkingDirectory/SimpleTest.tre\u0026#34; - ok Dividing up work for BLAST for parallel processing -------------------------------------------------- 2024-07-31 11:19:24 : Creating diamond database 1 of 4 2024-07-31 11:19:24 : Creating diamond database 2 of 4 2024-07-31 11:19:24 : Creating diamond database 3 of 4 2024-07-31 11:19:24 : Creating diamond database 4 of 4 Running diamond all-versus-all ------------------------------ Using 4 thread(s) 2024-07-31 11:19:24 : This may take some time.... 2024-07-31 11:19:24 : Done 0 of 16 2024-07-31 11:19:31 : Done 10 of 16 2024-07-31 11:19:35 : Done all-versus-all sequence search Running OrthoFinder algorithm ----------------------------- 2024-07-31 11:19:36 : Initial processing of each species 2024-07-31 11:19:36 : Initial processing of species 0 complete 2024-07-31 11:19:36 : Initial processing of species 1 complete 2024-07-31 11:19:36 : Initial processing of species 2 complete 2024-07-31 11:19:36 : Initial processing of species 3 complete 2024-07-31 11:19:39 : Connected putative homologues 2024-07-31 11:19:39 : Written final scores for species 0 to graph file 2024-07-31 11:19:39 : Written final scores for species 1 to graph file 2024-07-31 11:19:39 : Written final scores for species 2 to graph file 2024-07-31 11:19:39 : Written final scores for species 3 to graph file 2024-07-31 11:19:40 : Ran MCL Writing orthogroups to file --------------------------- OrthoFinder assigned 2216 genes (81.1% of total) to 608 orthogroups. Fifty percent of all genes were in orthogroups with 4 or more genes (G50 was 4) and were contained in the largest 280 orthogroups (O50 was 280). There were 268 orthogroups with all species present and 245 of these consisted entirely of single-copy genes. 2024-07-31 11:19:43 : Done orthogroups Analysing Orthogroups ===================== Calculating gene distances -------------------------- 2024-07-31 11:19:45 : Done Inferring gene and species trees -------------------------------- 2024-07-31 11:19:46 : Done 0 of 323 2024-07-31 11:19:47 : Done 100 of 323 2024-07-31 11:19:49 : Done 200 of 323 2024-07-31 11:19:50 : Done 300 of 323 268 trees had all species present and will be used by STAG to infer the species tree Best outgroup(s) for species tree --------------------------------- 2024-07-31 11:19:53 : Starting STRIDE 2024-07-31 11:19:53 : Done STRIDE Observed 2 well-supported, non-terminal duplications. 2 support the best roots and 0 contradict them. Best outgroups for species tree: Mycoplasma_hyopneumoniae Mycoplasma_agalactiae, Mycoplasma_hyopneumoniae Mycoplasma_agalactiae WARNING: Multiple potential species tree roots were identified, only one will be analyed. Reconciling gene trees and species tree --------------------------------------- Outgroup: Mycoplasma_hyopneumoniae 2024-07-31 11:19:53 : Starting Recon and orthologues 2024-07-31 11:19:53 : Starting OF Orthologues Exception RuntimeError: RuntimeError(\u0026#39;cannot join current thread\u0026#39;,) in \u0026lt;Finalize object, dead\u0026gt; ignored 2024-07-31 11:19:53 : Done 0 of 323 2024-07-31 11:19:54 : Done 100 of 323 2024-07-31 11:19:54 : Done 200 of 323 2024-07-31 11:19:55 : Done 300 of 323 2024-07-31 11:19:55 : Done OF Orthologues Writing results files ===================== 2024-07-31 11:19:59 : Done orthologues Results: /share/home/jianglab/pengchen/biosoft/OrthoFinder/ExampleData/OrthoFinder/Results_Jul31/ 一些问题 安装问题，glibc找不到合适版本 建议下载OrthoFinder v2.5.4的OrthoFinder_glibc-2.15.tar.gz文件，其中包含了正确的glibc，我运行成功。安装其他版本会报错找不到glibc，但我没有root权限，解决不了。\n我在使用的时候遇到了一个问题： 1 ERROR: The system limits on the number of files a process can open is too low. 这是因为OrthoFinder需要同时打开大量的文件，ulimit 应设置为物种数的平方加 100。我当时有3000多个物种，所以ulimit -n 应该设置为900多万，但实际上我没有root权限改不了，这个软件也不能摆脱这个限制。\n输出 标准 OrthoFinder 运行会生成一组文件，描述正向群、直系同源物、基因树、解析基因树、有根物种树、基因重复事件和正在分析的物种集的比较基因组统计数据。这些文件位于直观的目录结构中。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 OrthoFinder/ExampleData/OrthoFinder/ └── Results_Jul31 ├── Citation.txt ├── Comparative_Genomics_Statistics ├── Gene_Duplication_Events ├── Gene_Trees ├── Log.txt ├── Orthogroups ├── Orthogroup_Sequences ├── Orthologues ├── Phylogenetically_Misplaced_Genes ├── Phylogenetic_Hierarchical_Orthogroups ├── Putative_Xenologs ├── Resolved_Gene_Trees ├── Single_Copy_Orthologue_Sequences ├── Species_Tree └── WorkingDirectory Phylogenetic_Hierarchical_Orthogroups 目录 从版本 2.4.0 开始，OrthoFinder 通过分析有根基因树来推断 HOG，即每个层次级别（即物种树中的每个节点）的正交群。这是一种比所有其他方法使用的以及 OrthoFinder（已弃用的 Orthogroups/Orthogroups.tsv 文件）之前使用的基于基因相似性/图的方法准确得多的正交群推断方法。根据 Orthobench 基准测试，这些新的正交群比 OrthoFinder 2 正交群 (Orthogroups/Orthogroups.tsv) 的准确度高 12%。通过包含外群物种，可以进一步提高准确度（在 Orthobench 上准确度提高 20%），这有助于解释根基基因树。\n重要的是要确保 OrthoFinder 所使用的物种树准确，以便最大限度地提高 HOG 的准确性。要使用不同的物种树重新分析，请使用选项 -ft PREVIOUS_RESULTS_DIR -s SPECIES_TREE_FILE。这仅“从树”运行最终分析步骤，并且相对较快。如果使用外群物种，请参阅“Species_Tree/SpeciesTree_rooted_node_labels.txt”以确定哪个 N?.tsv 文件包含需要的正交群。\nN0.tsv 是制表符分隔的文本文件。每行包含属于单个正交群的基因。每个直系群的基因被组织成列，每个物种一个。其他列给出了 HOG（分层正交群）ID 以及确定 HOG 的基因树中的节点（注意，这可以位于包含基因的进化枝的根部之上）。该文件有效地替换了使用 MCL 进行马尔可夫聚类的 Orthogroups/Orthogroups.tsv 中的正交群。\nN1.txt、N2.tsv、\u0026hellip;：从与物种树 N1、N2 等中的物种进化枝相对应的基因树推断出的正交群。因为 OrthoFinder 现在推断物种树内每个层次级别的正交群，所以它是现在可以在分析中包含外类群物种，然后使用 HOG 文件获取为物种树中所选进化枝定义的直系类群。\n（分层正交群分裂：在分析基因树时，嵌套的分层群（除 N0 之外的任何 HOG，所有物种最后一个共同祖先级别的 HOG）有时可能会丢失来自最早分化物种的基因，然后复制在第一个现存基因之前，即使有证据表明它们属于同一个 HOG，两个最初的分歧进化枝也将是旁系同源的。对于大多数分析来说，通常最好将这些进化枝分成不同的组。使用 -y参数。）\nOrthologues 目录 Orthologues 目录包含每个物种的一个子目录，该子目录又包含每个成对物种比较的文件，列出该物种对之间的直向同源物。直向同源物可以是一对一、一对多或多对多，具体取决于直向同源物分歧以来的基因重复事件。\n文件中的每一行都包含一个物种中的基因，这些基因是其他物种中基因的直系同源物，并且每一行都交叉引用到包含这些基因的直系群。\nOrthogroups 目录（已弃用） 应使用 Phylogenesis_Hierarchical_Orthogroups/ 中的正交群。它们是使用有根基因树来识别的，准确率提高了 12%-20%。\nOrthogroups.tsv（已弃用）是一个制表符分隔的文本文件。每行包含属于单个正交群的基因。每个直系群的基因被组织成列，每个物种一个。应改用 Phylogenesis_Hierarchical_Orthogroups/N0.tsv 中的正交群。 Orthogroups_UnassignedGenes.tsv 是一个制表符分隔的文本文件，其格式与 Orthogroups.csv 相同，但包含未分配给任何 orthogroup 的所有基因。 Orthogroups.txt（旧格式）是第二个文件，其中包含 Orthogroups.tsv 文件中描述的正交群，但使用 OrthoMCL 输出格式。 Orthogroups.GeneCount.tsv 是一个制表符分隔的文本文件，其格式与 Orthogroups.csv 相同，但包含每个正交群中每个物种的基因数量计数。 Orthogroups_SingleCopyOrthologues.txt 是每个物种仅包含一个基因的直系群列表，即它们包含一对一的直系同源物。它们非常适合物种间比较和物种树推断。 Gene_Trees 目录 为每个具有 4 个或更多序列的正交群推断的有根系统发育树（4 个序列是大多数树推断程序进行树推断所需的最小数量）。\nResolved_Gene_Trees 目录 为每个具有 4 个或更多序列的正交群推断的有根系统发育树，并使用 OrthoFinder 混合物种重叠/重复丢失合并模型进行解析。\nSpecies_Tree 目录 SpeciesTree_rooted.txt 从所有正交群推断出的 STAG 物种树，包含内部节点处的 STAG 支持值并使用 STRIDE 进行设定根。 SpeciesTree_rooted_node_labels.txt 与上面相同的树，但节点给定标签（而不是支持值），以允许其他结果文件交叉引用物种树中的分支/节点（例如基因重复事件的位置）。 Comparative_Genomics_Statistics 目录 Duplications_per_Orthogroup.tsv 是一个制表符分隔的文本文件，给出每个正交群中标识的重复项数。该数据的主文件是 Gene_Duplication_Events/Duplications.tsv。 Duplications_per_Species_Tree_Node.tsv 是一个制表符分隔的文本文件，给出了物种树每个分支上识别出的重复数量。该数据的主文件是 Gene_Duplication_Events/Duplications.tsv。 Orthogroups_SpeciesOverlaps.tsv 是一个制表符分隔的文本文件，其中包含每个物种对之间共享的正交群数量（以方阵形式）。 OrthologuesStats_*.tsv 文件是制表符分隔的文本文件，其中包含矩阵，给出每对物种之间一对一、一对多和多对多关系中的直向同源物的数量。 OrthologuesStats_one-to-one.tsv 是每个物种对之间一对一直系同源物的数量。 OrthologuesStats_many-to-many.tsv 包含每个物种对的多对多关系中的直向同源物的数量（由于物种形成后两个谱系中的基因重复事件）。条目 (i,j) 是物种 i 中与物种 j 中的基因具有多对多直系关系的基因数量。 OrthologuesStats_one-to-many.tsv：条目 (i,j) 给出物种 i 中与物种 j 的基因处于一对多直系关系的基因数量。这里有一个示例结果文件的演练：#259。 OrthologuesStats_many-to-one.tsv：条目 (i,j) 给出物种 i 中与物种 j 的基因处于多对一直系关系的基因数量。这里有一个示例结果文件的演练：#259。 OrthologuesStats_Total.tsv 包含每个物种的直系同源对（无论多重性）的总数。条目 (i,j) 是物种 i 中与物种 j 中具有直向同源物的基因总数。 Statistics_Overall.tsv 是一个制表符分隔的文本文件，其中包含有关正交群大小和分配给正交群的基因比例的一般统计数据。 Statistics_PerSpecies.tsv 是一个制表符分隔的文本文件，其中包含与统计数据_Overall.csv 文件相同的信息，但针对每个单独的物种。 文件“Statistics_Overall.csv”和“Statistics_PerSpecies.csv”中的大多数术语都是不言自明的，其余术语定义如下。\n物种特异性正交群：完全由一个物种的基因组成的正交群。 G50：正交群中基因的数量，其中 50% 的基因位于该大小或更大的正交群中。 O50：50% 的基因位于该大小或更大的正交群中的最小数量。 单拷贝正交群：每个物种只有一个基因（且不再有）的正交群。这些正交群非常适合推断物种树和许多其他分析。 未分配的基因：尚未与任何其他基因一起放入邻位群的基因。 Gene_Duplication_Events 目录 Duplications.tsv 是一个制表符分隔的文本文件，其中列出了通过检查每个正交群基因树的每个节点识别的所有基因重复事件。这些列是“正交群”、“物种树节点”（发生复制的物种树的分支，请参阅 Species_Tree/SpeciesTree_rooted_node_labels.txt）、“基因树节点”（与基因复制事件相对应的节点，请参阅相应的正交群） Resolved_Gene_Trees/) 中的树； “支持”（存在复制基因的两个拷贝的预期物种的比例）； “类型”（“终端”：物种树的终端分支上的重复，“非终端”：物种树的内部分支上的重复，因此由多个物种共享，“非终端：STRIDE”：非终端复制也通过了非常严格的 STRIDE 检查，以了解复制后基因树的拓扑结构）； “基因 1”（源自重复基因的一个拷贝的基因列表）、“基因 2”（源自重复基因的另一个拷贝的基因列表。\nSpeciesTree_Gene_Duplications_0.5_Support.txt 提供了物种树分支上的上述重复项的总和。它是 newick 格式的文本文件。每个节点或物种名称后面的数字是在通向该节点/物种的分支上发生的具有至少 50% 支持的基因重复事件的数量。分支长度是标准分支长度，如 Species_Tree/SpeciesTree_rooted.txt 中给出。\nOrthogroup_Sequences 每个邻位群的 FASTA 文件给出了邻位群中每个基因的氨基酸序列。\nSingle_Copy_Orthologue_Sequences 与“Orthogroup Sequences”目录相同的文件，但仅限于每个物种仅包含一个基因的那些orthogroup。\nReferences Emms, D.M. and Kelly, S. (2019) OrthoFinder: phylogenetic orthology inference for comparative genomics. Genome Biology 20:238 ","date":"2024-07-31T00:00:00Z","image":"/p/orthofinder/images/Workflow_hu_772ed323f696a6d9.png","permalink":"/p/orthofinder/","title":"使用Orthofinder进行系统发育直系同源推断"},{"content":"Introduction METabolic And BiogeOchemistry anaLyses In miCrobes (METABOLIC) 是一款基于微生物群的生物化学分析软件。该软件能够预测任何给定基因组数据集的代谢和生物地球化学功能性状特征。这些基因组数据集可以是宏基因组组装基因组 (MAG)、单细胞扩增基因组 (SAG) 或分离菌株测序基因组。\nMETABOLIC有两个主要实现，分别是METABOLIC-G和METABOLIC-C。 METABOLIC-G.pl 允许生成输入基因组的代谢谱和生物地球化学循环图，并且不需要输入测序读数。 METABOLIC-C.pl 生成与 METABOLIC-G.pl 相同的输出，但由于它允许输入宏基因组读取数据，因此它将生成与群落代谢有关的信息。它还可以计算基因组覆盖度。解析信息并生成元素/生物地球化学循环路径（当前为氮、碳、硫和“其他”）的图表。\nZhou, Z., Tran, P.Q., Breister, A.M. et al. METABOLIC: high-throughput profiling of microbial genomes for functional traits, metabolism, biogeochemistry, and community-scale functional networks. Microbiome 10, 33 (2022). https://doi.org/10.1186/s40168-021-01213-8\n主页：https://github.com/AnantharamanLab/METABOLIC\n安装 Anaconda environment\nGit clone 1 2 3 4 # get to the path where you want to set up your METABOLIC_running folder mkdir /path/to/METABOLIC_running_folder cd /path/to/METABOLIC_running_folder git clone https://github.com/AnantharamanLab/METABOLIC.git 安装依赖包 1 2 3 4 5 conda env create -f METABOLIC/METABOLIC_v4.0_env.yml # In the popup after running all the installation in setting up this conda env, it asks you to rewrite the database address of GTDB-Tk; # Rewrite GTDBTK_DATA_PATH conda env config vars set GTDBTK_DATA_PATH=\u0026#34;/path/to/your/databases/GTDBTK_DB\u0026#34; 激活环境 1 conda activate METABOLIC_v4.0 Run the setup bash script 1 2 cd METABOLIC bash run_to_setup.sh #网速不是很好，花了4个小时 如果运行 bash 脚本，设置过程中可能会出现一些小问题，可以参考https://github.com/AnantharamanLab/METABOLIC/wiki/Installation里的步骤 2-8 来解决。\n运行 参数 所有必需和可选的参数： 要查看 METABOLIC-C.pl 和 METABOLIC-G.pl 的选项，请输入：\n1 2 perl METABOLIC-G.pl -help perl METABOLIC-C.pl -help -in-gn [必需，如果从核苷酸fasta文件开始]：定义包含以\u0026quot;.fasta\u0026quot;结尾的基因组核苷酸fasta文件的文件夹位置。 -in [必需，如果从faa文件开始]：定义包含以\u0026quot;.faa\u0026quot;结尾的基因组氨基酸文件的文件夹位置。 -r [必需]：定义包含配对reads路径的文本文件的路径。 -rt [可选]：定义使用“metaG”或“metaT”以指示是使用宏基因组reads还是宏转录组reads（默认值：“metaG”）。仅在使用 METABOLIC-C 时需要。 -st [可选]：定义测序类型（“illumina”、“pacbio”、“pacbio_hifi”、“pacbio_asm20”或“nanopore”）（默认值：“illumina”）。 -t [可选]：定义程序运行的线程数（默认值：20）。 -m-cutoff [可选]：定义将KEGG模块指定为存在的步骤比例（默认值：0.75）。 -kofam-db [可选]：定义程序使用的KOfam数据库类型（“full”或“small”）（默认值：“full”）。 -tax [可选]：计算微生物组贡献的分类学水平（默认值：“phylum”）。 -p [可选]：定义用于注释ORFs的Prodigal方法（“meta”或“single”）（默认值：“meta”）。 -o [可选]：定义程序创建的输出目录（默认值：当前目录）。 详细使用方法请查看帮助文档。\n“-in-gn”标志指定的目录应包含基因组的核苷酸序列，文件扩展名为“.fasta”。如果为每个基因组提供氨基酸序列，这些序列应包含在一个目录中并具有文件扩展名“.faa”，并且将使用“-in”选项。确保每个“.fasta”或“.faa”文件的 fasta 标头是唯一的（所有 fasta 或 faa 文件将连接在一起形成“total.fasta”或“total.faa”文件；确保所有序列标头是唯一的），并且文件名不包含空格（建议在文件名中仅使用字母数字字符和下划线）；确保在基因组文件夹中仅放置基因组，而不放置其他文件，例如非基因组宏基因组组件，因为 METABOLIC 会将文件夹中的所有文件作为基因组纳入。如果想使用 METABOLIC-C，则仅允许“fasta”文件和“-in-gn”标志才能正确执行分析。\n“-r”标志允许输入定义宏基因组读取路径的文本文件（如果运行 METABOLIC-C）。宏基因组读数是指用于生成 MAG 的宏基因组读数数据集。在运行 METABOLIC-C 之前，请尝试确认使用的是解压缩的 fastq 文件而不是压缩文件。成对的读数集输入一行，用“，”分隔。请注意，应该给出读取文件的绝对路径。该文本文件的示例如下：\n1 2 3 #Read pairs: /path/to/your/reads/file/SRR3577362_sub_1.fastq,/path/to/your/reads/file/SRR3577362_sub_2.fastq /path/to/your/reads/file/SRR3577362_sub2_1.fastq,/path/to/your/reads/file/SRR3577362_sub2_2.fastq 请注意，两组不同的配对读取由换行符（新行）分隔，并且每行中的两个读取由“,”分隔，但不是“ ,”或“, ”（逗号前后没有空格） 。不允许有空行。\n如果使用PacBio或Nanopore生成的长读长，则需要使用“-st”（或“-sequencing-type”）选项来指示测序方法的类型（请参阅上面的标志参数说明）。请注意，短读长 (Illumina) 和长读长（PacBio 或 Nanopore）不应一起用作输入。与短读取的要求一样，在运行 METABOLIC-C 之前尝试确认使用的是解压缩的 fastq 文件而不是压缩文件。由于长读取是作为单端读取提供的，因此请注意，应该给出读取文件的绝对路径。每行应提供不同的读取文件（如果有），如下所示： 1 2 3 #Read pairs: /path/to/your/reads/file/Nanopore_1st_run.fastq /path/to/your/reads/file/Nanopore_2nd_run.fastq 请注意，hmmsearch 和 hmmscan（在 dbCAN2 处理步骤中）通常会占用非常小的内存负载，而当与大量 CPU 线程并行运行时，聚合内存需求可能非常高，并可能给服务器带来问题。有人建议使用 40 个核心将占用 1TB RAM。可以以此为标准来自定义线数设置。 示例数据 METABOLIC 目录还包含一组 5 个基因组和一组配对的宏基因组读数，可用于测试 METABOLIC-G 和 METABOLIC-C 是否正确安装。这些基因组和读数可以在目录 METABOLIC_test_files/ 中找到，该目录包含在 METABOLIC 程序目录中。 METABOLIC-C.pl 和 METABOLIC-G.pl 可以使用 METABOLIC 的 -test true 函数使用测试数据运行：\n首先看看genome测试\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 $ perl METABOLIC-G.pl -test true [2024-07-19 11:01:20] The Prodigal annotation is running... [2024-07-19 11:02:07] The Prodigal annotation is finished [2024-07-19 11:02:08] The hmmsearch is running with 5 cpu threads... [2024-07-19 11:43:54] The hmmsearch is finished [2024-07-19 11:44:58] The hmm hit result is calculating... [2024-07-19 11:44:58] Generating each hmm faa collection... [2024-07-19 11:45:04] Each hmm faa collection has been made [2024-07-19 11:45:04] The KEGG module result is calculating... [2024-07-19 11:47:54] The KEGG identifier (KO id) result is calculating... [2024-07-19 11:47:54] The KEGG identifier (KO id) seaching result is finished [2024-07-19 11:47:54] Searching CAZymes by dbCAN2... [2024-07-19 11:56:58] dbCAN2 searching is done [2024-07-19 11:56:58] Searching MEROPS peptidase... [2024-07-19 11:57:27] MEROPS peptidase searching is done [2024-07-19 11:57:34] METABOLIC table has been generated [2024-07-19 11:57:34] Drawing element cycling diagrams... Loading required package: shape [2024-07-19 11:57:36] Drawing element cycling diagrams finished METABOLIC-G was done, the total running time: 00:56:16 (hh:mm:ss) 耗时56min，内存占用1.57 GB\n1 $ perl METABOLIC-C.pl -test true 运行程序 用于运行该程序的主要脚本是 METABOLIC-G.pl 或 METABOLIC-C.pl。 为了从核苷酸序列开始运行 METABOLIC-G，METABOLIC-G 至少应使用以下标志：\n1 perl METABOLIC-G.pl -in-gn [path_to_folder_with_genome_files] -o [output_directory_to_be_created] 如何运行METABOLIC：\n主要脚本是METABOLIC-G.pl或METABOLIC-C.pl。\n要从核苷酸序列运行METABOLIC-G，至少使用以下参数：\n1 perl METABOLIC-G.pl -in-gn [基因组文件夹路径] -o [输出目录] 要从氨基酸序列运行METABOLIC-G，至少使用以下参数：\n1 perl METABOLIC-G.pl -in [基因组文件夹路径] -o [输出目录] 要运行METABOLIC-C，至少使用以下参数：\n1 perl METABOLIC-C.pl -in-gn [基因组文件夹路径] -r [配对reads列表路径] -o [输出目录] （METABOLIC-C只使用fasta文件，因此不适用-in选项。）\n第二次运行METABOLIC-C： 提供了额外的脚本METABOLIC-C.2nd_run.pl，用于多次运行相同基因组集。使用“-2nd-run”选项（默认值：“false”），设置为“true”时，需将“-o”设置为上次成功运行的输出文件夹，并设置“-2nd-run-suffix”用于新生成文件和文件夹的后缀。\n示例：\n1 perl METABOLIC-C.2nd_run.pl -in-gn [上次运行的基因组文件夹路径] -r [配对reads列表路径] -o [上次运行的输出目录] -2nd-run true -2nd-run-suffix 2nd_run_test 带有后缀“MW_score_tax_genus”的第二次运行，使用上次运行的深度文件：\n1 perl METABOLIC-C.2nd_run.pl -in-gn [上次运行的基因组文件夹路径] -r [配对reads列表路径] -o [上次运行的输出目录] -2nd-run true -2nd-run-suffix MW_score_tax_genus -depth-file All_gene_collections_mapped.depth.txt -tax genus 输出 METABOLIC 结果表 (METABOLIC_result.xlsx) 该电子表格有 6 个工作表： “HMMHitNum” = 每个基因组内是否存在定制 HMM 图谱、在基因组内识别 HMM 图谱的次数以及代表所识别蛋白质的 ORF。 “FunctionHit”= 存在或不存在蛋白质组，这些蛋白质组被识别并在标题为“HMMHitNum”的工作表中显示为单独的蛋白质。对于每个基因组，功能被标识为“存在”或“不存在”。 “KEGGModuleHit” = 每个基因组的注释，其中包含 KEGG 数据库中按代谢类别组织的模块。对于每个基因组，模块被标识为“存在”或“不存在”。 “KEGGModuleStepHit” = 每个基因组内 KEGG 数据库中模块的存在或不存在，这些模块被分成组成模块的步骤。对于每个基因组，模块步骤被标识为“存在”或“不存在”。 “dbCAN2Hit”= 针对所有基因组的 dbCAN2 注释结果（CAZy 编号和命中）。对于每个基因组，有两个不同的列，显示 CAZy 被识别的次数以及代表该蛋白质的 ORF。 \u0026ldquo;MEROPSHit\u0026rdquo; = MEROPS 肽酶搜索结果（MEROPS 肽酶编号和命中）。对于每个基因组，有两个不同的列，显示肽酶被识别的次数以及代表蛋白质的 ORF。 每个 HMM 配置文件命中氨基酸序列集合 (Each_HMM_Amino_Acid_Sequence/) 从输入基因组“.faa”文件中提取的所有氨基酸序列的集合，这些序列被识别为与 METABOLIC 提供的 HMM 配置文件匹配。 KEGG 标识符结果 (KEGG_identifier_result/) KEGG 标识符搜索结果 - 每个基因组的 KEGG 标识符编号和命中，可用于在 KEGG Mapper 中可视化路径 METABOLIC-G.pl 和 METABOLIC-C.pl 生成的所有代谢数据 (METABOLIC_Figures/) Nutrient cycling diagrams Sequential transformation diagram Metabolic Sankey diagram Functional network diagrams MW-score result (MW-score_result/) 对于 MW 分数结果，将生成显示 MW 分数（代谢体重分数）的表格（“MW-score_result.txt”）。举一个例子： 该 MW 分数图基于太平洋瓜伊马斯盆地深海热液喷口环境中微生物群落的宏基因组数据集。它包含 98 个 MAG 和 1 组宏基因组读数。在弄清楚整个群落的功能能力和每个功能的基因覆盖范围后，通过使用类似的研究代谢相互作用的方法，选择了基因组之间共享的功能，并通过将它们的丰度相加来总结它们在整个群落中的权重。\n在示例图中，“每个功能的MW得分”列表示整个社区内的功能权重。更频繁地共享功能及其更高的丰度会导致更高的 MW 分数，这定量地反映了功能网络中的功能权重。 其余列表示每个门对 MW 分数的贡献。这有助于反映每个门对整个群落功能的贡献。总体而言，MW 分数提供了一种比较功能权重和功能网络内微生物群贡献的定量测量方法。\n","date":"2024-07-17T00:00:00Z","image":"/p/metabolic/images/MW-score_table_example_hu_e39c48da8c0e9d37.jpg","permalink":"/p/metabolic/","title":"METABOLIC：微生物基因组群落规模功能网络分析"},{"content":"Introduction 基因组规模代谢模型（Genome-scale metabolic model，GEM）是通过整合基因组数据、代谢途径和生化反应信息，模拟和分析生物体代谢网络的一种强大工具。GEM不仅能帮助我们理解生物体的代谢功能和代谢网络的复杂性，还可以用于预测基因敲除效应、代谢工程、药物开发等多种应用。我们应该可以从宏基因组组装的MAGs出发来做GEM建模。\n多个基因组规模的代谢重建软件平台已经开发出来并且正在不断更新。这些工具已广泛应用于重建数百种微生物的代谢模型，从重要的人类病原体到工业相关物种。2019年，Mendoza等人对以下7个基因组规模重建软件平台进行了系统评估，文章发表在genome biology上[1]，每个工具在不同的方面显示出优势和不足。\n19年有另一篇Genome biology回顾了当前重建的 GEM 并讨论了它们的应用[2]，包括化学品和材料生产的菌株开发、病原体药物靶向、酶功能预测、泛反应组分析、多个细胞或生物体之间的相互作用建模以及了解人类疾病。其中还介绍了以下参考GEM数据库： 本文将通过metaGEM 流程中的几个软件工具，介绍从宏基因组数据做 GEM 建模的原理的步骤。\nMethods metaGEM https://github.com/franciscozorrilla/metaGEM/\nmetaGEM 是一个 Snakemake 工作流程[3]，集成了一系列现有的生物信息学和代谢建模工具，旨在预测微生物组细菌群落内的代谢相互作用。根据整个宏基因组鸟枪数据集，重建宏基因组组装基因组 (MAG)，然后将其转换为基因组规模代谢模型 (GEM) 以进行计算机模拟。其他输出包括丰度估计、分类分配、增长率估计、全基因组分析和真核 MAG 鉴定。\n很明显，绿色方框内的MAG生成模块是我们之前已经介绍过的MetaWRAP实战深入binning；橙色方框是鉴定真核MAG模块；蓝色方框是MAG注释模块。这几步和GEM建模没有直接的关系，所以不在这里描述。关键的是粉色方框内的GEM建模模块。metaGEM 使用了以下几个工具：CarveMe，MEMOTE和SMETANA。\n如果按照metaGEM教程来安装这个流程会比较麻烦，需要conda安装大量的软件，metaWRAP一个流程就很难装了😂。他这里强行建了三个环境，还把mamba装在非base环境中，容易把我们已有的环境搞乱。\n所以我们假定我们已经有组装好的MAG开始分析么，关注最重要的粉色模块即可，分别介绍CarveMe，SMETANA和MEMOTE三个软件。\nCarveMe CarveMe 是一个基于 Python 的工具，用于基因组规模的代谢模型重建[4]。输入为 MAGs 的蛋白文件， 通过 BiGG 数据库构建一个通用的代谢模型，然后通用模型根据基因组文件转换为特定模型，输出构建好的代谢模型(GEMs)，是一个自上而下的流程。\n主页：https://github.com/cdanielmachado/carveme\n安装 使用pip包管理器可以轻松安装CarveMe： 1 pip install carveme 另外，还需手动安装diamond序列比对工具： 1 conda install -c bioconda diamond 安装优化求解器：推荐安装IBM CPLEX或Gurobi，并获取相应的学术许可证（演示版无效），或者用4的替代。 安装CPLEX后，还需安装CPLEX的Python API。 Cplex是IBM公司开发的一款商业版的优化引擎，当然也有免费版，只不过免费版的有规模限制，不能求解规模过大的问题。这里可以去申请学术教育版，但我们学校的邮箱居然不可以申请😭。\n然后我试了一下Gurobi：https://www.gurobi.com/downloads/gurobi-software/，用学校的邮箱申请免费试用，可以参考https://blog.csdn.net/weixin_46530492/article/details/134396504。\n1 2 3 4 5 6 7 8 9 10 # 下载解压 tar xvfz gurobi11.0.2_linux64.tar.gz # 设置环境变量： echo \u0026#39;export GUROBI_HOME=~/biosoft/gurobi1103/linux64/\u0026#39; \u0026gt;\u0026gt;~/.bashrc echo \u0026#39;export PATH=$PATH:~/biosoft/gurobi1103/linux64/bin\u0026#39; \u0026gt;\u0026gt;~/.bashrc echo \u0026#39;export LD_LIBRARY_PATH=~/biosoft/gurobi1103/linux64/lib:$LD_LIBRARY_PATH\u0026#39; \u0026gt;\u0026gt;~/.bashrc #安装gurobipy python -m pip install gurobipy 申请之后会运行一行命令得到gurobi.lic激活。\n作为替代方案，可以使用开源的SCIP求解器，但速度较慢（每次执行至少需10分钟）： 1 conda install -c conda-forge pyscipopt 执行时选择正确的求解器，默认是cplex，可以指定gurobi和scip：\n1 carve [ARGS] --solver scip 使用 构建模型：CarveMe提供了一个非常简单的命令行接口来构建模型。最基本的用法是： 1 2 3 4 5 6 7 carve genome.faa # 我们去下载一个E.coli的蛋白序列做测试 wget -c https://ftp.ncbi.nlm.nih.gov/genomes/all/GCF/000/005/845/GCF_000005845.2_ASM584v2/GCF_000005845.2_ASM584v2_protein.faa.gz gunzip GCF_000005845.2_ASM584v2_protein.faa.gz carve GCF_000005845.2_ASM584v2_protein.faa 这将从基因组文件构建一个全基因组代谢模型，试了一下，用SCIP求解器要11min，gurobi花了2min，400MB内存。\n默认情况下，CarveMe期望输入的是蛋白质FASTA文件。或者，你也可以提供DNA序列：\n1 carve --dna genome.fna 注意，不支持原始基因组文件，FASTA文件必须分成单独的基因。\n可以为输出文件指定不同的名称或目录： 1 carve genome.faa --output model.xml 如果你想生成一个压缩的SBML文件，只需更改扩展名（libSBML自动支持）：\n1 carve genome.faa -o model.xml.gz 如果不是自己提供基因组数据，你也可以提供一个NCBI RefSeq访问代码。这将自动下载序列并构建模型： 1 carve --refseq GCF_000005845.2 -o ecoli_k12_mg1655.xml 如果你已经下载了多个基因组序列，你可以运行递归模式，在一次调用中构建多个模型。这将启动多个并行进程，如果你在多核CPU或计算集群中运行CarveMe，可以减少整体计算时间： 1 2 3 4 carve -r myfolder/*.faa #与-o结合以更改输出文件夹： carve -r myfolder/*.faa -o mymodels/ 缺口填补：CarveMe尝试仅从遗传证据预测一个生物体的摄取和分泌能力，并且会生成一个不进行特定培养基缺口填补的模拟就绪模型。然而，有些情况下你希望确保模型能够在一个或多个实验验证的培养基中再现生长。例如，你可以确保模型在M9和LB培养基中再现生长： 1 carve genome.faa --gapfill M9,LB 请参阅高级用法部分了解如何提供你自己的培养基成分。如果你已经有了一个模型，只是想填补缺口，你可以使用gapfill实用函数：\n1 gapfill model.xml -m M9 -o new_model.xml 请注意，使用CarveMe生成的模型不会初始化任何培养基成分。你可以通过设置交换反应的流量边界来定义生物体的生长环境，以匹配相应的培养基成分。或者，你可以告诉CarveMe希望模型附带一个预定义的培养基成分： 1 carve genome.faa --init M9 注意，这不会填补模型的缺口，只会定义模拟目的的外部环境。要同时填补缺口并初始化模型以用于所需的培养基，你必须结合两个标志：\n1 carve genome.faa -g M9 -I M9 微生物群落：CarveMe允许从单一物种模型生成微生物群落模型。最基本的用法是： 1 2 3 merge_community organism_1.xml organism_2.xml ... organism_N.xml -o community.xml # 或更简单地： merge_community *.xml -o community.xml 这将生成一个包含每个生物体分配到自己隔室的群落的SBML文件，并生成一个通用的群落生物量方程。你可以像使用任何普通的约束模型一样将合并的模型导入任何模拟工具，并应用不同类型的模拟方法（FBA，FVA等）。你可以像单物种重建过程中一样用预定义的培养基初始化群落：\n1 merge_community [input files] -I M9 MEMOTE 主页：https://github.com/opencobra/memote\nMEMOTE全称基因组规模代谢模型测试套件，目标是推动代谢模型构建社区实现两个重大转变：\n模型应进行版本控制，以便可以跟踪并在必要时恢复更改。理想情况下，模型应通过公共存储库（如GitHub）提供，使其他研究人员能够检查、共享和贡献模型。 模型应达到某些标准和最低功能，以造福社区和研究。 MEMOTE工具执行以下四个子功能：\n创建模型的git存储库框架。 通过测试套件运行当前模型，代表社区标准。 生成详细报告，以视觉上吸引人的方式展示测试结果。 重新计算代谢模型版本控制历史的测试统计数据。 生成的存储库可以轻松集成到持续集成测试提供者（如Travis CI）中，这意味着每次将模型更改推送到GitHub时，测试套件将自动运行，并通过GitHub页面查看报告。\n安装 稳定版本：要安装memote，请在终端中运行以下命令： 1 $ pip install memote 这是安装memote的首选方法，因为它将始终安装最新的稳定版本。\n从源码安装：memote的源码可以从Github仓库下载。可以克隆公共仓库： 1 $ git clone https://github.com/opencobra/memote.git 或者下载压缩包：\n1 $ curl -OL https://github.com/opencobra/memote/archive/master.zip 下载源码文件后，可以使用以下命令安装：\n1 $ pip install . 使用 安装后，memote 可以通过三种不同的方式使用：\n作为临时模型评估的基准测试工具。当使用 memote 对模型进行基准测试时，测试会运行一次，并生成一份描述现状的报告。 1 memote report snapshot --filename \u0026#34;report.html\u0026#34; GCF_000005845.2_ASM584v2_protein.xml 虽然建议使用 html 报告，但频繁用户可能希望跳过 html 报告的生成，而仅使用原始控制台输出来获得快速概览。\n1 memote run path/to/model.xml 在控制台中，您首先会看到所有测试的列表及其 pytest 状态，读数为“通过”、“失败”、“跳过”或“错误”，然后是一个简短的回溯，显示某些测试失败的原因：\n同样，可以测试多个模型并生成比较差异的报告。 要比较两个（或更多）模型的性能，请在终端中运行以下命令：\n1 memote report diff path/to/model1.xml path/to/model2.xml [path/to/model3.xml ...] 作为一个自动化测试套件，memote 有助于跟踪版本控制存储库中的增量模型更改，并且可以根据需要启用连续测试和报告。这个我暂时用不到 SMETANA 物种代谢相互作用分析 (SMETANA) 是一个基于 Python 的命令行工具，用于分析微生物群落。 它以微生物群落（来自 SBML 格式的基因组规模代谢模型的集合）作为输入，并计算描述群落成员之间交叉喂养相互作用的潜力的几个指标[5]。\n主页：https://github.com/SBRG/smetana\n安装 SMETANA 目前支持 Python 2.7 和 Python 3.6，可用于所有主要操作系统。\n可以使用 pip 包管理器轻松安装它：\n1 $ pip install smetana 这也会自动安装其他依赖项：\nframed pandas 此外，必须安装受支持的求解器之一：\nCPLEX Gurobi 请注意，虽然这两种求解器均受支持，但 SMETANA 主要针对 CPLEX 进行了优化。\n使用 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 $ smetana -h 用法: smetana [-h] [-c COMMUNITIES.TSV] [-o OUTPUT] [--flavor FLAVOR] [-m MEDIA] [--mediadb MEDIADB] [-g | -d | -a ABIOTIC | -b BIOTIC] [-p P] [-n N] [-v] [-z] [--solver SOLVER] [--molweight] [--exclude EXCLUDE] [--no-coupling] MODELS [MODELS ...] 计算单一或多个微生物群落的SMETANA得分。 位置参数: MODELS 多个单一物种模型（一个或多个文件）。 你可以使用通配符，例如：models/*.xml，并选择用引号保护，以避免自动bash扩展（对于长列表，这会更快）：\u0026#34;models/*.xml\u0026#34;。 可选参数: -h, --help 显示帮助信息并退出 -c COMMUNITIES.TSV, --communities COMMUNITIES.TSV 为多个（子）群落运行SMETANA。 群落必须在一个两列的制表符分隔文件中指定，包含群落和生物体标识符。 生物体标识符应与SBML文件中的文件名匹配（无扩展名）。 示例: community1\torganism1 community1\torganism2 community2\torganism1 community2\torganism3 -o OUTPUT, --output OUTPUT 输出文件前缀。 --flavor FLAVOR 输入文件的预期SBML风格（cobra或fbc2）。 -m MEDIA, --media MEDIA 为指定培养基运行SMETANA（逗号分隔）。 --mediadb MEDIADB 培养基数据库文件。 -g, --global 运行全局分析（MIP/MRO），更快。 -d, --detailed 运行详细的SMETANA分析，较慢。 -a ABIOTIC, --abiotic ABIOTIC 使用给定的化合物列表测试无生物扰动。 -b BIOTIC, --biotic BIOTIC 使用给定的物种列表测试生物扰动。 -p P 同时扰动的成分数量（默认: 1）。 -n N 每个群落的随机扰动实验次数（默认: 1）。 选择n = 0将精确测试所有单一物种/化合物扰动。 -v, --verbose 切换到详细模式。 -z, --zeros 包括得分为零的条目。 --solver SOLVER 更改默认求解器（当前选项: \u0026#39;gurobi\u0026#39;, \u0026#39;cplex\u0026#39;）。 --molweight 使用分子量最小化（推荐）。 --exclude EXCLUDE 从计算中排除的化合物列表（例如：无机化合物）。 --no-coupling 不计算物种耦合得分。 单一群落 要在单一群落上运行SMETANA，只需提供一组以SBML格式表示的单一物种模型： 1 2 $ smetana species1.xml species2.xml ... $ smetana *.xml 尝试一下：\n1 smetana GCF_000005845.2_ASM584v2_protein.xml GCF_015291705.1_ASM1529170v1_protein.xml --solver gurobi 两个物种1分钟就算完了，结果：\n1 2 community\tmedium\tsize\tmip\tmro all\tcomplete\t2\t4\t0.6428571428571429 多个群落 可以在单行代码中对多个群落运行SMETANA。为此，需要创建一个描述每个群落组成的表格。该表应为长格式，使用制表符分隔，包含两列：群落ID和物种ID。后者应与SBML文件名（不带扩展名）匹配。例如： 1 2 3 4 community1 organism1 community1 organism2 community2 organism1 community2 organism3 创建此文件后，按以下方式调用SMETANA：\n1 $ smetana *.xml -c communities.tsv 培养基成分 默认情况下，SMETANA将在完全培养基成分上模拟每个群落。要在不同培养基上测试群落，提供培养基列表和包含培养基成分的文件。可以在单个命令中指定多个培养基，SMETANA将依次运行每个培养基。 1 $ smetana *.xml -m M9,LB --mediadb library.tsv 如何创建自己的库文件，请查看此示例。\n全局模式与详细模式 SMETANA有两种主要运行模式： 全局模式 (-g, \u0026ndash;global): 运行MIP/MRO，速度更快，推荐用于分析多个群落。 详细模式 (-d, \u0026ndash;detailed): 计算所有物种间相互作用（速度较慢），详细信息请参阅算法。 全局模式SMETANA 包括两种分析社区全局属性的算法： MRO（代谢资源重叠）：计算物种对相同代谢物的竞争程度。 MIP（代谢相互作用潜力）：计算物种可以共享多少代谢物以减少对外部资源的依赖。\n详细模式SMETANA 包含多个分数来表征社区中的物种互动。这包括： SCS（物种耦合评分）：衡量一个物种在其他物种存在的情况下生存的依赖性 MUS（代谢物摄取分数）：衡量一个物种生存所需摄取代谢物的频率 MPS（代谢物生产得分）：衡量一个物种产生代谢物的能力 SMETANA：个体 smetana 评分是上述 3 个评分的组合，它给出了交叉喂养相互作用的确定性度量（物种 A 从物种 B 接收代谢物 X）。\n应用 2023年的一篇Nature Biotechnology，对7,302 种人类微生物的基因组规模代谢重建，用于个性化医疗[6]。\n人类微生物群影响多种常用处方药的功效和安全性。设计结合微生物代谢的精准医学方法需要应变和分子解析的、可扩展的计算模型。在这里，通过大幅扩展的版本扩展了之前人类肠道微生物基因组规模代谢重建的资源。\nAGORA2（通过重建和分析组装肠道生物体，版本 2）包含 7,302 种菌株，包括 98 种药物的菌株解析药物降解和生物转化能力，并根据比较基因组学和文献检索进行了广泛的策划。微生物重建在三个独立组装的实验数据集上表现非常好，准确度为 0.72 至 0.84，超越了其他重建资源，并以 0.81 的准确度预测了已知的微生物药物转化。\n作者证明，AGORA2 通过预测 616 名结直肠癌患者和对照组肠道微生物组的药物转化潜力，实现了个性化、菌株解析的建模，这些微生物组在个体之间存在很大差异，并与年龄、性别、体重指数和疾病阶段相关。 AGORA2 作为人类微生物组的知识库，为宿主与微生物组代谢相互作用的个性化、预测性分析铺平了道路。\nReferences Mendoza, S.N., Olivier, B.G., Molenaar, D. et al. A systematic assessment of current genome-scale metabolic reconstruction tools. Genome Biol 20, 158 (2019). https://doi.org/10.1186/s13059-019-1769-1 Gu, C., Kim, G.B., Kim, W.J. et al. Current status and applications of genome-scale metabolic models. Genome Biol 20, 121 (2019). https://doi.org/10.1186/s13059-019-1730-3 metaGEM: reconstruction of genome scale metabolic models directly from metagenomes Francisco Zorrilla, Filip Buric, Kiran R Patil, Aleksej Zelezniak Nucleic Acids Research, 2021; gkab815, https://doi.org/10.1093/nar/gkab815 D. Machado et al, \u0026ldquo;Fast automated reconstruction of genome-scale metabolic models for microbial species and communities\u0026rdquo;, Nucleic Acids Research, gky537, 2018. doi: https://doi.org/10.1093/nar/gky537 Aleksej Zelezniak et al, Metabolic dependencies drive species co-occurrence in diverse microbial communities, PNAS, May 4, 2015, 112 (20) 6449-6454, https://doi.org/10.1073/pnas.1421834112 Heinken, A., Hertel, J., Acharya, G. et al. Genome-scale metabolic reconstruction of 7,302 human microorganisms for personalized medicine. Nat Biotechnol 41, 1320–1331 (2023). https://doi.org/10.1038/s41587-022-01628-0 ","date":"2024-07-17T00:00:00Z","image":"/p/gem/images/carveme_hu_d381b1c1cf2c437c.jpeg","permalink":"/p/gem/","title":"从宏基因组构建基因组规模代谢模型（GEM）"},{"content":"做生信分析时有时候要安装很多软件，软件之间的版本依赖关系复杂，这时候就需要用到Conda来安装软件。我一年前下载的conda，最近感觉安装软件越来越慢了，有试过一段时间的mamba（一个快速、强大、跨平台的包管理器），但是某个版本开始不兼容我已有的conda，会报错，我也没有仔细去解决。就一直在忍受着conda的慢。。。\n终于在前几天，在安装测试几个大型pipeline时受不了了，准备整理一下自己的环境，想试试最新的mamba。结果发现conda在去年十月份有一个重大更新，在这个 23.10.0 版本中，将 conda 的默认求解器更改为 conda-libmamba-solver！ 以前的“经典”求解器基于 pycosat/Picosat，并且在可预见的将来仍将是 conda 的一部分，并且可以使用后备方案。\nconda 更新日志：https://docs.conda.io/projects/conda/en/stable/release-notes.html\nconda慢就慢在计算环境中包之间的依赖关系，那换成mamba求解器，岂不是快很多而且不破坏原有的环境？（我不喜欢有个conda目录又一个mamba目录，两者的config也不太一样），赶紧试试：\n1 2 3 4 conda -V #看看你的conda版本，是不是在23.10.0以前 conda clean -a #注意，我的环境积压了太多东西，conda更新几个小时都没成功，于是清理了一下 conda update conda conda -V #再看看你的conda版本 亲身体验，更新后的conda在solve environment这一步快了非常多，几分钟左右（之前可能花上几个小时😭，因为我的一些环境已经安装了不少软件）。\n下面是conda的一些相关介绍：\nIntroduction Conda是一个开源的包管理和环境管理工具，主要用于数据科学和机器学习领域。它允许轻松地创建、安装、管理和切换不同版本的软件包和依赖项，以及创建和管理不同的虚拟环境。Conda最常用于Python环境，但也可用于其他编程语言的环境管理。(conda, mamba, python 都是蛇🐍的名字)\n以下是一些与Conda相关的基本概念和用法：\n环境（Environment）： 在Conda中，环境是一个独立的工作区，其中包含特定版本的软件包和其依赖项。可以创建多个环境，每个环境可以有不同的软件包配置，以满足不同项目的需求。\n软件包（Package）： 软件包是在Conda环境中安装的软件组件，可以包括Python库、工具和其他程序。Conda具有大量的预构建软件包，也支持创建自定义软件包。\n频道（Channel）： Conda软件包通常存储在称为\u0026quot;频道\u0026quot;的仓库中。默认情况下，Conda会从Anaconda仓库下载软件包，但也可以添加其他频道（镜像源，保证网络通畅），以获取更多软件包。\n基础使用： 安装Conda： 首先，需要安装Conda。可以选择安装Anaconda或Miniconda，它们是Conda的不同发行版。Anaconda包含大量的预安装软件包，而Miniconda只包含Conda本身和一些基本工具，允许自定义环境，服务器上的话上从miniconda上手就行。\n1 2 3 # 使用Miniconda安装 wget https://repo.anaconda.com/miniconda/Miniconda3-latest-Linux-x86_64.sh bash Miniconda3-latest-Linux-x86_64.sh 创建环境： 使用Conda可以轻松地创建新环境，例如：\n1 conda create --name myenv python=3.8 这将创建一个名为myenv的新环境，并在其中安装Python 3.8。\n激活环境： 要进入或激活一个环境，可以使用以下命令：\n1 conda activate myenv 激活环境后，将在其中运行软件包和Python。\n安装软件包： 使用Conda可以安装所需的软件包，例如：\n1 conda install numpy 这将在当前激活的环境中安装NumPy。\n管理环境： 可以列出已创建的环境、复制环境、删除环境等，以管理的工作环境。\n1 2 3 4 5 6 $ conda info -e #导出环境 conda env export \u0026gt; environment.yml #删除环境 conda remove --name myenv --all 卸载软件包： 如果不再需要某个软件包，可以使用以下命令卸载：\n1 conda remove numpy pip安装的包最好用pip来卸载，conda卸载也需要处理依赖关系，好慢的。\n我的浅薄理解：conda关键在把不同的软件放在不同文件夹下，切换环境时更新环境变量，让某些版本优先使用。\n所以有些不太依赖环境的软件可以直接用绝对路径使用，不需要激活环境：\n1 ~/miniconda3/envs/waste/bin/bowtie2 -h 有时候也可以通过软链接给某个环境“安装”软件。注意首先要清楚自己的环境以及该软件的性质，有的软件会有相对路径的依赖，简单的把bin文件移过去是不行的：\n1 ln -s ~/miniconda3/envs/waste/bin/bowtie2 ~/miniconda3/envs/new_env/bin/ 我觉得不能太过于依赖conda，自己必须也要有一定的安装软件和管理环境能力，才可以更好地面对未来各种环境问题😂。\n现在好多软件都要求新建一个环境安装，做着做着就有好多个环境了，但可能大部分通用包是冗余的，硬盘占用也大。有时候自己观察某个软件的本体和依赖项，说不定大部分依赖项我们已经装过了（我喜欢把目标类似的软件放一起，一般他们的依赖项也比较一致），我们可以手动处理。\n这里有一个简单的python脚本，用于将所有Conda环境中安装的包整理成表格，方便查看：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 import subprocess import pandas as pd import os # 获取所有conda环境的名称 def get_conda_envs(): result = subprocess.run([\u0026#39;conda\u0026#39;, \u0026#39;env\u0026#39;, \u0026#39;list\u0026#39;], stdout=subprocess.PIPE, text=True) envs = [line.split()[0] for line in result.stdout.split(\u0026#39;\\n\u0026#39;) if line and not line.startswith(\u0026#39;#\u0026#39;) and \u0026#39;envs\u0026#39; in line] envs.append(\u0026#39;base\u0026#39;) return envs # 获取指定环境中的包 def get_packages(env): result = subprocess.run([\u0026#39;conda\u0026#39;, \u0026#39;list\u0026#39;, \u0026#39;-n\u0026#39;, env], stdout=subprocess.PIPE, text=True) packages = [] for line in result.stdout.split(\u0026#39;\\n\u0026#39;)[3:]: # 跳过头几行 if line: parts = line.split() if len(parts) \u0026gt;= 4: packages.append((parts[0], parts[1], parts[2], parts[3], env)) return packages # 获取所有环境的包信息 all_packages = [] envs = get_conda_envs() for env in envs: all_packages.extend(get_packages(env)) # 转换为DataFrame并保存为CSV df = pd.DataFrame(all_packages, columns=[\u0026#39;Package\u0026#39;, \u0026#39;Version\u0026#39;, \u0026#39;Build\u0026#39;, \u0026#39;Channel\u0026#39;, \u0026#39;Environment\u0026#39;]) df.to_csv(\u0026#39;conda_packages.csv\u0026#39;, index=False) print(\u0026#34;Packages list saved to conda_packages.csv\u0026#34;) 一些问题 shell脚本中切换环境 常用的conda activate切换conda环境的方法只能在命令行中使用，放在脚本中会报错，该如何解决呢？\n必须要先在脚本里source ~/conda.sh，shell脚本里source一次就行，就可以切换多次了\n1 2 source ~/miniconda3/etc/profile.d/conda.sh conda activate waste 安装速度慢怎么办？ 可以使用国内镜像源：\n1 2 conda config --add channels https://mirrors.tuna.tsinghua.edu.cn/anaconda/pkgs/free/ conda config --set show_channel_urls yes 为什么不建议将所有内容安装到base环境中？ 随着时间的推移，Python 打包系统很容易出现不兼容性；在一个 conda 环境中安装的包越多，依赖关系图就越复杂，这使得默认的基本环境在每次安装另一个包时容易出现问题和损坏。\n因此，强烈建议为每个项目/目的使用单独的 conda 环境，以减轻 Python 打包系统的依赖关系管理问题，并使项目依赖关系尽可能独立和简单。\n","date":"2024-07-17T00:00:00Z","image":"/p/conda/images/conda_hu_e2cb5295f7a11924.png","permalink":"/p/conda/","title":"更新一下你的Conda吧"},{"content":"记录分享一些自己在linux下常用的shell脚本和小软件。\n脚本建议使用方式：新建一个储存脚本的目录如~/script，把脚本复制为相应文件，chmod +x 使脚本可执行，然后添加到PATH中方便使用。\n1 2 3 4 5 6 7 8 mkdir ~/script # add scripts chmod +x ~/script/* # add to PATH echo \u0026#39;export PATH=$PATH:~/script\u0026#39; \u0026gt;\u0026gt; ~/.bashrc source ~/.bashrc 脚本 无root使用yum安装包 参考： https://blog.csdn.net/GreenHandCGL/article/details/83055151\n现在很多服务器都是centos系统，可以用yum（ Yellow dog Updater, Modified）作为Shell 前端软件包管理器。\n而我们使用服务器的时候通常无法获得root权限，也就无法使用sudo提升权限直接用yum安装软件。 但是其实在linux中，安装软件需要权限通常是因为我们对安装位置没有权限，所以只要把软件安装到我们有权限的位置就行了。\n脚本，保存为yum_i：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 #!/bin/bash # Function to show usage show_usage() { echo \u0026#34;Usage: $0 [-y] package_name\u0026#34; exit 1 } # Check if at least one argument is provided if [ \u0026#34;$#\u0026#34; -lt 1 ]; then show_usage fi # Parse options DOWNLOAD_AND_INSTALL=false while getopts \u0026#34;:y\u0026#34; opt; do case ${opt} in y ) DOWNLOAD_AND_INSTALL=true ;; \\? ) show_usage ;; esac done shift $((OPTIND -1)) # Get the package name PACKAGE_NAME=$1 # If no package name is provided, show usage if [ -z \u0026#34;$PACKAGE_NAME\u0026#34; ]; then show_usage fi # Function to check if a command exists command_exists() { command -v \u0026#34;$1\u0026#34; \u0026gt;/dev/null 2\u0026gt;\u0026amp;1 } # Check if yum and yumdownloader are available if ! command_exists yum || ! command_exists yumdownloader; then echo \u0026#34;yum or yumdownloader command not found. Please make sure they are installed.\u0026#34; exit 1 fi # Extract the base package name BASE_NAME=$(echo \u0026#34;$PACKAGE_NAME\u0026#34; | cut -d. -f1) # If -y option is provided, download and install the package if [ \u0026#34;$DOWNLOAD_AND_INSTALL\u0026#34; = true ]; then echo \u0026#34;Downloading and installing package: $PACKAGE_NAME\u0026#34; cd ~ || exit 1 yumdownloader \u0026#34;$PACKAGE_NAME\u0026#34; RPM_FILE=$(ls \u0026#34;${BASE_NAME}\u0026#34;*.rpm 2\u0026gt;/dev/null) if [ -f \u0026#34;$RPM_FILE\u0026#34; ]; then rpm2cpio \u0026#34;$RPM_FILE\u0026#34; | cpio -idvm rm -f \u0026#34;$RPM_FILE\u0026#34; echo \u0026#34;Package $PACKAGE_NAME installed successfully.\u0026#34; else echo \u0026#34;Failed to download package $PACKAGE_NAME.\u0026#34; exit 1 fi else # Otherwise, list the package yum list \u0026#34;$PACKAGE_NAME\u0026#34; fi 使用方法：\n查询能装的包：yum_i package_name 1 2 3 4 5 6 7 8 9 $ yum_i graphviz Loaded plugins: fastestmirror, langpacks, product-id, search-disabled-repos, subscription-manager Loading mirror speeds from cached hostfile * base: mirrors.aliyun.com * extras: mirrors.aliyun.com * updates: mirrors.aliyun.com Available Packages graphviz.i686 2.30.1-22.el7 base graphviz.x86_64 2.30.1-22.el7 base 正式下载安装包：yum_i -y package_name 1 2 # 注意用上面查找到的包名替换 yum_i -y graphviz.x86_64 添加环境变量 这种方法默认安装位置是~/usr/bin/，我们把它添加到PATH中： 1 2 echo \u0026#39;export PATH=$PATH:~/usr/bin/\u0026#39; \u0026gt;\u0026gt; ~/.bashrc source ~/.bashrc 这样就可以正常调用该软件包了。\nautojump 官网：https://github.com/wting/autojump\nAutjump 是一个非常实用的命令行工具，帮助用户快速跳转到常用的目录，尤其适合经常在命令行中导航的用户。以下是一些常见的用法示例：\n快速跳转到包含特定关键字的目录 如果你想跳转到包含关键字 foo 的目录，可以使用：\n1 j foo 跳转到子目录 有时候你可能只想跳转到当前目录的某个子目录，而不想输入完整的路径名称。这时可以使用：\n1 jc bar 其中 bar 是子目录的名称。\n使用文件管理器打开目录 你还可以通过 jo 命令来使用系统的文件管理器（如 Mac Finder、Windows Explorer、GNOME Nautilus 等）打开目录，而不是直接跳转：\n1 jo music 如果你想打开子目录，也可以使用类似的命令：\n1 jco images 使用多个参数来跳转 假设你的数据库中有以下两个目录：\n1 2 30 /home/user/mail/inbox 10 /home/user/work/inbox 默认情况下，使用 j in 会跳转到 /home/user/mail/inbox，因为它的权重更高。但是，如果你想跳转到另一个目录，可以通过传递多个参数来实现：\n1 j w in 这会跳转到 /home/user/work/inbox。\n获取更多选项 如果你想了解更多使用选项，可以查看帮助文档：\n1 autojump --help 通过这些命令可以更高效地在系统目录中导航，节省大量时间。\n查找差集 使用awk查找file1中存在但file2中不存在的行，并将结果打印到标准输出，有时候在做文件名对比之类时很有用：\n脚本，保存为diff_rows：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 #!/bin/bash # 初始化变量 file1=\u0026#34;\u0026#34; file2=\u0026#34;\u0026#34; # 使用getopts解析命令行参数 while getopts \u0026#34;:f:s:\u0026#34; opt; do case \u0026#34;$opt\u0026#34; in f) file1=\u0026#34;$OPTARG\u0026#34; ;; s) file2=\u0026#34;$OPTARG\u0026#34; ;; \\?) echo \u0026#34;无效的选项： -$OPTARG\u0026#34; \u0026gt;\u0026amp;2 exit 1 ;; :) echo \u0026#34;选项 -$OPTARG 需要一个参数\u0026#34; \u0026gt;\u0026amp;2 exit 1 ;; esac done # 检查必需的参数是否提供 if [ -z \u0026#34;$file1\u0026#34; ] || [ -z \u0026#34;$file2\u0026#34; ]; then echo \u0026#34;用法: $0 -f \u0026lt;file1\u0026gt; -s \u0026lt;file2\u0026gt;\u0026#34; exit 1 fi awk \u0026#39;NR==FNR{seen[$0]=1; next} !seen[$0]\u0026#39; \u0026#34;$file2\u0026#34; \u0026#34;$file1\u0026#34; 文件夹软链接 方便创建多个软链接，将源目录中的所有文件链接到目标目录中：\n脚本，保存为link_dir：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 #!/bin/bash # 检查是否提供了源目录和目标目录 if [ $# -ne 2 ]; then echo \u0026#34;Usage: $0 \u0026lt;source_directory\u0026gt; \u0026lt;destination_directory\u0026gt;\u0026#34; exit 1 fi SOURCE_DIR=$1 DEST_DIR=$2 # 检查源目录是否存在 if [ ! -d \u0026#34;$SOURCE_DIR\u0026#34; ]; then echo \u0026#34;Source directory does not exist.\u0026#34; exit 1 fi # 检查目标目录是否存在，不存在则创建 if [ ! -d \u0026#34;$DEST_DIR\u0026#34; ]; then echo \u0026#34;Destination directory does not exist. Creating it now.\u0026#34; mkdir -p \u0026#34;$DEST_DIR\u0026#34; fi # 创建软链接 for file in \u0026#34;$SOURCE_DIR\u0026#34;/*; do ln -s \u0026#34;$file\u0026#34; \u0026#34;$DEST_DIR\u0026#34; done echo \u0026#34;Soft links created for all files in $SOURCE_DIR to $DEST_DIR\u0026#34; ","date":"2024-07-15T00:00:00Z","permalink":"/p/shell/","title":"一些实用的shell脚本"},{"content":"Introduciton 了解细菌在各种环境中的生长动态对于人类健康和环境监测等广泛领域至关重要。传统研究细菌生长的方法往往依赖于培养技术，这不仅耗时，而且对易培养的物种有偏向。然而，随着宏基因组测序技术的兴起，我们现在可以直接从环境样本中探讨整个微生物群落的生长动态。\n宏基因组学通过测序样本中所有微生物的集体基因组，提供了微生物群落的全面快照。这种方法使研究人员能够绕过培养步骤，捕捉细菌在自然栖息地中的多样性和动态。通过分析宏基因组数据，我们可以推断细菌的生长速率、种群变化和群落相互作用。\n本文主要介绍从宏基因组数据推断细菌生长速率的方法和简要应用。\nMethods PTR Science 2015: https://www.science.org/doi/10.1126/science.aac4812\n宏基因组测序增加了我们对微生物组在健康和疾病中的作用的理解，但它只提供了高度动态的生态系统的快照。在这里，作者表明不同微生物基因组的宏基因组测序读数覆盖模式包含单个波谷和单个波峰，后者与细菌复制起点一致。此外，峰和谷之间的测序覆盖率提供了物种生长速率的定量测量。\n原理：是否可以通过检查跨细菌基因组的测序读数覆盖模式来从单个宏基因组样本中探测微生物群的生长动态。除了少数例子 之外，大多数细菌都具有单个圆形染色体，它从单个固定起点向单个终点双向复制。因此，在DNA复制过程中，已经被复制叉通过的区域将有两个拷贝，而尚未复制的区域将有一个拷贝。\n总而言之，DNA 区域的拷贝数越接近复制起点，该区域的拷贝数就会越高；反之，该区域越接近复制终点，该区域的拷贝数就会越低。因此，复制起点附近的DNA拷贝数与复制终点附近的DNA拷贝数之间的比率，称之为峰谷比（Peak-to-Trough Ratio，PTR），应该反映细菌群体的生长速度。在较高的生长速率下，更大比例的细胞进行 DNA 复制，并且每个细胞中存在更活跃的复制叉。这导致近Origin DNA 和近 Terminus DNA 之间的比率高于 1:1，从而提供群落增长率的定量读数。\n该文章在体外和体内、不同生长条件下以及复杂的细菌群落中证明了这一点。对于几种细菌物种，峰谷覆盖率（而非相对丰度）与炎症性肠病和 II 型糖尿病的表现相关。\n文章提供的pipeline：http://genie.weizmann.ac.il/software/bac_growth.html ，该网页已经打不开了😂。\niRep Nature Biotechnology 2016：https://www.nature.com/articles/nbt.3704\n独立于培养物的微生物组研究增加了对微生物群落的复杂性和代谢潜力的理解。然而，为了了解单个微生物组成员对群落功能的贡献，确定哪些细菌正在积极复制非常重要。 作者开发了一种算法 iRep，它使用草稿质量的基因组序列和单时间点宏基因组测序来推断微生物群体的复制率。该算法根据从单个复制起点进行双向基因组复制产生的测序覆盖趋势来计算复制指数 (index of replication, iRep)。 作者应用这种方法来证明人类婴儿服用抗生素后微生物复制率增加。文章还表明，未培养的、与地下水相关的候选门辐射细菌很少在经历地球化学重大变化的地下群落中快速复制。该方法可以应用于任何基因组解析的微生物组研究，以跟踪生物体对不同条件的反应，识别活跃增长的种群并测量复制率以用于建模研究。\n软件：https://github.com/christophertbrown/iRep，亲测可用\niRep 是一种通过单时间点宏基因组测序和草图质量基因组确定细菌复制率的方法。\n安装:\n1 pip install iRep 注意：iRep 需要 Python 3。依赖项有lmfit，numpy，scipy，pandas，seaborn，matplotlib，cPickle。\n脚本:\niRep: 使用草稿质量的基因组序列测量复制速率 iRep_filter.py: 合并和/或过滤 iRep 输出 bPTR: 使用完整的基因组序列测量复制速率（修改自 Korem 等人，Science 2015） gc_skew.py: 计算完整基因组序列的 GC 偏斜 示例用法:\niRep:\n1 iRep -f sample_data/l_gasseri.fna -s sample_data/l_gasseri*sam -o test.iRep 注意：为节省时间，可以同时分析多个基因组：\n1 iRep -f genome1.fna genome2.fna -s sample_data/l_gasseri*sam -o test.iRep bPTR:\n1 bPTR -f sample_data/l_gasseri.fna -s sample_data/l_gasseri*sam -o test.bPTR.tsv -plot test.bPTR.pdf -m coverage GC 偏斜:\n1 gc_skew.py -f sample_data/l_gasseri.fna 使用说明: 运行 iRep 和 bPTR 需要每个目标微生物的基因组序列。每个程序都需要单独的 FASTA 文件作为输入。bPTR 需要完整（封闭）的基因组序列，而 iRep 需要高质量的草稿基因组（≥75% 完整性，≤175 个片段/Mbp 序列，≤2% 污染）。iRep 只使用长度≥5 Kbp 的 scaffold，因此基因组完整性估算需要基于通过此阈值的 scaffold。两种方法在基因组从研究样本中组装或已知系统中存在具有高度相似基因组序列的微生物时最为准确。第二组输入是 SAM 格式的映射文件，这些文件应通过使用 Bowtie2 将 DNA 测序读取映射到组装的基因组上生成。提供每个样本生成的 SAM 文件路径。\n仅通过所有基因组和映射质量要求的 iRep 值应被视为有效。默认阈值：min cov. = 5，min wins. = 0.98，min r² = 0.9，max fragments/Mbp = 175，GC 校正 min r² = 0.0。\n请注意，高水平的菌株变异会影响结果。\niRep 和 bPTR.py 输出包括结果表格（.tsv 文件）和 PDF，显示用于计算复制速率的基因组覆盖测量。 包含许多未映射读取的大型 SAM 文件解析速度较慢，可以使用 shrinksam 快速过滤 SAM 文件中的未映射读取。\n如果有 \u0026ldquo;ImportError: No module named \u0026lsquo;_tkinter\u0026rsquo;\u0026rdquo; 错误。可以通过修改 bash MPLBACKEND 变量修复：\n1 export MPLBACKEND=\u0026#34;agg\u0026#34; 重要提示： iRep 和 bPTR 都需要有序的 SAM 文件，这些文件可以使用 Bowtie2 的 --reorder 标志生成。有序的 SAM 文件中，表示一组配对读取的两个读取一个接一个排列，这对于这些脚本基于映射质量过滤读取（见 -mm 选项）是必需的。如果 SAM 文件未排序，请确保重新运行 Bowtie 并带上 --reorder 标志，或使用 --sort 选项排序 SAM 文件；否则，脚本在计算覆盖率时会错误选择要包含的映射读取。--sort 选项使用 Unix 排序重新排列 SAM 文件。此选项仅在使用映射质量截止时适用；然而，使用质量截止是推荐的，因为它有助于防止偏离目标的读取映射。\nDEMIC Nature Methods 2018: https://www.nature.com/articles/s41592-018-0182-0\n对没有完整基因组序列的物种的微生物生长动态进行准确定量在生物学上很重要，但在宏基因组学中在计算上具有挑战性。在这里，作者提出了微生物群落的动态估计器（DEMIC；https://sourceforge.net/projects/demic/），这是一种基于重叠群和覆盖值的多样本算法，用于推断重叠群与复制起点的相对距离，并得出准确比较样品之间的细菌生长率。作者使用多个合成和真实数据集展示了 DEMIC 对于各种样本大小和组装质量的稳健性能。\n软件：https://sourceforge.net/projects/demic/，perl报错未能解决\n安装，下载压缩包解压即可：\n1 2 3 4 5 6 7 wget -c https://master.dl.sourceforge.net/project/demic/DEMIC_v1.0.2.zip?viasf=1 -O DEMIC_v1.0.2.zip tar -jxvf DEMIC_v1.0.2.zip cd DEMIC_v1.0.2 # 下载测试数据 wget -c https://sourceforge.net/projects/demic/files/test_data.zip?viasf=1 -O test_data.zip unzip test_data.zip DEMIC是一种计算工具，用于比较宏基因组样本中细菌的生长速率，基于推测的从复制起点到contig相对距离及其覆盖度。\n如有任何关于DEMIC的问题，可以发邮件给工具作者：gy.james@163.com\n命令和参数 如何运行DEMIC：\n1 perl DEMIC.pl -S /input/sam_dir/ -F /input/fa_dir/ -O /output/dir/ DEMIC的参数如下：\n-S, --sam_dir：输入SAM文件目录（由bowtie2生成）（必需） -F, --fasta_dir：输入FASTA文件目录，每个文件对应一个物种（必需） -O, --out_dir：输出文件目录（默认：./） -W, --window_size：计算覆盖度的窗口大小（默认：5000） -D, --window_step：计算覆盖度的窗口步长（默认：100） -M, --mapq_cutoff：计算覆盖度时的映射质量阈值（默认：5） -L, --mapl_cutoff：计算覆盖度时的映射长度阈值（默认：50） -R, --max_mismatch_ratio：每个读取作为命中的最大错配率（默认：0.03） -G, --log：输出日志文件名（可选） -H, --help：显示帮助信息 -T, --thread_num：设置并行运行的线程数（默认：1） -Q, --quiet：运行时保持安静 -A, --output_all：运行后保留临时文件（需要更多磁盘空间） 使用DEMIC的准备工作 (1) 共组装 不同样本中的宏基因组读取共同组装。请使用现有算法如MegaHit和Ray-Meta。例如，使用MegaHit从三个样本的宏基因组读取生成contigs：\n1 2 cat sample1.fastq sample2.fastq sample3.fastq \u0026gt; samples.fastq megahit -m 100000000000 -r samples.fastq -o MEGAHIT_assembly (2) 比对 将宏基因组读取比对到contigs。请使用BowTie2。SAM文件需要用samtools排序。例如，使用以下命令比对sample1的读取并输出到目录SAM/：\n1 2 bowtie2-build MEGAHIT_assembly/final.contigs.fa MEGAHIT_assembly/final.contigs.fa bowtie2 -q -x MEGAHIT_assembly/final.contigs.fa -U sample1.fastq -S SAM/sample1.sam 排序比对并输出到SAM_sorted/sample1_sort.sam：\n1 2 samtools view -bS SAM/sample1.sam | samtools sort - SAM/sample1_sort samtools view -h SAM/sample1_sort.bam \u0026gt; SAM_sorted/sample1_sort.sam 请为所有样本的.sam文件执行此操作。\n(3) 分类 将contigs聚类到组。请使用现有算法如MaxBin和MetaBAT。例如，使用MaxBin将contig聚类输出到maxbin/：\n1 run_MaxBin.pl -contig MEGAHIT_assembly/final.contigs.fa -out maxbin -reads_list ./reads.list （./reads.list包含上述三个.fastq文件的路径）\n以上步骤是基于组装的宏基因组数据分析中常用的步骤。\nDEMIC需要目录maxbin/和SAM_sorted/。\n运行DEMIC示例 (1) 确保已安装并行Perl 5.10.1或更高版本，R 3.3.1或更高版本，并使用Linux或Mac OS X操作系统。\n(2) 在R中安装“lme4”和“FactoMineR”包：\n1 2 install.packages(\u0026#34;lme4\u0026#34;) install.packages(\u0026#34;FactoMineR\u0026#34;) (3) 在终端进入DEMIC目录，并将测试数据移动到该目录：\n1 2 cd /path/to/DEMIC_v1.0.2/ mv /path/to/test_data/ ./ 测试数据包括来自PTRC研究的三个样本的测序数据比对，这些数据格式化为目录SAM_sorted/中的已排序.sam。目录maxbin/中包括两个contig聚类，分别对应C. rodentium和E. faecalis。\n(4) 运行DEMIC命令：\n1 perl DEMIC.pl -S test_data/SAM_sorted/ -F test_data/maxbin/ -O DEMIC/ ！！暂时会报错，且没有具体报错原因\n(5) DEMIC将在大约1分钟内完成工作，并在目录DEMIC/中生成输出文件。\n在该目录中，可以查看文件all_PTR.txt的详细信息：\n1 2 3 4 5 $ cat DEMIC/all_PTR.txt Sample1 Sample2 Sample3 ContigCluster1 1.5549 2.3313 1.8395 ContigCluster2 2.2430 1.7119 2.2856 输出文件易于理解。例如，C. rodentium（ContigCluster1）在Sample2中的生长速率最高。\n常见问题 (1) 如何在DEMIC中使用多线程？ DEMIC支持多线程。使用多个CPU或内核时，请使用参数-T指定线程数。虽然优化了DEMIC的RAM使用，但使用多线程仍会略微增加RAM使用。建议选择不超过SAM文件数量和contig聚类数量的线程数。\n(2) 如何设计实验和分析流程以更好地使用DEMIC？ 虽然DEMIC适用于各种条件，但当实验和分析流程设计得更好时，它的性能可能更佳。\n样本数量：DEMIC基于多个样本，对于包含六个或更多样本的物种，其准确性更高。建议以合理和可比的深度测序超过六个样本。不同样本可以来自对照组、重复实验、不同个体或条件。 组装器：组装方法对binning方法和DEMIC的性能很重要。能够为不同深度和物种生成相对较长contig且错误较少的组装器更为优选。在测试中使用了MEGAHIT，表现良好。 分类器：尽管DEMIC可以通过去除潜在污染物纯化contig聚类，但其仍受binning质量（如完整性）的影响。对于低或中等复杂度的微生物群落，建议使用MaxBin。 CoPTR Genome Research 2022: https://genome.cshlp.org/content/32/3/558.full\n细菌基因组的测序覆盖模式（通过峰谷比（PTR）总结）已被证明可以准确反映微生物的生长速率，揭示微生物动力学和宿主-微生物相互作用的新方面。在这里，作者介绍Compute PTR (CoPTR)：一种用于从完整的参考基因组和组装中计算PTR的工具。\n使用简单和复杂群落中的生长实验的模拟和数据，作者表明 CoPTR 比当前最先进的技术更准确，同时还提供了更多的总体 PTR 估计。作者进一步发展了一种理论，正式化了 PTR 的生物学解释。作者使用 2935 个物种的参考数据库，将 CoPTR 应用于来自 106 名炎症性肠病患者的 1304 个宏基因组样本的病例对照研究。作者表明，增长率是个性化的，仅与相对丰度松散相关，并且与疾病状态相关。最后，作者展示了如何将 PTR 与相对丰度和代谢组学相结合来研究它们对微生物组的影响。\n软件：https://github.com/tyjo/coptr\nCoPTR 是一种工具，用于根据完整参考基因组和草图组件的宏基因组测序数据计算峰谷比。 CoPTR 将来自多个宏基因组样本和参考数据库的 fastq 文件作为输入。它输出样本中每个物种的 log2 PTR。\n快速使用：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 # 项目下载 git clone https://github.com/tyjo/coptr cd coptr # 测试数据 wget https://dl.dropboxusercontent.com/s/wrsxjimr6l96lcq/example-data.tar.gz tar -xzvf example-data.tar.gz # 设置环境： conda env create -f coptr.yml conda activate coptr # 软件安装 pip install . # 索引参考数据库： coptr index example-data/ref-db example-data/ref-db/example-index # 地图显示与参考相反： coptr map example-data/ref-db/example-index example-data/fastq example-data/bam # 提取读取位置： coptr extract example-data/bam example-data/coverage-maps #估计ptrs： #请注意，最小读取标志是可选的。我们建议使用默认设置（5000次读取）。 coptr estimate example-data/coverage-maps out.csv --min-reads 2500 # Output cat out.csv log2(PTR):genome_id/sample_id,ERR969281,ERR969282,ERR969283,ERR969285,ERR969286,ERR969428,ERR969429,ERR969430 l-gasseri-ref,,,,,,1.1840987863325785,1.1945539660363145,1.2879271469720541 e-coli-mag,1.2078623467253466,1.0375575947553943,0.9433005522894075,0.759132363901812,0.7846476652840171,,, References Tal Korem et al., Growth dynamics of gut microbiota in health and disease inferred from single metagenomic samples.Science349,1101-1106 (2015). DOI:10.1126/science.aac4812 Brown, C., Olm, M., Thomas, B. et al. Measurement of bacterial replication rates in microbial communities. Nat Biotechnol 34, 1256–1263 (2016). https://doi.org/10.1038/nbt.3704 Gao, Y., Li, H. Quantifying and comparing bacterial growth dynamics in multiple metagenomic samples. Nat Methods 15, 1041–1044 (2018). https://doi.org/10.1038/s41592-018-0182-0 Tyler A. Joseph et al., Accurate and robust inference of microbial growth dynamics from metagenomic sequencing reveals personalized growth rates. Genome Res. 2022. 32: 558-568 (2022). doi: 10.1101/gr.275533.121 ","date":"2024-07-15T00:00:00Z","image":"/p/growth/images/PTR_hu_2b16288de5186dd4.jpeg","permalink":"/p/growth/","title":"从宏基因组量化细菌生长动态"},{"content":"我自己在用R做各种分析时有不少需要反复用到的基础功能，比如一些简单的统计呀，画一些简单的图等等，虽说具体实现的代码也不麻烦，但还是不太想每次用的时候去找之前的代码。\n索性将常用的各种函数整成了一个包：pcutils， 网址：https://github.com/Asa12138/pcutils\n从CRAN安装：\n1 install.packages(\u0026#34;pcutils\u0026#34;) 但目前还是建议从github安装，包含的功能会多一些:\n1 2 install.packages(\u0026#34;devtools\u0026#34;) devtools::install_github(\u0026#39;Asa12138/pcutils\u0026#39;,dependencies=T) Introduction Venn图是一种比较常用的可视化方法，它可以用来展示多个集合的交集、并集、差集等信息。\nVenn图的基本思想是，将多个集合分成不同的区域，并用不同的颜色填充这些区域，从而展示出不同集合之间的关系。Venn图的变种有很多，比如花瓣图、Upset图、Venn网络图等，但它们想要展示的信息都是类似的。\n做这一类Venn图的在线网站有很多，我最推荐的是EVenn：http://www.ehbio.com/test/venn/#/，使用方便，种类多样：\n但有时候我们还是想自己用R来绘制Venn图，下面介绍一下pcutils 包中的venn函数。\nvenn venn 是 pcutils 包中提供的绘制Venn图的函数，它可以绘制多种类型的Venn图。\n输入数据也十分统一，可以是一个list如list(a = 1:3, b = 3:7, c = 2:4)，也可以是一个dataframe，其中每一列代表一个集合，每一行代表一个feature，如果值为0说明该集合不含该feature，大于0说明含有该feature。\n标准Venn图 标准Venn图通常用于比较两到六组实验数据，使用颜色编码元素来表示unique和common的组件。\n绘制标准Venn图的R包非常多，比如ggvenn,ggVennDiagram,Vennerable等，我这里内置的是ggVennDiagram的函数来绘制，可以使用ggplot的逻辑来方便修改：\n1 2 3 4 aa \u0026lt;- list(a = 1:3, b = 3:7, c = 2:4, d=7:8) p1=venn(aa[1:3], mode = \u0026#34;venn\u0026#34;) p2=venn(aa, mode = \u0026#34;venn\u0026#34;)+viridis::scale_fill_viridis() p1+p2 Euler图 Euler图在可行的情况下会省略空的交叉区域，从而提高了多个集合的可视化的精度和具体性。Euler图专门为两组和三组实验数据而设计，可生成面积比例表示，其中交叉区域的大小与共享元素的数量相关。此功能可以清晰地描述集合之间的部分包含、完全包含和完全排除关系。\n我这里内置的是eulerr包的函数来绘制：\n1 venn(aa, mode = \u0026#34;euler\u0026#34;) Upset图 UpSet 图是一种创新的可视化技术，专为集合交集的定量分析而设计，可容纳 3 到 几十组的复杂数据集。\n通过两种呈现模式，它可以熟练地可视化非空交叉点和空交叉点。该图由三个关键部分组成：水平条形图描绘每个集合中的总元素，垂直条形图指示相应交叉点中的元素，以及带有连接点的矩阵，描绘集合之间的所有交叉点类型。\n我这里内置的是UpSetR包的函数：\n1 venn(aa, mode = \u0026#34;upset\u0026#34;) 花瓣图 当处理超过10组的综合数据集时，维恩图、欧拉图、UpSet图等传统可视化方法会遇到局限性。花瓣图是平衡可解释性和信息丰富性的方法，只展示所有集合共有的部分和每个集合特有的部分，省略了两两之间的关系，因为实在太多了。\n我这里使用plotrix包手动来绘制中心的圆和周围的椭圆花瓣：\n1 2 data(otutab) venn(otutab, mode = \u0026#34;flower\u0026#34;) Venn网络图 维恩网络超越了标准维恩图的常规边界，超越了相交和共有的描述。它通过将每个集合指定为父节点并通过边缘将单个元素连接到其各自的父节点，从而巧妙地说明了集合中的关系。\n这里基于我的另一个包MetaNet来绘制网络，不同的数据类型会影响所得的网络结构：\n1 2 filter_df=otutab[sample(300:500,50),1:3] venn(filter_df, mode = \u0026#34;network\u0026#34;) 所有的可视化方法都是为展示数据服务的， 我整合这些函数也是希望可以更关注数据本身，花更少的精力在调节图形上，先快速对我们的数据有整体的把握。\npcutils的初衷还是迎合我自己的编程与数据分析习惯的，所以可能并不适合所有人，大家也可以直接fork并修改我的源码，欢迎大家提出建议与意见。\n","date":"2024-07-12T00:00:00Z","image":"/p/r-venn/images/venn_hu_61da34aff45f5b15.png","permalink":"/p/r-venn/","title":"R绘制Venn图及其变换"},{"content":"Introduction 我创建bio llbug这个公众号也一年多了，从最初的几篇文章到现在，已经有了50多篇长文，粉丝量也逐渐上升。\n有时候想具体看看自己的粉丝量变化趋势，或者想看看自己哪些文章受欢迎等，需要到微信公众号平台的数据板块查看：\n其实微信公众号平台的数据板块的图表做的都很好，但是基本所有的模块只能看至多90天的信息，再多的话就要手动选择时间段。它又不支持一键导出数据，只能手动每90天下载一个，再想办法整合在一起，很烦。\n我尝试用爬虫工具，奈何技艺不精，没有很好的实现。去github上找了一圈，大佬们搭的平台环境复杂，我也没有成功复刻。另外一些号称可以分析各种公众号数据的软件插件少不了收费。\n但我的目标并不是很复杂，只是几项简单数据，最后还是用一个笨方法，模拟人工打开浏览器下载表格操作，一步一步获取数据。\n下列步骤都是用R语言实现的，把所有代码拷贝到一个.R文件中，放在合适路径，设置好token和浏览器默认下载路径，运行即可。第一次会把从设置好的ori_begin_date开始的所有粉丝数据都下载下来，之后运行代码只会更新新增的数据。\n下载 思路：利用微信公众号提供的表格下载链接，模拟人工下载，获取数据。更改下载链接中的时间区间，获取不同时间段每90天一次的链接。\n直接通过链接下载会提示需要登录，下载下来的好像是微信前端的JS代码，哈哈哈。所以我利用utils::browseURL打开默认浏览器，自动下载表格。\n注意这里的文章数据只能统计文章发表7天内的数据，跟真实的最终阅读量还是有差距的。有其他需要下载的数据，可以尝试修改链接中的参数。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 #第一次运行的话，设置一下自己公众号创建时间： ori_begin_date=as.Date(\u0026#34;2023-03-30\u0026#34;, \u0026#34;%Y-%m-%d\u0026#34;) #打开自己的默认浏览器，登录微信公众号平台，这时候网址里就会有个token的值，复制到下面： token=\u0026#34;这里填入自己的token\u0026#34; #如1161650571 #下载路径 dowload_path=\u0026#34;这里填入自己的下载路径\u0026#34; #如\u0026#34;~/Downloads/\u0026#34; rm(wechat_user_analysis,wechat_article_analysis) if(file.exists(\u0026#34;wechat_user_analysis.csv\u0026#34;)){ wechat_user_analysis=read.csv(\u0026#34;wechat_user_analysis.csv\u0026#34;,header=TRUE,row.names = 1) wechat_user_analysis$Date=as.Date(wechat_user_analysis$Date,format=\u0026#34;%Y-%m-%d\u0026#34;) ori_begin_date=as.Date(max(wechat_user_analysis$Date),\u0026#34;%Y-%m-%d\u0026#34;)+1 message(\u0026#34;Last update date:\u0026#34;,format(ori_begin_date,\u0026#34;%Y-%m-%d\u0026#34;)) wechat_article_analysis=read.csv(\u0026#34;wechat_article_analysis.csv\u0026#34;,header=TRUE,row.names = 1) wechat_article_analysis$发表时间=as.Date(wechat_article_analysis$发表时间,format=\u0026#34;%Y-%m-%d\u0026#34;) } library(dplyr) begin_date=ori_begin_date end_date=begin_date+90 # 微信一次只能下载90天的数据 today=Sys.Date() # 写一个for循环，从start开始到今天，每90天为begin_date到end_date，调用utils::browseURL函数， # 打开微信的用户分析页面，并将begin_date和end_date参数传入。 file_list=c() stat_file_list=c() while (begin_date\u0026lt;=today) { if(end_date\u0026gt;today){ end_date=today } cat(\u0026#34;Downloading data from \u0026#34;,format(begin_date,\u0026#34;%Y-%m-%d\u0026#34;),\u0026#34; to \u0026#34;,format(end_date,\u0026#34;%Y-%m-%d\u0026#34;)) #粉丝数据 if(TRUE){ old_file=list.files(dowload_path,full.names = TRUE) url=paste(\u0026#34;https://mp.weixin.qq.com/misc/useranalysis?=\u0026amp;download=1\u0026amp;begin_date=\u0026#34;, format(begin_date,\u0026#34;%Y-%m-%d\u0026#34;),\u0026#34;\u0026amp;end_date=\u0026#34;,format(end_date,\u0026#34;%Y-%m-%d\u0026#34;), \u0026#34;\u0026amp;source=99999999\u0026amp;token=\u0026#34;,token,\u0026#34;\u0026amp;lang=zh_CN\u0026#34;,sep=\u0026#34;\u0026#34;) utils::browseURL(url) Sys.sleep(3) file_list=append(file_list,setdiff(list.files(dowload_path,full.names = TRUE),old_file)) } #文章数据 if(TRUE){ old_file=list.files(dowload_path,full.names = TRUE) url2=paste(\u0026#34;https://mp.weixin.qq.com/misc/datacubequery?action=query_download\u0026amp;busi=3\u0026amp;tmpl=19\u0026amp;args={%22begin_date%22:\u0026#34;, format(begin_date,\u0026#34;%Y%m%d\u0026#34;),\u0026#34;,%22end_date%22:\u0026#34;,format(end_date,\u0026#34;%Y%m%d\u0026#34;), \u0026#34;}\u0026amp;token=\u0026#34;,token,\u0026#34;\u0026amp;lang=zh_CN\u0026#34;,sep=\u0026#34;\u0026#34;) utils::browseURL(url2) Sys.sleep(3) stat_file_list=append(stat_file_list,setdiff(list.files(dowload_path,full.names = TRUE),old_file)) } begin_date=end_date+1 end_date=begin_date+90 } 合并数据 思路：刚刚通过循环我们已经下载下来的很多文件，看起来都是Excel格式的，需要用readxl包读取，然后合并到一个数据框中。\n实际上粉丝数据下下来的\u0026rsquo;user analysis.xls\u0026rsquo;文件是错误的，无法正常读取，最后用XML::readHTMLTable侥幸成功。\n我们把所有数据整合起来保存表格，并删除下载的中间文件。注意保存的wechat_article_analysis.csv和wechat_user_analysis.csv文件名不能改也不要删，因为下一次运行时会读取这个数据，来判断增量下载哪些部分。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 # 合并文章数据 if(length(stat_file_list)\u0026gt;0){ dflist=list() for (i in stat_file_list){ dflist[[i]]=readxl::read_excel(i) } all_df=data.frame(do.call(rbind,dflist),row.names = NULL) all_df$发表时间=as.Date(all_df$发表时间,format=\u0026#34;%Y%m%d\u0026#34;) all_df=mutate_at(all_df,vars(总阅读人数:阅读完成率),as.numeric) all_article_df=arrange(all_df,desc(发表时间)) if(exists(\u0026#34;wechat_article_analysis\u0026#34;)){ all_article_df=rbind(wechat_article_analysis,all_article_df) } all_article_df=arrange(all_article_df,desc(发表时间)) write.csv(all_article_df,paste0(\u0026#34;wechat_article_analysis.csv\u0026#34;)) file.remove(stat_file_list) } # 合并粉丝数据 if(length(file_list)\u0026gt;0){ dflist=list() for (i in file_list){ dflist[[i]]=XML::readHTMLTable(i)[[1]][-c(1:2),] } all_df=data.frame(do.call(rbind,dflist),row.names = NULL) colnames(all_df)=c(\u0026#34;Date\u0026#34;,\u0026#34;New_followers\u0026#34;,\u0026#34;Cancel_user\u0026#34;,\u0026#34;Increase_followers\u0026#34;,\u0026#34;Cumulative_followers\u0026#34;) all_df$Date=as.Date(all_df$Date,format=\u0026#34;%Y-%m-%d\u0026#34;) all_df=mutate_at(all_df,vars(New_followers:Cumulative_followers),as.numeric) all_df=na.omit(all_df) all_user_df=arrange(all_df,desc(Date)) if(exists(\u0026#34;wechat_user_analysis\u0026#34;)){ all_user_df=rbind(wechat_user_analysis,all_user_df) } all_user_df=arrange(all_user_df,desc(Date)) write.csv(all_user_df,paste0(\u0026#34;wechat_user_analysis.csv\u0026#34;)) file.remove(file_list) } 画图 思路：简单画一个折线图，看看一年多来的粉丝增长趋势。找一下增量最多的几天，然后找到对应那几天最近发表的文章标题，画在折线图上。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 if(!exists(\u0026#34;all_user_df\u0026#34;))all_user_df=wechat_user_analysis if(!exists(\u0026#34;all_article_df\u0026#34;))all_article_df=wechat_article_analysis library(ggplot2) p=ggplot(all_user_df,aes(x=Date,y=Cumulative_followers))+ geom_line()+geom_point(aes(colour = Increase_followers))+ labs(title=\u0026#34;Wechat User Analysis\u0026#34;,x=\u0026#34;Date\u0026#34;,y=\u0026#34;Cumulative Followers\u0026#34;)+ # viridis::scale_color_viridis(direction = -1)+ scale_color_gradientn(colours = get_cols(pal = \u0026#34;bluered\u0026#34;)[7:11],name = \u0026#34;Increase \\nFollowers\u0026#34;)+ theme_bw()+theme(legend.position = c(0.1,0.7)) #在净增最多的五天画个箭头 max_increase=top_n(all_user_df,10,Increase_followers)%\u0026gt;%filter(Increase_followers\u0026gt;20) #找到最近的一篇推文 max_increase$内容标题=rep(\u0026#34;\u0026#34;,nrow(max_increase)) for (i in 1:nrow(max_increase)){ max_date=max_increase$Date[i] max_increase$内容标题[i]=all_article_df[which.min(abs(all_article_df$发表时间-max_date)),\u0026#34;内容标题\u0026#34;] } max_increase=distinct(max_increase,内容标题,.keep_all = TRUE) max_increase$内容标题=stringr::str_wrap(max_increase$内容标题,16,whitespace_only = F) showtext::showtext_auto() p2=p+ ggrepel::geom_label_repel(data = max_increase, mapping = aes(x = Date, y = Cumulative_followers, label = 内容标题), size = 3, min.segment.length =0.1, fill=NA) # geom_segment(data = max_increase, # aes(x = Date-8, xend = Date, y = Cumulative_followers+50, yend = Cumulative_followers), # arrow = arrow(length = unit(0.2, \u0026#34;cm\u0026#34;), type = \u0026#34;closed\u0026#34;)) ggsave(\u0026#34;wechat_user_analysis.pdf\u0026#34;,p2,width=7,height=5) ggsave(\u0026#34;wechat_user_analysis_secret.pdf\u0026#34;, p2+theme(axis.text.y = element_blank(),legend.text = element_blank()), width=7,height=5) 终于大功告成了，以后只需要重新运行这个脚本，就可以获取更新的微信公众号数据了。话说这个方法真笨呀，要是我爬虫用的好就不需要这么麻烦了。\n","date":"2024-07-11T00:00:00Z","image":"/p/wechat/images/wechat_hu_8201399f9b7cf4a3.png","permalink":"/p/wechat/","title":"公众号长期数据统计（笨方法）"},{"content":"我自己在用R做各种分析时有不少需要反复用到的基础功能，比如一些简单的统计呀，画一些简单的图等等，虽说具体实现的代码也不麻烦，但还是不太想每次用的时候去找之前的代码。\n索性将常用的各种函数整成了一个包：pcutils， 网址：https://github.com/Asa12138/pcutils\n从CRAN安装：\n1 install.packages(\u0026#34;pcutils\u0026#34;) 但目前还是建议从github安装，包含的功能会多一些:\n1 2 install.packages(\u0026#34;devtools\u0026#34;) devtools::install_github(\u0026#39;Asa12138/pcutils\u0026#39;,dependencies=T) Introduction 层级数据展示是数据分析中常有的需求，比如物种分类等级，KEGG功能层次等。\n我们以下列test数据为例，这是一个物种分类等级的表格。表格从左到右具有包含关系，最后一列是物种的丰度：\n1 2 data(otutab) cbind(taxonomy, num = rowSums(otutab))[1:10, ] -\u0026gt; test Kingdom Phylum Class Order Family Genus Species num k__Bacteria p__Actinobacteria c__Actinobacteria o__Actinomycetales f__Thermomonosporaceae g__un_f__Thermomonosporaceae s__un_f__Thermomonosporaceae 26147 k__Bacteria p__Proteobacteria c__Betaproteobacteria o__Burkholderiales f__Comamonadaceae g__Pelomonas s__Pelomonas_puraquae 25217 k__Bacteria p__Proteobacteria c__Gammaproteobacteria o__Pseudomonadales f__Pseudomonadaceae g__Rhizobacter s__Rhizobacter_bergeniae 16592 k__Bacteria p__Bacteroidetes c__Flavobacteriia o__Flavobacteriales f__Flavobacteriaceae g__Flavobacterium s__Flavobacterium_terrae 16484 k__Bacteria p__Proteobacteria c__Gammaproteobacteria o__Pseudomonadales f__Pseudomonadaceae g__Rhizobacter s__un_g__Rhizobacter 13895 k__Bacteria p__Proteobacteria c__Betaproteobacteria o__Burkholderiales f__un_o__Burkholderiales g__un_o__Burkholderiales s__un_o__Burkholderiales 10937 k__Bacteria p__Actinobacteria c__Actinobacteria o__Actinomycetales f__Streptomycetaceae g__Streptomyces s__un_g__Streptomyces 10813 k__Bacteria p__Actinobacteria c__Actinobacteria o__Actinomycetales f__Pseudonocardiaceae g__Lentzea s__Lentzea_flaviverrucosa 9508 k__Bacteria p__Actinobacteria c__Actinobacteria o__Actinomycetales f__Micromonosporaceae g__Actinoplanes s__un_g__Actinoplanes 8518 k__Bacteria p__Proteobacteria c__Alphaproteobacteria o__Rhizobiales f__Rhizobiaceae g__Rhizobium s__un_g__Rhizobium 7789 我们有很多种方法来展示这种类型的层次数据，比如桑基图，旭日图，包珠图，Treemap等。\n桑基图 桑基图（Sankey diagram）是一种常用的层次数据展示方法，它通过使用有向连接不同的节点来显示流动的路径和量级。\n使用sankeyD3包绘制桑基图： 1 my_sankey(test,mode = \u0026#34;sankeyD3\u0026#34;) 使用ggsankey包绘制桑基图： 1 my_sankey(test, mode = \u0026#34;ggsankey\u0026#34;, space = 1e4) 旭日图 旭日图（sunburst）是饼图的变形，简单来说是多个饼图的组合升级版。饼图只能展示一层数据的占比情况，而旭日图不仅可以展示数据的占比情况，还能厘清多级数据之间的关系。\n1 my_sunburst(test) 多层环图 多层环图是一种多层次数据展示方法，它将数据分成多个环，每个环代表一层数据。可以使用gghuan2函数绘制：\n1 2 gghuan2(arrange_all(test[,c(1,2,7,8)]))+ scale_fill_pc(n = 14) 包珠图 包珠图（Circular Packing），是一种比较特殊的分类树状图，以气泡之间的包含关系展示层级关系，以气泡面积（或半径）展示数值的大小。\n1 2 3 my_circle_packing(test[,c(1,2,7,8)],show_level_name = T)+ viridis::scale_fill_viridis(na.value = NA)+ scale_color_pc(palette = \u0026#34;col2\u0026#34;) Treemap Treemap是一种层次数据展示方法，它将数据分成矩形，矩形的大小代表数值的大小，矩形之间的包含关系代表层级关系。\n1 my_treemap(test[,c(2,7,8)]) Voronoi Treemap Voronoi Treemap是一种基于Voronoi tessellation的层次数据展示方法，它将数据分成多边形，多边形的边界代表数据之间的距离，多边形的面积代表数值的大小，多边形之间的包含关系代表层级关系。\n1 my_voronoi_treemap(test[,c(2,7,8)]) 树图 我在pctax包中提供了一个函数df2tree可以将层级数据转换为树结构数据(phylo对象)，树图就可以用ggtree之类的包进行绘图，可以参考我之前介绍过的R绘制系统发育树的基本用法,进阶使用。\n1 2 3 # install.packages(\u0026#34;pctax\u0026#34;) tr=pctax::df2tree(test[,1:7]) class(tr) 1 ## [1] \u0026#34;phylo\u0026#34; 1 2 3 ggtree::ggtree(tr)+ ggtree::geom_tiplab(size = 2)+ ggtree::geom_nodepoint() 网络图 我在MetaNet包提供了将层级数据转换为网络图的功能，可以用MetaNet包进行绘图。\n1 2 3 4 5 6 # install.packages(\u0026#34;MetaNet\u0026#34;) go=MetaNet::df2net_tree(test) par(mfrow=c(1,2)) plot(go,edge_width_range=c(0.5,0.5)) plot(go,MetaNet::as_circle_tree(),edge_width_range=c(0.5,0.5)) 所有的可视化方法都是为展示数据服务的， 我整合这些函数也是希望可以更关注数据本身，花更少的精力在调节图形上，先快速对我们的数据有整体的把握。\npcutils的初衷还是迎合我自己的编程与数据分析习惯的，所以可能并不适合所有人，大家也可以直接fork并修改我的源码，欢迎大家提出建议与意见。\n","date":"2024-07-10T00:00:00Z","image":"/p/r-treemap/images/cengji_hu_10932b3424a5efa0.png","permalink":"/p/r-treemap/","title":"R展示层级数据（桑基/旭日/珠包/Treemap图等）"},{"content":"Introduction 病毒在生态系统中扮演着关键角色，宏基因组中病毒序列的鉴定十分重要。我之前已经介绍过了从宏基因组中鉴定病毒序列的常用方法，包括geNomad，DeepVirFinder，VirSorter2等，以及后续的质量评估方法。\n这方面的方法发展还是很快的，最近（2024/07/04），复旦大学赵兴明、华中科技大学陈卫华与团队在Genome Biology上发表研究，开发出一种人类肠道微生物基因组语言混合表征学习框架VriRep，能够整合基因组语义信息和序列同源性表征DNA序列，从而更精准地识别人类肠道环境中的病毒基因组。\n工具主页：https://github.com/Dongyq815/VirRep\n原文简介 原文：https://genomebiology.biomedcentral.com/articles/10.1186/s13059-024-03320-9\n从宏基因组中识别病毒是探索人类肠道病毒组成的常见步骤。VirRep是一种混合语言表征学习框架，用于从人类肠道宏基因组中识别病毒。 VirRep 结合了上下文感知编码器和进化感知编码器，通过结合 k-mer 模式和序列同源性来改进序列表征。 对不同病毒比例的模拟和真实数据集进行基准测试表明，VirRep 的性能优于最先进的方法。 当应用于结直肠癌队列的粪便宏基因组时，VirRep 识别出 39 种与该疾病相关的高质量病毒种类，其中许多病毒无法通过现有方法检测到。\nOverview VirRep 是一种混合语言表征学习框架，旨在从人类肠道宏基因组中识别病毒。\n如图 1a 所示，它以 1 kb 长的 DNA 序列及其反向互补链作为输入，其中较长的序列将被分割成 1 kb 长的序列片段。 VirRep 首先将每个序列片段及其反向互补链转换为连续 7-mers的短序列。以标记化的 7-mers序列作为输入，连体神经网络将生成 1 kb 长的序列片段属于病毒的概率，该概率是根据其两条链的病毒分数的平均值计算的。 对于长度超过 1 kb 的序列，VirRep 将预测定义为其所有片段的病毒概率的平均值。 鉴于温和噬菌体经常将其基因组整合到宿主中并在人类肠道中普遍存在，VirRep 还引入了迭代片段延伸机制来检测宿主基因组内的病毒区域。\nVirRep 结合了上下文感知编码器（语义编码器）和进化感知编码器（对齐编码器），以利用 k-mer 模式和序列同源性的优势来提高分类性能（图 1b，方法）。 语义编码器是一个类似 BERT 的神经网络，它通过捕获序列中不同位置的 k-mers 之间的依赖关系来生成全局上下文表征。 比对编码器利用 BiLSTM网络作为主干，通过隐式编码输入序列和原核基因组之间的序列相似性来产生进化表征。 VirRep 集成这两种表征形式以生成信息丰富的序列表征形式。编制了一个大型非冗余的人类肠道微生物基因组数据集来训练 VirRep，包括来自 GVD、GPD、CHVD 和 MGV 的~140,000 个病毒基因组（统称为 GGCM），以及 UHGG 中不同细菌和古菌物种的 4600 多个基因组。\nVirRep 能够稳健地检测各种序列长度的病毒 在多个人类肠道病毒组数据集上评估 VirRep，其中每个数据集中的病毒根据序列长度分为 5 组（1.5 k–3 k、3 k–5 k、5 k–10 k、10 k–20） k，\u0026gt;20 k）。作为阴性对照，还收集了等量的由人类肠道宏基因组组装的原核序列。 将 VirRep 与几种流行的病毒识别方法进行了比较，包括最近提出的混合方法（geNomad）、两种基于比对的方法（VIBRANT 和 VirSorter2）和五种免比对方法（VirFinder、DeepVirFinder、PPR-Meta、Seeker 和 INHERIT）。\n首先评估了 GGCM 测试数据集上每种方法的性能。对于不同长度的病毒序列（1.5 k–3 k：0.90、3 k–5 k：0.92、5 k–10 k：0.94、10 k–），VirRep 显着优于其他方法，具有最高的 MCC（马修斯相关系数）值20 k：0.96，\u0026gt;20 k：0.98；图 2a)。 通过更多的评估指标（包括 F1、精确率和召回率），VirRep 在保持较低误报率的同时实现了更高的召回率，从而带来更好的整体性能。 例如，与第二好的方法 geNomad 相比，VirRep 将短于 10 kb 的序列的病毒检出率提高了 2.5-44.2%，同时保持了相当的精度。 与性能最佳的免对齐方法 INHERIT 相比，它的精度提高了 2.5% 至 6.8%，召回率相似。在其他三个数据集（即 IMG/VR-gut、DEVoC 和 GPIC 数据集）上也可以找到类似的结果，其中 VirRep 优于所有其他方法（图 2b-d)。\n进一步研究了 GGCM 测试数据集上五组不同长度的每种方法的运行时间。每种方法在每个长度间隔对 5000 个序列运行五次。 VirRep 和四种无需对齐的方法（即 INHERIT、DeepVirFinder、PPR-Meta、Seeker）在 NVIDIA A100 GPU 上加速，而 geNomad 和两种基于对齐的方法（VirSorter2 和 VIBRANT）则使用 16 个线程运行。 一般来说，VirRep 比 geNomad 快大约 3-6 倍，比性能最佳的无比对方法 (IHERIT) 快 12-13 倍，比性能最佳的基于比对的方法 (VirSorter2) 快 33-130 倍。(图 2g)。\n专用表征学习提高了病毒识别的灵敏度和特异性 两个专用编码器可以有效地整合学习的 k-mer 模式和序列同源性，生成信息丰富的序列表征，从而通过利用免比对和基于比对的方法实现更灵敏和更精确的病毒识别。 预训练有助于将学习到的 k-mer 组成模式的一般规则快速转移并适应下游任务。 第一阶段的微调使 VirRep 能够学习多视图序列表征。 两个编码器连同预训练和第一阶段微调极大地提高了 VirRep 的整体性能。\nVirRep 非常适用于批量和富含 VLP 的人类肠道宏基因组样本 评估了 VirRep 和其他方法在大量宏基因组上的性能（即病毒比例为 5% 和 10% 的数据集；图 4a）。 发现 VirRep 在这两个病毒比例较低的数据集上明显优于其他方法。 VirRep 的平均 AUPRC（精确召回曲线下面积）值超过 0.94，比最近提出的混合方法 geNomad 好 3.0 和 2.0%，比性能最好的免对齐方法 INHERIT 好 8.1 和 4.6% 。 还在两个数据集上测试了 VirRep，其中病毒序列占整个社区的一半或以上。这些数据集是为了模拟富含 VLP 的宏基因组而构建的。尽管大多数评估方法在这两种情况下都表现良好，但 VirRep 获得了最高的 AUPRC 分数（图 4a）。\n此外，将 VirRep 与结合至少两种方法的几种方法进行了比较，其中每种方法结合了至少一种基于比对的方法和一种无比对的方法。与此类组合方法相比，VirRep 单独获得了更好或相当的结果（图 4b）。 这种改善在低病毒比例样本中尤其显著。 对于富含 VLP 的宏基因组，VirRep 仍然实现了最佳的整体性能，尽管改进并不像在批量宏基因组样本上那么明显。\n总之，无论样品中的病毒比例如何，VirRep 都优于最先进的方法及其组合，这表明它非常适合从大量样品和富含 VLP 的宏基因组样品中鉴定病毒基因组。\nVirRep 识别与结直肠癌相关的病毒种类 最近的研究表明肠道微生物组与结直肠癌 (CRC) 的发生有关，但肠道病毒组是否与该疾病有关却知之甚少。 受到 VirRep 在识别人类肠道病毒方面的有效性的启发，应用 VirRep 扫描了 74 名 CRC 患者和 54 名健康个体的真实人类肠道宏基因组。\n使用 VirRep 获得了包含 18,067 个病毒群体（VP，在物种水平）的非冗余集合，与竞争方法相比，增加了 22.3–4285.2%（图 5a） 。使用 CheckV 来评估每个 VP 的完整性。结果，VirRep 鉴定出了最多数量的完整且高质量（完整性 \u0026gt; 90%）的病毒基因组（图 5a）。\n使用blocked Wilcoxon 秩和检验进行差异分析。控制 P\u0026lt;0.001 和 FDR\u0026lt;0.05，我们从 2076 个完整且高质量的 VP 中鉴定出 39 个与 CRC 相关的病毒种类（图 5b）。VirRep 识别出了与 CRC 相关最多的 VP，并且基于该标记集开发的模型实现了最高的诊断功效（图 5c）。39 种病毒中有 23 种仍未被至少一半的竞争方法检测到，其中 2 种被所有方法漏掉（附加文件 1：图 S14）。这两种病毒都是原噬菌体，因为它们是从较长的基因组片段中鉴定出来的。据观察，其中一种 VP1279 在 CRC 患者中含量丰富，而另一种 VP2811 在健康个体中含量更高。 它们都编码几个病毒标志基因，包括终止酶大亚基、主要衣壳蛋白和门户蛋白（图 5d）。系统发育分析表明，它们均属于Caudoviricetes 纲内的未分类科（图5e）。\n软件使用 目前软件我运行有点问题，所以没有具体的使用测试结果，可能是环境依赖问题，我在github上提了issue，等待后续解决方案，目前可以先看README文件，了解软件的安装和使用方法：\nInstallation 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 # 创建conda环境 conda create -n vr python conda activate vr # 1.conda 安装依赖包, 或者用2.pip conda install -c bioconda biopython numpy pandas tqdm scipy scikit-learn packaging # 2.pip 安装依赖包 pip install biopython numpy pandas tqdm scipy scikit-learn packaging # 1. conda安装pytorch，如果之前没有装过的话，这一步很久的 conda install pytorch torchvision torchaudio pytorch-cuda=11.8 -c pytorch -c nvidia # 2. pip安装torch，如果之前没有装过的话，这一步很久的 pip3 install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118 下载软件包：\n1 2 3 4 5 6 7 git clone clone https://github.com/Dongyq815/VirRep.git cd VirRep python src/VirRep.py -h # 由于代码要求model文件夹在当前目录下，所以无法添加环境变量，只能在VirRep/src/目录下直接运行 cd VirRep/src python VirRep.py -h Usage VirRep 的输入是一个包含要预测的序列的 fasta 文件，输出由一个记录预测得分的 .tsv 文件和一个包含预测病毒序列的 fasta 文件组成。分数越高表明病毒序列的可能性越高。\n使用VirRep对测试数据集进行GPU加速运行： 1 python VirRep.py -i ../test/test.fasta -o vr_out -w 2 --use-amp --min-score 1000-5000:0.9,5001-10000:0.8,10001-Inf:0.7 输出目录（vr_out）中的文件：\ntest_viruses.fna：识别出的病毒序列 test_score.tsv：每个病毒序列的评分表及其他特征 注意\n输出文件名附带后缀||full或||partial，表示病毒序列是否从较大的片段中提取。\n跳过迭代段扩展机制运行VirRep： 1 python VirRep.py -i ../test/test.fasta -o vr_out --use-amp --provirus-off -w 2 用于在基准数据集上与其他方法比较，所有输入序列将在输出的.tsv文件中报告得分。\n在批量宏基因组上运行VirRep 1 python VirRep.py -i ../test/toy.fasta -o vr_out --use-amp --conservative -w 2 该模式使用保守设置以减少假阳性，只输出高置信度的病毒序列。\n运行以下命令查看所有选项：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 python VirRep.py -h usage: VirRep.py [-h] -i INPUT_FILE -o OUTPUT_DIR [--label LABEL] [-m MODEL] [--use-amp] [--conservative] [-l MINLEN] [--provirus-off] [-b BASELINE] [--max-gap MAX_GAP] [--max-frac MAX_FRAC] [--provirus-minlen PROVIRUS_MINLEN] [--provirus-minfrac PROVIRUS_MINFRAC] [-c MIN_SCORE] [-k MINLEN_KEEP] [-n BATCH_SIZE] [-w NUM_WORKERS] [--cpu] [--cpu-threads CPU_THREADS] [--gpu-device GPU_DEVICE] A hybrid language representation learning framework for identifying viruses from human gut metagenomes. optional arguments: -h, --help: 显示帮助信息 -i INPUT_FILE, --input-file INPUT_FILE: 输入fasta格式文件 -o OUTPUT_DIR, --output-dir OUTPUT_DIR: 输出目录 --label LABEL: 输出文件名前缀 -m MODEL, --model MODEL: 模型路径 --use-amp: 使用自动混合精度以提高计算效率 --conservative: 使用保守设置 -l MINLEN, --minlen MINLEN: 预测序列的最小长度 --provirus-off: 跳过迭代段扩展程序 -b BASELINE, --baseline BASELINE: 启动段扩展的基准得分 --max-gap MAX_GAP: 合并相邻扩展区域的最大距离 --max-frac MAX_FRAC: 合并相邻区域的最大比率 --provirus-minlen PROVIRUS_MINLEN: 被认为是前病毒的区域的最小长度 --provirus-minfrac PROVIRUS_MINFRAC: 被认为是前病毒的区域长度的最小比率 -c MIN_SCORE, --min-score MIN_SCORE: 最终保留的病毒候选序列的最低得分 -k MINLEN_KEEP, --minlen-keep MINLEN_KEEP: 最终保留的病毒命中的最小长度 -n BATCH_SIZE, --batch-size BATCH_SIZE: 一次评分的1kb段数 -w NUM_WORKERS, --num-workers NUM_WORKERS: 用于数据加载的子进程数 --cpu: 在CPU上运行VirRep --cpu-threads CPU_THREADS: 在CPU上运行VirRep的线程数 --gpu-device GPU_DEVICE: 运行VirRep的GPU设备编号 ","date":"2024-07-10T00:00:00Z","image":"/p/virrep/images/workflow_hu_51233161231a7b87.png","permalink":"/p/virrep/","title":"VirRep: 人类肠道微生物组识别病毒新方法"},{"content":"我自己在用R做各种分析时有不少需要反复用到的基础功能，比如一些简单的统计呀，画一些简单的图如柱形图，箱形图等等，虽说具体实现的代码也不麻烦，但有一些细节如给箱形图加上显著性分组，将柱形图按照metadata合并或分面等事情还是不太想每次用的时候去找之前的代码。\n索性将常用的各种函数整成了一个包：pcutils， 网址：https://github.com/Asa12138/pcutils\n从CRAN安装：\n1 install.packages(\u0026#34;pcutils\u0026#34;) 但目前还是建议从github安装，包含的功能会多一些:\n1 2 install.packages(\u0026#34;devtools\u0026#34;) devtools::install_github(\u0026#39;Asa12138/pcutils\u0026#39;,dependencies=T) Introduction 箱形图是一种常见的统计图，用来显示一组数据分散情况，箱体的上下边界分别代表Q1（25%分位数）和Q3（75%分位数），箱体内部的线条代表中位数（median），箱体的宽度代表IQR（Interquartile Range，中间五分位数范围），箱体的颜色代表数据的分组。\n箱形图又可以和其他图表结合，如箱形+连线，箱形+点图，箱形+密度图，箱形+小提琴图等等，可以帮助我们展示数据分布的整体情况。\n在具有多个分组的数据中，我们可以通过各种统计方法对分组均值进行多组比较和两两比较，在箱形间加上p值，或者在箱形上加显著性分组，可以帮助我们发现显著性差异。\n在之前用R做统计分析中，我们就已经使用过ggstatsplot包绘制包含许多信息的箱形图，展示了均值比较的信息：\n1 2 3 4 5 6 7 8 library(ggstatsplot) set.seed(123) library(PMCMRplus) # for pairwise comparisons # create a plot p \u0026lt;- ggbetweenstats(mtcars, am, mpg) # looking at the plot p group_box group_box 是 pcutils 包中提供的箱形图绘制函数，可以绘制各种箱形图并进行显著性分组等。\n输入表格型数据tab（一列或者多列均可以，多列将分面绘制）， 分组变量名，以及分组变量所在的表格metadata。tab和metadata根据行名匹配，方便有时候我们需要对某些行进行过滤。\n1 2 3 4 data(\u0026#34;otutab\u0026#34;) p=group_box(tab = metadata[c(\u0026#34;env1\u0026#34;,\u0026#34;env2\u0026#34;)], group = \u0026#34;Group\u0026#34;, metadata = metadata) #加上主题和配色 p+theme_bw()+scale_color_brewer(palette = \u0026#34;Set1\u0026#34;) mode mode 参数可以指定箱形图的绘图类型，都是我常用的一些风格，1～9：\n1 2 3 4 5 6 7 plist=list() for (i in 1:9) { plist[[i]]=group_box(tab = mtcars[c(\u0026#34;mpg\u0026#34;)], group = \u0026#34;am\u0026#34;, metadata = mtcars,mode = i)+ ggtitle(paste0(\u0026#34;mode\u0026#34;,i))+ theme_classic()+theme(legend.position = \u0026#34;none\u0026#34;) } cowplot::plot_grid(plotlist = plist, ncol = 3) mode3，使用gghalves包绘制的一半小提琴图加上一半的散点图，中间是一个箱形图，这种展示方法又叫做云雨图（旋转90度后很像一朵云在下雨） mode5，使用geom_dotplot绘制的散点图，y轴相同的点会横向排开 mode6，使用ggbeeswarm包绘制的蜂巢图（蜂巢状分布） mode9，手动用ggplot绘制的豆荚图。目前有一个beanplot包，但是用的是基础绘图系统。 显著性检验 group_box 还可以进行显著性检验，用p_value1参数指定全局检验方法。如果有两个分组，可使用t.test，wilcox.test，anova，kruskal.test等方法进行比较。\n1 2 3 p1=group_box(tab = mtcars[c(\u0026#34;mpg\u0026#34;)], group = \u0026#34;am\u0026#34;, metadata = mtcars, p_value1 = \u0026#34;t.test\u0026#34;) p2=group_box(tab = mtcars[c(\u0026#34;mpg\u0026#34;)], group = \u0026#34;am\u0026#34;, metadata = mtcars, p_value1 = \u0026#34;wilcox.test\u0026#34;) cowplot::plot_grid(p1,p2) 如果分组多于两个，可以用anova，kruskal.test比较。使用p_value2参数指定分组两两间的检验方法，only_sig可以只展示显著的比较结果。\n1 2 3 4 p1=group_box(tab = metadata[c(\u0026#34;env1\u0026#34;)], group = \u0026#34;Group\u0026#34;, metadata = metadata, p_value1 = \u0026#34;anova\u0026#34;) p2=group_box(tab = metadata[c(\u0026#34;env1\u0026#34;)], group = \u0026#34;Group\u0026#34;, metadata = metadata, p_value2 = \u0026#34;t.test\u0026#34;, only_sig = FALSE) 1 ## [1] FALSE 1 cowplot::plot_grid(p1,p2) 当分组更多的时候，我们可以使用字母分组来展示分组间的比较结果，alpha开启字母分组，method指定两两比较检验方法。\n1 2 group_box(tab = metadata[c(\u0026#34;env1\u0026#34;)], group = \u0026#34;Group\u0026#34;, metadata = metadata, alpha = TRUE, method = \u0026#34;t.test\u0026#34;) 配对连线 如果我们分组之间的点具有配对关系，我们可以用paired参数绘制配对连线。如果要展示整体的趋势，可以用trend_line参数画出趋势线。\n1 2 3 p1=group_box(tab = metadata[c(\u0026#34;env1\u0026#34;)], group = \u0026#34;Group\u0026#34;, metadata = metadata, paired = TRUE) p2=group_box(tab = metadata[c(\u0026#34;env1\u0026#34;)], group = \u0026#34;Group\u0026#34;, metadata = metadata, trend_line = TRUE) cowplot::plot_grid(p1,p2) group_box还提供了一些其他参数用于调节箱形图元素，如paired_line_param, alpha_param, point_param, trend_line_param等。\n但所有的可视化方法都是为展示数据服务的， 我整合这些函数也是希望可以更关注数据本身，花更少的精力在调节图形上，先快速对我们的数据有整体的把握。\npcutils的初衷还是迎合我自己的编程与数据分析习惯的，所以可能并不适合所有人，大家也可以直接fork并修改我的源码，欢迎大家提出建议与意见。\n","date":"2024-07-06T00:00:00Z","image":"/p/r-box/index.en_files/figure-html/unnamed-chunk-6-1_hu_461a3480b713c8dd.png","permalink":"/p/r-box/","title":"R绘制箱形图及其变换"},{"content":"Introduction Positron（正电子），是由 RStudio 母公司（改名叫 Posit）构建的下一代数据科学 IDE，一个可用于编写代码和探索数据的可扩展的多语言工具，并提供可重复创作和发布的熟悉环境。\n主页：https://github.com/posit-dev/positron\n下载：https://github.com/posit-dev/positron/releases。目前，Positron 正在通过适用于 macOS、Windows 和 Linux 的持续集成 (CI) 系统生成预发布版本。选择要下载的版本，.dmg（适用于 Mac）、.exe（适用于 Windows）或 .deb（适用于 Linux）文件。\n正电子（又称阳电子、反电子、正子）是电子的反粒子，即电子的对应反物质，与电子碰撞时会产生湮灭现象。这名字不错。\nPositron 构建于 Code OSS 之上，外观和功能都跟VS Code很像。官方直接说了，要了解命令、设置、使用源代码管理等基本功能，请参阅 VS Code 文档😂。\nPositron适合你吗？ 注意⚠️：Positron 是一个正在积极开发的早期项目。官方并不期望它立即适合每个从事数据科学的人。\nPositron 适合以下情况： 您使用 VS Code 进行数据科学（Python 或 R），但希望它包含专用控制台、变量窗格、数据浏览器以及其他用于特定数据工作的功能。 您使用 Jupyterlab 进行数据科学（Python 或 R），并准备好使用更强大、功能齐全的 IDE。 您使用 RStudio 并希望拥有更多自定义或扩展 IDE 的能力。 您在日常数据科学或包开发工作中使用其他语言，例如 Rust、C++、JavaScript 或 Lua。 Positron 不适合以下情况： 您需要稳定、完善的软件。 Positron 仍处于测试阶段，某些功能不稳定或未完成。 您需要 RStudio IDE 的所有功能。 Positron 不具备 RStudio 的所有功能；一些值得注意的缺失是 Quarto 和 R Markdown 的内联输出、分析、Sweave、RStudio 插件支持等。 您使用远程开发功能（例如开发容器、远程 SSH）； Positron 尚不支持这些。然而，提供远程 SSH 工具已在我们的路线图中。 Positron 与 RStudio、VS Code 或 Jupyter 有何不同 Positron 通过集成控制台对 R 和/或 Python 提供一流的内置支持，并在未来提供针对其他语言的扩展选项。这包括整个 Positron 的专用视图和窗格，例如数据浏览器、连接窗格、变量窗格等。 Positron 与 IDE 分开运行解释器，因此与 RStudio 不同，R/Python 中的崩溃不会使 IDE 崩溃。这还意味着您可以即时在首选语言的版本之间进行切换，而无需完全重新加载 IDE，只需集成控制台即可。 Positron 支持 VS Code 兼容扩展（.vsix 文件），允许扩展核心 IDE 本身之外的功能。通过在 Code OSS 上构建，Positron 获得了丰富的文本编辑器功能，并可以立即访问 1,000 个社区扩展。 Positron 深度专注于原生数据科学工作流程；它提供了超越通用 IDE 或文本编辑器（如 VS Code）的功能和凝聚力体验。 体验 R/R markerdown/Qurato Rstudio界面： Positron界面： Positron 内置了 R、R Markdown 和 Quarto 的支持。基本上是开箱即用，我之前的R环境和python环境都得到了很好的兼容，打开之前的代码项目也都能直接运行。\nR的debug我试了一下也挺好的，可以直接在R环境中调试，很方便。R Markdown 和 Quarto的预览功能也没问题，可以实时看到效果。\n点击data.frame对象可进入数据浏览器（和Rstudio的不太一样），可以看到以下信息：\n数据网格：以类似于电子表格的方式显示各个单元格和列以及排序 摘要面板：每列的列名称、类型和缺失数据百分比 过滤栏：特定列的临时过滤器 Python Positron 也支持 Python，脚本和Jupyter Notebook 都可以运行。运行逻辑跟R基本一致，我很喜欢使用Ctrl/Cmd+Enter来运行代码块。\nShiny Positron 也支持 Shiny等交互应用，可以直接运行R Shiny应用。另外的网页构建，Rbookdown等项目也都顺利执行了（毕竟对R的支持做了很多年了）。\nConnection Connection窗格允许探索在 R 或 Python 会话中创建的数据库连接。它还包括对存储和管理连接字符串以供将来使用的基本支持。\n用R连接，只需使用支持连接协定的任何包（例如 odbc、sparklyr、bigrquery 等）连接到数据库。 用Python连接，支持使用 sqlite3 和 SQLAlchemy 模块创建的连接。要在连接窗格中打开连接，请创建代表连接/引擎的顶级对象。 总结 我简单体验了一下 Positron，因为我之前VS Code用得不多，主要用的都是Rstudio（Rstudio基本也支持R和python的，而且R makerdown和Quarto写起来也很流畅）。Positron挺酷的，基本的界面和功能都有了，各种常用语言的界面也统一了，可以尝试一下。\n而且感觉这种趋势也是对的，比如我们做生信的，基本上都是用R，Python比较多的，再提供一下Terminal用来连接服务器，这几个体验做好了整个IDE感觉就不错。\nRStudio不会消失，Posit官方表示将继续致力于维护和更新 RStudio。\n虽然 Positron 和 RStudio 有一些共同的功能，但一些以 R 为中心的功能仍将是 RStudio 独有的。 他们开始开发 Positron，作为支持多种语言（包括 R 和 Python）开源数据科学的使命的一部分。\n如果你当前正在使用 RStudio 并且对体验感到满意，则可以继续使用 RStudio。 RStudio 包含 10 多年针对 R 数据分析和包开发的应用优化。\n","date":"2024-07-05T00:00:00Z","image":"/p/positron-ide-r-python/images/Positron_hu_2f953ce6e3bdea95.png","permalink":"/p/positron-ide-r-python/","title":"Positron初尝试，新一代数据科学IDE（R+Python+...）"},{"content":"Introduction 在环境微生物学和生态学研究中，宏基因组学（Metagenomics）技术的应用已经彻底改变了我们对微生物群落的理解。宏基因组学通过对环境样本中的全部遗传物质进行测序和分析，可以全面揭示微生物群落的组成、功能和相互作用。然而，在这些复杂的微生物群落中，病毒序列的鉴定仍然是一个巨大的挑战。\n病毒在生态系统中扮演着关键角色，它们通过感染宿主微生物调控微生物群落的动态和功能。病毒的存在和活动对宿主的进化、生物地球化学循环以及环境健康有着深远的影响。尽管病毒在生态系统中至关重要，但由于它们的基因组多样性高、没有通用的保守基因、以及基因组片段化严重，传统的宏基因组分析方法常常难以有效地识别和解析病毒序列。\n为了克服这些挑战，研究人员开发了一系列专门的工具和方法，用于从宏基因组数据中提取和鉴定病毒序列。这些方法结合了序列比对、结构特征分析和机器学习等技术，显著提高了病毒序列的鉴定效率和准确性。通过这些方法，科学家们不仅能够更全面地了解环境病毒的多样性，还能揭示病毒与其宿主之间的复杂关系，为生态学、进化生物学和公共卫生等领域的研究提供重要的参考。\n本文我们将介绍从宏基因组数据中鉴定病毒序列的主要方法和工具。\n从宏基因组数据中鉴定病毒序列的主要方法可以分为几类：\n序列比对方法 鉴定病毒序列的最直接方法。这些方法依赖于将宏基因组数据中的序列与已知病毒数据库进行比对，以找到相似的序列。常用的序列比对工具和数据库包括：\nBLAST（Basic Local Alignment Search Tool）：这是最常用的序列比对工具，可以用于将宏基因组数据与病毒数据库进行比对。 Diamond：比BLAST更快速的序列比对工具，适用于大规模宏基因组数据的处理。 NCBI RefSeq Viral Database：一个广泛使用的病毒序列数据库。 特征分析方法 通过分析序列的特定特征来鉴定病毒序列。常用的特征分析包括：\nk-mer 分析：分析序列中固定长度的子序列（k-mers）的频率分布，用于区分病毒和宿主序列。 GC含量分析：病毒和宿主的GC含量往往有所不同，通过分析GC含量可以辅助鉴定病毒序列。 序列深度分析：病毒序列在宏基因组数据中的覆盖深度可能与宿主序列不同，通过比较覆盖深度可以辅助识别病毒序列。 机器学习方法 机器学习方法通过训练模型来自动鉴定病毒序列，如支持向量机（SVM），随机森林， 深度学习等。\nTools 目前，有多种专门用于病毒鉴定的工具，每个工具都有其独特的优势和适用场景。以下是一些常用的病毒鉴定工具的简要介绍：\ngeNomad geNomad 是一种用于识别和分类病毒序列的工具，2023年9月发表在Nature Biotechnology上[1]。它结合了序列比对和机器学习方法，能够高效地从宏基因组数据中提取病毒序列。geNomad 擅长处理复杂和高噪声的环境数据，适用于多样化的宏基因组样本。geNomad运行速度快，可对大型数据集进行分析。\n软件：https://github.com/apcamargo/genomad\n教程：https://portal.nersc.gov/genomad/\nInstallation 安装软件 可以使用通用包管理器（mamba 或 conda）或特定于 Python 的包管理器（pip）在计算机中安装 geNomad。\n1 2 3 4 5 6 7 8 9 10 # mamba mamba create -n genomad -c conda-forge -c bioconda genomad mamba activate genomad # conda conda create -n genomad -c conda-forge -c bioconda genomad conda activate genomad # pip pip install genomad Conda 和 Mamba 将安装 geNomad 所需的 Python 依赖项和第三方软件。如果使用 pip 或 pipx 安装 geNomad，要将 MMseqs2 和 ARAGORN 添加到环境变量里。 MMseqs2 和 ARAGORN是我常用的软件，所以我直接用pip安装，注意MMseqs2最好是最新版，不然可能有点问题。\n下载数据库 geNomad 依赖于一个包含用于对序列进行分类的标记的概况、它们的分类信息、它们的功能注释等的数据库： 可以通过软件下载：\n1 genomad download-database . 也可以自行下载并解压（我试了这个快），网址：https://portal.nersc.gov/genomad/data/genomad_db_v1.7.tar.gz ，我放在了~/db/genomad_db/genomad_db目录，解压后大概1.4G。\nExample geNomad通过顺序执行一系列模块来工作（见下列Pipeline），但也提供了一个方便的一键式命令，可以一次性执行整个流程。\n示例：使用肺炎克雷伯氏菌基因组（GCF_009025895.1）作为输入。geNomad适用于分离基因组、宏基因组和宏转录组中的病毒序列。\n执行geNomad的命令结构如下：\n1 genomad end-to-end [OPTIONS] INPUT OUTPUT DATABASE 所以，为了运行完整的geNomad流程（end-to-end命令），我们将核苷酸FASTA文件（GCF_009025895.1.fna.gz）和数据库（genomad_db）作为输入，执行以下命令：\n1 2 3 4 #下载genome wget https://ftp.ncbi.nlm.nih.gov/genomes/all/GCF/009/025/895/GCF_009025895.1_ASM902589v1/GCF_009025895.1_ASM902589v1_genomic.fna.gz -O GCF_009025895.1.fna.gz genomad end-to-end --cleanup --splits 8 GCF_009025895.1.fna.gz genomad_output ~/db/genomad_db/genomad_db 注意，输入的FASTA文件是压缩的。geNomad支持.gz、.bz2或.xz格式的压缩文件。结果将写入genomad_output目录中，--splits 8参数：将搜索分成8个块以节省内存空间。如果你在大服务器上运行geNomad，可能不需要分割搜索，这样可以提高执行速度。--cleanup会强制geNomad删除在执行过程中生成的中间文件。\n我试了一下，不带--splits 8参数时，内存消耗20G，耗时300s。如果想要进一步加快速度，可以考虑：\n使用合适的 --threads，默认是64，但一般可能没有这么多。 使用 --disable-nn-classification 选项禁用基于神经网络的分类，这也将禁用分数聚合并强制 geNomad 仅依赖基于标记的分类器。可能对 geNomad 的分类性能产生负面影响。 使用 --sensitivity 参数降低 MMseqs2 搜索的灵敏度，该搜索将标记分配给基因。这将使注释模块更快，但也会减少分配给标记的基因数量。可能对 geNomad 的分类性能产生负面影响。 控制分类严格性\n默认情况下，geNomad应用一系列分类后过滤器以移除可能的假阳性。例如，序列需要具有至少0.7的质粒或病毒得分，且长度小于2500 bp的序列需要编码至少一个标志基因。如果你想禁用这些过滤器，可以在命令中添加--relaxed标志。相反，如果你希望分类更加保守，可以使用--conservative标志。这将使分类后过滤器更加严格，防止没有强有力支持的序列被分类为质粒或病毒。\nOutput\n1 2 3 4 5 6 7 8 9 10 11 12 13 genomad_output ├── GCF_009025895.1_aggregated_classification ├── GCF_009025895.1_aggregated_classification.log ├── GCF_009025895.1_annotate ├── GCF_009025895.1_annotate.log ├── GCF_009025895.1_find_proviruses ├── GCF_009025895.1_find_proviruses.log ├── GCF_009025895.1_marker_classification ├── GCF_009025895.1_marker_classification.log ├── GCF_009025895.1_nn_classification ├── GCF_009025895.1_nn_classification.log ├── GCF_009025895.1_summary ╰── GCF_009025895.1_summary.log _summary 目录包含总结整个管道生成的结果的文件。如果只想要输入中识别出的质粒和病毒的列表，这个是最关键的。\n1 2 3 4 5 6 7 8 9 10 11 genomad_output ╰── GCF_009025895.1_summary ├── GCF_009025895.1_plasmid.fna ├── GCF_009025895.1_plasmid_genes.tsv ├── GCF_009025895.1_plasmid_proteins.faa ├── GCF_009025895.1_plasmid_summary.tsv ├── GCF_009025895.1_summary.json ├── GCF_009025895.1_virus.fna ├── GCF_009025895.1_virus_genes.tsv ├── GCF_009025895.1_virus_proteins.faa ╰── GCF_009025895.1_virus_summary.tsv GCF_009025895.1_virus_summary.tsv:\n该表格文件列出了geNomad在输入数据中找到的所有病毒，并提供了一些方便的信息。每列包含的内容如下：\nseq_name：输入FASTA文件中序列的标识符。内源病毒会有以下命名格式：\u0026lt;sequence_identifier\u0026gt;|provirus_\u0026lt;start_coordinate\u0026gt;_\u0026lt;end_coordinate\u0026gt;。 length：序列（或内源病毒）的长度。 topology：病毒序列的拓扑结构。可能的值包括：无末端重复（No terminal repeats）、直接末端重复（DTR）、倒置末端重复（ITR）或内源病毒（Provirus）。 coordinates：内源病毒在宿主序列中的1索引坐标。对于未预测为内源病毒的病毒，此值为NA。 n_genes：序列中编码的基因数量。 genetic_code：预测的遗传密码。可能的值包括：11（细菌和古菌的标准密码）、4（重新编码的TGA终止密码）或15（重新编码的TAG终止密码）。 virus_score：geNomad对序列是病毒的置信度测量。得分接近1.0的序列更有可能是病毒。 fdr：分类的估计假发现率（FDR），即该行之前序列中的预期假阳性比例。估计FDR需要得分校准，默认关闭，因此本例中此列将仅包含NA值。 n_hallmarks：匹配geNomad标志基因的基因数量。标志基因与病毒功能相关，其存在强烈表明该序列确实是病毒。 marker_enrichment：表示序列中病毒标志基因总富集的得分。随着序列中病毒标志基因数量的增加，该值会增加，具有多个标志基因的序列得分较高。染色体和质粒标志基因会降低得分。 taxonomy：病毒基因组的分类。分类依据ICTV的VMR第19号内容。病毒可以分类到科级，但不能分类到具体的属或种。分类以固定数量的字段（对应分类等级）表示，用分号分隔，空字段留空。 此外，在执行过程中，geNomad 使用染色体、质粒和病毒特异性标记数据库对输入序列编码的基因进行注释。 _virus_genes.tsv 文件总结了已识别病毒编码的基因的注释。\nGCF_009025895.1_virus_genes.tsv，文件中的列如下：\ngene：基因的标识符（\u0026lt;sequence_name\u0026gt;_\u0026lt;gene_number\u0026gt;）。通常基因编号从1开始（序列中的第一个基因）。然而，由于内源噬菌体整合在宿主染色体中间，基因编号可能会因其在染色体中的位置而不同。 start：基因的起始坐标（1索引）。 end：基因的终止坐标（1索引）。 length：基因位点的长度（以碱基对为单位）。 strand：编码基因的链。可以是1（正链）或-1（负链）。 gc_content：基因位点的GC含量。 genetic_code：预测的遗传密码（详见摘要文件解释）。 rbs_motif：检测到的核糖体结合位点的基序。 marker：最佳匹配的geNomad标记。如果该基因不匹配任何标记，则值为NA。 evalue：基因编码的蛋白质与最佳匹配的geNomad标记之间比对的E值。 bitscore：基因编码的蛋白质与最佳匹配的geNomad标记之间比对的Bitscore值。 uscg：分配给该基因的标记是否对应于通用单拷贝基因（UCSG，如BUSCO v5中定义）。这些基因预期在染色体中发现，在质粒和病毒中很少见。可以是1（基因是USCG）或0（基因不是USCG）。 plasmid_hallmark：分配给该基因的标记是否代表质粒标志基因。 virus_hallmark：分配给该基因的标记是否代表病毒标志基因。 taxid：分配给该基因的标记的分类标识符（此字段主要用于geNomad内部）。 taxname：与分配的geNomad标记相关的分类名称。在此示例中，可以看到所有注释的蛋白质都具有Caudoviricetes的特征（这也是内源病毒被分配到该类的原因）。 annotation_conjscan：如果匹配基因的标记是与接合作用相关的基因（如CONJscan中定义），此字段将显示分配给标记的CONJscan访问号。 annotation_amr：如果匹配基因的标记被注释为具有抗微生物耐药性（AMR）功能（如NCBIfam-AMRFinder中定义），此字段将显示分配给标记的NCBIfam访问号。 annotation_accessions：一些geNomad标记具有功能注释。此列告诉您哪些Pfam、TIGRFAM、COG和KEGG条目分配给了标记。 annotation_description：描述分配给标记功能的文本。 质粒鉴定相关的数据可以在 _plasmid_summary.tsv、_genes.tsv、_plasmid.fna 和 plasmid Proteins.faa 文件中找到。\nPipeline geNomad的具体工作流程如下：\n对于大多数情况，使用 genomad end-to-end 就足够了。然而，了解执行完整管道时涉及的具体流程非常重要。 这里对每个模块的功能进行解释，了解这些功能将帮助掌握 geNomad 如何处理输入序列以识别质粒和病毒。\nannotate annotate模块有两个主要功能：使用 Pyrodigal-gv 预测输入序列中的基因，并使用 MMseqs2 将这些预测基因分配给来自 227,897 个染色体、质粒或病毒特有图谱的数据集中的标记蛋白家族。该标记数据集提供了全面的元数据，可以帮助下游结果的解释。这包括：\n通过 Pfam、COG、TIGRFAM 和 KEGG Orthology 种质进行功能注释。 标志基因，涉及关键的质粒或病毒功能。 接合基因，通过CONJscan加入。 抗菌素抗性基因，通过 AMRFinder获得。 使用 BUSCO 鉴定的通用单拷贝基因 (USCG) 通常存在于染色体中，但在质粒和病毒中很少见。 通过使用 ICTV 的 VMR 编号 19 谱系进行病毒分类。 注释模块生成两个主要输出：输入序列的分类分配（可以在此处找到 geNomad 如何将序列分配给病毒分类群的说明）和基因级注释（如快速入门示例中所示）。这些输出被 find-proviruses, marker-classification, summary使用。\nfind-proviruses find-proviruses 模块旨在识别宿主序列内的原病毒区域。 为了实现这一目标，它使用条件随机场 (CRF) 模型，该模型采用注释模块生成的基因注释，并划分富含病毒特异性标记的区域，周围环绕着宿主特异性标记。 为了细化原病毒的边界，geNomad 利用了噬菌体通常在 tRNA 旁边整合以及整合酶通常位于整合噬菌体边缘的事实。 这是通过延伸边缘直到到达邻近的 tRNA（用 ARAGORN 识别）和/或整合酶（用 MMseqs2 识别）来实现的。\nmarker-classification geNomad 中的marker-classification模块旨在根据标记内容将序列分类为染色体、质粒或病毒。为了实现这一目标，该模块获取基因注释并计算一组数字特征，这些特征描述了需要分类的序列的基因结构和标记内容。这些特征包括基因密度以及染色体、质粒和病毒标记的频率。\n然后，marker-classification将这些特征提供给使用 XGBoost 训练的树集成分类算法，该算法为每个序列生成三个分数。这些分数代表模型对该序列代表染色体、质粒或病毒的置信度。\nnn-classification nn-classification模块还将输入序列分类为染色体、质粒或病毒，类似于标记分类模块。然而，与后者不同的是，它不依赖于标记信息。相反，它使用神经网络直接处理核苷酸序列。核苷酸序列首先被编码成数字矩阵，然后输入 IGLOO 神经网络。该网络能够检测区分染色体、质粒和病毒的序列特征。最后，该模块生成分类的置信度分数。\naggregated-classification aggregated-classification模块结合了marker-classification和nn-classification的输出，以产生一组利用两个分类器的优势的分数。为了实现这一目标，它采用了一种注意力机制，对每个分类器的贡献进行加权，使得标记分类的贡献与分配给标记的基因的比例成比例地增加。\nscore-calibration 标记分类、神经网络分类和聚合分类生成的分数表明这些模型对其预测的置信度，值越高则表明置信度越高。然而，这些值并不等于实际概率。例如，未校准病毒得分为 0.87 的序列没有 87% 的可能性是病毒。 score-calibration是一个可选模块，它将先前模块产生的原始分数转换为估计概率。这确保了校准病毒得分为 0.87 的序列成为病毒的概率接近 87%。要启用分数校准使用 --enable-score-calibration 参数。\nsummary summary模块具有三个主要功能：(1) 根据各种标准过滤序列，为用户提供最可靠的预测（在此处阅读有关过滤过程的更多信息）， (2) 总结所有先前模块为已识别质粒生成的数据和(3) 编写包含已识别质粒和病毒的核苷酸和蛋白质序列的 FASTA 文件，并附有基因注释文件。\nDeepVirFinder DeepVirFinder 使用深度学习方法预测病毒序列。该方法对短病毒序列具有良好的预测准确性，因此可用于预测宏基因组数据中的序列，于2020年发表在quantitative biology上[2]。 相比基于k-mer的方法VirFinder，DeepVirFinder使用卷积神经网络（CNN）显著提高了预测准确性。CNN可以自动从病毒和原核生物序列中学习基因组模式，并基于所学的基因组模式构建预测模型。学到的模式以大小为4×k的权重矩阵形式表示，类似于位置权重矩阵（PWM）。这种灵活的CNN模型在病毒序列预测问题上优于k-mer模型。\n软件：https://github.com/jessieren/DeepVirFinder\nInstallation DeepVirFinder 需要Python 3.6，并安装numpy、theano、keras、scikit-learn和Biopython等包。推荐使用Miniconda安装所有依赖项。\n我已经有了python3.5和python3.7两个做深度学习的环境，本来想着偷懒直接用，但是发现都不支持，所以只能再创建一个python3.6的环境：\n1 2 conda create --name dvf python=3.6 numpy theano=1.0.3 keras=2.2.4 scikit-learn Biopython h5py source activate dvf 下载软件包：\n1 2 3 4 5 6 7 8 9 10 11 git clone https://github.com/jessieren/DeepVirFinder cd DeepVirFinder python dvf.py -h # 可以添加环境变量，方便调用 chmod +x dvf.py sed -i \u0026#39;1d\u0026#39; dvf.py sed -i \u0026#39;1i #!/miniconda3/envs/dvf/bin/python\u0026#39; dvf.py ln -s ./dvf.py ~/miniconda3/envs/dvf/bin/ ln -s ~/biosoft/DeepVirFinder/models ~/miniconda3/envs/dvf/bin/models dvf.py -h Example DeepVirFinder的输入是包含要预测序列的fasta文件，输出是包含每个输入序列的预测得分和p值的.txt文件。更高的得分或更低的p值表明更高的病毒序列可能性。\n默认情况下，输出文件与输入文件在同一目录。用户也可以通过[-o]选项指定输出目录。[-l]选项设置最小序列长度阈值，低于此阈值的序列将不会被预测。该程序支持并行计算，通过[-c]指定使用的线程数。[-m]选项指定模型目录，默认模型目录为./models。\n1 2 3 4 5 6 7 python dvf.py [-i INPUT_FA] [-o OUTPUT_DIR] [-l CUTOFF_LEN] [-c CORE_NUM] -h, --help 显示此帮助信息并退出 -i INPUT_FA, --in=INPUT_FA 输入fasta文件 -m MODDIR, --mod=MODDIR 模型目录（默认./models） -o OUTPUT_DIR, --out=OUTPUT_DIR 输出目录 -l CUTOFF_LEN, --len=CUTOFF_LEN 仅预测长度\u0026gt;= L bp的序列（默认1） -c CORE_NUM, --core=CORE_NUM 并行核心数（默认1） 我们来试试，预测test文件中的crAssphage基因组：\n1 python dvf.py -i ./test/crAssphage.fa -o ./test/ -l 300 测试没问题：\n1 2 3 4 5 6 7 8 9 10 $ python dvf.py -i ./test/crAssphage.fa -o ./test/ -l 300 WARNING (theano.configdefaults): install mkl with `conda install mkl-service`: No module named \u0026#39;mkl\u0026#39; Using Theano backend. 1. Loading Models. model directory /share/home/jianglab/pengchen/biosoft/DeepVirFinder/models 2. Encoding and Predicting Sequences. processing line 1 processing line 1389 3. Done. Thank you for using DeepVirFinder. output in ./test/crAssphage.fa_gt300bp_dvfpred.txt Output:\ncrAssphage.fa_gt300bp_dvfpred.txt，输出非常简单，4列:\n1 2 name\tlen\tscore\tpvalue gi|674660337|ref|NC_024711.1| Uncultured phage crAssphage, complete genome\t97065\t0.9978806972503662\t0.004702016768638115 如需计算q值（假发现率），可以使用R包“qvalue”进行p值矫正。\n关于阈值：deepvirfinder官方推荐q-value\u0026lt;0.01的序列认定为病毒序列，也有文献（Biogeographic patterns and drivers of soil viromes）采用 score ≥0.7 and P \u0026lt; 0.05来界定病毒序列，没有具体标准。\n如果要自己构建数据库训练模型，可以参考软件主页。\nVirSorter2 VirSorter2 是 VirSorter 的升级版，于2021年发表在Microbiome上[3]。\nVirSorter2 采用多分类器、专家指导的方法来检测不同的 DNA 和 RNA 病毒基因组。它对之前的版本进行了重大更新：\n包含更多病毒，包括双链 DNA 噬菌体、单链 DNA 病毒、RNA 病毒、NCLDV（核细胞病毒）、拉维病毒科（病毒噬菌体）； 应用机器学习使用基因组特征（包括结构/功能/分类注释和病毒标志基因）来估计病毒性； 使用来自宏基因组或其他来源的高质量病毒基因组进行训练。\n软件：https://github.com/jiarong/VirSorter2\nInstallation 安装：\n1 2 mamba create -n vs2 -c conda-forge -c bioconda virsorter=2 mamba activate vs2 下载数据库：\n1 2 3 4 5 6 7 8 9 10 11 #以防之前尝试失败； #删除-d指定的整个目录 rm -rf ./virsorter_db # run setup virsorter setup -d ./virsorter_db -j 4 #若下载失败也可手动下载，https://osf.io/v46sc/download #解压后将路径传给--db-dir tar -xzf db.tgz mv db virsorter_db virsorter config --init-source --db-dir=./virsorter_db Example 1 2 3 4 5 6 7 8 9 wget -O test.fa https://raw.githubusercontent.com/jiarong/VirSorter2/master/test/8seq.fa virsorter run -w test.out -i test.fa --min-length 1500 -j 4 all #基于不同得分（min-score）重新快速运行程序（只运行classify步骤），新文件添加后缀（label）为rerun virsorter run -w test.out -i test.fa --include-groups \u0026#34;dsDNAphage,ssDNA\u0026#34; -j 4 --min-score 0.9 --label rerun classify #增加hmmscan线程数提高运行速度 virsorter config --set HMMSEARCH_THREADS=4 由于 VirSorter2 使用大型 HMM 数据库，这个小数据集需要几分钟才能完成。在输出目录（test.out）中，三个文件很有用：\nFinal-viral-combined.fa：确定的病毒序列 Final-viral-score.tsv：包含各组病毒序列得分的表格以及一些其他关键特征，可用于进一步过滤 Final-viral-boundary.tsv：包含边界信息的表；这是一个中间文件，1）与其他两个文件相比可能有额外的记录，应被忽略； 2) 不包括带有 \u0026lt; 2 个基因但具有 \u0026gt;= 1 个标志基因的病毒序列； 3) group和trim_pr是中间结果，可能与final-viral-score.tsv中的max_group和max_score分别不匹配 如果要自己构建数据库训练模型，可以参考软件主页。\nVIBRANT VIBRANT 是一个功能强大的工具，用于自动恢复和注释细菌和古细菌病毒、确定基因组完整性以及从宏基因组组装中表征病毒群落，于2020年发表在Microbiome上[4]。\n使用蛋白质注释签名的神经网络机器学习 指定新颖的“v-score”来确定所有注释的病毒性质 确定基因组完整性 通过代谢分析表征病毒群落功能 鉴定辅助代谢基因 (AMG) 从宿主支架上切除整合的病毒基因组 在不同的环境中表现良好 恢复新颖且丰富的病毒基因组 专为 dsDNA、ssDNA 和 RNA 病毒而设计 VIBRANT 使用三个数据库来识别病毒并表征病毒组代谢潜力：\nKEGG（三月发布）：https://www.genome.jp/kegg/（FTP：ftp://ftp.genome.jp/pub/db/kofam/archives/2019-03-20/） Pfam (v32)：https://pfam.xfam.org（FTP：ftp://ftp.ebi.ac.uk/pub/databases/Pfam/releases/Pfam32.0/） VOG（版本 94）：http://vogdb.org/（FTP：http://fileshare.csb.univie.ac.at/vog/vog94/） 安装和示例：\n1 2 3 4 5 6 conda create -n vibrant python=3 pandas numpy=1.19 scikit-learn=0.21.3 prodigal hmmer biopython matplotlib seaborn conda install -c bioconda vibrant==1.2.1 download-db.sh ~/db/VIBRANT/ #下载数据库 ~/miniconda3/envs/vibrant/bin/VIBRANT_run.py ~/miniconda3/envs/vibrant/bin/VIBRANT_run.py -i contig.fa -t 180 -folder {out_dir} -l 1000 -d ~/db/VIBRANT/databases/ -m ~/db/VIBRANT/files/ Others 其他还有一些类似的工具，但我没有一一安装测试，如：\nPPR-Meta 使用机器学习方法来预测病毒和原核生物的序列。通过训练支持向量机（SVM）模型，PPR-Meta 能够高效地区分病毒和非病毒序列。该工具适用于大规模宏基因组数据的快速处理和分析。 viralVerify 是一个专门用于病毒序列验证的工具。它结合了多种分析方法，包括序列比对、特征分析和机器学习，来验证和注释病毒序列。viralVerify 提供了详细的报告，包括病毒序列的覆盖度、基因组组成和功能注释。 MetaPhinder 使用序列比对方法，通过与病毒数据库比对，识别宏基因组中的病毒序列。该工具适用于快速识别已知病毒序列，并能提供详细的分类信息。 最近还看到了一些比较新的工具文章可以帮助病毒分析，如：\nCOBRA（Contig Overlap Based Re-Assembly）是一种生物信息学工具[5]，可从短双端读长的宏基因组中组装出更高质量的病毒基因组。 COBRA 是用 Python 编写的。迄今为止，COBRA 仅在来自 metaSPAdes、IDBA_UD 和 MEGAHIT 的组装contigs和支架上进行了测试。\nbio-transformers 证明蛋白质语言模型可以捕获原核病毒蛋白质功能[6]，从而使病毒序列空间的新部分能够被分配具有生物学意义的标签。蛋白质语言模型增强了病毒蛋白质的远程同源性检测，作为现有方法的有用补充。\nQuality assessment CheckV CheckV 是一个完全自动化的命令行管道，用于评估单contig病毒基因组的质量，包括识别集成原病毒的宿主污染、估计基因组片段的完整性以及识别封闭基因组，于2017年发表在Nature Biotechnology[7]。\n软件：https://bitbucket.org/berkeleylab/checkv/src/master/\nInstallation 安装软件 可以使用通用包管理器（mamba 或 conda）或特定于 Python 的包管理器（pip）在计算机中安装 checkv。\n1 2 3 4 5 6 7 8 # mamba mamba install -c conda-forge -c bioconda checkv=1.0.1 # conda conda install -c conda-forge -c bioconda checkv=1.0.1 # pip pip install checkv 因为跟上面讲的genomad的依赖项基本一致，所以我直接用pip安装在同一环境中就可以用了。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 $ checkv end_to_end -h usage: checkv end_to_end \u0026lt;input\u0026gt; \u0026lt;output\u0026gt; [options] positional arguments: input 以FASTA格式输入核苷酸序列（支持.gz，.bz2和.xz文件） output 输出目录 optional arguments: -h, --help 显示此帮助消息并退出 -d PATH 引用数据库路径。默认情况下，使用 CHECKVDB 环境变量【添加后可不写】 --remove_tmp 从输出目录中删除中间文件 -t INT 用于Prodigal和DIAMOND的线程数 --restart 覆盖现有的中间文件。默认情况下，CheckV 在程序中断的地方继续 --quiet 禁止记录消息 programs: end_to_end 运行完整的管道以估计完整性，污染并识别封闭的基因组 contamination 识别并消除集成前病毒上的宿主污染 completeness 估计基因组片段的完整性 complete_genomes 根据末端重复序列和侧翼宿主区域识别完整基因组 quality_summary 跨模块汇总结果 download_database 下载最新版本的CheckV数据库 下载数据库 geNomad 依赖于一个包含用于对序列进行分类的标记的概况、它们的分类信息、它们的功能注释等的数据库： 可以通过软件下载：\n1 checkv download_database ./ 也可以自行下载并解压（我试了这个快），解压后大概5.4G，我放在~/db/genomad_db/checkv-db-v1.0。\n1 2 3 #数据库下载（手动） wget https://portal.nersc.gov/CheckV/checkv-db-v1.0.tar.gz tar zxvf checkv-db-v1.0.tar.gz Example 我们使用上面genomad运行得到的GCF_009025895.1_ASM902589v1_genomic_virus.fna文件来测试：\n1 2 checkv end_to_end GCF_009025895.1_ASM902589v1_genomic_virus.fna checkv_out \\ -t 4 -d ~/db/genomad_db/checkv-db-v1.0 --remove_tmp 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 CheckV v1.0.3: contamination [1/8] Reading database info... [2/8] Reading genome info... [3/8] Skipping gene calling... [4/8] Reading gene info... [5/8] Skipping hmmsearch... [6/8] Annotating genes... [7/8] Identifying host regions... [8/8] Writing results... Run time: 0.77 seconds Peak mem: 0.08 GB CheckV v1.0.3: completeness [1/8] Skipping gene calling... [2/8] Initializing queries and database... [3/8] Running DIAMOND blastp search... [4/8] Computing AAI... [5/8] Running AAI based completeness estimation... [6/8] Running HMM based completeness estimation... [7/8] Determining genome copy number... [8/8] Writing results... Run time: 9.69 seconds Peak mem: 1.12 GB CheckV v1.0.3: complete_genomes [1/7] Reading input sequences... [2/7] Finding complete proviruses... [3/7] Finding direct/inverted terminal repeats... [4/7] Filtering terminal repeats... [5/7] Checking genome for completeness... [6/7] Checking genome for large duplications... [7/7] Writing results... Run time: 0.02 seconds Peak mem: 1.12 GB CheckV v1.0.3: quality_summary [1/6] Reading input sequences... [2/6] Reading results from contamination module... [3/6] Reading results from completeness module... [4/6] Reading results from complete genomes module... [5/6] Classifying contigs into quality tiers... [6/6] Writing results... Run time: 2.42 seconds Peak mem: 1.12 GB Output\nquality_summary.tsv 这包含三个主要模块的综合结果，应该是所用的主要输出： contig_id contig_length provirus proviral_length gene_count viral_genes host_genes checkv_quality miuvig_quality completeness completeness_method complete_genome_type contamination kmer_freq warnings 1 5325 No NA 11 0 2 Not-determined Genome-fragment NA NA NA 0.0 1.00 no viral genes detected 2 41803 No NA 72 27 1 Low-quality Genome-fragment 21.99 AAI-based (medium-confidence) NA 0.0 1.00 flagged DTR 3 38254 Yes 36072 54 23 2 Medium-quality Genome-fragment 80.30 HMM-based (lower-bound) NA 5.7 1.00 NA 4 67622 No NA 143 25 0 High-quality High-quality 100.00 AAI-based (high-confidence) NA 0.0 1.76 high kmer_freq 5 98051 No NA 158 27 1 Complete High-quality 100.00 AAI-based (high-confidence) DTR 0.0 1.00 NA 在上面的示例中，有 5 个病毒contig的结果：\n第一个 5325 bp contig没有完整性预测，这由“checkv_quality”字段的“未确定”指示。该contig也没有鉴定出病毒基因，因此它甚至有可能不是病毒。\n第二个 41803 bp contig被归类为“低质量”，因为其完整性\u0026lt;50%。这是基于“AAI”方法的估计。请注意，quality_summary.tsv 文件中仅报告高或中置信度估计值。您可以查看“completeness.tsv”了解更多详细信息。该contig具有 DTR，但由于某种原因被标记（有关详细信息，请参阅complete_genomes.tsv）\n第三个contig被认为是“中等质量”，因为其完整性估计为 80%（基于“HMM”方法）。这意味着它太新颖了，无法基于 AAI 来估计完整性，但与 CheckV 参考基因组共享 HMM。请注意，该值代表一个下限（意味着真实的完整性可能高于但不低于该值）。请注意，该contig也被归类为原病毒。\n第四个contig基于 \u0026gt;90% 的完整性被归类为高质量。但请注意，“kmer_freq”的值为 1.7。这表明病毒基因组在contig中多次出现。这些情况相当罕见，但仍需警惕。\n根据直接末端重复 (DTR) 的存在，第五个contig被分类为完整，并且根据 AAI 方法具有 100% 完整性。该序列可以放心地视为完整的基因组。\ncontamination.tsv 如何估计污染的详细概述\ncompleteness.tsv 关于如何估计完整性的详细概述\ncomplete_genomes.tsv 已确定的假定完整基因组的详细概述\nPipeline CheckV的具体工作流程如下：\nA: 去除宿主污染\n基因首先基于与自定义HMM数据库的比较被注释为病毒或微生物。 CheckV扫描contig（从5\u0026rsquo;到3\u0026rsquo;），比较基因注释和相邻基因窗口之间的GC含量。 这些信息用于计算每个基因间位置的分数并识别宿主-病毒断点。 这种方法最适合主要为病毒的contig。 B: 估计基因组完整性\n蛋白质首先使用AAI（平均氨基酸身份）与CheckV基因组数据库进行比较。 在识别到最佳匹配后，完整性作为contig长度（或provirus的病毒区域长度）与匹配参考长度的比率计算。 根据比对的强度报告置信水平。 通常，高和中等置信水平的估计非常准确。 如果病毒基因组没有与CheckV数据库的密切匹配，CheckV基于contig上识别的病毒HMM估计完整性。 基于找到的HMM，CheckV返回基因组完整性的估计范围（例如，35%到60%完整性），表示基于具有相同病毒HMM的参考基因组长度分布的90%置信区间。 C: 预测封闭基因组\n直接末端重复（DTRs）：在contig的起始和结束处有\u0026gt;20bp的重复序列，这是最可信的标志，可能表示环状基因组或从环状模板复制的线性基因组。 Provirus：在5\u0026rsquo;和3\u0026rsquo;末端有预测的宿主边界的病毒区域（参见部分A）。 注意：如果宿主区域已被移除（如使用VIBRANT或VirSorter），CheckV将不会检测到provirus。 倒位末端重复（ITRs）：在contig的起始和结束处有\u0026gt;20bp的重复序列（3\u0026rsquo;重复倒置），这是最不可信的标志。 对于上述所有方法，CheckV还会检查contig是否大致符合基于估计完整性的正确序列长度；这很重要，因为末端重复可能代表宏基因组组装的伪影。 D: 总结质量\n基于A-C的结果，CheckV生成报告文件，并将查询contig分配到五个质量层次之一（与MIUViG质量层次一致并扩展）： 完整（参见部分C） 高质量（\u0026gt;90%完整性） 中等质量（50-90%完整性） 低质量（\u0026lt;50%完整性） 未确定质量 可以分步使用checkV：\n1 2 3 4 checkv contamination input_file.fna output_directory -t 16 checkv completeness input_file.fna output_directory -t 16 checkv complete_genomes input_file.fna output_directory checkv quality_summary input_file.fna output_directory Application 这些专门的病毒鉴定工具各有优劣，研究者可以根据具体的研究需求和数据特征选择合适的工具。通过结合多种方法，可以提高病毒序列鉴定的准确性和效率，为深入理解病毒在生态系统中的角色和功能提供有力支持。\nBiogeographic patterns and drivers of soil viromes 这是马斌老师团队2024发表于Nature Ecology \u0026amp; Evolution的一篇文章[8]。\n病毒对于塑造土壤微生物功能和生态系统至关重要。然而，对土壤病毒组的研究在空间尺度和生物群落覆盖方面都受到限制。\n在这里，使用全球土壤病毒组数据集 (GSV) 全面综合了土壤病毒组生物地理模式，分析了全球 1,824 个土壤宏基因组，发现了 80,750 个 DNA 病毒的部分基因组，其中 96.7% 未分类。 不同生物群落的土壤病毒多样性和群落结构的生物地理学各不相同。有趣的是，病毒的多样性与微生物的多样性并不相符，相反，森林和灌木丛土壤中的病毒多样性较低。\n预测的土壤病毒多样性图谱进一步证实了土壤质地和水分条件是影响多样性的关键因素，揭示了潮湿和半湿润地区更高的多样性。此外，二项式度分布模式表明土壤病毒的随机共现模式。这些发现对于阐明土壤病毒生态学以及将病毒全面纳入土壤生态系统模型至关重要。\n他们在这篇文章里用的鉴定病毒的方法是：\n组装的contigs通过 VirSorter (v.1.0.5)比对 NCBI 病毒参考序列数据库 (Refseq) (www.ncbi.nlm.nih.gov/genome/viruses/) ；使用VIBRANT (v.1.2.1) 和 DeepVirFinder (v.1.0)，截止长度为 1,000bp。注释为 VirSorter 类别 1、2、4 和 5 的contigs，或 DeepVirFinder 评分≥0.7 且 P \u0026lt; 0.05 的contigs，被视为假定的病毒contigs。通过将数据与 VIBRANT 的数据相结合，CAT (v.5.0.3) 用于进一步估计按 VirSorter 类别 3 和 6 排序的contigs，或 DeepVirFinder 得分为 0.7-0.9 且 P\u0026lt; 0.05 的contigs。具有 \u0026gt;40% 开放阅读框注释为细菌、古细菌或真核生物的contigs被视为非病毒contigs。取出≥5 kb或≥1.5 kb的contigs和环状片段进行进一步研究；通过 BLAST (v.2.11.0) 鉴定的 Φx174 DNA 被手动去除。\nA global atlas of soil viruses 这也是一篇2024年发表于Nature microbiology的文章[9]：\n历史上被微生物生态学家忽视的土壤病毒现在被认为对全球生物地球化学循环至关重要。然而，我们对其全球分布、活动以及与土壤微生物组相互作用的了解仍然有限。 在这里展示了全球土壤病毒图谱，这是一个综合数据集，由 2,953 个先前测序的土壤宏基因组编译而成，由 616,935 个未培养的病毒基因组和 38,508 个独特的病毒操作分类单元组成。 全球土壤病毒图谱的稀疏曲线表明，大多数土壤病毒多样性仍未被探索，样本间高空间周转率和低共享病毒操作分类单元率进一步强调了这一点。 通过检查与生物地球化学功能相关的基因，还证明了病毒影响土壤碳和养分循环的潜力。这项研究代表了土壤病毒多样性的广泛特征，并为制定有关病毒圈在土壤微生物组和全球生物地球化学中的作用的可检验假设奠定了基础。\n这篇文章中鉴定病毒的方法是：\n使用 IMG/VR v3 病毒识别管道的修改版本对病毒contigs进行了初步识别。该管道根据 Pfam 数据库 和 VirFinder 中 23,841 个病毒蛋白家族、16,260 个微生物来源蛋白家族的存在来识别病毒，以识别至少 1 kb 长的contigs中的假定病毒基因组。\n在本研究过程中，发布了 geNomad v1.3.3，这是一种具有改进的分类性能的病毒识别工具，并将其纳入流程中，以提高预测置信度并执行分类分配。 使用 CheckVv1.0.1（数据库版本 1.5） 进一步处理预测的病毒序列，以评估病毒基因组的质量。 由于本研究重点关注非整合病毒基因组，因此被 geNomad 或 CheckV 标记为原病毒的contigs被丢弃。 从剩余的contigs中，使用以下规则选择病毒基因组：\n至少 1 kb 的contigs，与 CheckV数据库中的基因组具有高度相似性（即具有高质量或中等完整性估计）或包含自动选择直接末端重复； 长于 10 kb 的contigs需要具有高于 0.8 的 geNomad 病毒评分，并且编码一种病毒标志（例如，终止酶、衣壳蛋白、门户蛋白等）（由 geNomad 确定），或者具有gNomad 病毒标记至少为 5.0； 短于10kb和长于5kb的contigs需要具有高于0.9的geNomad病毒评分，编码至少一种病毒标志并且具有高于2.0的病毒标记富集。 这产生了 49,649 个病毒contigs，将其用于下游分析。 病毒基因组按照 MIUViG 指南聚类成 vOTU（平均核苷酸同一性为 95%，比对分数为 85%）。简而言之，进行了全对全 BLAST（v2.13.0+，\u0026rsquo;-task megablast -evalue 1e-5 -max_target_seqs 20000\u0026rsquo;）搜索来估计成对平均核苷酸身份和比对分数 (AF)。并采用 pyLeiden对基因组进行聚类，使用图作为输入，其中满足 MIUViG 标准的基因组对通过边连接。\n使用 DIAMOND 进行蛋白质比对，使用 Markov Cluster Process 进行聚类，将病毒按大致属水平（40% 平均氨基酸同一性，20% 共享基因）和科水平（20% 平均氨基酸同一性，10% 共享基因）聚类进行分组。通过与先前描述的来自 NCBI GenBank 和 MAG 的 160 万个细菌和古菌基因组的 CRISPR 间隔区数据库相匹配，将病毒序列分配给假定的宿主（细菌和古菌）分类群。\nBacteriophage in 1300-year-old human palaeofaeces 这是2024年在NC上发表的研究[10]：\n噬菌体被广泛认为是快速进化的生物实体。然而，关于古代噬菌体的知识是有限的。在这里，我们分析了先前从古代古粪便和人类肠道内容物样本中生成的 DNA 序列数据集，并鉴定了与当今的 Mushuvirus mushu（一种感染肠道共生细菌的病毒）几乎相同的古代噬菌体基因组。 基因组的 DNA 损伤模式与其古代起源一致，尽管经过 1300 年的进化，古代木须病毒基因组与现代对应物具有 97.7% 的核苷酸同一性，表明原噬菌体与其宿主之间存在长期关系。此外，还重建并验证了过去 5300 年的 297 个其他噬菌体基因组，包括属于未知家族的噬菌体基因组。 研究结果证明了重建古代噬菌体基因组序列的可行性，从而扩大了已知的病毒圈，并为跨越数千年的噬菌体-细菌相互作用提供了见解。\n病毒contigs鉴定：\n使用三种机器学习工具来识别病毒contigs。第一个是 Jaeger v.1.1.0，这是一种深度学习模型，可基于自动组成特征提取来识别宏基因组中的噬菌体基因组序列 (https://github.com/Yasas1994/Jaeger)。第二个和第三个是 VIBRANT v.1.2.124 和 VirSorter2 v.2.2.325，它们依赖于分析代表与预测蛋白质相似但应用不同分类器和参考数据库的保守家族和/或结构域的 HMM 图谱。 Jaeger 和 VIBRANT 使用默认设置运行。对于 VirSorter2，我们使用了位置参数“\u0026ndash;include-groups dsDNAphage,NCLDV,ssDNA,lavidaviridae all”。进一步分析了至少两种工具分类为病毒的contigs。\nReferences Camargo, A.P., Roux, S., Schulz, F. et al. Identification of mobile genetic elements with geNomad. Nat Biotechnol (2023). https://doi.org/10.1038/s41587-023-01953-y Ren, J., Song, K., Deng, C., Ahlgren, N.A., Fuhrman, J.A., Li, Y., Xie, X., Poplin, R. and Sun, F. (2020), Identifying viruses from metagenomic data using deep learning. Quantitative Biology, 8: 64-77. https://doi.org/10.1007/s40484-019-0187-4 Guo, J., Bolduc, B., Zayed, A.A. et al. VirSorter2: a multi-classifier, expert-guided approach to detect diverse DNA and RNA viruses. Microbiome 9, 37 (2021). https://doi.org/10.1186/s40168-020-00990-y Kieft, K., Zhou, Z. \u0026amp; Anantharaman, K. VIBRANT: automated recovery, annotation and curation of microbial viruses, and evaluation of viral community function from genomic sequences. Microbiome 8, 90 (2020). https://doi.org/10.1186/s40168-020-00867-0 Chen, L., Banfield, J.F. COBRA improves the completeness and contiguity of viral genomes assembled from metagenomes. Nat Microbiol 9, 737–750 (2024). https://doi.org/10.1038/s41564-023-01598-2 Flamholz, Z.N., Biller, S.J. \u0026amp; Kelly, L. Large language models improve annotation of prokaryotic viral proteins. Nat Microbiol 9, 537–549 (2024). https://doi.org/10.1038/s41564-023-01584-8 Nayfach, S., Camargo, A.P., Schulz, F. et al. CheckV assesses the quality and completeness of metagenome-assembled viral genomes. Nat Biotechnol 39, 578–585 (2021). https://doi.org/10.1038/s41587-020-00774-7 Ma, B., Wang, Y., Zhao, K. et al. Biogeographic patterns and drivers of soil viromes. Nat Ecol Evol 8, 717–728 (2024). https://doi.org/10.1038/s41559-024-02347-2 Graham, E.B., Camargo, A.P., Wu, R. et al. A global atlas of soil viruses reveals unexplored biodiversity and potential biogeochemical impacts. Nat Microbiol (2024). https://doi.org/10.1038/s41564-024-01686-x Rozwalak, P., Barylski, J., Wijesekara, Y. et al. Ultraconserved bacteriophage genome sequence identified in 1300-year-old human palaeofaeces. Nat Commun 15, 495 (2024). https://doi.org/10.1038/s41467-023-44370-0 ","date":"2024-06-20T00:00:00Z","image":"/p/virus/images/genomad_hu_47439e71e5a10571.png","permalink":"/p/virus/","title":"从宏基因组中鉴定病毒序列"},{"content":"Introduction 分享一些R进阶使用的技巧，相当于是之前写的R语言学习的实践和总结了。\nOnline slide: https://asa-blog.netlify.app/R_tips_for_advanced_use_byAsa/R_tips.html\n下载slide和相关的各种test文件: https://asa-blog.netlify.app/R_tips_for_advanced_use_byAsa/R_tips_for_advanced_use_byAsa.zip\n视频教程: https://www.bilibili.com/video/BV1eg4y1w7AL/\n*才疏学浅，仅代表本人学习经验，R是一个宝库，此处只是冰山一角\nUse R R语言简介 R语言是S语言的一个变种。S语言由Rick Becker等人在贝尔实验室开发（著名的C语言、Unix系统开发实验室）。\nR是一个自由源代码软件，GPL授权，于1997年发布，实现了与S语言基本相同的功能和统计功能。 现在由R核心团队开发，但全世界的用户都可以贡献软件包。\nR的网站: http://www.r-project.org/\n特点：\n自由软件，免费、开放源代码，支持各个主要计算机系统； 具有完善的数据类型，代码简洁、可读； 强调交互式数据分析，支持复杂算法描述，图形功能强； 统计科研工作者广泛使用R进行计算和发表算法。R有上万扩展包(截止2023年7月5日在R包网站CRAN上有19784个)。 S语言作者，R语言专家J. M. Chambers指出R的.red[本质特征]：\nR中所有的存在都是对象（object）； R中发生的动作都是函数调用（function call）。 详细地说R有如下技术特点：\n函数编程（functional programming）。 支持对象类和类方法，面向对象的程序设计。 动态类型语言，解释执行，速度较慢。 数据框（data.frame）是基本数据类型，类似于数据库的表。 可以用作C和C++、FORTRAN语言编写的算法库的接口。 内部数值算法采用已广泛测试和采纳的算法实现，如排序、线性代数等。 R \u0026amp; Rstudio R是一种统计学编程语言 Rstudio是R语言最好的IDE（Integrated development environment） 2022年RStudio公司正式改名Posit，拥抱大数据科学生态：R、Python、Julia\u0026hellip;\nRStudio使用方法概要PDF下载：rstudio-ide.pdf\nRstuido的魔法：按住Ctrl（Command）单击某个变量名或函数名，如果是data.frame就可以进入预览窗格， 如果是函数就可以进入函数内部看具体的代码。\n其实是调用了View()函数，对于不是以上类型的对象我们可以手动调用。\n学习资料 全面教程 小白上手首推北大李老师的课程讲义《R语言教程》，中文讲义，简单易读，甚至整本书就是用Rbookdown编写的，电子书也比较好复制代码进行学习。\n《R语言实战》，也有中文版，介绍地更加全面且有不少进阶知识，值得一看！\n然后是著名的英文书和参考手册：\n《An Introduction to R》 《R Cookbook》 数据处理\ntidyverse全家桶，其中包含ggplot2，tibble，dplyr，readr，stringr等常用的全面的数据处理包，能够很好的满足我们下游数据处理需求：\n读取数据 清洗数据 转换数据 合并数据 筛选数据 可视化 官方教程：《R for Data Science》，非常建议熟读并使用\n可视化\nggplot官方教程：《ggplot2: Elegant Graphics for Data Analysis》\n为可视化而建的网站：From data to Viz | Find the graphic you need\n基本使用 很多人使用 R，只为用其中的某个包的某个功能，只需学会以下几步即可：\n1. 装好R \u0026amp; Rstudio ✅ 2. 认识基本数据类型，结构 数值型常量 1,1e2,5L,Inf,-Inf; 字符型常量 \u0026quot;str\u0026quot;,'str'; 逻辑型常量 TRUE,FALSE,T,F; 缺失值 NaN,NA, 空值 NULL; 复数常量 2.2 + 3.5i; 变量，区分大小写的字母、数字、下划线和句点组成变量名，支持但不建议中文; 向量(vector)：用c()函数把多个元素或向量组合成一个向量。如果元素基本类型不同，将统一转换成最复杂的一个，复杂程度从简单到复杂依次为： logical\u0026lt;integer\u0026lt;double\u0026lt;character。此外还可以有Date和factor类型的元素 列表(list)：包装保存不同类型的数据。单个列表元素必须用两重方括号格式访问,单重方括号结果还是列表而不是列表元素。普通有names属性的列表可以用$访问元素，S4对象可以用@访问元素。 矩阵，数组(matrix, array)：矩阵用matrix函数定义，实际存储成一个向量，根据保存的行数和列数对应到矩阵的元素， 存储次序为按列存储。 数据框(data.frame)：数据框类似于一个矩阵，有多个横行、多个纵列，各列允许有不同类型：数值型、因子、字符、日期时间，但同一列的数据类型相同。取子集应注意drop 。 改进数据框(tibble)：tibble类型是一种改进的数据框，tidyverse全家桶推荐使用，确实有不少好处： 不会随意改变我们的数据名称，类型。打印优美。 3. 装好需要的包 包是R函数、数据、预编译代码以一种定义完善的格式组成的集合。\n找到包，主要平台： CRAN 官方存储库，多个镜像 BioConductor 用于生物信息学的开源软件专题库 Github 开发版本，无限惊喜，但也可能缺少维护 Bitbucket、SVN\u0026hellip; 装在哪，本机位置： 计算机上存储包的目录称为库（library）。 函数.libPaths()能够显示库所在的位置，函数library()可以显示库中有哪些包。\n1 .libPaths() 这个地址很重要，有时候会有多个（如Windows分区），我们要搞清楚装在哪里。\n怎么装，例子：大部分情况下CRAN用 install.packages(\u0026quot;pkg\u0026quot;)，BioConductor用BiocManager::install(\u0026quot;pkg\u0026quot;)，Github用devtools::install_github(\u0026quot;repos\u0026quot;)即可。 但有时候会有依赖包相关的报错，我们可以手动下载特定版本包文件后安装。 source， 源码，一堆R脚本和文本文件，我们直接在github上看的就是这个。 bundle， 捆绑态，其实就是打包过的source，一般.tar.gz结尾。 binary， 二进制版本，架构不一样，.zip(Windows)或.tgz(macOS)结尾。 所谓安装包就是把source变成binary在放在我们的.libPaths()文件夹下。\n还有问题，谷歌大法，或github问包作者。 带C++的R包出问题会麻烦一些，需要考察自己本机的C语言编译器。\n怎么用包 首先可以用library(pkg)或require(pkg)将包导入内存，这样便可以调用其中的函数。 search()函数可以查看我们已经library的包。\n1 2 library(pcutils) search() 1 if(!require(\u0026#34;pcutils\u0026#34;)) install.packages(\u0026#34;pcutils\u0026#34;) 使用pkg::加上tab键可以列出某个包里所有导出的函数，多用help(pkg::func)或?pkg::func查看某个函数的用法。\n如果不想用某个包了，可以用detach从当前环境移除（不是删除包）\n1 detach(\u0026#34;package:pcutils\u0026#34;) 4. 正确数据/图像读入和写出 各种表格读取：read.table(), read.csv(), read.delim()\n1 read.table(\u0026#34;test.txt\u0026#34;) #无法读取 当我们的表格含有 \u0026quot;, ', # 或者列名中含有任何非变量名字符时都要小心\n1 read.table(\u0026#34;test.txt\u0026#34;,header = T,sep = \u0026#34;\\t\u0026#34;,comment.char = \u0026#34;\u0026#34;,quote = \u0026#34;\u0026#34;,check.names = F) 建议在readr包的支持下用read_csv(), read_table2(), read_delim()等函数读入。\n保存为tibble类型，快得多，也不自动将字符型列转换成因子，不自动修改变量名为合法变量名。\n1 readr::read_delim(\u0026#34;test.txt\u0026#34;,delim = \u0026#34;\\t\u0026#34;) excel用readxl包，剪切板可用datapasta包或clipr::read_clip()。表格写出用write_*()，与读入一致。\n任意文件访问，跟python很像，使用file()打开文件，close()关闭。\nr—文本型只读; w—文本型只写; a—文本型末尾添加; rb—二进制只读; wb—二进制只写; ab—二进制末尾添加; r+或r+b—读写; w+或w+b—读写，清空文件; a+或a+b—读和末尾添加。 或者可以用cat()直接输出任意文本到文件。\nclipr::write_clip()可以把R数据框或向量写入剪切板，可以直接粘贴他处。\n图片保存：\n1 2 3 pdf(\u0026#34;new.pdf\u0026#34;) #png(),jpg(),tiff(),bmp() #画一些图 dev.off() #要记得关闭设备 1 2 ggplot2::ggsave(\u0026#34;new.pdf\u0026#34;,plot = p,device = \u0026#34;pdf\u0026#34;) #p是一个ggplot对象，device可选各种文件格式 R变量储存：\nR的save()命令可以将一个或者多个R变量保存到文件(.rda或.RData)中，保存结果是经过压缩的，在不同的R运行环境中兼容。 使用load()可以恢复保存的变量。\n强烈建议传递数据时用这种文件，避免了数据写入和读取时引起的差异。\n使用save.image()可以把整个环境的所有变量保存，方便结果复现。\n保存单变量时推荐使用saveRDS()，用readRDS()载入并返回变量，这样可以将某个变量赋值给某个拟定的变量名，避免某个变量值变了我们还不知道， 如\n1 2 saveRDS(old,file = \u0026#34;tmp.RDS\u0026#34;) new=readRDS(\u0026#34;tmp.RDS\u0026#34;) 5. 关闭R走人 ✅ R programming 程序控制结构 分支结构 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 x=1 if(x\u0026gt;0) { print(\u0026#34;x \u0026gt; 0\u0026#34;) } else { print(\u0026#34;x \u0026lt;= 0\u0026#34;) } #或者用switch函数 switch (x\u0026gt;0, T = {print(\u0026#34;x \u0026gt; 0\u0026#34;)}, F = {print(\u0026#34;x \u0026lt;= 0\u0026#34;)} ) #或者用ifelse函数，向量式 x \u0026lt;- c(-2, 0, 1) ifelse(x \u0026gt;=0, 1, 0) 循环结构 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 for (i in 1:3) { print(i) } #或者用while函数 i=1 while (i\u0026lt;4) { print(i) i=i+1 } #或者用repeat函数 i=1 repeat{ print(i) i=i+1 if(i\u0026gt;3)break } 注意用到的判断条件必须是逻辑标量值，不能为NA或零长度。 这是R编程时比较容易出错的地方。\n循环结构进阶，apply()家族\n上述显式循环是R运行速度较慢的部分，有循环的程序也比较冗长，建议使用apply, sapply, lapply, vapply, tapply等函数替代。\n1 2 func=function(i)print(i) a=lapply(1:3, func) 另外，建议循环过程不要制作副本：\n类似于x \u0026lt;- c(x, y)这样的累积结果每次运行都会制作一个x的副本， 在x存储量较大或者重复修改次数很多时会减慢程序。\n而是应该在循环前设置好用来保存结果的数据结构：\n1 2 x=numeric(100) x[[i]]={i循环100次产生的结果} 管道 原生管道，R从4.1.0版本开始提供了一个|\u0026gt;运算符实现管道，如计算 $e^{\\sqrt{2}}$：\n1 2 |\u0026gt; sqrt() |\u0026gt; exp() 但是我还是更喜欢用magrittr提供的%\u0026gt;%，支持更复杂的应用，比如用.代表产生的中间变量放到合适的参数位置：\n1 2 library(magrittr) \u0026#34;hhh\u0026#34;%\u0026gt;%paste0(\u0026#34;prefix_\u0026#34;,.) 还有%\u0026lt;\u0026gt;%等方便的变体:\n1 2 a=\u0026#34;hhh\u0026#34;; a%\u0026lt;\u0026gt;%paste0(\u0026#34;prefix_\u0026#34;,.) a 函数 使用自定义函数， 优点是代码复用、模块化设计。\n函数名 \u0026lt;- function(形式参数表) 函数体\n特殊形参：...\n1 2 my_mean=function(...)sum(...)/length(c(...)) my_mean(1,2,3,4) 无名函数: 不定义函数名也可以调用\n1 a=lapply(1:3, \\(i)print(i)) 变量作用域：全局变量 vs 局部变量\n1 2 3 4 5 x=100 func=function(x){ print(x+1) } func(0) R中所有的存在都是对象（object） 对象其实就是一种封装的概念，它把事物封装成一个类(class)，然后提供类的方法(method)，而具体的过程人们看不到。 1 class(mean) R中发生的动作都是函数调用（function call）??? 函数调用有四种方式：\n1 前缀形式。 这也是一般的格式\n1 mean(1:2) 2 中缀形式。二元运算符实际上都是函数\n1 2 3 4 5 1+1 `+`(1,1) `%love%`=function(a,b)paste0(a,\u0026#34; loves \u0026#34;,b) \u0026#34;Romeo\u0026#34;%love%\u0026#34;Juliet\u0026#34; 3 替换形式。\n1 2 3 4 5 x \u0026lt;- 1:2 names(x) \u0026lt;- c(\u0026#34;a\u0026#34;, \u0026#34;b\u0026#34;) x print(`names\u0026lt;-`) 4 特殊形式。x[1], x[[1]]这些取子集或元素等\n1 2 3 x \u0026lt;- 1:5 x[1] `[`(x, 1) 确实，R中发生的动作都是函数调用（function call），知晓函数调用的形式，可以让我们在用某些包的函数时明确问题来源，查找源码等。\nDebug 某个函数突然失灵了\n工作环境变化 环境是R语言比较困难的概念，一般不需要深入了解也能用。\n但我们要知道，大多数时候我们处于Global Environment，我们敲出来的每一个变量名(函数名)都是优先在全局环境找，找不到的话就search()里面按顺序去每个环境找。 所以要注意环境优先级以及变量名冲突，极端情况如下：\n1 2 3 4 1+1 #正常当然等于2 #定义了`+`,或者新导入的包包含一个`+`的函数名，覆盖了base的加法 `+`=`-` 1+1 #结果会变成0 常使用pkg::func的形式调用函数是个好习惯，可以防止不同包的同名函数冲突。\n断点，traceback()，debug()， browser() 反向追踪(traceback)将错误定位到某一函数调用。\n可以用debug(func)命令对函数func开启跟踪运行。\n用undebug(func)取消对func的这种操作。\n我要debug的函数在哪？ 一般来说我们可以找到报错的代码行以及具体的函数，便可以使用debug()。\n但有时候会发现一些函数无法被正确定位，具体代码也只能看到UseMethod()：其实是我们碰到了泛型函数。下面同样一个summary函数，为啥对women和fit做出了完全不同的处理？\n1 2 3 summary(women) fit \u0026lt;- lm(weight ~ height, data=women) summary(fit) 1 2 3 summary(women) fit \u0026lt;- lm(weight ~ height, data=women) summary(fit) 1 class(women); class(fit) 原来他们是不同的类（class），泛型函数会更具对象的类选择运行什么样的代码（即见人说人话，见鬼说鬼话）： 调用func.class()函数，上述就是分别调用了summary.data.frame()，summary.lm()。print和plot也是非常常见的泛型函数。\n或者我们可能发现某些报错函数not found（但我们又确定有这样一个函数）： 其实是我们碰到了非导出函数（R包开发者不想用户看到所有的函数，只把有用的导出）。\n1 2 3 4 5 6 library(reshape2) class(mtcars) #melt是泛型函数，那应该调用melt.data.frame melt.data.frame(mtcars,id.vars = \u0026#34;cyl\u0026#34;) ## Error in melt.data.frame(mtcars, id.vars = \u0026#34;cyl\u0026#34;) : ## could not find function \u0026#34;melt.data.frame\u0026#34; 找到这些函数的方法也很简单（毕竟R包需要都开源）：pkg:::func即可\n1 reshape2:::melt.data.frame(mtcars,id.vars = \u0026#34;cyl\u0026#34;) 有时候我们通过debug可以发现一些有用的内部函数（比如从那种一步/很久完成XX分析的函数中找到我们需要的功能）， 这样我们便可以使用pkg:::func做想做的部分。\n代码整理 我们在做数据分析时会产生大量代码，做好整理非常重要。\n最开始，每一个独立的R脚本进行分析 （代码冗余度太高，后期很难快速看懂）\n学会编写函数，复制函数到不同的R脚本使用（n个地方的函数需要修改n次）\n将常用的函数放在一个R脚本下，要用的时候source()整个脚本（全局环境中出现大量函数名，可能还会引起冲突）\n将常用函数整理成R包，写好注释和帮助文档，方便调用和分享 （嘎嘎香)\n接下来的3,4部分非必需，但我觉得学习后便会有惊喜：\nR markdown (to everything) R Markdown是一种文本格式，用于创建具有代码、文本、图形和输出结果的可重复性报告。 是“文学式编程”(literate programming, (Knuth 1984))思想的实践。\n它是在R语言环境中开发的，也可以与其他编程语言（如Python，shell）结合使用。\n优点：\n可重复性：代码和结果都是可重复的，有助于确保研究结果的可靠性和透明度。 效率：使用R Markdown在单个文件中组织和记录所有内容，节省时间和精力。 灵活性：R Markdown支持多种格式和输出选项，根据需要自定义样式布局。 总之，比word好用，比Latex好学😂\nYihui Xie大佬的官方文档：R Markdown: The Definitive Guide (bookdown.org)\n以及参考书：R Markdown Cookbook (bookdown.org)\nTo Documents Rmd文档头部是YAML元数据，可指定各种输出参数\nHTML\nPDF\nWord\n优点：\n公式，化学分子式非常好写\n文献插入也不错（配合Zotero）\n图表自动编号和引用、链接（我觉得比word好用点）\n支持交互式图形（HTML）\nTo Presentation R Markdown支持生成各种幻灯片文件（此幻灯片也是由Rmd生成的😂）\nPowerPoint\n常用，易分享\nioslide/Slidy\n网页格式的幻灯片，支持交互 (拜托，PPT可交互真的很酷)\nBeamer\nPDF幻灯片，模版众多，大学课堂热衷使用\nTo Research Papers rticle包，包含一套自定义 R Markdown 格式和模板，用于创作期刊文章和会议提交。\n例子：\nFrontiers\nBioinformatics\nTo Website Rmarkdown可以帮助我们搭建简易网站：\nindex.Rmd是主页内容， 可以在此处人工加入其它页面链接。\n_site.yml是一个YAML文件， 其中包含站点的设定和输出设定。\n例子：\nFile -\u0026gt; New Project -\u0026gt; New directory -\u0026gt; Simple R Markdown Website -\u0026gt;\nCreate Project (click Open in new session) -\u0026gt; Build -\u0026gt; Build Website\nTo Blog R扩展包blogdown可以与Hugo软件配合制作简单的静态博客网站。\n网站的所有文件都在一个目录中，只要上传到任意的网站服务器就可以发布，没有任何限制。\n我的博客：Asa\u0026rsquo;s blog\n参考书：blogdown: Creating Websites with R Markdown (bookdown.org)\nTo Book R的bookdown扩展包\n在bookdown的管理下：一本书的内容可以分解成多个Rmd文件， 其中可以有可执行的R代码， R代码生成的文字结果、表格、图形可以自动插入到生成的内容中， 表格和图形可以是浮动排版的。 输出格式主要支持gitbook格式的网页图书。\n我也稍微尝试写了一下：MetaNet Tutorial\n参考书：bookdown: Authoring Books and Technical Documents with R Markdown\nR package/shiny 写R包 包是可重现 R 代码的基本单元，包括可重用的 R 函数、描述如何使用它们的文档和示例数据。 一个包将代码、数据、文档和测试捆绑在一起，并且很容易与他人共享。\n简单例子（需要下载roxygen2包）：\nFile -\u0026gt; New Project -\u0026gt; New directory -\u0026gt; R package -\u0026gt;\nCreate Project (click Open in new session)-\u0026gt; Package name -\u0026gt; Build -\u0026gt; Install\n最简单的包只需要这些目录和文件即可，\nR目录下放在我们编写的R函数脚本 man目录放着所有函数的帮助文档（roxygenise()函数生成，不要自己写） DECRIPTION定义了包的各种元数据，包名/版本/依赖包等等，非常重要 NAMESPACE控制函数的可视性（roxygenise()函数生成，不要修改！） 参考书：R Packages (2e) (r-pkgs.org)\n如果真的有意开发R包，建议走devtools的流程，要比前面的简单例子好用。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 library(devtools) #创建R包 create_package(\u0026#34;testpkg\u0026#34;) #配置git用于版本控制 use_git() #创建一个R脚本，开始写函数 use_r(\u0026#34;first\u0026#34;) #生成man文件和NAMESPACE document(\u0026#34;./\u0026#34;) #使所有函数可用（没有install但R包已在内存） load_all(\u0026#34;./\u0026#34;) #检查R包语法，建议每次重要修改后运行一次，解决完所有的Error，Warning，Note再进一步修改，不要积累较多错误 check(\u0026#34;./\u0026#34;) #打包为bundle包，.tar.gz build(\u0026#34;./\u0026#34;) #install我们写好的R包 install(\u0026#34;./\u0026#34;) #定义一些测试例子 use_testthat() 循环后面几步：function -\u0026gt; document -\u0026gt; load_all -\u0026gt; check -\u0026gt;install，直到功能完善，check无误。\n函数应该功能明确，不能使用library，而应该用pkg::func调用，并且这里的pkg一定要在DESCRIPTION中声明。 函数不应该产生不良副作用，比如修改用户环境变量，谨慎使用option, par, setwd等函数。 函数的头文件很重要，包含了帮助文档以及决定函数性质的参数： 使用Shift+option+command+R可以帮助生成头文件 发布包:\nCRAN submission 请仔细阅读CRAN Repository Policy，然后必须让代码通过R CMD check再提交，不然会直接拒收。我们提交的包是bundle包，.tar.gz格式。过了机检后就会有“审包人”联系（一般是志愿者，我们应当态度好些）， 再积极沟通修改代码就好，最后通过审核一天就能在CRAN上看到了。\nBioConductor submission 用于生物信息学的开源软件专题库，上传前仔细阅读Guidelines， 明确包的主题要跟生物有相关性（ Software, Experiment Data, Annotation and Workflow.），发布包的流程是Github issues， 审核过程全公开透明，你现在就能点进去看有哪些包正在提交。\nGithub 这里就最自由了，你可以随意上传在自己的仓库，也可以邀请别人直接从github安装。\n制作Shiny APP Shiny 是一个 R 包，可轻松地直接从 R 构建交互式 Web 应用程序。\n可以在网页上托管独立应用程序或将它们嵌入 R Markdown 文档。还可以使用 CSS 主题、html 小部件和 JavaScript 操作扩展Shiny 应用程序。\n例子：\nFile -\u0026gt; New Project -\u0026gt; New directory -\u0026gt; Shiny Application -\u0026gt;\nCreate Project (click Open in new session) -\u0026gt; Run App\n1 shiny::runApp(\u0026#34;test_shiny/app.R\u0026#34;) 官方教程：Shiny Learning Resources\n参考书：Mastering Shiny\n","date":"2024-06-16T00:00:00Z","image":"/p/r-tips/images/r-tips_hu_1fd32692dfd56c4f.png","permalink":"/p/r-tips/","title":"R进阶使用技巧"},{"content":"Introduction 上一篇里通过Metabat2了解了宏基因组分箱的关键步骤，这篇文章将介绍一个更全面的binning流程：MetaWRAP的具体使用方法。\nMetaWRAP 是一个集成的宏基因组分析工具包，旨在简化和提高宏基因组数据的处理、分析和解释。它结合了多个独立的宏基因组分析工具，提供了一系列模块来处理从原始数据质控到基因组注释的各个步骤，侧重于宏基因组Binning。本质来说，MetaWRAP并不是一种新的binning方法，而是一个整合其他binning方法的refiner。\nMetaWRAP的文章于2018年发表于Microbiome，软件主页：https://github.com/bxlab/metaWRAP，到今天也没有重大更新，但仍然可以比较流畅的使用。以下是metaWRAP的主要工作流程：\n图中红色代表分析模块，绿色代表宏基因组数据，橙色代表中间文件，蓝色代表结果图表。\n更详细的工作流程请查看官方细节图，还是非常复杂的。\nmodules MetaWRAP的主要功能模块包括：\n宏基因组数据预处理模块\n质控Read_QC： read质控剪切和移除人类宿主 组装Assembly: 使用megahit或metaSPAdes拼接 物种注释Kraken: 对reads和contigs层面进行可视化 这几步不一定要在MetaWRAP的流程中完成，我们在做别的分析时可能已经做完了这几步，只需要将组装后的contigs拿去后续的Bin处理模块即可。\n分箱Bin处理模块\n分箱Binning: 利用MaxBin2, metaBAT2, 和CONCOCT三个软件分别分箱； 提纯Bin_refinement：对多种Bin结果评估和综合分析，获得更好的结果； 重组装Reassemble_bins：利用原始序列和评估软件二次组装，改善Bin的N50、完整度； 定量Quant_bins: 估计样品中每个bin的丰度并热图展示； 气泡图Blobology: blobplots可视化群体的contigs的物种和Bin分布； 物种注释Classify_bins: 对Bin物种注释； 基因注释Annotate_bins: 预测Bin中的基因功能。 MetaWRAP实战 软件，数据准备 安装 MetaWRAP的资源需求根据处理的数据量而有很大差异。由于许多使用的软件（KRAKEN 和 metaSPAdes 等）需要大量内存，作者建议使用 8 个以上内核和 64GB 以上 RAM。实际使用感觉要更多，Binning确实算是比较耗时耗算力的分析了。\nMetaWRAP依赖超过140个软件，而且很多都是之前的老版本（python用的还是2.7），很容易引起与已经安装的软件冲突。 强烈推荐使用conda创建一个虚拟环境再安装。\nconda可能也会比较慢，毕竟软件太多了，一定要耐心，装好了之后很多依赖软件也可以单拎出来使用；或者参考软件主页方法，先用conda装好mamba（可以认为是一个升级版的更快的conda），再用mamba去装MetaWRAP。\n1 2 3 4 5 6 7 8 9 10 conda create -n metawrap python=2.7 source activate metawrap # ORDER IS IMPORTANT!!! conda config --add channels defaults conda config --add channels conda-forge conda config --add channels bioconda conda config --add channels ursky conda install -c ursky metawrap-mg 祝你安装顺利！\n安装完成后可以看一下命令行参数：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 $metaWRAP -h MetaWRAP v=1.3.2 用法：metaWRAP [模块] 模块： read_qc\t原始读段质控模块（读段剪切和污染去除） assembly\t组装模块（宏基因组组装） kraken\tKRAKEN 模块（读段和组装的分类注释） kraken2\tKRAKEN2 模块（读段和组装的分类注释） blobology\tBlobology 模块（contigs 和 bins 的 GC vs Abund 图） binning\t分箱模块（metabat, maxbin 或 concoct） bin_refinement\t分箱模块的精细化 reassemble_bins 使用宏基因组读段重新组装 bins quant_bins\t量化每个 bin 在样本中的丰度 classify_bins\t对基因组 bin 进行分类注释 annotate_bins\t草图基因组的功能注释 --help | -h\t显示此帮助信息 --version | -v\t显示 metaWRAP 版本 --show-config\t显示 metaWRAP 配置文件的存储位置 配置数据库 conda安装软件并不带数据库，需要手动下载数据库，并设置数据库的位置。\n主要大小和依赖模块如下：\nDatabase Size Used in module Checkm 1.4GB binning, bin_refinement, reassemble_bins KRAKEN 192GB kraken NCBI_nt 99GB blobology, classify_bins NCBI_tax 283MB blobology, classify_bins Indexed hg38 34GB read_qc 这里的根据需求装就好了，如果不需要某个模块，就不需要下载对应的数据库。如果实验室已经有人下载过了最好设置软链接到自己目录并加可读权限即可，否则手动下载这些还是比较耗时的。\n我们尽量把数据库放在一起比如~/db/下，方便管理和使用。\nCheckM 数据库 1 2 3 4 5 6 7 8 9 10 11 12 # 创建存储目录 cd ~/db mkdir checkm # 设置CheckM数据存储位置 checkm data setRoot ~/db/checkm # 手动下载数据库 cd ~/db/checkm wget https://data.ace.uq.edu.au/public/CheckM_databases/checkm_data_2015_01_16.tar.gz # 解压下载的数据库 tar -xvf checkm_data_2015_01_16.tar.gz # 删除压缩文件 rm checkm_data_2015_01_16.tar.gz Kraken 数据库 1 2 3 4 5 6 7 # 创建存储目录 cd ~/db mkdir kraken # 下载和建索引标准数据库 kraken-build --standard --threads 24 --db ~/db/kraken # 清理临时文件 kraken-build --db ~/db/kraken --clean NCBI_nt 数据库 NCBI_nt 是一个非冗余核酸序列数据库，用于BLAST搜索。\n1 2 3 4 5 6 7 8 # 创建存储目录 cd ~/db mkdir NCBI_nt cd NCBI_nt # 下载数据库文件 wget -c \u0026#34;ftp://ftp.ncbi.nlm.nih.gov/blast/db/nt.*.tar.gz\u0026#34; # 解压所有下载的文件 for a in nt.*.tar.gz; do tar xzf $a; done NCBI 物种信息数据库 1 2 3 4 5 6 7 8 # 创建存储目录 cd ~/db mkdir NCBI_tax cd NCBI_tax # 下载数据库文件，可以找适合自己的版本 wget https://ftp.ncbi.nlm.nih.gov/pub/taxonomy/taxdump.tar.gz # 解压下载的数据库 tar -xvf taxdump.tar.gz 人类基因组 BMTAGGER 索引 BMTAGGER 是一个用于从宏基因组数据中去除宿主基因组序列的工具。我们将下载并索引人类基因组 hg38。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 # 创建存储目录 mkdir ~/db/BMTAGGER_INDEX cd ~/db/BMTAGGER_INDEX # 下载人类基因组序列 wget ftp://hgdownload.soe.ucsc.edu/goldenPath/hg38/chromosomes/*fa.gz # 解压所有下载的文件 gunzip *fa.gz # 合并所有染色体序列 cat *.fa \u0026gt; hg38.fa # 删除单个染色体文件 rm chr*.fa # 创建 bitmask 索引 bmtool -d hg38.fa -o hg38.bitmask # 创建 srprism 索引 srprism mkindex -i hg38.fa -o hg38.srprism -M 100000 下载完自己需要的数据库后，使用which config-metawrap命令查找配置文件位置，配置文件为config-metawrap，然后再用vim修改这个配置文件中的数据库地址即可，比如：\n1 2 3 4 5 6 7 # path to kraken standard database KRAKEN2_DB=~/db/kraken # path to indexed human (or other host) genome (see metaWRAP website for guide). This includes .bitmask and .srprism files BMTAGGER_DB=~/db/BMTAGGER_INDEX # paths to BLAST databases BLASTDB=~/db/NCBI_nt TAXDUMP=~/db/NCBI_tax 示例数据 本文使用的示例数据和上一篇推文一致，来自https://zenodo.org/records/7818827，这是基于咖啡发酵系统研究的6个原始数据集生成的模拟数据集。\n里面已经提供了双端fastq测序文件和组装好的contigs，我们直接下载下列链接即可：\n1 https://zenodo.org/api/records/7818827/files-archive 把其中的双端fastq测序文件放在reads文件夹下，解压一下后缀改为.fastq。 组装好的contigs放在contigs文件夹下，把6个样本名写入到samplelist。\n1 ls contigs|sed -E \u0026#39;s/contigs_(ERR[0-9]+)\\.fasta/\\1/\u0026#39; \u0026gt; samplelist 分箱Binning 假设我们已经完成了宏基因组数据预处理模块的内容，测序的reads已经质控并组装过了（也可以参考之前写的宏基因组分析流程）。我们从contigs开始进行binning分析：\n1 2 3 4 5 for i in `cat samplelist` do metawrap binning -o INITIAL_BINNING_${i} -t 2 -m 4 -a contigs/contigs_${i}.fasta \\ --metabat2 --maxbin2 --concoct reads/${i}*.fastq done Binning模块的具体参数： 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 $ metawrap binning -h 用法：metaWRAP binning [选项] -a assembly.fa -o output_dir readsA_1.fastq readsA_2.fastq ... [readsX_1.fastq readsX_2.fastq] 注意1：请确保提供所有单独的重复读段文件，而不是合并的文件。 注意2：您也可以使用正确的选项提供单端或交错的读段。 注意3：如果输出目录中已有来自之前运行的 .bam 比对文件，此模块将跳过重新比对读段的步骤。 选项： -a STR 宏基因组组装文件 -o STR 输出目录 -t INT 线程数（默认=1） -m INT\t可用内存大小（默认=4） -l INT\t进行分箱的最小contig长度（默认=1000bp）。注意：metaBAT 默认最小为1500bp --metabat2 使用 metaBAT2 对 contig 进行分箱 --metabat1\t使用原版 metaBAT 对 contig 进行分箱 --maxbin2\t使用 MaxBin2 对 contig 进行分箱 --concoct\t使用 CONCOCT 对 contig 进行分箱 --universal\t在 MaxBin2 中使用通用标记基因而不是细菌标记基因（提高古菌分箱效果） --run-checkm\t在分箱结果上立即运行 CheckM（需要 40GB+ 内存） --single-end\t非配对读段模式（提供 *.fastq 文件） --interleaved\t输入的读段文件包含交错的配对读段 输出文件： concoct_bins，maxbin2_bins，metabat2_bins：三个目录为三种bin的结果 work_files：三种bin分析所需要的文件，如不同格式的bin覆盖度或丰度信息。 运行情况（参考）： 单样本reads 一个文件（*.fastq）为600M，组装后的contig为100M 2核cpu，运行时间为1500s 平均内存占用1.1G，最大内存占用1.3G 结果 concoct_bins，maxbin2_bins，metabat2_bins分别有30，4，5个MAGs 提纯Bin_refinement 三种主流bin结果各有优缺点，我们需要对这些初步分箱结果进行进一步的提纯和优化。\n我们可以把所有样本的结果添加样本名前缀后，合并在同一文件夹中，使用metaWRAP的bin_refinement模块来提纯分箱结果：\n推荐(默认)使用完整度70，污染率10的阈值。要求越高，bin越少，请根据个人需要调整。这里的测序数据较小，仅使用50和10级别的阈值。\n1 2 metawrap bin_refinement -o REFINED_BINS -t 4 -c 50 -x 10 \\ -A INITIAL_BINNING/maxbin2_bins -B INITIAL_BINNING/metabat2_bins -C INITIAL_BINNING/concoct_bins Bin_refinement模块的具体参数： 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 $ metawrap bin_refinement -h 用法：metaWRAP bin_refinement [选项] -o output_dir -A bin_folderA [-B bin_folderB -C bin_folderC] 注意1：请提供至少两个独立的bin结果集合进行提纯。 注意2：输出目录必须为空，以确保结果不会被覆盖。 选项： -o STR 输出目录 -t INT 线程数（默认=1） -m INT 可用内存大小（默认=4） -c FLOAT 完整性阈值（默认=70.0） -x FLOAT 污染度阈值（默认=10.0） -A STR 第一个分箱结果集合目录 -B STR 第二个分箱结果集合目录 -C STR 第三个分箱结果集合目录（可选） --skip-refinement 不要使用binning_refiner来根据binner输出的组合来提出精炼的bins --skip-checkm 跳过CheckM步骤 --skip-consolidation 从所有bin细化迭代中选择每个bin的最佳版本 --keep-ambiguous 对于最终在多个bin中的配置，将它们保存在所有bin中(默认:仅将它们保存在最佳bin中) --remove-ambiguous\t对于最终在多个bin中的配置，将它们从所有bin中删除(默认:仅将它们保留在最佳bin中) --quick\t为checkm添加--reduced_tree选项，减少运行时间，特别是在内存不足的情况下 输出文件： concoct_bins，maxbin2_bins，metabat2_bins：三个目录为三种bin在Refine后保留的结果 concoct_bins.stats，maxbin2_bins.stats，metabat2_bins.stats：三个文件为三种bin在Refine后的统计信息 metawrap_50_10_bins：提纯后的bin文件目录，包括最终的提纯bin。 metawrap_50_10_bins.stats：提纯后的bin文件目录，包括最终的提纯bin。 work_files：提纯过程中产生的中间文件。 *.contigs：contigs figures：提纯过程中产生的图表。 运行情况（参考）： concoct_bins，maxbin2_bins，metabat2_bins输入分别有30，4，5个MAGs 4核cpu，运行时间为3926s 平均内存占用30GB，最大内存占用36GB .stat文件包含每个bin的统计：完整性、污染率、GC含量、物种、N50、大小和来源:\n1 2 bin\tcompleteness\tcontamination\tGC\tlineage\tN50\tsize\tbinner bin.1\t83.60\t1.340\t0.389\tLactobacillales\t4991\t1574040\tbinsB figures里展示了提纯效果： 重组装Reassemble_bins (可选) 重组装模块用于使用原始的宏基因组测序数据重新组装已经分箱的基因组草图。这个模块可以帮助提高基因组的连续性和完整性，进一步优化分箱结果。\nreassemble_bins基于原始reads对结果优化，只有结果更优的情况，才对结果进行更新。\n1 metawrap reassemble_bins -o BIN_REASSEMBLY -1 reads/ALL_READS_1.fastq -2 reads/ALL_READS_2.fastq -t 4 -m 800 -c 50 -x 10 -b REFINED_BINS/metaWRAP_bins Reassemble_bins模块的具体参数： 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 $ metawrap reassemble_bins -h 用法：metawrap reassemble_bins -o 输出目录 -b 分箱结果文件夹 -1 正向测序文件.fastq -2 反向测序文件.fastq 选项： -b STR：包含已分箱的基因组草图的文件夹路径。 -o STR：指定输出目录。 -1 STR：用于重新组装的正向测序文件。 -2 STR：用于重新组装的反向测序文件。 -t INT：线程数，默认为1。 -m INT：内存大小（GB），默认为40。 -c INT：期望的最小分箱完成度百分比，默认为70。 -x INT：期望的最大分箱污染度百分比，默认为10。 -l INT：包含在重新组装中的最小contig长度，默认为500。 --strict-cut-off：严格读取映射的最大允许SNP数，默认为2。 --permissive-cut-off：宽容读取映射的最大允许SNP数，默认为5。 --skip-checkm：跳过对分箱结果的CheckM评估。 --parallel：并行运行Spades重新组装，但每个分箱只使用一个线程。 输出文件： reassembled_bins：重新组装过的基因组草图文件夹，包含了进一步优化和改进后的基因组序列。 reassembled_bins.stats：重组装过程的总结文件，包含了每个基因组草图的改进信息和指标。 我没有跑这一步，用时一般比较久。\n定量Quant_bins 在完成分箱和提纯步骤后，我们需要对各个bin进行定量分析，评估每个bin在不同样本中的相对丰度。 合并一下所有的contigs文件为all_contigs.fasta：\n1 metawrap quant_bins -b REFINED_BINS/metawrap_50_10_bins -t 4 -o QUANT_BINS -a contigs/all_contigs.fasta reads/*_1.fastq reads/*_2.fastq Quant_bins模块的具体参数： 1 2 3 4 5 6 7 8 9 10 $ metawrap quant_bins -h 用法：metaWRAP quant_bins [选项] -b bins_folder -o output_dir -a assembly.fa readsA_1.fastq readsA_2.fastq ... [readsX_1.fastq readsX_2.fastq] 选项： -b STR 提纯后的bin目录 -o STR 输出目录 -t INT 线程数（默认=1） -a STR 宏基因组组装文件 输出文件： bin_abundance_table.tab：每个样本中每个bin的相对丰度表格。 assembly_index：salmon 给contigs建立的index。 alignment_files：salmon 对每个样本进行定量后生成的文件。 quant_files：salmon 提出的count文件。 genome_abundance_heatmap.png：每个样本中每个bin的丰度热图。 运行情况（参考）： 单样本reads 一个文件（*.fastq）为600M，组装后的contig为100M，合格MAG一个bin为1.6M 4核cpu，运行时间为302s 平均内存占用2.8G，最大内存占用3G 结果 concoct_bins，maxbin2_bins，metabat2_bins分别有30，4，5个MAGs 一个MAG绘制热图失败，理论上会有下列丰度热图： 这个模块通过将reads映射回bin，并计算每个bin在不同样本中的覆盖度，从而定量分析每个bin的相对丰度。这样可以帮助我们了解各个微生物群体在不同样本中的分布和丰度变化。\n气泡图Blobology Blobology模块用于生成气泡图，以便可视化contigs或bins的GC含量与丰度的关系。这种可视化方法可以帮助我们识别和分离不同来源的序列，检测可能的污染，并了解样本中的微生物群体组成。\n1 metawrap blobology --bins REFINED_BINS/metawrap_50_10_bins -t 4 -o BLOBOLOGY -a contigs/all_contigs.fasta reads/*_1.fastq reads/*_2.fastq Blobology模块的具体参数： 1 2 3 4 5 6 7 8 9 10 11 12 $ metawrap blobology -h 用法：metaWRAP blobology [选项] -a assembly.fasta -o output_dir readsA_1.fastq readsA_2.fastq [readsB_1.fastq readsB_2.fastq ...] 选项： -a STR 组装的fasta文件 -o STR 输出目录 -t INT 线程数 --subsample INT 对contig进行子采样分析的数量。子采样是随机的。（默认=所有） --bins STR 包含bin的文件夹。contig名称必须与组装文件匹配。（默认=None） 输出文件： blobplot.png：GC含量与丰度的气泡图。 all_contigs.binned.blobplot：图表中数据点的详细信息，包括每个contig的GC含量、丰度和bin分配。 NT数据库实在太大了，我没有跑这个，看一下理论输出：\n通过气泡图，我们可以直观地看到每个contig或bin的GC含量与其在样本中的丰度。不同来源的序列通常会显示出不同的GC含量和丰度模式，从而在图中形成不同的群体。这种可视化方法对于识别和去除样本中的污染序列以及了解样本的微生物群体结构非常有用。\n物种注释Classify_bins 物种注释模块用于对提纯后的基因组bin进行分类学注释。这个过程可以帮助我们确定每个bin所属的物种或更高的分类层次，从而更好地理解样本中的微生物群落组成。\n其实Bin提纯和重组装中，在checkM的stat文件中，就有物种的注释结果，但软件和数据库都不完善。基于NCBI_nt和NCBI_tax数据库，MetaWRAP使用 MEGABLAST和Taxator-tk 进行每条contig物种注释，再估计bin整体的物种。\n另外物种注释可以使用GTDB-Tk和GTDB数据库，因为它专门针对微生物基因组的分类进行了优化，但也可以选择使用其他分类数据库，如Kraken。\n1 metawrap classify_bins -b REFINED_BINS/metawrap_50_10_bins -o BIN_CLASSIFICATION -t 4 Classify_bins模块的具体参数： 1 2 3 4 5 6 7 8 9 $ metawrap classify_bins -h 用法：metaWRAP classify_bins [选项] -b bin_folder -o output_dir 选项： -b STR 提纯后的bin目录 -o STR 输出目录 -t INT 线程数（默认=1） 输出文件： bin_taxonomy.txt：每个bin的分类信息，包括门、纲、目、科、属、种等分类层次。 bin_quality.txt：每个bin的质量信息，包括完整性、污染度等（如果使用了--run_checkm选项）。 classification_plots：分类结果的可视化图表，展示各个bin在不同分类层次上的分布情况。 work_files：分类分析过程中产生的中间文件。 NT数据库实在太大了，我也没有跑这个，我一般选择用GTDB-tk做物种注释。\n基因注释Annotate_bins 基因注释模块用于对分箱结果中的基因组草图进行功能注释。这个模块通过多种数据库和工具，对基因组中的编码基因序列进行预测和注释，帮助我们理解微生物群体的功能特性。\nMetaWRAP基于PROKKA进行基因预测和注释，调用Barrnap 预测rRNA，Aragorn预测tRNA。\n1 metawrap annotate_bins -b REFINED_BINS/metawrap_50_10_bins -o FUNCT_ANNOT -t 4 Annotate_bins模块的具体参数： 1 2 3 4 5 6 7 8 9 $ metawrap annotate_bins -h 用法：metaWRAP annotate_bins [选项] -b bin_folder -o output_dir 选项： -b STR 包含分箱结果的文件夹 -o STR 输出目录 -t INT 线程数 输出文件： bin_funct_annotations/*.gff：每个bin的注释GFF文件 bin_translated_genes/*.faa：每个bin的翻译蛋白序列文件 bin_untranslated_genes/*.fna：每个bin的未翻译蛋白序列文件 prokka_out：Prokka预测结果原始文件 运行情况（参考）： 一个合格MAGbin，1.6M 4核cpu，运行时间为100s 平均内存占用0.15G，最大内存占用0.17G 基因注释的话我们还可以把MAGs的所有fasta序列合并起来，用prodigal统一预测基因并翻译为蛋白序列，然后用序列比对软件diamond比对各种功能数据库比如KEGG，Eggnog，CARD等进行注释整理，从而进行更深入的功能分析。\nReferences Uritskiy, G. V., DiRuggiero, J., \u0026amp; Taylor, J. (2018). MetaWRAP—a flexible pipeline for genome-resolved metagenomic data analysis. Microbiome, 6(1), 158. https://github.com/bxlab/metaWRAP https://github.com/bxlab/metaWRAP/blob/master/Usage_tutorial.md https://mp.weixin.qq.com/s/Ecn4DOrhfUhz1HynbgQtnw https://mp.weixin.qq.com/s/WrbKYybTCKab3AUcSzUWqg https://blog.csdn.net/woodcorpse/article/details/118124686 ","date":"2024-05-30T00:00:00Z","image":"/p/binning2/images/metawrap_hu_39ac4c2ac6beffda.png","permalink":"/p/binning2/","title":"宏基因组分箱（binning）｜2. MetaWRAP实战深入binning"},{"content":"Introduction 宏基因组学是直接从环境样本（如土壤、水、肠道内容物等）中回收遗传物质并进行研究的学科，无需对个体生物进行分离或培养。这一领域的研究为我们提供了对微生物群落多样性及其功能的深入理解。可以查看我之前写的宏基因组分析流程，当时想着在另一篇里介绍binning，结果拖了一年，哈哈😂，现在补上。\n宏基因组分箱（Metagenomics Binning）是一个将宏基因组测序获得的DNA序列分类为离散组或“bins”的过程，这些组基于序列间的相似性来定义。分箱的目的是将DNA序列分配给其来源的生物或分类群，从而更好地了解样本中存在的微生物群落的多样性和功能。\n分箱得到的较高质量bins也可以称为我们经常说的MAGs（Metagenome-Assembled Genomes，宏基因组组装基因组）或者draft genome，MAGs代表从宏基因组数据中组装并分箱出来的完整或几乎完整的基因组。因为许多微生物无法通过传统的培养方法进行研究，MAGs在环境微生物学研究中非常有用，可以做后续的很多深入分析比如BGCs，进化分析等。\n常用方法 宏基因组分箱有几种方法，包括：\n基于序列组成的分箱：这种方法基于不同基因组具有独特的序列组成模式（如GC含量或密码子使用偏好）的观察。通过分析宏基因组数据中的这些模式，可以将序列片段分配到单个基因组或基因组组。 基于覆盖度的分箱：这种方法利用测序读段的覆盖深度将它们分组。来自同一基因组的测序读段预期具有相似的覆盖度，这些信息可以用来识别代表单个基因组或基因组簇的读段组。 混合分箱：这种方法结合了基于序列组成和基于覆盖度的分箱，以提高分箱结果的准确性。通过使用多种信息源，混合分箱可以更好地区分序列组成模式相似的近缘基因组。 基于聚类的分箱：这种方法根据序列相似性将序列片段分为多个簇，然后根据其序列组成和覆盖度将每个簇分配到一个基因组或基因组簇。此方法对于具有高基因组多样性的宏基因组数据集特别有用。 基于监督机器学习的分箱：这种方法使用在注释参考基因组上训练的机器学习算法来将宏基因组数据分类到各个分箱。这种方法可以实现高准确性，但需要大量的注释基因组进行训练。 这些方法都有其优点和局限性，分箱方法的选择取决于宏基因组数据集的具体特征和所解决的研究问题。\n存在挑战 宏基因组分箱是一个复杂的过程，涉及许多步骤，由于过程中可能出现的多个问题，这一过程充满挑战。宏基因组分箱中常见的一些问题包括：\n高复杂性：宏基因组样本包含来自多个生物的DNA，这会导致数据的高复杂性。 片段化序列：宏基因组测序通常生成片段化的序列，这使得将读段分配到正确的分箱变得困难。 覆盖度不均：宏基因组样本中的一些生物可能比其他生物更丰富，导致不同基因组的覆盖度不均。 不完整或部分基因组：宏基因组测序可能无法捕获某个生物的完整基因组，这使得准确分箱该生物的序列变得困难。 水平基因转移：水平基因转移（HGT）可以使一个生物的遗传物质引入到另一个生物中，从而使宏基因组分箱变得复杂。 嵌合序列：由于测序错误或污染产生的嵌合序列，会使得准确分箱读段变得困难。 菌株变异：同一物种内的生物可以表现出显著的遗传变异，这使得区分宏基因组样本中不同的菌株变得困难。 常用软件 有许多计算工具可以执行宏基因组分箱。以下是一些最广泛使用的工具：\nMaxBin (Wu et al. 2015)： 一种流行的从头分箱算法，使用序列特征和标记基因的组合将重叠群聚类到基因组箱中。 MetaBAT2（Kang 等人，2019）： 另一种广泛使用的从头分箱算法，采用基于四核苷酸频率和覆盖信息的分层聚类方法。 CONCOCT（Alneberg et al. 2014）： 一种从头分箱工具，使用基于序列组成和覆盖信息的聚类算法将重叠群分组到基因组箱中。 MyCC (Lin and Liao 2016)： 一种基于参考的分箱工具，使用序列比对来识别属于同一基因组或分类组的重叠群。 GroopM (Imelfort et al. 2014)： 一种混合分箱工具，结合了基于参考和从头方法来实现高分箱精度。 MetaWRAP (Uritskiy et al. 2018)： 一个全面的宏基因组分析流程，包括用于质量控制、组装、分箱和注释的各种模块。 Anvi’o (Eren et al. 2015)： 一个用于可视化和分析宏基因组数据的平台，包括分箱、注释和比较基因组学的功能。 SemiBin (Pan et al. 2022)： 一种利用深度学习进行宏基因组分箱的命令行工具，可处理短读和长读。 Sczyrba等人在2017年进行了一项基准测试研究，对多种宏基因组分箱工具的性能进行了评估。他们发现，Metabat2在准确性和计算效率方面均优于以前的MetaBAT和其他替代方案。所有这些评估都是基于默认参数进行的（Sczyrba et al. 2017）。\nMetaWRAP是一个非常全面详细的流程，包含了binning上下游的各种分析，还整合了三种软件的binning结果，对于刚开始学习binning的核心步骤可能不是很合适。 所以我想先从MetaBAT讲起，通过MetaBAT2实战来了解分箱流程。\n参考教程：\nNikolaos Pechlivanis, Fotis E. Psomopoulos, Binning of metagenomic sequencing data (Galaxy Training Materials). https://training.galaxyproject.org/training-material/topics/microbiome/tutorials/metagenomics-binning/tutorial.html Online; accessed Wed May 29 2024\nMetabat实战 以下描述来自MetaBat在Bioinformatics发表的论文：\nGrouping large fragments assembled from shotgun metagenomic sequences to deconvolute complex microbial communities, or metagenome binning, enables the study of individual organisms and their interactions. Here we developed automated metagenome binning software, called MetaBAT, which integrates empirical probabilistic distances of genome abundance and tetranucleotide frequency. On synthetic datasets MetaBAT on average achieves 98percent precision and 90% recall at the strain level with 281 near complete unique genomes. Applying MetaBAT to a human gut microbiome data set we recovered 176 genome bins with 92% precision and 80% recall. Further analyses suggest MetaBAT is able to recover genome fragments missed in reference genomes up to 19%, while 53 genome bins are novel. In summary, we believe MetaBAT is a powerful tool to facilitate comprehensive understanding of complex microbial communities. — Kang et al, 2019\n软件，数据准备 使用conda安装Metabat2非常简单：\n1 conda install -c bioconda metabat2 另外我们安装一下后续会用到的dRep和CheckM\n1 conda install drep checkm-genome -y CheckM需要下载对应数据库：https://data.ace.uq.edu.au/public/CheckM_databases并配置环境变量：\ncheckm data setRoot \u0026lt;checkm_data_dir\u0026gt;\n本文使用的示例数据来自https://zenodo.org/records/7818827，这是基于咖啡发酵系统研究的6个原始数据集生成的模拟数据集。\n里面已经提供了双端fastq测序文件和组装好的contigs，我们直接下载下列链接即可：\n1 https://zenodo.org/api/records/7818827/files-archive Binning Metabat2 需要以组装的contigs（fasta格式）和覆盖信息（bam格式）的形式输入宏基因组测序数据。具体而言，Metabat2 需要两个输入文件：\nfasta文件：包含组装的contigs，可以使用MEGAHIT、SPAdes或IDBA-UD等组装工具从原始宏基因组测序读段生成。\nbam文件：包含每个contig的读段覆盖信息，可以使用Bowtie2或BWA等比对软件从相同的测序读段生成。\n此外，Metabat2 还需要一个配置文件，用于指定分箱过程的各种参数和选项，如最小contig长度、要生成的最大簇数以及最大预期污染水平。\n具体流程：\n组装contigs：\n使用MEGAHIT、SPAdes或IDBA-UD等工具组装测序读段，生成contigs.fasta文件。 1 megahit -1 reads_1.fq -2 reads_2.fq -o output_dir 生成覆盖信息：\n使用Bowtie2或BWA将读段比对到组装的contigs上，并生成bam文件。 1 2 3 4 5 bowtie2-build contigs.fasta contigs bowtie2 -x contigs -1 reads_1.fq -2 reads_2.fq -S alignment.sam samtools view -bS alignment.sam \u0026gt; alignment.bam samtools sort alignment.bam -o sorted_alignment.bam samtools index sorted_alignment.bam 生成覆盖深度文件：\n使用MetaBAT提供的工具计算每个contig的覆盖深度。 1 jgi_summarize_bam_contig_depths --outputDepth depth.txt sorted_alignment.bam 运行Metabat2：\n使用Metabat2进行分箱。 1 metabat2 -i contigs.fasta -a depth.txt -o bins_dir/bin 配置文件：\nMetabat2 可以使用默认参数进行运行，但用户也可以通过配置文件指定参数，如最小contig长度、最大簇数和最大预期污染水平。配置文件的内容示例如下： 1 2 3 minContig 1500 maxClusters 200 maxExpectedContamination 10 分别对上述6个样本跑这个流程，MetaBAT 2生成的输出文件包括（以下某些文件是可选的，只有在用户需要时才会生成）：\n最终的基因组分箱（FASTA格式）（.fa文件）：包含分箱结果的基因组序列。 总结文件（.txt文件）：包含每个基因组分箱的信息，包括其长度、完整性、污染度和分类信息。 映射结果文件（.bam文件）：显示每个contig如何被分配到基因组分箱。 基因组分箱丰度估算文件（.txt文件）：包含每个基因组分箱的丰度估算信息。 基因组分箱覆盖率文件（.txt文件）：包含每个基因组分箱的覆盖率信息。 基因组分箱的核苷酸组成文件（.txt文件）：包含每个基因组分箱的核苷酸组成信息。 预测的基因序列文件（.faa文件）：包含每个基因组分箱的预测基因序列。 输出文件示例：\n基因组分箱文件（.fa）：\n包含分箱后的基因组序列，每个文件代表一个基因组bin。 1 2 3 4 \u0026gt;bin1_contig1 ATGCGT... \u0026gt;bin1_contig2 ATGCGT... 总结文件（.txt）：\n包含每个基因组分箱的详细信息，如长度、完整性、污染度等。 1 2 3 Bin ID Length Completeness Contamination Taxonomy bin1 3.2 Mb 95% 2% Bacteria bin2 4.1 Mb 90% 5% Archaea 映射结果文件（.bam）：\n包含contigs如何被分配到基因组分箱的映射信息。 丰度估算文件（.txt）：\n包含每个基因组分箱在样本中的丰度估算。 1 2 3 Bin ID Abundance bin1 0.25 bin2 0.30 覆盖率文件（.txt）：\n包含每个基因组分箱的覆盖率信息。 1 2 3 Bin ID Coverage bin1 30x bin2 25x 核苷酸组成文件（.txt）：\n包含每个基因组分箱的核苷酸组成信息。 1 2 3 Bin ID GC Content bin1 45% bin2 50% 预测基因序列文件（.faa）：\n包含每个基因组分箱的预测蛋白质序列。 1 2 3 4 \u0026gt;bin1_gene1 MKTIIALSYIFCLVFA \u0026gt;bin1_gene2 MKSVIIFLCLCVFA 这些输出文件可以进一步分析并用于下游应用，例如功能注释、比较基因组学和系统发育分析。\nbinning整体流程还是比较慢的，我们也可以下载已经跑好的结果（下面链接）看看去做后续分析：\n1 https://zenodo.org/api/records/7845138/files-archive 里面包含了6个样本单样本binning的结果，每个样本各3～8个bins。\nChecking quality 在宏基因组分箱完成后，评估其质量非常重要。CheckM (Parks et al. 2015) 是一个常用的评估分箱质量的工具。CheckM 使用一组在几乎所有细菌和古菌基因组中存在的通用单拷贝标记基因来评估基因组分箱的完整性和污染度。\nCheckM 的关键功能 基因组完整性估计： CheckM 使用一组通用单拷贝标记基因来估计基因组分箱的完整性。完整性得分表示这些标记基因中有多少比例存在于分箱中，从而提供了回收基因组的程度估计。 基因组污染度估计： CheckM 也使用同一组标记基因来估计基因组分箱的污染度。污染度得分表示在多个分箱中发现的标记基因的比例，这表明该基因组分箱可能包含来自多个生物的DNA。 潜在错误组装的识别： CheckM 可以根据标记基因在基因组中的分布识别潜在的错误组装。 结果可视化： CheckM 能生成各种图表和表格来可视化基因组分箱的完整性、污染度和其他质量指标，使得结果更易于解释。 分类学分类： CheckM 也可以基于特定标记基因的存在对基因组分箱进行分类，提供从域到种的不同分类水平的信息。 使用 CheckM 进行评估 以下是使用 CheckM 的一个示例工作流程，主要使用 lineage_wf 工作流程来评估基因组分箱的完整性和污染度，并进行分类学分类：\n准备输入数据： 将你的分箱结果（通常是FASTA文件格式）准备好。\n1 2 mkdir bins mv bin*.fa bins/ 运行 CheckM lineage_wf： 使用 lineage_wf 工作流程来评估基因组分箱。\n1 checkm lineage_wf -x fa bins/ checkm_output/ -t 4 参数解释：\n-x fa 指定文件扩展名为 .fa。 bins/ 是输入分箱文件的目录。 checkm_output/ 是输出结果的目录。 -t 4 指定使用 4 个线程。 Lineage_wf(更准确)，taxonomy_wf(更快)。\n查看结果： 运行完成后，结果会保存在 checkm_output 目录中。你可以查看主要的结果文件 bins_stats 以获得每个分箱的完整性和污染度等信息。\n“CheckM lineage_wf”的输出包括多个文件和表格，提供了有关基因组分箱的分类和质量评估的信息。以下是一些关键的输出内容：\n输出报告（CheckM Lineage Workflow Output Report）： 该报告提供了 CheckM 进行的质量评估的总结。包括分析的基因组数量、它们的完整性、污染度及其他质量指标。 特定谱系的质量评估（Lineage-specific Quality Assessment）： CheckM 为每个分析的基因组生成特定谱系的质量评估文件。这些文件包含基于分类谱系的基因组完整性和污染度的详细信息。 标记集分析（Marker Set Analysis）： CheckM 使用一组标记基因来估计基因组的完整性和污染度。工具生成标记特定分析文件，提供分析基因组中每个标记基因的存在、缺失和拷贝数的详细信息。 可视化（Visualizations）： CheckM 生成各种可视化图表，以帮助解释结果。这些图包括谱系特定的完整性和污染度图、散点图及其他数据的可视化表示。 表格和数据文件（Tables and Data Files）： CheckM 生成包含分析基因组详细信息的表格数据文件，包括它们的名称、分类分配、完整性评分、污染度评分和其他相关指标。这些文件对于进一步的下游分析或数据处理非常有用。 示例输出文件和解释 输出报告文件： checkm_output/storage/bin_stats_ext.tsv：包含每个分箱的详细统计信息，如完整性、污染度、标记基因数目等，自行整理为表格： 1 2 3 Bin Id Completeness Contamination Strain heterogeneity bin1 98.5 1.2 0.0 bin2 85.4 4.7 0.5 谱系特定质量评估文件： checkm_output/lineage.ms：包含每个基因组分箱的谱系特定质量评估信息，自行整理为表格： 1 2 bin1 Bacteria;Proteobacteria;Gammaproteobacteria 98.5 1.2 bin2 Bacteria;Firmicutes;Bacilli 85.4 4.7 标记基因分析文件： checkm_output/marker_gene_stats.tsv：提供分析基因组中每个标记基因的存在、缺失和拷贝数的详细信息，自行整理为表格： 1 2 3 4 5 Bin Id Marker gene Presence Copy number bin1 rplA Present 1 bin1 rplB Present 1 bin2 rplA Present 2 bin2 rplB Absent 0 可视化文件： checkm_output/plots/ 目录包含各种图表，如完整性和污染度的散点图、谱系特定的完整性和污染度图等。 De-replication 去冗余（De-replication）是识别基因组列表中“相同”基因组集合的过程，并从每个冗余集合中去除除“最佳”基因组之外的所有其他基因组。基因组需要多相似才被认为是“相同的”、如何确定哪个基因组是“最佳的”以及其他重要决策将在重要概念中讨论。\n去冗余的一个常见用途是针对个别宏基因组数据的组装。如果宏基因组样本是按系列收集的，一种常见的组装短读段的方法是“共组装”。即将所有样本的读段结合在一起进行组装。然而，这样做的问题是，相似菌株的组装会严重导致组装的片段化，妨碍获得一个好的基因组分箱。\n一种替代方案是分别组装每个样本，然后对每个组装结果中的分箱进行去冗余，以生成最终的基因组集合。\nMetaBAT 2 并不会明确地执行去冗余过程，即在给定的数据集中识别相同或高度相似的基因组组。相反，MetaBAT 2 主要通过利用读段覆盖率、样本间的差异覆盖率和序列组成等特征来提高分箱的准确性。它的目标是区分宏基因组数据集中不同的基因组，并将contigs分配到适当的分箱中。\ndRep 是一个专门设计用于宏基因组数据集中基因组去冗余的软件工具。其目标是保留一个代表性基因组集，以改善后续的分析，如分类学分析和功能注释。\ndRep 的典型工作流程 基因组质量评估： dRep 会运行checkM评估每个簇内基因组的质量，考虑因素包括完整性、污染度和菌株异质性。 基因组比较： dRep 使用成对基因组比较方法来评估给定宏基因组数据集中基因组之间的相似性。 聚类： 根据基因组相似性，dRep 执行聚类，将相似基因组分组为“基因组簇”。每个簇代表一组密切相关的基因组。 基因组选择： 在每个基因组簇内，dRep 根据用户定义的标准选择一个代表性基因组。这个代表性基因组被视为簇的“去冗余”版本。 去冗余输出： dRep 的输出包括去冗余基因组的信息，包括它们的身份、完整性和污染度。用户可以选择一个基因组相似性阈值来控制去冗余的水平。 dRep 的使用示例 准备输入文件：\n将所有要去冗余的基因组文件放在一个目录中。 1 2 mkdir genomes mv genome1.fasta genome2.fasta ... genomes/ 运行dRep：\n使用 dRep 对基因组进行去冗余。以下命令会在指定的输出目录中执行去冗余分析。 相似性阈值：可以通过 --S_algorithm 和 --S_ani 参数设置用于基因组聚类的相似性计算方法和阈值。 质量标准：可以通过 --completeness、--contamination 等参数设置选择代表性基因组的质量标准。 1 dRep dereplicate output_directory -g genomes/*.fasta 如果你已经自己运行了checkM，可以直接使用 checkM 的输出文件指定给 --genomeInfo（毕竟checkM也要很久）。 自己整理bin_info.csv文件，3列，分别为genome name，completeness，contamination。 1 dRep dereplicate output_directory -g genomes/*.fasta --genomeInfo checkm_output/storage/bin_info.csv 如果你自行筛选了bins，也就是说你认为输入的都是合格bins，可以用--ignoreGenomeQuality 忽略质量评估。 1 dRep dereplicate output_directory -g genomes/*.fasta --ignoreGenomeQuality 输出解释：\n输出目录中将包含多个文件和子目录，其中包括： dereplicated_genomes：去冗余后的基因组文件。 cluster_reports：包含每个基因组簇的信息。 quality_reports：评估基因组质量的报告。 至此，我们就完成了使用Metabat2进行基因组分箱，使用checkM评估bins以及使用dRep进行bins去冗余得到最终的合格bins，这些是宏基因组binning分析的核心步骤。\n后续可以对得到的MAGs进行物种注释（比如用GTDB-tk），功能注释（比如antismash分析BGCs），以及很多基因组级别的深入分析。\nReferences Alneberg, J., B. S. Bjarnason, I. de Bruijn, M. Schirmer, J. Quick et al., 2014 Binning metagenomic contigs by coverage and composition. Nature Methods 11: 1144–1146. https://doi.org/10.1038/nmeth.3103 Imelfort, M., D. Parks, B. J. Woodcroft, P. Dennis, P. Hugenholtz et al., 2014 GroopM: an automated tool for the recovery of population genomes from related metagenomes. PeerJ 2: e603. https://doi.org/10.7717/peerj.603 Eren, A. M., Özcan C. Esen, C. Quince, J. H. Vineis, H. G. Morrison et al., 2015 Anvi’o: an advanced analysis and visualization platform for ‘omics data. PeerJ 3: e1319. https://doi.org/10.7717/peerj.1319 Parks, D. H., M. Imelfort, C. T. Skennerton, P. Hugenholtz, and G. W. Tyson, 2015 CheckM: assessing the quality of microbial genomes recovered from isolates, single cells, and metagenomes. Genome Research 25: 1043–1055. https://doi.org/10.1101/gr.186072.114 Wu, Y.-W., B. A. Simmons, and S. W. Singer, 2015 MaxBin 2.0: an automated binning algorithm to recover genomes from multiple metagenomic datasets. Bioinformatics 32: 605–607. https://doi.org/10.1093/bioinformatics/btv638 Lin, H.-H., and Y.-C. Liao, 2016 Accurate binning of metagenomic contigs via automated clustering sequences using information of genomic signatures and marker genes. Scientific Reports 6: https://doi.org/10.1038/srep24175 Sczyrba, A., P. Hofmann, P. Belmann, D. Koslicki, S. Janssen et al., 2017 Critical Assessment of Metagenome Interpretation—a benchmark of metagenomics software. Nature Methods 14: 1063–1071. https://doi.org/10.1038/nmeth.4458 Uritskiy, G. V., J. DiRuggiero, and J. Taylor, 2018 MetaWRAP—a flexible pipeline for genome-resolved metagenomic data analysis. Microbiome 6: https://doi.org/10.1186/s40168-018-0541-1 Kang, D. D., F. Li, E. Kirton, A. Thomas, R. Egan et al., 2019 Metabat2: an adaptive binning algorithm for robust and efficient genome reconstruction from metagenome assemblies. PeerJ 7: e7359. https://doi.org/10.7717/peerj.7359 Evans, J. T., and V. J. Denef, 2020 To Dereplicate or Not To Dereplicate? mSphere 5: e00971–19. Publisher: American Society for Microbiology. https://doi.org/10.1128/mSphere.00971-19 Pan, S., C. Zhu, X.-M. Zhao, and L. P. Coelho, 2022 A deep siamese neural network improves metagenome-assembled genomes in microbiome datasets across different environments. Nature Communications 13: https://doi.org/10.1038/s41467-022-29843-y ","date":"2024-05-29T00:00:00Z","image":"/p/binning/images/binning_hu_6b66f1f898ee76b9.png","permalink":"/p/binning/","title":"宏基因组分箱（binning）｜1.Metabat实战了解binning"},{"content":"Logs 增加使用bwa-mem2去宿主，可以去得更干净。适于宿主序列很高，害怕假阳性结果的情况。（2024.07.15） 更新全文细节（2024.05.29） 增加Mmseqs2用于去冗余，基因聚类的速度非常快，且随序列量线性增长（2024.03.12） 增加R包pctax内的一些帮助上游分析的小脚本（2024.03.03） 注意：\n篇幅有限，本文一般不介绍具体的软件安装配置，数据库下载等，也不提供示例数据，主要帮助快速了解整个宏基因组的上游分析流程。所以软件安装请参考软件自身介绍，运行时遇到具问题也最好先Google或者去github issue里面问问。\n宏基因组分析技术还是在不停的更新迭代，很多更新更好用的软件在不断推出，所以我在这也会持续更新（如果我还一直做这个方向的话）。这里介绍的也只是比较基本的分析流程，但是掌握了之后，自己进一步去做个性化分析也会顺手很多。\n完成上游分析后我们可以得到各种物种或者功能的profile，后续一般用python，R进行数据分析和可视化，可参考我的其他博文。\n绝大多数这里介绍的软件都是仅支持linux平台的，我们做测序文件上游分析也肯定是在服务器上做，个人PC一般很难满足需求，所以在做这些分析前必须先学习linux基础知识如文件系统，shell脚本编写，软件安装等。安装软件建议使用conda或mamba（新建环境和管理），有很多参考方法。\n我使用的集群是slurm作业管理系统，下面的示例脚本也是适用与slurm的，尽量先学习一下slurm的使用再尝试提交作业。如果不用slurm的话可以只参考#############中间的软件部分。\nIntroduction 宏基因组（Metagenome）是指对一个生态系统中的所有微生物进行DNA分析的过程，可以帮助研究人员了解微生物的多样性、功能和互作关系。\n宏基因组的应用非常广泛，包括：\n生物多样性研究：通过对宏基因组进行分析，可以了解不同生态系统中微生物的多样性和分布情况。 生态学研究：宏基因组可以帮助研究人员了解微生物在生态系统中的功能、互作关系和生态位等。 生物技术：宏基因组可以用于筛选具有特定功能的微生物，例如，寻找能够降解有害物质的微生物。 宏基因组的分析一般包括以下步骤：\nDNA提取与建库。 高通量测序：使用高通量测序技术对扩增后的DNA进行测序，得到原始序列数据。 数据清洗和组装：对原始数据进行质量控制、去除低质量序列和冗余序列，将序列拼接成较长的连续序列（contigs）。 基因注释：将contigs中的基因进行注释，得到基因功能信息。 数据分析：了解微生物多样性、群落结构、功能特征等信息（更多是指获取了物种丰度表或功能丰度表之后的进一步分析）。 MAGs binning， 进化动态等进一步分析 下图是我常用的一套上游基本流程，当然在面对不同项目时应该有不同的侧重点和适用的分析方法，可以在此基础上添加或修改。\n最早的时候，这方面的分析我都是参考刘永鑫老师的EasyMetagenome，现在这套流程也发文章了 (1)，值得参考，对上手16S测序数据或宏基因组数据都很有帮助。\n最近（2024.3.3）我整理了一下流程放在我的R包pctax里了，方便整个宏基因组的上下游流程结合：\n1 2 3 install.packages(\u0026#34;pctax\u0026#34;) #使用micro_sbatch可以快速获得每一步的slurm脚本： pctax::micro_sbatch(work_dir = \u0026#34;~/work/\u0026#34;,step = \u0026#34;fastp\u0026#34;) preprocess 一般把所有样本的测序双端文件放在一个data文件夹下，然后把所有样本名写入到一个samplelist文件中，方便后续各种软件的批量操作。\n质控：fastp 测序文件质控是指在下游分析前对测序数据进行质量控制和清理，以确保数据的准确性和可靠性。\nfastp是一个非常快速、多功能的测序数据质控工具，支持自动化的质控处理，包括去除低质量序列、剪切接头序列和生成质控报告。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 #!/bin/bash #SBATCH --job-name=fastp #SBATCH --output=/share/home/jianglab/pengchen/work/asthma/log/%x_%A_%a.out #SBATCH --error=/share/home/jianglab/pengchen/work/asthma/log/%x_%A_%a.err #SBATCH --array=1 #SBATCH --partition=cpu #SBATCH --cpus-per-task=8 #SBATCH --mem-per-cpu=2G samplelist=/share/home/jianglab/pengchen/work/asthma/samplelist echo start: `date +\u0026#34;%Y-%m-%d %T\u0026#34;` start=`date +%s` #################### echo \u0026#34;SLURM_ARRAY_TASK_ID: \u0026#34; $SLURM_ARRAY_TASK_ID START=$SLURM_ARRAY_TASK_ID NUMLINES=40 #how many sample in one array STOP=$((SLURM_ARRAY_TASK_ID*NUMLINES)) START=\u0026#34;$(($STOP - $(($NUMLINES - 1))))\u0026#34; echo \u0026#34;START=$START\u0026#34; echo \u0026#34;STOP=$STOP\u0026#34; #################### for (( N = $START; N \u0026lt;= $STOP; N++ )) do sample=$(head -n \u0026#34;$N\u0026#34; $samplelist | tail -n 1) echo $sample mkdir -p data/fastp ~/miniconda3/envs/waste/bin/fastp -w 8 -i data/rawdata/${sample}_f1.fastq.gz -o data/fastp/${sample}_1.fq.gz \\ -I data/rawdata/${sample}_r2.fastq.gz -O data/fastp/${sample}_2.fq.gz -j data/fastp/${i}.json done ############## echo end: `date +\u0026#34;%Y-%m-%d %T\u0026#34;` end=`date +%s` echo TIME:`expr $end - $start`s fastp的json文件中统计了测序数据的基本指标，我们可以将其整理为表格： 把所有的.json文件移到一个文件夹里report/下，使用我写的R包pctax读取json文件并整理成表格：\n1 pctax::pre_fastp(\u0026#34;report/\u0026#34;) 另外，FastQC，Cutadapt，Trimmomatic等也是常用的测序质控工具。\n去宿主 去宿主的过程其实就是将序列比对到宿主基因组上，然后没有比对到的序列整合成新文件就是去宿主后的了。\nbowtie2 宿主基因组需要自己先下载好并用 bowtie2-build 建立索引，以人类为例：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 #!/bin/bash #SBATCH --job-name=rm_human #SBATCH --output=/share/home/jianglab/pengchen/work/asthma/log/%x_%A_%a.out #SBATCH --error=/share/home/jianglab/pengchen/work/asthma/log/%x_%A_%a.err #SBATCH --array=1 #SBATCH --partition=cpu #SBATCH --cpus-per-task=8 #SBATCH --mem-per-cpu=2G samplelist=/share/home/jianglab/pengchen/work/asthma/samplelist echo start: `date +\u0026#34;%Y-%m-%d %T\u0026#34;` start=`date +%s` #################### echo \u0026#34;SLURM_ARRAY_TASK_ID: \u0026#34; $SLURM_ARRAY_TASK_ID START=$SLURM_ARRAY_TASK_ID NUMLINES=40 #how many sample in one array STOP=$((SLURM_ARRAY_TASK_ID*NUMLINES)) START=\u0026#34;$(($STOP - $(($NUMLINES - 1))))\u0026#34; echo \u0026#34;START=$START\u0026#34; echo \u0026#34;STOP=$STOP\u0026#34; #################### for (( N = $START; N \u0026lt;= $STOP; N++ )) do sample=$(head -n \u0026#34;$N\u0026#34; $samplelist | tail -n 1) echo $sample mkdir -p data/rm_human ~/miniconda3/envs/waste/bin/bowtie2 -p 8 -x ~/db/humangenome/hg38 -1 data/fastp/${sample}_1.fq.gz \\ -2 data/fastp/${sample}_2.fq.gz -S data/rm_human/${sample}.sam \\ --un-conc data/rm_human/${sample}.fq --very-sensitive rm data/rm_human/${sample}.sam done ############## echo end: `date +\u0026#34;%Y-%m-%d %T\u0026#34;` end=`date +%s` echo TIME:`expr $end - $start`s 据说bowtie2的敏感性比较低，所以我们这里已经打开了--very-sensitive模式。 敏感度不足会导致有些可能是人类序列但不会比对到genome上而导致结果还有人类序列（https://mp.weixin.qq.com/s/Qxj0PvVn49ynrD5jVxucTw），可以用使用bwa-mem，或者在后续kraken中使用带有人类genome的数据库进一步去除宿主。\nbwa-mem2 bwa-mem2的敏感度较高（https://hc1023.github.io/2020/11/03/extract-paired-mapping-reads-and-flagstat/）。\n我拿了一个样本试了下，原始reads有10,260,663条，bowtie2过滤有9,441,462条，bwa-mem过滤掉只有6,520,171条，bwa-mem是宁可错杀1000，不放过一个。\n宿主基因组需要自己先下载好并用 bwa-mem2 index 建立索引，以人类为例：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 #!/bin/bash #SBATCH --job-name=rm_human #SBATCH --output=/share/home/jianglab/pengchen/work/asthma/log/%x_%A_%a.out #SBATCH --error=/share/home/jianglab/pengchen/work/asthma/log/%x_%A_%a.err #SBATCH --array=1 #SBATCH --partition=cpu #SBATCH --cpus-per-task=8 #SBATCH --mem-per-cpu=2G # bwa-mem2 index ~/db/humangenome/hg38.fa #70G内存，1300s samplelist=/share/home/jianglab/pengchen/work/asthma/samplelist echo start: `date +\u0026#34;%Y-%m-%d %T\u0026#34;` start=`date +%s` #################### echo \u0026#34;SLURM_ARRAY_TASK_ID: \u0026#34; $SLURM_ARRAY_TASK_ID START=$SLURM_ARRAY_TASK_ID NUMLINES=40 #how many sample in one array STOP=$((SLURM_ARRAY_TASK_ID*NUMLINES)) START=\u0026#34;$(($STOP - $(($NUMLINES - 1))))\u0026#34; echo \u0026#34;START=$START\u0026#34; echo \u0026#34;STOP=$STOP\u0026#34; #################### for (( N = $START; N \u0026lt;= $STOP; N++ )) do sample=$(head -n \u0026#34;$N\u0026#34; $samplelist | tail -n 1) echo $sample mkdir -p data/rm_human bwa-mem2 mem -t 8 ~/db/humangenome/hg38.fa data/fastp/${sample}_1.fq.gz \\ data/fastp/${sample}_2.fq.gz \u0026gt; data/rm_human/${sample}_aligned_reads.sam # 20G内存，8核，419s ~/miniconda3/envs/waste/bin/samtools view -Sb data/rm_human/${sample}_aligned_reads.sam \u0026gt; data/rm_human/${sample}_reads.bam ~/miniconda3/envs/waste/bin/samtools sort data/rm_human/${sample}_reads.bam data/rm_human/${sample}_sorted_reads ~/miniconda3/envs/waste/bin/samtools view -b -f 4 data/rm_human/${sample}_sorted_reads.bam \u0026gt; data/rm_human/${sample}_non_host_reads.bam ~/miniconda3/envs/waste/bin/bedtools bamtofastq -i data/rm_human/${sample}_non_host_reads.bam -fq data/rm_human/${sample}.1.fq -fq2 data/rm_human/${sample}.2.fq rm data/rm_human/${sample}_aligned_reads.sam rm data/rm_human/${sample}_reads.bam rm data/rm_human/${sample}_sorted_reads.bam rm data/rm_human/${sample}_non_host_reads.bam done ############## echo end: `date +\u0026#34;%Y-%m-%d %T\u0026#34;` end=`date +%s` echo TIME:`expr $end - $start`s fastq信息统计 可以用一些小工具如FastqCount，seqkit等来统计reads数，碱基数，GC，Q20，Q30等指标：\n1 2 3 4 ~/biosoft/FastqCount-master/FastqCount_v0.5 xx.fastq.gz Total Reads Total Bases N Bases Q20 Q30 GC 11568822 (11.57 M) 1702829127 (1.70 G) 0.00% 98.00% 94.00% 54.00% 还可以把cleandata再跑一下fastp😂，但是只看处理前的统计指标。因为fastp确实非常快，纯粹用来统计也行。\nreads-based reads-based宏基因组分析是指直接利用测序读长（reads）进行宏基因组数据分析的方法，而不是先进行基因组组装。该方法通过对短读长进行比对和注释，从中提取功能信息和物种组成，常用于快速评估环境样本中的微生物群落结构和功能潜力。\n优点： 快速：无需组装，处理速度较快。 全面：能够检测到低丰度的微生物和功能基因，适合大规模样本分析。 局限性： 片段化：由于不进行组装，分析基于短读长，可能会错过长距离的基因联系和结构信息。 依赖数据库：分析结果依赖于参考数据库的全面性和准确性。 物种注释：kraken2 Kraken2是一个用于对高通量测序数据进行分类和标识物种的软件。它使用参考数据库中的基因组序列来进行分类，并使用k-mer方法来实现快速和准确的分类。\n使用Kraken2进行基本分类的简单步骤：\n准备参考数据库：Kraken2需要一个参考数据库，以便对测序数据进行分类。可以直接下载官方构建的标准库，也可以从NCBI、Ensembl或其他数据库下载相应的基因组序列，并使用Kraken2内置的工具来构建数据库。 kraken2-build --standard --threads 24 --db ./\n--standard标准模式下只下载5种数据库：古菌archaea、细菌bacteria、人类human、载体UniVec_Core、病毒viral。\n安装Kraken2：可以从Kraken2官方网站下载并安装Kraken2软件。\n运行Kraken2：使用Kraken2对测序数据进行分类需要使用以下命令：\nkraken2 --db \u0026lt;path_to_database\u0026gt; \u0026lt;input_file\u0026gt; --output \u0026lt;output_file\u0026gt;\n这里，\u0026lt;path_to_database\u0026gt;是参考数据库的路径，\u0026lt;input_file\u0026gt;是需要进行分类的输入文件，\u0026lt;output_file\u0026gt;是输出文件的名称。Kraken2将输出一个分类报告文件和一个序列文件。\n需要注意的是kraken运行至少要提供数据库大小的内存大小（运行内存），因为它会把整个数据库载入内存后进行序列的注释，所以如果发现无法载入数据库的报错，可以尝试调大内存资源。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 #!/bin/bash #SBATCH --job-name=kraken2 #SBATCH --output=/share/home/jianglab/pengchen/work/asthma/log/%x_%A_%a.out #SBATCH --error=/share/home/jianglab/pengchen/work/asthma/log/%x_%A_%a.err #SBATCH --partition=cpu #SBATCH --cpus-per-task=8 #SBATCH --mem-per-cpu=40G samplelist=/share/home/jianglab/pengchen/work/asthma/samplelist echo start: `date +\u0026#34;%Y-%m-%d %T\u0026#34;` start=`date +%s` #################### echo \u0026#34;SLURM_ARRAY_TASK_ID: \u0026#34; $SLURM_ARRAY_TASK_ID START=$SLURM_ARRAY_TASK_ID NUMLINES=40 #how many sample in one array STOP=$((SLURM_ARRAY_TASK_ID*NUMLINES)) START=\u0026#34;$(($STOP - $(($NUMLINES - 1))))\u0026#34; #################### for (( N = $START; N \u0026lt;= $STOP; N++ )) do sample=$(head -n \u0026#34;$N\u0026#34; $samplelist | tail -n 1) echo $sample mkdir -p result/kraken2 ~/miniconda3/envs/waste/bin/kraken2 --threads 8 \\ --db ~/db/kraken2/stand_krakenDB \\ --confidence 0.05 \\ --output result/kraken2/${sample}.output \\ --report result/kraken2/${sample}.kreport \\ --paired \\ data/rm_human/${sample}.1.fq \\ data/rm_human/${sample}.2.fq done ############## echo end: `date +\u0026#34;%Y-%m-%d %T\u0026#34;` end=`date +%s` echo TIME:`expr $end - $start`s 另外，kraken数据库是可以自己构建的，所以适用于各种项目的物种注释，我做的比较多的是环境样本的宏基因组，就可能需要更全面的物种数据库（甚至除了各种微生物，还要动植物数据等），我们实验室的WX师姐收集构建了一个超大的物种库。\nkraken软件运行时载入数据库是一个十分耗时的步骤，而每条序列的鉴定时间差不多，所以我们可以将很多样本的fastq文件合并成一个大文件后输入kraken注释，之后再按照序列的数量拆分结果文件，这样多个样本也只需要载入一次数据库，节省时间，以下是用自定义的kraken2M.py脚本实现。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 #!/bin/bash #SBATCH --job-name=kraken2M #SBATCH --output=/share/home/jianglab/pengchen/work/asthma/kraken/%x_%a.out #SBATCH --error=/share/home/jianglab/pengchen/work/asthma/kraken/%x_%a.err #SBATCH --time=14-00:00:00 #SBATCH --partition=mem #SBATCH --cpus-per-task=32 #SBATCH --mem-per-cpu=100G echo start: `date +\u0026#34;%Y-%m-%d %T\u0026#34;` start=`date +%s` #################### mkdir -p result/kraken python /share/home/jianglab/shared/krakenDB/K2ols/kraken2M.py -t 16 \\ -i data/rm_human \\ -c 0.05 \\ -s .1.fq,.2.fq \\ -o result/kraken \\ -d /share/home/jianglab/shared/krakenDB/mydb2 \\ -k ~/miniconda3/envs/waste/bin/kraken2 \\ -kt /share/home/jianglab/shared/krakenDB/K2ols/KrakenTools mkdir -p result/kraken/kreport mv result/kraken/*_kreport.txt result/kraken/kreport/ python ~/db/script/format_kreports.py -i result/kraken/kreport \\ -kt /share/home/jianglab/shared/krakenDB/K2ols/KrakenTools --save-name2taxid ############## echo end: `date +\u0026#34;%Y-%m-%d %T\u0026#34;` end=`date +%s` echo TIME:`expr $end - $start`s Kraken输出格式 标准输出格式output文件(五列表):\nC/U代表分类classified或非分类unclassifed 序列ID 物种注释 比序列注释的区域，如98|94代表左端98bp，右端94bp比对至数据库 LCA比对结果，如”562:13 561:4”代表13 k-mer比对至物种#562，4 k-mer比对至#561物种 报告输出格式report文件(包括6列，方便整理下游分析):\n百分比 count count最优 (U)nclassified, (R)oot, (D)omain, (K)ingdom, (P)hylum, (C)lass, (O)rder, (F)amily, (G)enus, or (S)pecies. “G2”代表位于属一种间 NCBI物种ID 科学物种名 常用的物种丰度表格式除了kraken report，还有mpa，spf，krona等格式，关于kraken结果的整理以及格式转换方式，有一些现成的脚本或者自己写。\nKrakenTools (jhu.edu) 就是一套很好用的kraken工具包，其中常用的有：\nextract_kraken_reads.py 此程序提取读取在任何用户指定的分类id处分类的内容。用户必须指定Kraken输出文件、序列文件和至少一个分类法ID。下面指定了其他选项。截至2021年4月19日，此脚本与KrakenUniq/Kraken2Uniq报告兼容。\ncombine_kreports.py 这个脚本将多个Kraken报告合并到一个合并的报告文件中。\nkreport2krona.py 这个程序需要一个Kraken报告文件，并打印出一个krona兼容的文本文件，换成krona文件好画图。\n转换后的krona使用 ktImportText MYSAMPLE.krona -o MYSAMPLE.krona.html得到网页可视化结果。\nkreport2mpa.py 这个程序需要一个Kraken报告文件，并打印出一个mpa (MetaPhlAn)风格的文本文件。\ncombine_mpa.py 这个程序合并来自kreport2mpa.py的多个输出。\n物种+功能：HUMAnN HUMAnN（The HMP Unified Metabolic Analysis Network）是一款用于分析人类微生物组的功能和代谢能力的工具。\n它通过将宏基因组序列与参考基因组数据库比对，利用MetaCyc代谢通路数据库和UniRef蛋白质序列数据库，分析微生物组在功能和代谢通路水平上的组成和活性。HUMAnN2还提供了多样性分析、关联分析和可视化工具，可用于深入研究人类微生物组对宿主健康的影响和治疗策略的制定等方面。\nHUMAnN是由美国国家人类微生物组计划（HMP）开发的，目前最新版本为HUMAnN3，于2020年发布。与HUMAnN2相比，HUMAnN3改进了基因家族注释的方法，提高了注释精度和速度，并提供了新的功能和工具，如功能韧度分析、代谢指纹识别和多样性分析等。\n但是HUMAnN的数据库基本都是与人相关的微生物，比较适合做各种人体微生物组（肠道，肺部，口腔，皮肤等等），对于环境样本可能unclassified比较多。\nHUMAnN要求双端序列合并的文件作为输入，for循环根据实验设计样本名批量双端序列合并。\n物种组成调用MetaPhlAn3, bowtie2比对至核酸序列库，解决有哪些微生物存在的问题； 功能组成为humann3调用diamond比对至蛋白库，解决这些微生物参与哪些功能通路的问题； 1 2 3 4 5 6 cd data/rm_human for i in `cat ~/work/asthma/samplelist` do echo $i cat ${i}_f1.fastq ${i}_r2.fastq \u0026gt;${i}_paired.fastq done 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 #!/bin/bash #SBATCH --job-name=humann #SBATCH --output=/share/home/jianglab/pengchen/work/asthma/log/%x_%A_%a.out #SBATCH --error=/share/home/jianglab/pengchen/work/asthma/log/%x_%A_%a.err #SBATCH --array=1 #SBATCH --partition=cpu #SBATCH --nodes=1 #SBATCH --tasks-per-node=1 #SBATCH --cpus-per-task=1 #SBATCH --mem-per-cpu=2G samplelist=/share/home/jianglab/pengchen/work/asthma/samplelist echo start: `date +\u0026#34;%Y-%m-%d %T\u0026#34;` start=`date +%s` #################### echo \u0026#34;SLURM_ARRAY_TASK_ID: \u0026#34; $SLURM_ARRAY_TASK_ID START=$SLURM_ARRAY_TASK_ID NUMLINES=40 #how many sample in one array STOP=$((SLURM_ARRAY_TASK_ID*NUMLINES)) START=\u0026#34;$(($STOP - $(($NUMLINES - 1))))\u0026#34; #set the min and max if [ $START -lt 1 ] then START=1 fi if [ $STOP -gt 40 ] then STOP=40 fi echo \u0026#34;START=$START\u0026#34; echo \u0026#34;STOP=$STOP\u0026#34; #################### for (( N = $START; N \u0026lt;= $STOP; N++ )) do sample=$(head -n \u0026#34;$N\u0026#34; $samplelist | tail -n 1) echo $sample mkdir -p data/paired cat data/rm_human/${sample}.1.fq data/rm_human/${sample}.2.fq \u0026gt; data/paired/${sample}_paired.fq mkdir -p result/humann ~/miniconda3/envs/waste/bin/humann --input data/paired/${sample}_paired.fq \\ --output result/humann/ --threads 24 ln result/humann/${sample}_paired_humann_temp/${sample}_paired_metaphlan_bugs_list.tsv result/humann/ rm -rf result/humann/${sample}_paired_humann_temp done ############## echo end: `date +\u0026#34;%Y-%m-%d %T\u0026#34;` end=`date +%s` echo TIME:`expr $end - $start`s 1 2 3 4 5 6 mkdir -p result/metaphlan2 ## 合并、修正样本名 merge_metaphlan_tables2.py \\ result/humann/*_metaphlan_bugs_list.tsv | \\ sed \u0026#39;s/_metaphlan_bugs_list//g\u0026#39; \\ \u0026gt; result/metaphlan2/taxonomy.tsv contigs-based contigs-based宏基因组分析是指先将测序读长（reads）组装成较长的序列片段（contigs），然后对这些contigs进行进一步的分析。这种方法可以提供更长的基因组片段，有助于更准确地进行基因注释和微生物群落结构分析。\n优点： 更高的解析度：通过组装生成较长的序列片段，可以更准确地进行基因和基因组注释。 结构信息：能够获得长距离的基因联系和基因组结构信息，有助于更全面的功能和进化分析。 局限性： 计算资源需求高：组装过程需要较高的计算资源和时间。 复杂性：组装和binning步骤增加了分析的复杂性，需要更多的技术经验和工具支持。 组装（assembly） 组装（assembly）是指将测序产生的短读长（reads）拼接成更长的连续序列（contigs）的过程。这个过程在基因组学和宏基因组学研究中至关重要，因为它能够将片段化的信息整合成更完整的基因组序列，便于后续的功能和分类分析。\n注意assembly有单样本拼装和混拼等策略，可以自行根据计算资源和研究目的选择。\n单样本拼装（Single-sample Assembly） 定义：单样本拼装是指对来自单一环境或条件下的样本进行组装。这种策略适用于相对简单的样本，或者希望单独分析每个样本的基因组组成。\n优点：\n独立分析：每个样本单独组装，有助于深入分析样本特定的基因组特征。 数据简单：适用于数据复杂度较低的样本，组装结果较为清晰。 缺点：\n资源需求高：对每个样本进行独立组装，计算资源和时间需求较高。 有限的覆盖度：对于低丰度微生物，单样本组装可能无法提供足够的覆盖度和组装质量。 适用场景：\n环境样本较为简单的研究。\n需要对每个样本进行独立比较和分析的研究。\n混拼策略（Co-assembly）\n定义：混拼是指将多个样本的数据合并在一起进行组装。这种策略适用于复杂的宏基因组样本，通过整合多个样本的数据，可以提高组装的覆盖度和质量。\n优点：\n提高覆盖度：合并多个样本的数据，增加了序列的覆盖度，有助于更完整的组装。 处理复杂样本：适用于复杂的环境样本，能够捕捉到更多的低丰度微生物和基因组信息。 缺点：\n复杂性增加：混拼的数据复杂度高，组装和后续分析更为复杂。 样本间差异模糊化：样本间的独特特征可能在混拼过程中被模糊化，影响对个体样本的具体分析。 适用场景：\n环境样本复杂，包含多种微生物群落。 需要提高低丰度物种的检测能力。 目标是获取整体微生物群落的综合信息。 megahit Megahit是一个用于对高通量测序数据进行de novo组装的软件。 它使用了一种基于短读比对和图形构建的算法来组装基因组，可以高效地处理大规模的数据集。 以下是Megahit的一些优点和适用情况：\n速度快：Megahit的算法非常高效，可以处理大规模的数据集，通常比其他de novo组装工具更快。 高质量的组装：Megahit在组装结果的连通性和准确性方面表现优异，尤其在处理高GC含量基因组时效果显著。 适用于不同类型的测序数据：Megahit支持多种不同类型的测序数据，包括 Illumina HiSeq/MiSeq、IonTorrent和PacBio等平台。 易于使用：Megahit具有简单的命令行语法，方便用户进行组装操作，且具有中断点，避免失败后全部重跑。 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 #!/bin/bash #SBATCH --job-name=megahit #SBATCH --output=/share/home/jianglab/pengchen/work/asthma/log/%x_%A_%a.out #SBATCH --error=/share/home/jianglab/pengchen/work/asthma/log/%x_%A_%a.err #SBATCH --array=1 #SBATCH --partition=cpu #SBATCH --cpus-per-task=8 #SBATCH --mem-per-cpu=10G samplelist=/share/home/jianglab/pengchen/work/asthma/samplelist echo start: `date +\u0026#34;%Y-%m-%d %T\u0026#34;` start=`date +%s` #################### echo \u0026#34;SLURM_ARRAY_TASK_ID: \u0026#34; $SLURM_ARRAY_TASK_ID START=$SLURM_ARRAY_TASK_ID NUMLINES=40 #how many sample in one array STOP=$((SLURM_ARRAY_TASK_ID*NUMLINES)) START=\u0026#34;$(($STOP - $(($NUMLINES - 1))))\u0026#34; echo \u0026#34;START=$START\u0026#34; echo \u0026#34;STOP=$STOP\u0026#34; #################### for (( N = $START; N \u0026lt;= $STOP; N++ )) do sample=$(head -n \u0026#34;$N\u0026#34; $samplelist | tail -n 1) echo $sample #single sample mkdir -p result/megahit mkdir -p result/megahit/contigs ~/miniconda3/envs/waste/bin/megahit -t 8 -1 data/rm_human/${sample}.1.fq \\ -2 data/rm_human/${sample}.2.fq \\ -o result/megahit/${sample} --out-prefix ${sample} sed -i \u0026#34;/\u0026gt;/s/\u0026gt;/\u0026gt;${sample}_/\u0026#34; result/megahit/${sample}/${sample}.contigs.fa mv result/megahit/${sample}/${sample}.contigs.fa result/megahit/contigs/ done ############## echo end: `date +\u0026#34;%Y-%m-%d %T\u0026#34;` end=`date +%s` echo TIME:`expr $end - $start`s 混拼的话：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 #!/bin/bash #SBATCH --job-name=megahit2 #SBATCH --output=/share/home/jianglab/pengchen/work/asthma/log/%x_%A_%a.out #SBATCH --error=/share/home/jianglab/pengchen/work/asthma/log/%x_%A_%a.err #SBATCH --array=1 #SBATCH --partition=mem #SBATCH --cpus-per-task=8 #SBATCH --mem-per-cpu=100G samplelist=/share/home/jianglab/pengchen/work/asthma/samplelist echo start: `date +\u0026#34;%Y-%m-%d %T\u0026#34;` start=`date +%s` #################### #multi-sample混拼 #需要大内存，建议3倍fq.gz内存 mkdir -p data/com_read mkdir -p result/megahit2 for i in `cat samplelist` do echo ${i} cat data/rm_human/${i}.1.fq \u0026gt;\u0026gt; data/com_read/R1.fq cat data/rm_human/${i}.2.fq \u0026gt;\u0026gt; data/com_read/R2.fq done ~/miniconda3/envs/waste/bin/megahit -t 8 -1 data/com_read/R1.fq \\ -2 data/com_read/R2.fq \\ -o result/megahit2/ --out-prefix multi_sample ############## echo end: `date +\u0026#34;%Y-%m-%d %T\u0026#34;` end=`date +%s` echo TIME:`expr $end - $start`s metaSPAdes SPAdes 是一款多功能工具包，专为测序数据的组装和分析而设计。 SPAdes 主要是为 Illumina 测序数据而开发的，但也可用于 IonTorrent。大多数 SPAdes 管道支持混合模式，即允许使用长读取（PacBio 和 Oxford Nanopore）作为补充数据。\n而metaSPAdes是目前宏基因组领域组装指标较好的软件，尤其在株水平组装优势明显。相比Megahit表现出更好的基因长度和读长比较率，但是更好的组装质量也伴随着更长时间和内存消耗，同时也有错误组装上升的风险。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 #!/bin/bash #SBATCH --job-name=asthma_megahit #SBATCH --output=/share/home/jianglab/pengchen/work/asthma/megahit/log/%x_%a.out #SBATCH --error=/share/home/jianglab/pengchen/work/asthma/megahit/log/%x_%a.err #SBATCH --array=1-33 #SBATCH --partition=cpu #SBATCH --cpus-per-task=32 echo start: `date +\u0026#39;%Y-%m-%d %T\u0026#39;` start=`date +%s` echo \u0026#34;SLURM_ARRAY_TASK_ID: \u0026#34; $SLURM_ARRAY_TASK_ID sample=$(head -n $SLURM_ARRAY_TASK_ID ~/work/asthma/data/namelist | tail -1) #sample=$(head -n 1 namelist | tail -1) echo handling: $sample\t#################### for (( N = $START; N \u0026lt;= $STOP; N++ )) do sample=$(head -n \u0026#34;$N\u0026#34; $samplelist | tail -n 1) echo $sample #single sample mkdir -p result/metaspades mkdir -p result/metaspades/contigs ~/miniconda3/envs/metawrap/bin/metaspades.py –t 8 -k 21,33,55,77,99,127 --careful \\ -1 data/rm_human/${sample}.1.fq \\ -2 data/rm_human/${sample}.2.fq \\ -o result/metaspades/${sample} sed -i \u0026#34;/\u0026gt;/s/\u0026gt;/\u0026gt;${sample}_/\u0026#34; result/metaspades/${sample}/scaffolds.fasta mv result/metaspades/${sample}/scaffolds.fasta result/metaspades/contigs/ done #################### echo end: `date +\u0026#39;%Y-%m-%d %T\u0026#39;` end=`date +%s` echo TIME:`expr $end - $start`s 组装评估：QUAST QUAST是一个质量评估工具。 QUAST可以使用参考基因组以及不使用参考基因组来评估装配。 QUAST生成详细的报告，表格和图解，以显示装配的不同方面。\n基因预测：Prodigal 基因预测是指在基因组序列（如contigs）中识别出编码区序列（CDS, Coding DNA Sequences）的过程。这个过程对于理解基因组功能和注释基因组中的基因是至关重要的。常用的软件有Prodigal，GeneMark（GeneMarkS用于细菌，GeneMark-ES用于真核生物），Glimmer等。\n这里以Prodigal为例： 输入文件：拼装好的序列文件 megahit/final.contigs.fa 输出文件：prodigal预测的基因序列 prodigal/gene.fa\nprodigal不支持多线程运行，所以我们可以自行分割序列文件调用多个prodigal程序分别跑实现伪多线程。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 #!/bin/bash #SBATCH --job-name=prodigal #SBATCH --output=/share/home/jianglab/pengchen/work/asthma/log/%x_%A_%a.out #SBATCH --error=/share/home/jianglab/pengchen/work/asthma/log/%x_%A_%a.err #SBATCH --array=1 #SBATCH --partition=cpu #SBATCH --cpus-per-task=1 #SBATCH --mem-per-cpu=2G samplelist=/share/home/jianglab/pengchen/work/asthma/samplelist echo start: `date +\u0026#34;%Y-%m-%d %T\u0026#34;` start=`date +%s` #################### echo \u0026#34;SLURM_ARRAY_TASK_ID: \u0026#34; $SLURM_ARRAY_TASK_ID START=$SLURM_ARRAY_TASK_ID NUMLINES=40 #how many sample in one array STOP=$((SLURM_ARRAY_TASK_ID*NUMLINES)) START=\u0026#34;$(($STOP - $(($NUMLINES - 1))))\u0026#34; echo \u0026#34;START=$START\u0026#34; echo \u0026#34;STOP=$STOP\u0026#34; #################### for (( N = $START; N \u0026lt;= $STOP; N++ )) do sample=$(head -n \u0026#34;$N\u0026#34; $samplelist | tail -n 1) echo $sample mkdir -p result/prodigal mkdir -p result/prodigal/gene_fa mkdir -p result/prodigal/gene_gff ~/miniconda3/envs/waste/bin/prodigal -i result/megahit/contigs/${sample}.contigs.fa \\ -d result/prodigal/gene_fa/${sample}.gene.fa \\ -o result/prodigal/gene_gff/${sample}.gene.gff \\ -p meta -f gff mkdir -p result/prodigal/fullgene_fa ## 提取完整基因(完整片段获得的基因全为完整，如成环的细菌基因组) grep \u0026#39;partial=00\u0026#39; result/prodigal/gene_fa/${sample}.gene.fa | cut -f1 -d \u0026#39; \u0026#39;| sed \u0026#39;s/\u0026gt;//\u0026#39; \u0026gt; result/prodigal/gene_fa/${sample}.fullid seqkit grep -f result/prodigal/gene_fa/${sample}.fullid result/prodigal/gene_fa/${sample}.gene.fa \u0026gt; result/prodigal/fullgene_fa/${sample}.gene.fa done ############## echo end: `date +\u0026#34;%Y-%m-%d %T\u0026#34;` end=`date +%s` echo TIME:`expr $end - $start`s 去冗余 基因集去冗余是指在预测到的基因集中去除重复的基因或高度相似的基因，以获得一个非冗余的基因集合。这一步骤在宏基因组分析中非常重要，因为宏基因组样本中通常包含来自多种微生物的重复或相似序列，去冗余可以简化数据集并提高后续分析的效率和准确性。常用软件有CD-HIT，MMseqs2，UCLUST（集成在QIIME和USEARCH中的工具）等。\n上面产生了n个样本的基因预测结果文件，gene.fa文件要先想办法整合为一个文件再去去冗余。\nCD-HIT 之前大家常用的是CD-HIT来去冗余：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 #!/bin/bash #SBATCH --job-name=cluster #SBATCH --output=/share/home/jianglab/pengchen/work/asthma/log/%x_%A_%a.out #SBATCH --error=/share/home/jianglab/pengchen/work/asthma/log/%x_%A_%a.err #SBATCH --array=1 #SBATCH --partition=cpu #SBATCH --nodes=1 #SBATCH --tasks-per-node=1 #SBATCH --cpus-per-task=1 #SBATCH --mem-per-cpu=2G samplelist=/share/home/jianglab/pengchen/work/asthma/samplelist echo start: `date +\u0026#34;%Y-%m-%d %T\u0026#34;` start=`date +%s` #################### echo \u0026#34;start merge\u0026#34; cat result/prodigal/gene_fa/*.gene.fa \u0026gt; result/prodigal/all.gene.fa cat result/prodigal/fullgene_fa/*.gene.fa \u0026gt; result/prodigal/all.fullgene.fa echo \u0026#34;done\u0026#34; ~/miniconda3/envs/waste/bin/cd-hit-est -i result/prodigal/all.gene.fa \\ -o result/NR/nucleotide.fa \\ -aS 0.9 -c 0.9 -G 0 -g 0 -T 0 -M 0 mv result/NR/nucleotide_rep_seq.fasta result/NR/nucleotide.fa rm result/NR/nucleotide_all_seqs.fasta ~/miniconda3/envs/waste/bin/seqkit translate result/NR/nucleotide.fa \u0026gt; result/NR/protein.fa sed \u0026#39;s/\\*//g\u0026#39; result/NR/protein.fa \u0026gt; result/NR/protein_no_end.fa rm result/NR/protein.fa ############## echo end: `date +\u0026#34;%Y-%m-%d %T\u0026#34;` end=`date +%s` echo TIME:`expr $end - $start`s Mmseqs2 最近发现了Mmseqs2这个神器，这个聚类要比CD-HIT快非常多，其他应用参见Mmseqs2的基础使用：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 #!/bin/bash #SBATCH --job-name=cluster #SBATCH --output=/share/home/jianglab/pengchen/work/asthma/log/%x_%A_%a.out #SBATCH --error=/share/home/jianglab/pengchen/work/asthma/log/%x_%A_%a.err #SBATCH --array=1 #SBATCH --partition=cpu #SBATCH --nodes=1 #SBATCH --tasks-per-node=1 #SBATCH --cpus-per-task=1 #SBATCH --mem-per-cpu=2G samplelist=/share/home/jianglab/pengchen/work/asthma/samplelist echo start: `date +\u0026#34;%Y-%m-%d %T\u0026#34;` start=`date +%s` #################### echo \u0026#34;start merge\u0026#34; cat result/prodigal/gene_fa/*.gene.fa \u0026gt; result/prodigal/all.gene.fa cat result/prodigal/fullgene_fa/*.gene.fa \u0026gt; result/prodigal/all.fullgene.fa echo \u0026#34;done\u0026#34; mkdir -p result/NR mmseqs easy-linclust result/prodigal/all.gene.fa result/NR/nucleotide mmseqs_tmp \\ --min-seq-id 0.9 -c 0.9 --cov-mode 1 --threads 8 mv result/NR/nucleotide_rep_seq.fasta result/NR/nucleotide.fa rm result/NR/nucleotide_all_seqs.fasta ~/miniconda3/envs/waste/bin/seqkit translate result/NR/nucleotide.fa \u0026gt; result/NR/protein.fa sed \u0026#39;s/\\*//g\u0026#39; result/NR/protein.fa \u0026gt; result/NR/protein_no_end.fa rm result/NR/protein.fa ############## echo end: `date +\u0026#34;%Y-%m-%d %T\u0026#34;` end=`date +%s` echo TIME:`expr $end - $start`s fasta信息统计 使用seqkit统计刚刚得到的一些关键fasta文件的基础信息。\n1 2 3 4 5 6 7 8 9 10 11 12 13 test_file=`head -n1 $samplelist` if [ -f result/megahit/contigs/${test_file}.contigs.fa ]; then ~/miniconda3/envs/waste/bin/seqkit stats result/megahit/contigs/*.contigs.fa \u0026gt;result/megahit/contig_stats fi if [ -f result/prodigal/gene_fa/${test_file}.gene.fa ]; then ~/miniconda3/envs/waste/bin/seqkit stats result/prodigal/gene_fa/*.gene.fa \u0026gt;result/prodigal/gene_fa_stats fi if [ -f result/prodigal/fullgene_fa/${test_file}.gene.fa ]; then ~/miniconda3/envs/waste/bin/seqkit stats result/prodigal/fullgene_fa/*.gene.fa \u0026gt;result/prodigal/fullgene_fa_stats fi if [ -f result/NR/nucleotide.fa ]; then ~/miniconda3/envs/waste/bin/seqkit stats result/NR/nucleotide.fa \u0026gt;result/NR/nucleotide_stat fi 基因定量：salmon 建立索引 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 #!/bin/bash #SBATCH --job-name=salmon-index #SBATCH --output=/share/home/jianglab/pengchen/work/asthma/log/%x_%A_%a.out #SBATCH --error=/share/home/jianglab/pengchen/work/asthma/log/%x_%A_%a.err #SBATCH --array=1 #SBATCH --partition=cpu #SBATCH --cpus-per-task=4 #SBATCH --mem-per-cpu=10G echo start: `date +\u0026#34;%Y-%m-%d %T\u0026#34;` start=`date +%s` #################### ## 建索引, -t序列, -i 索引 # 大点内存 mkdir -p result/salmon ~/miniconda3/envs/waste/share/salmon/bin/salmon index \\ -t result/NR/nucleotide.fa \\ -p 4 \\ -i result/salmon/index ############## echo end: `date +\u0026#34;%Y-%m-%d %T\u0026#34;` end=`date +%s` echo TIME:`expr $end - $start`s 对每个样本定量 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 #!/bin/bash #SBATCH --job-name=salmon-quant #SBATCH --output=/share/home/jianglab/pengchen/work/asthma/log/%x_%A_%a.out #SBATCH --error=/share/home/jianglab/pengchen/work/asthma/log/%x_%A_%a.err #SBATCH --array=1 #SBATCH --partition=cpu #SBATCH --cpus-per-task=4 #SBATCH --mem-per-cpu=2G samplelist=/share/home/jianglab/pengchen/work/asthma/samplelist echo start: `date +\u0026#34;%Y-%m-%d %T\u0026#34;` start=`date +%s` #################### echo \u0026#34;SLURM_ARRAY_TASK_ID: \u0026#34; $SLURM_ARRAY_TASK_ID START=$SLURM_ARRAY_TASK_ID NUMLINES=40 #how many sample in one array STOP=$((SLURM_ARRAY_TASK_ID*NUMLINES)) START=\u0026#34;$(($STOP - $(($NUMLINES - 1))))\u0026#34; echo \u0026#34;START=$START\u0026#34; echo \u0026#34;STOP=$STOP\u0026#34; #################### ## 输入文件：去冗余后的基因和蛋白序列：NR/nucleotide.fa ## 输出文件：Salmon定量后的结果：salmon/gene.count; salmon/gene.TPM ## 定量，l文库类型自动选择，p线程，--meta宏基因组模式 for (( N = $START; N \u0026lt;= $STOP; N++ )) do sample=$(head -n \u0026#34;$N\u0026#34; $samplelist | tail -n 1) echo $sample mkdir -p result/salmon/quant ~/miniconda3/envs/waste/share/salmon/bin/salmon quant \\ --validateMappings \\ -i result/salmon/index -l A -p 4 --meta \\ -1 data/rm_human/${sample}.1.fq \\ -2 data/rm_human/${sample}.2.fq \\ -o result/salmon/quant/${sample}.quant done ############## echo end: `date +\u0026#34;%Y-%m-%d %T\u0026#34;` end=`date +%s` echo TIME:`expr $end - $start`s 合并各样本结果 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 #!/bin/bash #SBATCH --job-name=salmon-merge #SBATCH --output=/share/home/jianglab/pengchen/work/asthma/log/%x_%A_%a.out #SBATCH --error=/share/home/jianglab/pengchen/work/asthma/log/%x_%A_%a.err #SBATCH --array=1 #SBATCH --partition=cpu #SBATCH --cpus-per-task=1 #SBATCH --mem-per-cpu=2G samplelist=/share/home/jianglab/pengchen/work/asthma/samplelist echo start: `date +\u0026#34;%Y-%m-%d %T\u0026#34;` start=`date +%s` #################### ls result/salmon/quant/*.quant/quant.sf |awk -F\u0026#39;/\u0026#39; \u0026#39;{print $(NF-1)}\u0026#39; |sed \u0026#39;s/.quant//\u0026#39; \u0026gt;tmp_finished diff_rows -f samplelist -s tmp_finished \u0026gt;tmp_diff # 计算结果的行数 line_count=$( cat tmp_diff| wc -l) # 检查行数是否大于1，如果是则终止脚本 if [ \u0026#34;$line_count\u0026#34; -gt 1 ]; then echo \u0026#39;sf文件和samplelist数量不一致\u0026#39; exit 1 fi ##mapping rates cat result/salmon/quant/*.quant/logs/salmon_quant.log |grep \u0026#39;Mapping rate = \u0026#39;|awk \u0026#39;{print $NF}\u0026#39;\u0026gt; tmp paste samplelist tmp \u0026gt; result/salmon/mapping_rates ## combine ~/miniconda3/envs/waste/share/salmon/bin/salmon quantmerge \\ --quants result/salmon/quant/*.quant \\ -o result/salmon/gene.TPM ~/miniconda3/envs/waste/share/salmon/bin/salmon quantmerge \\ --quants result/salmon/quant/*.quant \\ --column NumReads -o result/salmon/gene.count sed -i \u0026#39;1 s/.quant//g\u0026#39; result/salmon/gene.* ############## echo end: `date +\u0026#34;%Y-%m-%d %T\u0026#34;` end=`date +%s` echo TIME:`expr $end - $start`s 功能基因注释 功能基因注释是对非冗余基因集进行分类和功能描述的过程，以便理解这些基因在生物体内可能的角色和作用。\n上一步已经有了所有的基因和每个样本所有基因的read count定量结果， 我们只需要对上一步的基因序列（或蛋白质序列）进行不同数据库的注释， 然后合并注释结果得到的就是功能丰度表。\n很多数据库自带软件都是用diamond比对，如果没有专用软件的数据库我们也可以自己用diamond比对。\ndiamond选择\u0026ndash;outfmt 6的输出结果和blastp格式一样。\neggNOG (COG/KEGG/CAZy) EggNOG数据库收集了COG（Clusters of Orthologous Groups of proteins，直系同源蛋白簇）,构成每个COG的蛋白都是被假定为来自于一个祖先蛋白，因此是orthologs或者是paralogs。通过把所有完整基因组的编码蛋白一个一个的互相比较确定的。在考虑来自一个给定基因组的蛋白时，这种比较将给出每个其他基因组的一个最相似的蛋白（因此需要用完整的基因组来定义COG），这些基因的每一个都轮番地被考虑。如果在这些蛋白（或子集）之间一个相互的最佳匹配关系被发现，那么那些相互的最佳匹配将形成一个COG。这样，一个COG中的成员将与这个COG中的其他成员比起被比较的基因组中的其他蛋白更相像。\nEggNOG里面已经包含了GO，KEGG，CAZy等。\n1 2 3 4 5 6 7 8 9 ## 下载常用数据库，注意设置下载位置 mkdir -p ${db}/eggnog5 \u0026amp;\u0026amp; cd ${db}/eggnog5 ## -y默认同意，-f强制下载，eggnog.db.gz 7.9G+4.9G download_eggnog_data.py -y -f --data_dir ./ ## 下载方式2(可选)：链接直接下载 wget -c http://eggnog5.embl.de/download/emapperdb-5.0.0/eggnog.db.gz ## 7.9G wget -c http://eggnog5.embl.de/download/emapperdb-5.0.0/eggnog_proteins.dmnd.gz ## 4.9G gunzip *.gz 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 #!/bin/bash #SBATCH --job-name=eggnog #SBATCH --output=/share/home/jianglab/pengchen/work/asthma/log/%x_%A_%a.out #SBATCH --error=/share/home/jianglab/pengchen/work/asthma/log/%x_%A_%a.err #SBATCH --array=1 #SBATCH --partition=cpu #SBATCH --cpus-per-task=8 #SBATCH --mem-per-cpu=10G echo start: `date +\u0026#34;%Y-%m-%d %T\u0026#34;` start=`date +%s` #################### ## 大点内存, 数据库有50G左右 source ~/miniconda3/etc/profile.d/conda.sh conda activate func ## diamond比对基因至eggNOG 5.0数据库, 1~9h，默认diamond 1e-3 mkdir -p result/eggnog emapper.py --no_annot --no_file_comments --override \\ --data_dir ~/db/eggnog5 \\ -i result/NR/protein_no_end.fa \\ --cpu 8 -m diamond \\ -o result/eggnog/protein ## 比对结果功能注释, 1h emapper.py \\ --annotate_hits_table result/eggnog/protein.emapper.seed_orthologs \\ --data_dir ~/db/eggnog5 \\ --cpu 8 --no_file_comments --override \\ -o result/eggnog/output ## 添表头, 1列为ID，9列KO，16列CAZy，21列COG，22列描述 sed \u0026#39;1 i Name\\tortholog\\tevalue\\tscore\\ttaxonomic\\tprotein\\tGO\\tEC\\tKO\\tPathway\\tModule\\tReaction\\trclass\\tBRITE\\tTC\\tCAZy\\tBiGG\\ttax_scope\\tOG\\tbestOG\\tCOG\\tdescription\u0026#39; \\ result/eggnog/output.emapper.annotations \\ \u0026gt; result/eggnog/eggnog_anno_output ############## echo end: `date +\u0026#34;%Y-%m-%d %T\u0026#34;` end=`date +%s` echo TIME:`expr $end - $start`s dbCAN2（碳水化合物） 1 2 3 4 5 6 7 8 9 10 11 12 13 ## dbCAN2 http://bcb.unl.edu/dbCAN2 ## 创建数据库存放目录并进入 mkdir -p ${db}/dbCAN2 \u0026amp;\u0026amp; cd ${db}/dbCAN2 ## 下载序列和描述 wget -c http://bcb.unl.edu/dbCAN2/download/CAZyDB.07312020.fa wget -c http://bcb.unl.edu/dbCAN2/download/Databases/CAZyDB.07302020.fam-activities.txt ## 备用数据库下载地址并解压 #wget -c http://210.75.224.110/db/dbcan2/CAZyDB.07312020.fa.gz #gunzip CAZyDB.07312020.fa.gz ## diamond建索引 time diamond makedb \\ --in CAZyDB.07312020.fa \\ --db CAZyDB.07312020 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 #!/bin/bash #SBATCH --job-name=cazy #SBATCH --output=/share/home/jianglab/pengchen/work/asthma/log/%x_%A_%a.out #SBATCH --error=/share/home/jianglab/pengchen/work/asthma/log/%x_%A_%a.err #SBATCH --array=1 #SBATCH --partition=cpu #SBATCH --cpus-per-task=8 #SBATCH --mem-per-cpu=2G echo start: `date +\u0026#34;%Y-%m-%d %T\u0026#34;` start=`date +%s` #################### mkdir -p result/dbcan2 diamond blastp \\ --db ~/db/dbcan2/CAZyDB.07312020 \\ --query result/NR/protein_no_end.fa \\ --threads 8 -e 1e-5 --outfmt 6 \\ --max-target-seqs 1 --quiet \\ --out result/dbcan2/gene_diamond.f6 ############## echo end: `date +\u0026#34;%Y-%m-%d %T\u0026#34;` end=`date +%s` echo TIME:`expr $end - $start`s CARD（抗生素抗性基因ARGs） RGI软件Github主页: https://github.com/arpcard/rgi，可以参考之前写的Antibiotics resistance gene。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 #!/bin/bash #SBATCH --job-name=rgi #SBATCH --output=/share/home/jianglab/pengchen/work/asthma/log/%x_%A_%a.out #SBATCH --error=/share/home/jianglab/pengchen/work/asthma/log/%x_%A_%a.err #SBATCH --array=1 #SBATCH --partition=cpu #SBATCH --cpus-per-task=8 #SBATCH --mem-per-cpu=2G echo start: `date +\u0026#34;%Y-%m-%d %T\u0026#34;` start=`date +%s` #################### source ~/miniconda3/etc/profile.d/conda.sh conda activate rgi mkdir -p result/card ~/miniconda3/envs/rgi/bin/rgi main \\ --input_sequence result/NR/protein_no_end.fa \\ --output_file result/card/protein \\ --input_type protein --num_threads 8 \\ --clean --alignment_tool DIAMOND # --low_quality #partial genes ############## echo end: `date +\u0026#34;%Y-%m-%d %T\u0026#34;` end=`date +%s` echo TIME:`expr $end - $start`s VFDB（毒力因子） 官网地址：http://www.mgc.ac.cn/VFs/\n在官网下载数据库时，带有setA 的库为VFDB数据库核心库(set A)，而setB为全库(setB), 其中setA仅包含经实验验证过的毒力基因，而setB则在setA的基础上增加了预测的毒力基因，选择好数据库后，直接用blast/diamond即可完成注释。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 #!/bin/bash #SBATCH --job-name=vfdb #SBATCH --output=/share/home/jianglab/pengchen/work/asthma/log/%x_%A_%a.out #SBATCH --error=/share/home/jianglab/pengchen/work/asthma/log/%x_%A_%a.err #SBATCH --array=1 #SBATCH --partition=cpu #SBATCH --cpus-per-task=8 #SBATCH --mem-per-cpu=2G echo start: `date +\u0026#34;%Y-%m-%d %T\u0026#34;` start=`date +%s` #################### mkdir -p result/vfdb diamond blastp \\ --db ~/db/VFDB/VFDB_setB_pro \\ --query result/NR/protein_no_end.fa \\ --threads 8 -e 1e-5 --outfmt 6 \\ --max-target-seqs 1 --quiet \\ --out result/vfdb/gene_diamond.f6 ############## echo end: `date +\u0026#34;%Y-%m-%d %T\u0026#34;` end=`date +%s` echo TIME:`expr $end - $start`s 其他数据库 NCBI NR（Non-redundant）:包含广泛的已知蛋白序列，是常用的参考数据库。 Pfam：包含蛋白质家族和功能域的信息，通过Hidden Markov Models (HMMs) 描述蛋白质功能域。 元素循环数据库：专注于环境中的元素（如碳、氮、硫、磷等）的生物地球化学循环相关基因和途径注释。如NCycDB，SCycDB，PCycDB，MCycDB等 这些数据库我们可以自行下载蛋白数据库，然后用blast建库比对。\n功能注释合并 写一个python脚本，将表1（基因-功能的对应表）与表2（基因丰度表）合并，即不同基因可能注释到相同功能，把它们的丰度加在一起得到新表3（功能丰度表）。\n可以参考https://github.com/YongxinLiu/EasyMicrobiome/blob/master/script/summarizeAbundance.py。\n1 2 3 4 5 6 7 8 9 10 mkdir -p result/summ_table if [ -f result/eggnog/eggnog_anno_output ]; then # 汇总，9列KO，16列CAZy按逗号分隔，21列COG按字母分隔，原始值累加 ~/db/script/summarizeAbundance.py \\ -i result/salmon/gene.count \\ -m result/eggnog/eggnog_anno_output \\ -c \u0026#39;9,16,21\u0026#39; -s \u0026#39;,+,+*\u0026#39; -n raw \\ -o result/summ_table/eggnog sed -i \u0026#39;s/^ko://\u0026#39; summ_table/eggnog.KO.raw.txt fi 分箱（binning） 宏基因组binning是指将不同的序列集合（如metagenome序列集合）根据它们的物种归类到不同的bins中，以便进一步研究它们的组成和功能。这个过程可以将类似的序列组合在一起，形成代表不同物种或基因组的bins，以便进行后续分析，如物种注释、基因组组装等。\n以下是常用的宏基因组binning方法：\n基于聚类的方法：该方法使用序列聚类将相似序列分到同一个bin中。一般来说，聚类算法可分为两类：无监督聚类（如k-means、DBSCAN等）和有监督聚类（如CAMI、MyCC等）。\n基于组装的方法：该方法使用de novo组装来将相似序列组装成连续的序列，再根据这些序列的基因组信息来将其分类到不同的bins中。这种方法的优点是可以更好地处理重复序列，缺点是需要大量的计算资源和时间。\n基于分类器的方法：该方法使用机器学习分类器来将序列分配到不同的bins中。这种方法的优点是可以自动学习特征并在处理大规模数据时效率高，缺点是需要先建立一个分类器并进行训练。\n在进行宏基因组binning时，通常需要使用多个方法进行比较，以选择最适合数据集的方法。可以使用一些流行的工具来进行binning，如MetaBAT、MaxBin、CONCOCT和MEGAN等。这些工具通常包含各种binning方法，可以根据数据集和分析目的选择适合的方法。\n篇幅限制，具体的方法放在另一篇里面讲解吧，查看宏基因组分箱流程。\nReference 1. Y.-X. Liu, Y. Qin, T. Chen, M. Lu, et al., A practical guide to amplicon and metagenomic analysis of microbiome data. Protein \u0026amp; Cell. 12, 315–330 (2021).\n","date":"2024-05-28T00:00:00Z","image":"/p/metagenomic-workflow/images/workflow_hu_c30ec9b0ff59e5c2.png","permalink":"/p/metagenomic-workflow/","title":"宏基因组分析流程（Metagenomic workflow）202408｜持续更新"},{"content":"Introduction 我们在做生物信息分析时，对于大规模的上游数据的处理，一般需要在大型服务器或集群上进行。我最早接触并使用的是一个基于SLURM调度系统的集群，在此记录一下基础使用方法。\n高性能计算集群（High-Performance Computing Cluster，简称HPC集群）是一种计算系统，通过将多台计算机（通常称为节点）连接在一起，协同工作来解决需要大量计算资源的问题。这些集群被广泛应用于科学研究、工程计算、金融建模、大数据分析等领域。\nSLURM（Simple Linux Utility for Resource Management）是一种开放源码的资源管理和任务调度系统，广泛应用于高性能计算（HPC）集群。SLURM负责分配计算资源、调度作业、监控系统状态和用户任务等工作，是HPC集群中不可或缺的一部分。\n主要功能 资源分配：SLURM能够根据用户需求和集群资源情况，动态分配计算节点、CPU、内存和其他资源，确保资源的高效利用。\n任务调度：SLURM可以将用户提交的计算任务按照优先级、依赖关系和资源需求进行调度，决定何时在何处执行这些任务。\n任务管理：用户可以通过SLURM提交、监控和管理他们的任务，包括查看任务状态、取消任务、重新排队等操作。\n负载均衡：SLURM通过智能调度算法，尽量均衡各节点的负载，避免资源浪费，提高集群的整体效率。\n作业依赖管理：支持复杂的作业依赖关系管理，例如在一个作业完成后再启动另一个作业，或多个作业之间的依赖关系管理。\n工作流程 提交作业：用户通过sbatch命令提交编写好的作业脚本，描述作业的资源需求（如节点数、CPU数、内存等）和执行命令。 资源分配：SLURM的调度器（slurmctld）根据当前的资源可用情况和作业队列中的优先级，分配资源给新提交的作业。 作业执行：分配到资源的作业通过srun命令在指定的节点上启动并运行。 作业监控：运行中的作业由slurmd守护进程进行监控，用户可以使用squeue命令查看作业的执行状态。 结果处理：作业完成后，输出结果通常会被保存到用户指定的文件中，用户可以通过slurm提供的命令查看和管理这些结果。 优势 高可扩展性：能够管理从几台到上百万台计算节点的集群。 开源和社区支持：丰富的文档和活跃的用户社区，便于问题解决和功能扩展。 灵活性和可配置性：支持多种调度策略和配置，适应不同的工作负载和需求。 基础使用 常用命令 sinfo: 查看队列状态和信息\n用途: 显示集群的分区和节点状态信息。 选项: -s 简要格式输出 -N 显示每个节点的信息 -p \u0026lt;partition\u0026gt; 只显示特定分区的信息 输出字段: PARTITION: 分区名称 AVAIL: 节点可用性状态（up/down） TIMELIMIT: 分区的时间限制 NODES: 分区中的节点数量 STATE: 节点状态：drain(节点故障)，alloc(节点在用)，idle(节点可用)，down(节点下线)，mix（节点被占用，但仍有剩余资源） NODELIST: 节点名称列表 sacct: 显示用户作业历史\n用途: 查询作业历史记录，显示已完成和正在进行的作业信息。 选项: -j \u0026lt;jobid\u0026gt; 查询特定作业 -S \u0026lt;YYYY-MM-DD\u0026gt; 查询指定开始日期的作业 -u \u0026lt;username\u0026gt; 查询特定用户的作业 输出字段: JobID: 作业ID JobName: 作业名称 Partition: 分区名称 Account: 用户账户 State: 作业状态（COMPLETED、FAILED、CANCELLED等） Elapsed: 作业运行时间 squeue: 显示当前作业状态\n用途: 显示当前在队列中排队和运行的作业状态。 选项: -u \u0026lt;username\u0026gt; 只显示特定用户的作业 -p \u0026lt;partition\u0026gt; 只显示特定分区的作业 输出字段: JOBID: 作业ID PARTITION: 分区名称 NAME: 作业名称 USER: 用户名 ST: 作业状态（PD排队；R运行；S挂起；CG正在退出） TIME: 作业运行时间 NODES: 作业使用的节点数量 NODELIST(REASON): 作业所在节点或排队原因 sbatch: 提交作业\n用途: 提交批处理作业脚本。 示例: 1 sbatch my_job_script.sh 常用选项: --job-name=\u0026lt;name\u0026gt; 设置作业名称 --partition=\u0026lt;partition\u0026gt; 指定作业提交的分区 --time=\u0026lt;time\u0026gt; 设置作业运行时间限制 scancel: 取消指定作业\n用途: 取消一个或多个作业。 示例: 1 scancel 12345 选项: -u \u0026lt;username\u0026gt; 取消特定用户的所有作业 -p \u0026lt;partition\u0026gt; 取消特定分区中的作业 pestat: 节点使用信息\n用途: 显示集群节点的使用情况和状态信息（此命令可能是集群特定的，或者通过管理员定义的别名）。 示例: 1 pestat sacct -j \u0026lt;jobid\u0026gt;: 检查已完成作业的信息\n用途: 查看特定作业的详细信息，包括如何完成或失败。 示例: 1 sacct -j 12345 seff \u0026lt;jobid\u0026gt;: 查看已完成任务的资源使用情况\n用途: 显示特定作业的资源使用效率，包括CPU、内存等。 示例: 1 seff 12345 scontrol show job \u0026lt;jobid\u0026gt;: 显示作业细节\n用途: 提供有关特定作业的详细信息，包括作业配置和当前状态。 示例: 1 scontrol show job 12345 其他有用的SLURM命令\nsrun: 直接运行并行作业\n用途: 在分配的资源上运行一个并行任务，通常用于交互式会话。 示例: 1 srun --partition=short --ntasks=4 my_program scontrol: 管理SLURM系统\n用途: 用于查询和更改SLURM系统的配置和状态。 常用命令: scontrol show partition 显示分区信息 scontrol update NodeName=\u0026lt;node\u0026gt; State=RESUME 恢复节点 sreport: 生成使用报告\n用途: 生成有关作业、用户和账户的资源使用报告。 示例: 1 sreport cluster utilization 作业参数 #SBATCH --job-name 作业名称 #SBATCH --output 标准输出文件：如/share/home/pengchen/work/%x_%A_%a.out #SBATCH --error ERROR输出文件：如/share/home/pengchen/work/%x_%A_%a.err #SBATCH --partition 工作分区，我们用cpu之类的 #SBATCH --nodelist 可以制定在哪个节点运行任务 #SBATCH --exclude 可以设置不放在某个节点跑任务 #SBATCH --nodes 使用nodes数量 #SBATCH --ntasks tasks数量，可能分配给不同node #SBATCH --ntasks-per-node 每个节点的tasks数量，由于我们只有1 node，所以ntasks和ntasks-per-node是相同的 #SBATCH --cpus-per-task 每个task使用的core的数量（默认 1 core per task），同一个task会在同一个node #SBATCH --mem 这个作业要求的内存 (Specified in MB，GB) #SBATCH --mem-per-cpu 每个core要求的内存 (Specified in MB，GB) 在SLURM中，一个任务（task）被理解为一个进程（process），一个多进程（multi-process）程序由多个任务组成。相反，多线程（multithreaded）程序只有一个任务，但这个任务使用多个logical CPU。更好的理解ntasks，参考what does the ntasks or n tasks does in slurm\n例子：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 #!/bin/bash #SBATCH --job-name=myjob #SBATCH --output=/share/home/pengchen/work/%x_%A_%a.out #SBATCH --error=/share/home/pengchen/work/%x_%A_%a.err #SBATCH --partition=cpu #SBATCH --nodes=1 #SBATCH --tasks-per-node=1 #SBATCH --cpus-per-task=1 #SBATCH --mem-per-cpu=2g #SBATCH --time=14-00:00:00 echo start: `date +\u0026#39;%Y-%m-%d %T\u0026#39;` start=`date +%s` #################### do something #################### echo end: `date +\u0026#39;%Y-%m-%d %T\u0026#39;` end=`date +%s` echo TIME:`expr $end - $start`s 把上面的内容保存为myjob.sh文件，然后使用sbatch即可提交排队。\ntmux+srun tmux是一个 terminal multiplexer（终端复用器），它可以启动一系列终端会话。\n在我们使用命令行时,打开一个终端窗口,会话开始,执行某些命令如sleep 100,关闭此终端窗口,会话结束,sleep命令会话随之被关闭而非等到正常结束。\n当我们希望运行的程序不会受会话窗口的关闭而随之消失,我们会使用到类似于nohup这样的方式将运行的命令后台化的。\n但集群并不可以如此：当我们申请节点资源后到该节点去执行nohup时看上去程序已经后台运行了,但当会话窗口关闭后作业将会被视为结束,节点则会运行相应的清理动作结束掉后台运行的程序;此时tmux的功能便显现出优势。\n申请节点资源（使用SLURM调度器）：\n1 salloc -N 1 -n 1 --time=01:00:00 这条命令申请一个节点，时间为1小时。\n在节点上启动tmux会话：\n1 tmux new-session -s myjob # 新建一个名称为myjob的会话 运行任务：\n1 ./run_my_simulation.sh 分离会话： 可以在不影响任务运行的情况下关闭终端窗口或断开连接：\n1 2 3 # Ctrl+b，然后按 d # 或者 tmux detach 重新连接到会话（如有需要）：\n1 2 3 tmux ls # 查看所有的会话 tmux attach-session # 默认进入第一个会话 tmux attach-session -t myjob # 进入到名称为myjob的会话 关闭会话。\n会话的使命完成后是一定要关闭的;可以使用exit退出,快捷键Ctrl+d\n或者使用tmux配合srun申请资源：\n1 2 3 tmux srun -n 1 --pty /bin/bash tmux detach 此窗口作业会一直运行，直到手动退出/作业时间限制。\nmodule 在SLURM集群环境中，模块管理系统（如Lmod或Environment Modules）常用于管理和切换不同的软件环境。模块系统可以简化软件依赖和版本控制，允许用户动态加载或卸载软件包和库。\n模块系统使用模块文件来描述如何设置环境变量（如PATH、LD_LIBRARY_PATH等），以便使用特定的软件包或库。常用命令包括module load、module unload、module list等。\n查看可用模块：\n1 module avail 这将列出所有可用的模块。\n加载模块：\n1 module load module_name 例如，加载GCC编译器：\n1 module load gcc 卸载模块：\n1 module unload module_name 例如，卸载GCC编译器：\n1 module unload gcc 显示已加载模块：\n1 module list 这将显示当前会话中已加载的模块。\n显示模块信息：\n1 module show module_name 例如，查看GCC模块的详细信息：\n1 module show gcc 在SLURM作业脚本中使用模块\n在提交到SLURM的作业脚本中，可以使用模块命令来设置所需的软件环境。以下是一个示例SLURM作业脚本：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 #!/bin/bash #SBATCH --job-name=myjob # 作业名称 #SBATCH --output=myjob.out # 标准输出和错误日志 #SBATCH --error=myjob.err # 错误日志文件 #SBATCH --ntasks=1 # 运行的任务数 #SBATCH --time=01:00:00 # 运行时间 #SBATCH --partition=compute # 作业提交的分区 # 加载模块 module load gcc module load python # 打印加载的模块 module list # 运行命令 python my_script.py 在这个脚本中，module load gcc 和 module load python 用于加载所需的GCC编译器和Python环境。module list命令将打印当前加载的模块，方便调试。\nconda 集群上一般用户都没有root权限，无法使用普通服务器的sudo安装软件方法，也无法使用docker（但是可以用singularity，下次可以讲讲这个）。建议使用conda进行环境配置和软件安装：\nConda 是一个开源的软件包管理和环境管理系统，支持跨平台使用，包括Linux、macOS和Windows。Conda 可以用于安装、运行和更新各种软件包和依赖，并能在不同环境之间轻松切换。用户可以在自己的家目录中安装Miniconda，这是Conda的一个轻量级版本，只包含包管理系统和Python。\n安装Miniconda 下载Miniconda安装脚本：\n1 wget https://repo.anaconda.com/miniconda/Miniconda3-latest-Linux-x86_64.sh 运行安装脚本：\n1 bash Miniconda3-latest-Linux-x86_64.sh 按照提示完成安装。安装完成后，您可能需要重启终端或运行以下命令来激活Conda：\n1 source ~/.bashrc 使用Conda创建和管理环境 创建新环境：\n1 conda create --name myenv python=3.8 这将创建一个名为myenv的新环境，并安装Python 3.8。\n激活环境：\n1 conda activate myenv 激活后，所有在此环境下运行的命令都将使用该环境中的软件和库。\n安装软件包：\n1 conda install numpy scipy 这将在当前激活的环境中安装NumPy和SciPy。\n列出已安装环境：\n1 conda env list 停用环境：\n1 conda deactivate 删除环境：\n1 conda remove --name myenv --all 在提交到SLURM的作业脚本中，可以激活Conda环境以确保作业在正确的软件环境中运行。以下是一个示例SLURM作业脚本：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 #!/bin/bash #SBATCH --job-name=myjob # 作业名称 #SBATCH --output=myjob.out # 标准输出和错误日志 #SBATCH --error=myjob.err # 错误日志文件 #SBATCH --ntasks=1 # 运行的任务数 #SBATCH --time=01:00:00 # 运行时间 #SBATCH --partition=compute # 作业提交的分区 # 加载Conda source ~/miniconda3/etc/profile.d/conda.sh # 激活环境 conda activate myenv # 运行命令 python my_script.py Conda与其他工具的比较\nConda vs. Virtualenv：\nConda不仅管理Python包，还能管理非Python软件包和库，如R、C++库等。 Virtualenv专注于Python环境，轻量级但功能不如Conda全面。 Conda vs. Docker/Singularity：\nConda在不需要root权限的情况下，为用户提供了灵活的软件管理方式。 Docker需要root权限，但提供更隔离的容器化环境。集群上通常不能使用。 Singularity与Docker类似，但更适合在HPC环境中使用，不需要root权限。将在后续讨论。 ","date":"2024-05-24T00:00:00Z","image":"/p/slurm/images/slurm_hu_e98eea1f55920fdb.png","permalink":"/p/slurm/","title":"Slurm集群使用基础"},{"content":"Introduction 了解控制群落多样性、功能、演替和生物地理学的机制是生态学，尤其是微生物生态学中的一个核心。推荐阅读综述：\nZhou, J. \u0026amp; Ning, D. Stochastic Community Assembly: Does It Matter in Microbial Ecology? Microbiol Mol Biol Rev 81, e00002-17 (2017). This review is very comprehensive (1)！\n周集中老师实验室的长期研究兴趣集中在从基因组到生态系统的不同组织层面的环境微生物学，其中一项就是宏基因组学和微生物生态学：利用高通量基因组测序和相关基因组学技术检查不同栖息地的微生物群落多样性、微生物生物地理学和形成微生物多样性模式、分布和动态的机制；\nUnderstanding the mechanisms controlling community diversity, functions, succession, and biogeography is a central, but poorly understood, topic in ecology, particularly in microbial ecology. Traditional niche-based theory hypothesizes that deterministic factors such as species traits, inter-species interactions (e.g., competition, predation, mutualisms, and trade-offs), and environmental conditions (e.g., pH, temperature, salt, and moisture) govern community structure, which are often referred to as deterministic processes.\nIn contrast, neutral theory assumes that community structures are independent of species traits and governed by stochastic processes of birth, death, colonization, extinction, and speciation.\nAlthough, recently, it has been generally accepted that both deterministic and stochastic processes occur simultaneously in the assembly of local communities, a central debate is on their relative importance in controlling community structure, succession, and biogeography.\nMethods 目前在文章中普遍出现的计算群落构建的方法主要有三套：\n1.Stegen （βNTI \u0026amp; RCbray-based） 原始文章： (2), (3)\n在确定性与随机性二分法的背景下塑造微生物群落多样性的生态过程。该方案显示了在文中讨论的假设下，基于系统发育和分类多样性划分各种生态过程的不同步骤。 NTI（最近分类单元指数）基于系统发育多样性指数 MNTD（平均最近分类单元距离）的空模型检验，RCBray（修正的 Raup-Crick 指数）基于 Bray-Curtis 的空模型检验分类多样性指数。这两个框分别表示确定性选择和未支配部分的主要组成部分。除了影响较小的选择外，未支配部分的弱选择也可能是由于抵消了有影响的选择因素和/或不同分类群的对比选择。该图主要是根据 Stegen 等人先前报告的数据制作的。\nbeta-NTI（nearest taxon index）： 使用 NTI/NRI 指示单个群落内共存的分类单元相比偶然预期的关系更为紧密还是分散，使用 βNTI/βNRI 指示两两群落间的变化受确定性或随机性因素影响的大小。 MNTD 即mean-nearest-taxon-distance (最近种间平均进化距离) ， 关于 NTI/NRI、βNTI/βNRI 的结果解释时其显著性的判断依据是其临界值是否大于|2|，实际上这是依据标准正态分布的 95%置信区间得到的，一般认为 NRI 或者 NTI 大于 1.96 或者小于-1.96 的结果，在 95%的水平是显著的。\nRCbray: 相异指数的一种。\ncode https://blog.csdn.net/weixin_43367441/article/details/118515090\n非常重要的一点：这类方法是基于系统发育树推断的，所以一定要有跟tax表对应的系统发育树。 如果用的是16S/ITS测序，可以通过扩增子数据多序列比对并建一个树。 如果已有物种的genome，可以根据GTDB数据库的保守基因来建树。 如果只有物种名称，替代方法是利用阶层分类关系（界门纲目科属种）来做一个拟系统发育树（枝长都为1） ，参见pctax的df2tree函数：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 library(pcutils) library(pctax) data(otutab,package = \u0026#34;pcutils\u0026#34;) df2tree(taxonomy)-\u0026gt;phylo #计算 nti_rc(otutab,phylo,metadata[,\u0026#34;Group\u0026#34;,drop=F])-\u0026gt;nti_res #可视化 nti_res$type=factor(nti_res$type,levels = c(\u0026#34;Homo_S\u0026#34;,\u0026#34;Heter_S\u0026#34;,\u0026#34;Homo_D\u0026#34;,\u0026#34;D_limit\u0026#34;,\u0026#34;Undominated\u0026#34;)) table(nti_res$type,nti_res$variable)%\u0026gt;%data.frame()%\u0026gt;% reshape2::acast(Var1~Var2)-\u0026gt;com_p stackplot(com_p)+scale_fill_pc() iCAMP 现在大家经常用的iCAMP包就是基于这个理论框架进行分析的 (4)，其进行了一定的升级优化：提出了系统发育分箱零模型。下次用在自己项目中的话可以进一步分享。\n2.ST，NST，MST （stochasticity ratio） PNAS：NST方法定量生态过程中的随机性\n周老师的新文章，开发出新的方法对生态过程中的随机性进行了定量。提出了一个新的指数，normalized stochasticity ratio (NST)，作为确定性主导（deterministic, \u0026lt;50%）和随机性主导（stochastic, \u0026gt;50%）的边界点 (5)。\ncode 已经有相应的计算R包了：NST\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 #install.packages(\u0026#34;NST\u0026#34;) library(NST) data(tda) comm=tda$comm bray=beta.g(comm,dist.method=\u0026#34;bray\u0026#34;) bray.3col=dist.3col(bray) group=tda$group tnst=tNST(comm=comm, group=group, rand=20, output.rand=TRUE, nworker=1) #检验各组ST、NST的分布情况及各组ST、NST差异的显著性。 nst.bt=nst.boot(nst.result=tnst, group=NULL, rand=99, trace=TRUE, two.tail=FALSE, out.detail=FALSE, between.group=FALSE, nworker=1) #ST和NST组间进行Permutational multivariate ANOVA nst.pova=nst.panova(nst.result=tnst, rand=99) #可视化 group_box(tnst$index.pair.grp, group = tnst$index.pair.grp$group, mode = 3,p_value2 = T) ## [1] FALSE example 地下水微生物群落演替过程中估计的 NST 动态变化对乳化植物油注入的响应。 NST 是基于 (A) Jaccard 和 (B) Ru ziˇ cka 指标使用空模型算法 PF 计算的。在零模型 PF 中，类群发生的概率与观察到的发生频率成正比，并且每个样本中的类群丰富度是固定的（19）。当使用基于丰度的指标 Ru ziˇ cka 时，每个样本中的空分类群丰度被计算为观察到的个体数量的随机抽取，其概率与样本中空分类群的区域相对丰度成比例（26）。 W8 是植物油对其没有影响或影响最小的对照井。\n3.Solan NCM 只有当物种死亡或离开这个系统时，群落结构才会发生改变。此时，离开个体的生态位就会空余出来，其它个体会通过来自群落外的迁移或群落内部的繁殖来填补空出的生态位。因此可以把群落的动态描述为死亡——繁殖/扩散——死亡这样的循环 (6)。\n计算公式：\n$Pr(\\frac{N_i+1}{N_i})=(\\frac{N_T-N_i}{N_T})[mp_i+(1+\\alpha_i)(1-m)(\\frac{N_i}{N_T-1})$\n$Pr(\\frac{N_i}{N_i})=\\frac{N_i}{N_T}[mp_i+{(1+\\alpha_i)}(1-m)(\\frac{N_i-1}{N_T-1})]+(\\frac{N_T-N_i}{N_T})[m(1-p_i)+{red}{(1-\\alpha_i)}(1-m)(\\frac{N_T-N_i-1}{N_T-1})]$\n$Pr(\\frac{N_i-1}{N_i})=\\frac{N_i}{N_T}[m(1-p_i)+(1-\\alpha_i)(1-m)(\\frac{N_T-N_i}{N_T-1})]$\n物种 i 占居的频率（occurrence frequency: row sums of binary OTU table/number of sites）为其概率密度函数的积分。 此时该分布是一个beta分布，我们就可以在R语言中利用beta分布对其进行拟合，获得参数m的评估值。\ncode 1 2 3 4 library(devtools) install_github(\u0026#34;Russel88/MicEco\u0026#34;) library(MicEco) neutral.fit(t(otutab))#使用的是最大似然估计拟合模型，R2计算方法也不同 另一个代码来自https://mp.weixin.qq.com/s/opFXl-TvkJfmPcWKFwhCFA，比较经典，用的是非线性模型:\nN描述了宏群落规模（metacommunity size），在本文中为每个样本中所有OTU的总丰度。 m量化了群落层面的迁移率（migration rate），该值对于每个群落成员都是统一的（与物种无关），m值越小说明整个群落中物种扩散越受限制，反之m值越高则表明物种受到扩散限制越低。 Nm是元群落规模（N）与迁移率（m）的乘积 (Nm = N*m)，量化了对群落之间扩散的估计，决定了发生频率和区域相对丰度之间的相关性。\n可以使用pctax中的绘图代码：\n1 2 3 data(otutab) ncm(otutab)-\u0026gt;ncm_res plot(ncm_res) R2代表了中性群落模型的整体拟合优度，R2越高表明越接近中性模型，即群落的构建受随机性过程的影响越大，受确定性过程的影响越小。\n值得注意，R方不是某个数值的平方，可以是负值。因为拟合程度没有下限，可以无限差，R方的范围是(−∞,1]。R方的取值，有以下的可能性：\n等于1。理想状况，该模型对所有的真值预测准确，没有偏差。泼个冷水，如果某篇文章里出现了R方=1，要么是问题过于简单没有研究价值，要么是模型过于复杂，对数据进行了过度拟合。\n小于1大于0。这是常见状况，表明该模型的拟合水平比均值模型好。\n等于0。该模型的拟合水平接近于均值模型。该模型没有价值。\n小于0。该模型的拟合水平不如均值模型。同样，该模型没有价值。\nexample **随机过程，例如散布、出生、死亡、灭绝和移民，在呼气细菌和真菌群落的组装中发挥作用。**真菌微生物群的 SNM 拟合性能（图 2）优于细菌（细菌 R2 = 0.353，真菌 R2 = 0.683）。这种差异表明随机过程对于 EBC 真菌群落的组装可能相对更重要，而对 EBC 细菌群落的组装则不太重要。这种现象可能与细菌和真菌之间的大小差异有关，较小的细菌受扩散限制的影响较小，而受确定性过程的影响更大 (7)。\nStochastic processes played a role in assembling expiratory bacterial (A) and fungal (B) communities based on Sloan neutral model fitting. The black solid line represents the best fit, and the dotted lines represent the 95% CI (confidence interval) around the model fit. The blue dots refer to taxa that occur more frequently than predicted, and the red dots refer to taxa that occur less frequently than predicted. The green dots refer to taxa that occur in a manner consistent with predicted values.\n原核生物细胞直径大概在0.5 ~ 2.0 μm； 微真核生物个体大小大概在1 ~ 200 mm； 之前的研究已经报道了较小的生物不太可能受到扩散限制的影响，因为它们与较大的生物相比具有更高的扩散能力。因此假设在细菌群落中生态位过程的相对影响可能比在微真核生物群落中更强。微真核生物个体大，可能会影响其扩散过程。\nOthers 参考自历神公众号文章：https://mp.weixin.qq.com/s/nwNuPlY7x6VScJA44c0MjQ\nCompetitive lottery 基于竞争彩票模型(competitive lottery model)的群落构建 假设一个两步模型:在第一步中，样本的总丰度(100%)根据某个未知的过程在组之间分配。 然后在第二步中，分配给每个小组的丰度会根据一个竞争彩票模式在小组成员之间进行分配。 竞争彩票模型的概念说明:\n在第一阶段，每个样本的总丰度(100%)在一组预定义的组之间进行分割。\n在第二阶段，每一组的丰度分配根据竞争彩票模型在子组之间进行分配，其中一个子组获得了大部分的丰度。\nDNCI 在PER-SIMPER方法的基础上，提出了一个新的度量指标: dispersal–niche continuum index (DNCI)，该指数可估计是扩散过程还是生态位过程主导群落的构建，并便于不同数据集之间的比较。\nPER-SIMPER利用物种在不同站点之间的矩阵，在排列过程中生成三种不同的零模型： 通过约束行(生态位构建)、约束列(扩散构建)或两者都约束。 PER-SIMPER利用SIMPER方法对原始群落矩阵组成相似度模式进行建模，并与三个零模型比较。 PER-SIMPER通过识别哪个零模型与经验分析最匹配来进行定性评估。然而，大多数群落都是由生态位和扩散过程共同构成的，这限制了构建机制定性方法的敏感性。此外简单决策过程的定性特性使不同群落之间的构建过程难以进行精确比较。\nPER-SIMPER分析返回三个E-metric分布,这与SIMPER经验值与三个PER-SIMPER零模型之间的偏差相关。本文提出的新的DNCI是由这些计算的E值推导而来的。 定量结果是基于标准效应量En(即来自”生态位”模型的E-metric分布)减去标准效应量Ed (即来自”扩散”模型的E-metric分布)。 DNCI提供了一种方法来量化和比较跨数据集构建过程的强度。DNCI值正或负表明生态位或分散过程分别是群组构建的主要过程。指数的绝对值越高，代表占主导地位的构建过程的潜力越大。\n$$ DNCI=SES_d-SES_n=\\frac{1}{n}\\sum_{i=1}^n\\left(\\frac{E_{d(i)}-\\overline {E_{dn}}}{\\sigma E_{dn}}\\right)-\\frac{1}{n}\\sum_{i=1}^n\\left(\\frac{E_{n(i)}-\\overline {E_{dn}}}{\\sigma E_{dn}}\\right) $$\n如果DNCI与0差异不显著，则可以认为扩散过程和生态位过程对群落构建的影响是相等的。 当DNCI显著低于0时，扩散过程是群落构建的主导驱动因素; 如果DNCI显著高于0，生态位过程是群落构建的主要决定因素。 注意，表明扩散过程优势的负DNCI值并不能提供实际扩散速率的信息。\nReferences 1. J. Zhou, D. Ning, Stochastic Community Assembly: Does It Matter in Microbial Ecology? Microbiology and Molecular Biology Reviews. 81, e00002–17 (2017).\n2. J. C. Stegen, X. Lin, J. K. Fredrickson, X. Chen, et al., Quantifying community assembly processes and identifying features that impose them. The ISME Journal. 7, 2069–2079 (2013).\n3. J. C. Stegen, X. Lin, A. E. Konopka, J. K. Fredrickson, Stochastic and deterministic assembly processes in subsurface microbial communities. The ISME Journal. 6, 1653–1664 (2012).\n4. D. Ning, M. Yuan, L. Wu, Y. Zhang, et al., A quantitative framework reveals ecological drivers of grassland microbial community assembly in response to warming. Nature Communications. 11, 4717 (2020).\n5. D. Ning, Y. Deng, J. M. Tiedje, J. Zhou, A general framework for quantitatively assessing ecological stochasticity. Proceedings of the National Academy of Sciences. 116, 16892–16898 (2019).\n6. W. T. Sloan, M. Lunn, S. Woodcock, I. M. Head, et al., Quantifying the roles of immigration and chance in shaping prokaryote community structure. Environmental Microbiology. 8, 732–740 (2006).\n7. Y. Zhang, F. Shen, Y. Yang, M. Niu, et al., Insights into the Profile of the Human Expiratory Microbiota and Its Associations with Indoor Microbiotas. Environmental Science \u0026amp; Technology. 56, 6282–6293 (2022).\n","date":"2024-05-23T00:00:00Z","image":"/p/community-assembly/comm_hu_2bd25e201a68942b.jpg","permalink":"/p/community-assembly/","title":"微生物群落构建（community assembly）"},{"content":"Introduction GTDB（Genome Taxonomy Database）是一个专注于基因组分类学的数据库，旨在提供高质量的细菌、古细菌、叶绿体和线粒体的分类信息。通过使用全基因组信息，GTDB提供了多级别的分类，包括域、界、纲、目、科、属等级别。其系统发育分类系统使得研究人员能够深入了解生物的演化和功能。GTDB主要以细菌中普遍存在的120个单拷贝蛋白质（bac120）和古菌中53个（arc53，从R07-RS207开始）标记蛋白为基础，在对多分组类别消歧后，根据相对演化散度标准化和分级，得到基因组分类结果。\nGTDB定期更新，与其他生物信息数据库整合，为基因组学研究和微生物生态学等领域的研究提供了全面且可靠的分类信息。GTDB数据库已经于2018/2020连续发表两篇Nature Biotechnology，2021年又发表在Nature Microbiology和Nucleic Acids Research上，是目前最权威的微生物分类数据库之一。 GTDB配套软件在2019/2022发表了两篇Bioinformatcs，时提供了物种分类、进化树构建的全套工具。\n官网：https://gtdb.ecogenomic.org/\nGTDB数据库 可以看到上面的官网主页，目前最新版的GTDB数据库包含了584,382个细菌基因组和12,477个古菌基因组（2024.04.24，Release 09-RS220），在属、种分辨率水平上描述了190多个门。\nBrowsers GTDB支持以Alphabetical table和Tree两种形式来探索或查询整个GTDB数据库，包括分类信息和基因组信息。\n此外，可以在Taxon History输入 GTDB 或 NCBI 分类单元，以可视化分配给该分类单元的基因组在版本之间如何变化，比如p__Proteobacteria从Release 214开始改名为p__Pseudomonadota，在不断壮大的同时也有一部分genome被分配给了其他门。\nTools GTDB提供了一些配套的工具：\nGTDB-Tk：下一章节详细介绍 Third-party tools：AnnoTree，IDTAXA，SingleM，sourmash Third-party GTDB databases：HUMANn2，Kraken2，Bracken2，Centrifuge，Kraken，DADA2等 Third-party scripts：tax_from_gtdb.py，genome_updater，gtdb_to_taxdump FastANI calculator：可用于原核生物 NCBI 基因组的ANI比较，一次最多可以进行 1,000 次成对比较，例如下图。 Downloads 该页面提供了GTDB数据库和配套软件的下载链接。\nStatistics 统计页面提供了各个版本的GTDB数据库的各类基础信息：\nTaxon overview：GTDB R220 包含 596,859 个基因组，组织成 113,104 个物种簇。\nSpecies overview：GTDB R220 由 584,382 个细菌和 12,477 个古细菌基因组组成，分为 107,235 个细菌和 5,869 个古细菌物种簇。\nGenome categories：GTDB 分类群由分离基因组（isolate）、宏基因组组装基因组 (MAG) 和单扩增基因组 (SAG) 组成。\nGTDB species representatives：每个 GTDB 物种簇都由一个基因组表示。\nQuality of GTDB representative genomes：被选为 GTDB 物种代表的基因组的质量。使用 CheckM 估计基因组完整性和污染，并根据 MIMAG 基因组标准进行着色。一般来说，代表性基因组仅限于满足completeness - 5*contamination \u0026gt;50，存在一些例外情况，如下面所示。 Taxa with the largest number of species：给出了每个分类等级包含最多 GTDB 物种簇的分类单元，门水平是常见的Pseudomonadota，Bacillota，Bacteroidota，Actinomycetota等。\nTaxa with the largest number of sequenced genomes，与6类似。\nRelative evolutionary divergence（RED）：提供了从门到属的每个分类等级的类群的相对进化分歧（RED）。 RED 值提供了相对时间的操作近似值，其中现有分类群存在于当前 (RED=1)，最后一个共同祖先出现在过去的固定时间 (RED=0)，内部节点根据以下值在这些值之间线性插值谱系特定的进化速率。\nComparison of GTDB and NCBI taxa：GTDB 物种代表性基因组和所有具有分配的 NCBI 分类法的 GTDB 基因组的 GTDB 和 NCBI 分类学分配的比较。对于每个分类等级，如果一个分类单元在两个分类标准中名称相同，则该分类单元被分类为unchange；如果 GTDB 分类标准提供了 NCBI 分类标准中缺少的名称信息，则该分类单元被分类为passive change；如果两个分类标准之间的名称不同，则该分类单元被分类为actively changed。可以看到，在genome水平上GTDB和NCBI还是有很多名称不对应的，可以考虑使用gtdb_to_taxdump进行转化。 Genomic statistics：GTDB 物种代表性基因组和 GTDB 中所有基因组的关键基因组统计数据。 Nomenclatural types per rank：显示了每个分类等级的占位符与拉丁化名称的细分。\nForum GTDB还专门搭建了一个用户社区和讨论区：\nAnnouncement：用于公布最新 GTDB 新闻、即将举行的会议和以分类学为重点的手稿的开放论坛。 Taxonomy (Bacteria/Archaea)：这个分类专注于讨论与GTDB分类法相关的内容。用户在这里讨论分类法的具体细节、与其他数据库（如NCBI）的比较、分类标准的更新等。 GTDB-Tk：专注于GTDB-Tk工具包的使用和讨论。用户可以在这里提出关于GTDB-Tk的使用问题、分享使用经验、讨论工具包的功能和性能等。 GTDB：与基因组分类数据库 (GTDB) 相关的一般问题。 Website feedback：讨论该网站、其组织、其运作方式以及如何改进它。 Help 帮助页面也提供了一些非常有用的信息。\nAbout：GTDB简要介绍，管理团队以及发表论文\nFAQ：列出了一些常见问题，例如：\n为什么门名称的后缀更改为-ota？Whitman et al. (2018) 建议像其他等级一样规范门等级的后缀。 为什么一些family和更高级别的名字以字母后缀结尾？属等级以上的分类单元名称附加字母后缀表示属于以下类别的类群： GTDB 参考树中不是单系类群，但存在其他证据表明它们是单系类群； 在版本之间位置不稳定的组。 Methods：对GTDB数据库构建过程中的方法进行具体描述，例如：\nGene identification，使用Prodigal鉴定基因，HMMER鉴定标记基因（来自Pfam和TIGRFAM）并序列比对。 Multiple sequence alignment，细菌和古菌多重序列比对 (MSA) 分别由 120 个 (bac120) 或 53 个 (arc53) 系统发育信息标记串联而成。 Tree inference，细菌参考树是在 WAG 模型下使用 FastTree。古菌参考树是根据 PMSF 模型下的 IQ-Tree，并使用 FastTree推断初始树以恢复单系谱系。 Identifying 16S rRNA sequences，使用 nhmmer以及来自 RFAM 数据库的 16S rRNA 模型（RF00177）。 Average nucleotide identity，skani（从版本 220 开始），之前是FastANI。 RED normalization：相对进化分歧用于帮助描绘物种等级之上的分类群，RED的概念是相同等级的类群在过去应该同时出现。RED 提供了相对时间的操作近似值，其中现有分类群存在于当前 (RED = 1)，最后一个共同祖先出现在过去的固定时间 (RED = 0)，内部节点根据谱系在这些值之间线性插值-特定的进化速率。 API：功能较多，但文档不是很详细，未来也许会用上\nGTDB-Tk GTDB-Tk 是一个软件工具包，用于根据基因组数据库分类法 (GTDB) 对细菌和古细菌基因组进行客观分类。 它旨在与最新进展相结合，允许直接从环境样本中获得数百或数千个宏基因组组装基因组 (MAG)，还可以应用于分离和单细胞基因组。\n地址：https://github.com/Ecogenomics/GTDBTk\n官方文档：https://ecogenomics.github.io/GTDBTk/\nInstall 首先要安装软件和下载对应的Reference data，最新的R220数据库需要使用v2.4.0的GTDB-Tk（2024.04.24）。如果要和之前项目一致，可以使用R214版本数据库对应v2.3.2的GTDB-Tk。\n1.conda conda安装比较简单，但最好新建一个环境，可能会比较慢（mamba代替conda会快一点）：\n1 2 3 4 5 6 7 8 # using conda conda create -n gtdbtk-2.3.2 -c conda-forge -c bioconda gtdbtk=2.3.2 # 下载 GTDB-Tk 参考数据并为其命名 download-db.sh # 激活GTDB-Tk conda环境 conda 激活 gtdbtk-2.3.2 # 将环境变量设置为包含GTDB-Tk参考数据的目录 conda env config vars set GTDBTK_DATA_PATH=\u0026#34;/path/to/release/package/\u0026#34;; 2.pip pip可以快速安装gtdbtk包，但是它的第三方依赖项需要手动安装一下 （不是很复杂，我用的pip安装，因为不想要太多的conda环境，太冗余了）：\n1 python -m pip install gtdbtk==2.3.2 第三方依赖项：\nProdigal（原核基因识别和翻译起始位点鉴定） HMMER（加速族HMM 搜索） pplacer（线性时间最大似然和贝叶斯系统发育将序列放置到固定参考树上） skani (v2.4.0开始依赖，通过 skani 的稀疏链接进行快速、稳健的宏基因组序列比较，比fastANI还快，下次有机会讲一下这个) FastTree（用于大对齐的近似最大似然树） Mash（快速估计基因组和宏基因组距离） 这些都是很常用的软件，没有的话用conda安装一下。\nGTDB-Tk 需要将 GTDBTK_DATA_PATH 环境变量设置为包含未存档的 GTDB-Tk 参考数据的目录。\n1 2 echo \u0026#39;export GTDBTK_DATA_PATH=/path/to/release/package/\u0026#39; \u0026gt;\u0026gt; ~/.bashrc source ~/.bashrc 3.docker 如果用过docker的话，这个也非常简单：\n1 2 3 4 5 6 #下载解压的 GTDB-Tk 参考数据到您选择的目录，例如：/host/release_data/ mv /path/to/release/package/ /host/release_data/ #为 GTDB-Tk 创建本地 I/O 目录 mkdir /host/gtdbtk_io/ # 运行容器 docker run -v /host/gtdbtk_io:/data -v /host/release_data:/refdata ecogenomic/gtdbtk classify_wf --genome_dir /data/genomes --out_dir /data/output Reference data GTDB-Tk 需要约 110G 的外部数据，需要下载和解档。直接wget很慢的话，也可以先下载到本地，再通过FTP软件或scp上传到服务器：\n数据地址：https://data.gtdb.ecogenomic.org/releases/latest/auxillary_files/gtdbtk_package/\n对于完整包(full package)：\n1 2 wget https://data.ace.uq.edu.au/public/gtdb/data/releases/latest/auxillary_files/gtdbtk_package/full_package/gtdbtk_data.tar.gz tar xvzf gtdbtk_data.tar.gz 对于拆分包(split package)：\n确保 GTDB-Tk 发布数据的所有部分都位于同一目录中。 打开终端或命令提示符。 导航到包含 GTDB-Tk 发布数据部分的目录。 使用以下命令将所有部分连接到一个存档中： cat gtdbtk_r220_data.tar.gz.part_* \u0026gt; gtdbtk_r220_data.tar.gz 命令执行完成后，将在同一目录中拥有一个名为“gtdbtk_r220_data.tar.gz”的存档文件。 Check 检查数据库和软件，结果显示OK和Done表示正常（检查fastani这一步要很久，文件非常多。所以如果三方软件都OK的话也可以直接运行下一个示例测试）:\n1 gtdbtk check_install [2024-05-20 14:10:37] INFO: GTDB-Tk v2.3.2 [2024-05-20 14:10:37] INFO: gtdbtk check_install [2024-05-20 14:10:37] INFO: Using GTDB-Tk reference data version r214: /data/home/jianglab/share/GTDB_r214/release214/ [2024-05-20 14:10:37] INFO: Running install verification [2024-05-20 14:10:37] INFO: Checking that all third-party software are on the system path: [2024-05-20 14:10:37] INFO: |-- FastTree OK [2024-05-20 14:10:37] INFO: |-- FastTreeMP OK [2024-05-20 14:10:37] INFO: |-- fastANI OK [2024-05-20 14:10:37] INFO: |-- guppy OK [2024-05-20 14:10:37] INFO: |-- hmmalign OK [2024-05-20 14:10:37] INFO: |-- hmmsearch OK [2024-05-20 14:10:37] INFO: |-- mash OK [2024-05-20 14:10:37] INFO: |-- pplacer OK [2024-05-20 14:10:37] INFO: |-- prodigal OK [2024-05-20 14:10:37] INFO: Checking integrity of reference package: /data/home/jianglab/share/GTDB_r214/release214/ [2024-05-20 14:10:38] INFO: |-- pplacer OK [2024-05-20 14:10:38] INFO: |-- masks OK [2024-05-20 14:10:39] INFO: |-- markers OK [2024-05-20 14:10:39] INFO: |-- radii OK [2024-05-20 14:10:41] INFO: |-- msa OK [2024-05-20 14:10:41] INFO: |-- metadata OK [2024-05-20 14:10:41] INFO: |-- taxonomy OK [2024-05-20 15:13:45] INFO: |-- fastani OK [2024-05-20 15:13:45] INFO: |-- mrca_red OK [2024-05-20 15:13:45] INFO: Done. 注意GTDB-Tk的硬件要求，关键是Memory一定要给足够，不然会程序会中途终止：\nDomain Memory Storage Time Archaea ~60 GB ~106 GB ~90 minutes / 1,000 genomes @ 64 CPUs Bacteria ~90GB (545 GB when using –full_tree) ~106 GB ~90 minutes / 1,000 genomes @ 64 CPUs 测试流程，无报错确定程序的软件和数据库正常（此示例是3个古菌genome，建议分配60GB内存来运行，另外gtdbtk_test必须是不存在的或空文件夹）:\n1 gtdbtk test --out_dir gtdbtk_test [2024-05-20 14:34:51] INFO: GTDB-Tk v2.3.2 [2024-05-20 14:34:51] INFO: gtdbtk test --out_dir gtdbtk_test [2024-05-20 14:34:51] INFO: Using GTDB-Tk reference data version r214: /data/home/jianglab/share/GTDB_r214/release214/ [2024-05-20 14:34:51] INFO: Command: gtdbtk classify_wf --skip_ani_screen --genome_dir gtdbtk_test/genomes --out_dir gtdbtk_test/output --cpus 1 -f \u0026lt;TEST OUTPUT\u0026gt; [2024-05-20 14:34:52] INFO: gtdbtk classify_wf --skip_ani_screen --genome_dir gtdbtk_test/genomes --out_dir gtdbtk_test/ \u0026lt;TEST OUTPUT\u0026gt; [2024-05-20 14:34:52] INFO: Using GTDB-Tk reference data version r214: /data/home/jianglab/share/GTDB_r214/release214/ \u0026lt;TEST OUTPUT\u0026gt; [2024-05-20 14:42:06] INFO: Note that Tk classification mode is insufficient for publication of new taxonomic designatio \u0026lt;TEST OUTPUT\u0026gt; [2024-05-20 14:42:06] INFO: Done. [2024-05-20 14:42:09] INFO: Test has successfully finished. 我分配了4核共60GB内存运行gtdbtk test，约439s完成，消耗了~45GB内存。\n使用方法 先看看help文档：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 $ gtdbtk -h ## GTDB-Tk v2.4.0 帮助文档 Workflows: classify_wf -\u0026gt; 通过在 GTDB 参考树中的位置对基因组进行分类 (ani_screening -\u0026gt; identify -\u0026gt; align -\u0026gt; classify) de_novo_wf -\u0026gt; 推断新的树并使用 GTDB 分类进行修饰 (identify -\u0026gt; align -\u0026gt; infer -\u0026gt; root -\u0026gt; decorate) Methods: identify -\u0026gt; 识别基因组中的标记基因 align -\u0026gt; 创建多序列比对 classify -\u0026gt; 确定基因组的分类 infer -\u0026gt; 从多序列比对中推断树 root -\u0026gt; 使用外群对树进行根定 decorate -\u0026gt; 用 GTDB 分类修饰树 Tools: infer_ranks -\u0026gt; 利用RED建立内部节点的分类等级 ani_rep -\u0026gt; 计算ANI到GTDB的代表性基因组 trim_msa -\u0026gt; 基于掩码修剪未修剪的MSA文件 export_msa -\u0026gt; 导出未修剪的古生菌或细菌MSA文件 remove_labels -\u0026gt; 从Newick树中删除标签(引导值，节点标签) convert_to_itol -\u0026gt; 将GTDB-Tk Newick树转换为iTOL树 convert_to_species -\u0026gt; 将GTDB基因组id转换为GTDB物种名称 Testing: test -\u0026gt; 用3个古细菌基因组验证classify_wf管道 check_install -\u0026gt; 验证第三方程序和GTDB参考包 对于每一个模块可以单独查看help，例如最重要的classify_wf工作流：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 $ gtdbtk classify_wf -h usage: gtdbtk classify_wf (--genome_dir GENOME_DIR | --batchfile BATCHFILE) --out_dir OUT_DIR (--skip_ani_screen | --mash_db MASH_DB) [--no_mash] [--mash_k MASH_K] [--mash_s MASH_S] [--mash_v MASH_V] [--mash_max_distance MASH_MAX_DISTANCE] [-f] [-x EXTENSION] [--min_perc_aa MIN_PERC_AA] [--prefix PREFIX] [--genes] [--cpus CPUS] [--pplacer_cpus PPLACER_CPUS] [--force] [--scratch_dir SCRATCH_DIR] [--write_single_copy_genes] [--keep_intermediates] [--min_af MIN_AF] [--tmpdir TMPDIR] [--debug] [-h] mutually exclusive required arguments: --genome_dir GENOME_DIR 包含FASTA格式基因组文件的目录 --batchfile BATCHFILE 描述基因组的文件路径 - 2或3列的制表符分隔文件（FASTA文件、基因组ID、翻译表[可选]） required named arguments: --out_dir OUT_DIR 输出文件的目录 mutually exclusive required arguments: --skip_ani_screen 跳过ani筛选步骤，使用mash和skani对基因组进行分类。（默认：False） --mash_db MASH_DB 保存/读取Mash参考草图数据库（.msh）的路径 optional Mash arguments: --no_mash 跳过使用Mash进行的基因组预过滤（默认：False） --mash_k MASH_K k-mer大小[1-32]（默认：16） --mash_s MASH_S 最大非冗余哈希数（默认：5000） --mash_v MASH_V 保留的最大p值[0-1]（默认：1.0） --mash_max_distance MASH_MAX_DISTANCE 选择潜在GTDB基因组作为用户基因组代表的最大Mash距离。（默认：0.15） optional arguments: -f，--full_tree 在分类步骤中使用未分割的细菌树；这是原始的GTDB-Tk方法（版本\u0026lt;2）， 需要超过320 GB的RAM来加载参考树（默认：False） -x，--extension EXTENSION 要处理的文件扩展名，gz = gzipped（默认：fna） --min_perc_aa MIN_PERC_AA 排除在MSA中AA百分比不足此值的基因组（包含界限）（默认：10） --prefix PREFIX 所有输出文件的前缀（默认：gtdbtk） --genes 表示输入文件包含预测的蛋白质（作为氨基酸），跳过基因调用。 警告：此标志将跳过ANI比较步骤（ani筛选和分类）。（默认：False） --cpus CPUS 要使用的CPU数量（默认：1） --pplacer_cpus PPLACER_CPUS pplacer放置过程中使用的CPU数量 --force 如果单个基因组发生错误，则继续处理（默认：False） --scratch_dir SCRATCH_DIR 通过写入磁盘来减少pplacer内存使用（较慢） --write_single_copy_genes 输出未对齐的单拷贝标记基因（默认：False） --keep_intermediates 在最终目录中保留中间文件（默认：False） --min_af MIN_AF 将基因组分配到物种簇的最小对齐比例（默认：0.5） --tmpdir TMPDIR 指定临时文件的备用目录（默认：/tmp） --debug 创建用于调试目的的中间文件（默认：False） classify_wf 注释物种 classify_wf全称为 Classify workflow，即分类工作流程。\n分类工作流程由四个步骤组成：ani_screen（v2.4.0开始加入）, identify, align, classify.\nani_screen 步骤将用户基因组与由所有 GTDB 代表性基因组组成的 Mash 数据库进行比较，然后使用 skani 验证最佳的 mash 命中。使用 skani 分类的用户基因组不会运行管道的其余部分（识别、对齐、分类），并在摘要文件中报告。 identify步骤使用 Prodigal 调用基因，并使用 HMM 模型和 HMMER 包来识别用于系统发育推断的 120 个细菌和 53 个古细菌标记基因 (Parks et al., 2018)。通过将标记基因与其各自的 HMM 模型进行比对来获得多重序列比对 (MSA)。 align步骤连接比对的标记基因，并将连接的 MSA 过滤为大约 5,000 个氨基酸。 最后，classify步骤使用 pplacer 查找 GTDB-Tk 参考树中每个基因组的最大似然位置。 GTDB-Tk 根据每个基因组在参考树中的位置、相对进化分歧和/或与参考基因组的平均核苷酸同一性 (ANI) 对每个基因组进行分类。 1 2 # 输入基因组目录 gtdbtk classify_wf --genome_dir genomes/ --out_dir classify_wf_out --cpus 16 可以根据下图估计自己的任务运行时间，评估资源分配： output GTDB-Tk 在classify_wf管道的各个阶段输出许多文件，具体格式和示例可以在官网查看： https://ecogenomics.github.io/GTDBTk/files/index.html\n结果目录(classify_wf_out/output)中主要结果文件 (ar53为古菌相关文件，bac120为细菌相关文件)：\nclassify/gtdbtk.ar53.classify.tree 树文件，Newick格式，可以用于系统发育树的绘制。 classify/gtdbtk.ar53.summary.tsv 分类结果文件，主要结果，可以用于系统发育树的注释。 identify/gtdbtk.ar53.markers_summary.tsv 使用标记基因情况 align/gtdbtk.ar53.msa.fasta.gz 多序列对齐文件(输入+参考) align/gtdbtk.ar53.user_msa.fasta.gz 多序列对齐文件(输入) 绘制系统发育树可以参考我之前写的R绘制优美的进化树（基础）和R绘制优美的进化树（进阶），或者使用iPhylo网站来交互式绘图：iPhylo 生成并绘制优美的分类树。\n分步示例 获取数据 此示例将使用以下两个基因组：基因组A：GCF_003947435.1 [GTDB / NCBI]，基因组B：GCA_002011125.1 [GTDB / NCBI]\n1 2 3 4 # 获取基因组。 mkdir -p gtdbtk_test_steps/genomes wget -q https://ftp.ncbi.nlm.nih.gov/genomes/all/GCF/003/947/435/GCF_003947435.1_ASM394743v1/GCF_003947435.1_ASM394743v1_genomic.fna.gz -O gtdbtk_test_steps/genomes/genome_a.fna.gz wget -q https://ftp.ncbi.nlm.nih.gov/genomes/all/GCA/002/011/125/GCA_002011125.1_ASM201112v1/GCA_002011125.1_ASM201112v1_genomic.fna.gz -O gtdbtk_test_steps/genomes/genome_b.fna.gz 基因鉴定 (identify) 可以通过classify_wf单步完成，但是有时候分步流程更适合处理大数据（可以自行分配每一步的资源）：\n1 2 3 ls -l gtdbtk_test_steps/genomes # –extension，gz是基因组文件的后缀名 gtdbtk identify --genome_dir gtdbtk_test_steps/genomes --out_dir gtdbtk_test_steps/identify --extension gz --cpus 2 [2024-05-20 15:25:20] INFO: GTDB-Tk v2.3.2 [2024-05-20 15:25:20] INFO: gtdbtk identify --genome_dir gtdbtk_test_steps/genomes --out_dir gtdbtk_test_steps/identify --extension gz --cpus 2 [2024-05-20 15:25:20] INFO: Using GTDB-Tk reference data version r214: /data/home/jianglab/share/GTDB_r214/release214/ [2024-05-20 15:25:20] INFO: Identifying markers in 2 genomes with 2 threads. [2024-05-20 15:25:20] TASK: Running Prodigal V2.6.3 to identify genes. [2024-05-20 15:25:30] INFO: Completed 2 genomes in 9.31 seconds (4.65 seconds/genome). [2024-05-20 15:25:30] TASK: Identifying TIGRFAM protein families. [2024-05-20 15:25:38] INFO: Completed 2 genomes in 7.16 seconds (3.58 seconds/genome). [2024-05-20 15:25:38] TASK: Identifying Pfam protein families. [2024-05-20 15:25:38] INFO: Completed 2 genomes in 0.59 seconds (3.37 genomes/second). [2024-05-20 15:25:38] INFO: Annotations done using HMMER 3.3.2 (Nov 2020). [2024-05-20 15:25:38] TASK: Summarising identified marker genes. [2024-05-20 15:25:38] INFO: Completed 2 genomes in 0.03 seconds (75.34 genomes/second). [2024-05-20 15:25:38] INFO: Done. 耗时40s，内存消耗131.76MB。\n产生idetity/文件夹，关注摘要文件gtdbtk_test_steps/identify/identify/gtdbtk.ar53.markers_summary.tsv，其中详细介绍了从古细菌 53 或细菌 120 标记组中识别出的标记。\n还可以在每个基因组对应的中间文件目录下找到被调用的基因和标记信息:\n1 ls gtdbtk_test_steps/identify/identify/intermediate_results/marker_genes/genome_a.fna/ 基因比对 (align) 比对步骤将对齐所有已识别的标记，确定最可能的域并输出串联的MSA:\n1 gtdbtk align --identify_dir gtdbtk_test_steps/identify --out_dir gtdbtk_test_steps/align --cpus 2 [2024-05-20 15:32:01] INFO: GTDB-Tk v2.3.2 [2024-05-20 15:32:01] INFO: gtdbtk align --identify_dir gtdbtk_test_steps/identify --out_dir gtdbtk_test_steps/align --cpus 2 [2024-05-20 15:32:01] INFO: Using GTDB-Tk reference data version r214: /data/home/jianglab/share/GTDB_r214/release214/ [2024-05-20 15:32:03] INFO: Aligning markers in 2 genomes with 2 CPUs. [2024-05-20 15:32:04] INFO: Processing 2 genomes identified as archaeal. [2024-05-20 15:32:06] INFO: Read concatenated alignment for 4,416 GTDB genomes. [2024-05-20 15:32:06] TASK: Generating concatenated alignment for each marker. [2024-05-20 15:32:06] INFO: Completed 2 genomes in 0.02 seconds (130.19 genomes/second). [2024-05-20 15:32:06] TASK: Aligning 52 identified markers using hmmalign 3.3.2 (Nov 2020). [2024-05-20 15:32:06] INFO: Completed 52 markers in 0.43 seconds (121.60 markers/second). [2024-05-20 15:32:06] TASK: Masking columns of archaeal multiple sequence alignment using canonical mask. [2024-05-20 15:32:10] INFO: Completed 4,418 sequences in 3.59 seconds (1,231.58 sequences/second). [2024-05-20 15:32:10] INFO: Masked archaeal alignment from 13,540 to 10,135 AAs. [2024-05-20 15:32:10] INFO: 0 archaeal user genomes have amino acids in \u0026lt;10.0% of columns in filtered MSA. [2024-05-20 15:32:10] INFO: Creating concatenated alignment for 4,418 archaeal GTDB and user genomes. [2024-05-20 15:32:12] INFO: Creating concatenated alignment for 2 archaeal user genomes. [2024-05-20 15:32:12] INFO: Done. 耗时10s，内存忽略不计（因为这里只有两个genome，输入的多了还是要考虑这步的内存的）\n产生align/文件夹，如果基因组识别出的标记数量较少，它将被排除在这一步的分析之外。如果是这种情况，将会出现Warning。\n根据基因组Domain的不同，将出现 ar53 或 bac120 前缀文件。\ngtdbtk.ar53.msa.fasta.gz：其中包含用户基因组和 GTDB基因组的 MSA。 gtdbtk.ar53.user_msa.fasta.gz：仅包含用户基因组 物种分类 (classify) 分类步骤会将基因组放入参考树中，然后确定其最可能的分类。\n1 gtdbtk classify --genome_dir gtdbtk_test_steps/genomes --align_dir gtdbtk_test_steps/align --out_dir gtdbtk_test_steps/classify -x gz --cpus 2 --skip_ani_screen [2024-05-20 15:42:48] INFO: GTDB-Tk v2.3.2 [2024-05-20 15:42:48] INFO: gtdbtk classify --genome_dir gtdbtk_test_steps/genomes --align_dir gtdbtk_test_steps/align --out_dir gtdbtk_test_steps/classify -x gz --cpus 2 --skip_ani_screen [2024-05-20 15:42:48] INFO: Using GTDB-Tk reference data version r214: /data/home/jianglab/share/GTDB_r214/release214/ [2024-05-20 15:42:49] TASK: Placing 2 archaeal genomes into reference tree with pplacer using 2 CPUs (be patient). [2024-05-20 15:42:49] INFO: pplacer version: v1.1.alpha19-0-g807f6f3 [2024-05-20 15:48:46] INFO: Calculating RED values based on reference tree. [2024-05-20 15:48:48] TASK: Traversing tree to determine classification method. [2024-05-20 15:48:48] INFO: Completed 2 genomes in 0.00 seconds (8,621.39 genomes/second). [2024-05-20 15:48:48] TASK: Calculating average nucleotide identity using FastANI (v1.33). [2024-05-20 15:48:52] INFO: Completed 6 comparisons in 2.69 seconds (2.23 comparisons/second). [2024-05-20 15:48:52] INFO: 2 genome(s) have been classified using FastANI and pplacer. [2024-05-20 15:48:52] INFO: Note that Tk classification mode is insufficient for publication of new taxonomic designations. New designations should be based on one or more de novo trees, an example of which can be produced by Tk in de novo mode. [2024-05-20 15:48:52] INFO: Done. 耗时368s，内存消耗45GB（因为这里只有两个古菌genome，如果还有细菌的话应该分配100GB左右）\n产生align/文件夹，摘要文件gtdbtk.ar53.summary.tsv和包含这些基因组的参考树gtdbtk.ar53.classify.tree。\n注意事项 为什么 GTDB-Tk 和 NCBI 或 Silva 分类名称之间的命名系统存在差异？ GTDB-Tk 使用 GTDB 分类法 (https://gtdb.ecogenomic.org/)。此分类法与NCBI 和 Silva 类似，但不完全相同。 在许多情况下，GTDB分类法更严格地遵循等级后缀的命名规则，比如GTDB有 Nitrospirota 而没有Nitrospirae。\n可以将细菌树和古细菌树合并成一棵树吗？ 细菌树和古细菌树是从不同的标记基因推断出来的。目前，这些树的正确生根仍然是一个开放的研究领域。 GTDB-Tk 不提供合并树的工具，但可以通过操作 Newick文件来人为地组合它们。\nGTDB-Tk 如何使用平均核苷酸同一性（ANI）验证物种分配？ GTDB-Tk 使用 skani（在 v2.3.2 之前一直使用 fastANI）来估计基因组之间的ANI。 仅当基因组之间的 ANI 在物种 ANI 限制半径内（通常为 95%）且比对分数(AF)\u0026gt;=0.5时，查询基因组才被分类为与参考基因组属于同一物种。 在某些情况下，查询基因组的系统发育位置可能不支持物种分配。\n互斥选项 --mash_db 和 --skip_ani_screen 之间有什么区别？ 从 GTDB-Tk v2.2+ 开始，classify_wf和分类函数需要额外的参数才能运行：--mash_db 或 --skip_ani_screen。\n使用新版本的 GTDB-Tk v2.4.0，分类管道（classify_wf 和 classify）的第一阶段是将所有用户基因组与所有参考基因组进行比较，并在可能的情况下根据ANI 匹配对它们进行注释。 使用 --mash_db 选项将向 GTDB-Tk 指示 ANI筛选所需的草图 Mash 数据库的路径。 如果没有可用的数据库（即这是第一次运行分类），则 --mash_db选项将绘制一个可用于后续调用的新 Mash 数据库。 --skip_ani_screen 选项将跳过预筛选步骤并对所有基因组进行分类，类似于之前版本的 GTDB-Tk。\n","date":"2024-05-20T00:00:00Z","image":"/p/gtdb/images/gtdb_hu_f905914162e54229.png","permalink":"/p/gtdb/","title":"GTDB基因组分类数据库及GTDB-Tk工具"},{"content":"Introduction ANI 是指平均核苷酸一致性（Average Nucleotide Identity），它是一种用来比较两种基因组之间相似度的方法。 ANI 主要用于微生物基因组学和系统生物学，以评估不同细菌或古菌基因组之间的相似性。 它被广泛应用于种的分类、基因组分类以及新物种的鉴定。\nANI 一般通过以下步骤计算：\n基因组切割：将两个基因组切割成小片段。 片段比对：使用序列比对工具将片段进行两两比对。 相似性计算：计算每对片段的相似度得分。 平均值计算：对所有比对片段的相似度得分取平均值，得到 ANI 值。 常用的 ANI 计算工具：\nANI calculator：http://enve-omics.ce.gatech.edu/ani/ 可以快速计算两个genome的 ANI 值。 JSpecies：一个基于 Java 的工具，提供图形界面和命令行两种使用方式，适合不同需求的用户。 FastANI：一个高效的 ANI 计算工具，适用于处理大规模基因组数据。 PyANI：一个基于 Python 的工具包，支持多种 ANI 计算方法（如 MUMmer、BLAST）。 OrthoANI：提供网络服务和命令行工具，适用于比较较大的基因组数据。 Skani：使用 MinHash 技术和线性空间算法，能够快速处理大规模基因组数据。 GTDB数据库构建的时候就需要进行巨大规模的ANI计算分析，他们使用的就是FastANI（v2.3.2之前）和Skani（最新的v2.4.0，更快），接下来简要介绍一下这两款软件。\nFastANI FastANI 专为全基因组平均核苷酸一致性 (ANI) 的快速免比对计算而开发。 ANI 被定义为两个微生物基因组之间共享的直系同源基因对的平均核苷酸一致性。\nFastANI 支持完整基因组组装和草图基因组组装的成对比较。其基本过程遵循 Goris 等人描述的类似工作流程， 它避免了麻烦的序列比对，并使用 Mashmap 作为其基于 MinHash 的序列映射引擎来计算直系映射和比对同一性估计。\n根据对完整基因组和草图基因组的实验，其精度与基于 BLAST 的 ANI calculator相当，并且实现了两到三个数量级的加速。 因此，它对于大量基因组对的成对 ANI 计算非常有用。\n发表文章：Jain, C., Rodriguez-R, L.M., Phillippy, A.M. et al. High throughput ANI analysis of 90K prokaryotic genomes reveals clear species boundaries. Nat Commun 9, 5114 (2018). https://doi.org/10.1038/s41467-018-07641-9\nInstall FastANI的安装非常简单，可以选择以下一种方式：\nbinary file 可以在https://github.com/ParBliSS/FastANI/releases页面上选择合适的版本zip文件下载解压即可使用：\n1 2 3 wget -c https://github.com/ParBLiSS/FastANI/releases/download/v1.34/fastANI-linux64-v1.34.zip unzip fastANI-linux64-v1.34.zip ./fastANI -h conda 1 2 conda install -c bioconda fastani fastANI -h Build from source 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 This software requires c++11 to build, which is available in GCC \u0026gt;= 4.8 (on linux) and Clang \u0026gt;= 3.3 (on mac) Dependencies: ------------- - CMake 3.2 or above ( https://cmake.org/ ) - either... GNU Scientific Library ( http://www.gnu.org/software/gsl/ ) or.. Boost Library ( http://www.boost.org ) (see \u0026#34;-DBOOST_ROOT\u0026#34; below) - Zlib ( included with OS X and most Linuxes, http://www.zlib.net ) * - C++ compiler with C++11 and openmp support Note for macOS users: Use \u0026#34;libomp\u0026#34; to link openmp with Clang libomp is available through brew ( https://formulae.brew.sh/formula/libomp ) Steps: ------ mkdir build cd build cmake .. -DCMAKE_BUILD_TYPE=Release [--install-prefix ... -DGSL_SHARED=... -DGSL_ROOT_DIR=... -DBOOST_ROOT=...] cmake --build . Usage FastANI 使用帮助页面 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 $ fastANI -h ----------------- 示例用法： $ fastANI -q genome1.fa -r genome2.fa -o output.txt $ fastANI -q genome1.fa --rl genome_list.txt -o output.txt 语法: -------- fastANI [-h] [-r \u0026lt;value\u0026gt;] [--rl \u0026lt;value\u0026gt;] [-q \u0026lt;value\u0026gt;] [--ql \u0026lt;value\u0026gt;] [-k \u0026lt;value\u0026gt;] [-t \u0026lt;value\u0026gt;] [--fragLen \u0026lt;value\u0026gt;] [--minFraction \u0026lt;value\u0026gt;] [--maxRatioDiff \u0026lt;value\u0026gt;] [--visualize] [--matrix] [-o \u0026lt;value\u0026gt;] [-s] [-v] 选项: -------- -h, --help 打印此帮助页面 -r, --ref \u0026lt;值\u0026gt; 参考基因组文件（fasta/fastq）[支持 .gz 压缩] --rl, --refList \u0026lt;值\u0026gt; 包含参考基因组文件列表的文件，每行一个基因组文件 -q, --query \u0026lt;值\u0026gt; 查询基因组文件（fasta/fastq）[支持 .gz 压缩] --ql, --queryList \u0026lt;值\u0026gt; 包含查询基因组文件列表的文件，每行一个基因组文件 -k, --kmer \u0026lt;值\u0026gt; kmer 大小，最大值为 16 [默认值：16] -t, --threads \u0026lt;值\u0026gt; 并行执行的线程数 [默认值：1] --fragLen \u0026lt;值\u0026gt; 片段长度 [默认值：3000] --minFraction \u0026lt;值\u0026gt; 信任 ANI 结果所需的基因组最小共享比例。如果参考和查询基因组大小不同，则取较小的一个 [默认值：0.2] --maxRatioDiff \u0026lt;值\u0026gt; (总参考长度/总发生哈希数) 和 (总参考长度/总哈希数) 之间的最大差异 [默认值：10.0] --visualize 输出用于可视化的映射，仅适用于单个基因组与单个基因组的比较 [默认禁用] --matrix 以下三角矩阵格式输出 ANI 值（格式参照 phylip）。启用后，输出文件将带有 .matrix 扩展名 [默认禁用] -o, --output \u0026lt;值\u0026gt; 输出文件名 -s, --sanityCheck 运行完整性检查 一对一计算 计算单个查询基因组与单个参考基因组之间的ANI：\n1 ./fastANI -q [QUERY_GENOME] -r [REFERENCE_GENOME] -o [OUTPUT_FILE] 在此，QUERY_GENOME 和 REFERENCE_GENOME 是以fasta或多fasta格式提供的查询和参考基因组装。\n我们来计算数据文件夹中提供的大肠杆菌和福氏志贺氏菌基因组之间的 ANI。\n1 2 3 4 git clone https://github.com/ParBLiSS/FastANI fastANI -q FastANI/tests/data/Shigella_flexneri_2a_01.fna -r FastANI/tests/data/Escherichia_coli_str_K12_MG1655.fna -o fastani.out head fastani.out 结果有6列：查询基因组、参考基因组、ANI值、双向片段映射计数、总查询片段\n1 Shigella_flexneri_2a_01.fna\tEscherichia_coli_str_K12_MG1655.fna\t99.853\t76\t77 一对多计算 计算单个查询基因组与多个参考基因组之间的ANI：\n1 ./fastANI -q [QUERY_GENOME] --rl [REFERENCE_LIST] -o [OUTPUT_FILE] 对于上述用例，REFERENCE_LIST 应为包含参考基因组目录路径的文件，每行一个基因组。\n多对多计算 当有多个查询基因组和多个参考基因组时：\n1 ./fastANI --ql [QUERY_LIST] --rl [REFERENCE_LIST] -o [OUTPUT_FILE] 同样，QUERY_LIST 和 REFERENCE_LIST 是包含基因组路径的文件，每行一个基因组。\n输出格式 在上述所有用例中，OUTPUT_FILE 将包含制表符分隔的行，包括查询基因组、参考基因组、ANI值、双向片段映射计数和总查询片段。\n比对比例（相对于查询基因组）仅是映射数和总片段的比率。用户还可以通过提供--matrix参数获得一个包含身份值的phylip格式的下三角矩阵文件（.matrix）。\n注意：如果ANI值远低于80%，则不会报告基因组对的ANI输出。此类情况应在氨基酸水平进行计算。FastANI还建议用户对其输入基因组装（包括参考基因组和查询基因组）进行充分的质量检查，特别是N50应≥10 Kbp。\nVisualize Conserved Regions FastANI 支持两个基因组之间计算的相互映射的可视化。 获得此可视化效果需要使用 FastANI 进行一对一比较，应提供附加标志 --visualize，FastANI 输出包含所有相互映射信息的映射文件（扩展名为 .visual）。\n1 fastANI -q FastANI/tests/data/Shigella_flexneri_2a_01.fna -r FastANI/tests/data/Escherichia_coli_str_K12_MG1655.fna -o fastani.out --visualize 最后，可以使用genoPlotR 包来绘制这些映射：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 query_fasta=\u0026#34;FastANI/tests/data/Shigella_flexneri_2a_01.fna\u0026#34; subject_fasta=\u0026#34;FastANI/tests/data/Escherichia_coli_str_K12_MG1655.fna\u0026#34; fastANI_visual_file=\u0026#34;fastani.out.visual\u0026#34; library(genoPlotR) #Read fastANI output comparison \u0026lt;- try(read_comparison_from_blast(fastANI_visual_file)) #Read sequences into genoPlotR objects Query \u0026lt;- try(read_dna_seg_from_file(query_fasta)) Ref \u0026lt;- try(read_dna_seg_from_file(subject_fasta)) plotTitle = paste(query_fasta, subject_fasta, sep=\u0026#34; v/s \u0026#34;) pdf(paste(fastANI_visual_file,\u0026#34;.pdf\u0026#34;,sep=\u0026#34;\u0026#34;),width = 10) plot_gene_map(dna_segs=list(Query, Ref), comparisons=list(comparison), main=plotTitle, scale=FALSE, scale_cex=1, n_scale_ticks=4) dev.off() 看看结果的fastani.out.visual.pdf：\nGTDB的Tools中提供了FastANI calculator的在线工具：https://gtdb.ecogenomic.org/tools/fastani，可用于原核生物 NCBI基因组的ANI比较，一次最多可以进行 1,000 次成对比较，例如下图：\nSkani 用于宏基因组组装基因组 (metagenome-assembled genome, MAG) 的序列比较工具难以处理大量或低质量的数据。 研究人员提出了 skani，一种通过稀疏近似比对确定ANI的方法。\nskani 使用近似映射方法，无需基础级别对齐来获取 ANI。它比基于 BLAST 的方法快几个数量级，并且几乎同样准确。其主要特点有：\nMAG 的准确 ANI 计算。 skani 对于不完整和中等质量的宏基因组组装基因组 (MAG) 是准确的。纯草图方法（例如 Mash）可能会低估不完整 MAG 的 ANI。 对齐部分结果。 skani 输出基因组对齐的部分，而基于纯 k-mer 的方法则不会。 快速计算。Indexing/sketching 比 Mash 快约 3 倍，查询比 FastANI 快约 25 倍（但比 Mash 慢）。 高效的数据库搜索。使用单个处理器和约 6 GB 的 RAM，根据超过 65000 个原核基因组的预处理数据库查询基因组只需几秒钟。从基因组序列构建数据库需要几分钟到一个小时。 发表文章：Jim Shaw and Yun William Yu. Fast and robust metagenomic sequence comparison through sparse chaining with skani. Nature Methods (2023). https://doi.org/10.1038/s41592-023-02018-3\n确实牛，文章很短两张主图，直接发在Nature Methods上。\nInstall Skani的安装也非常简单，可以选择以下一种方式：\nbinary file 可以在https://github.com/bluenote-1577/skani/releases/页面上选择合适的版本直接下载使用：\n1 2 3 wget https://github.com/bluenote-1577/skani/releases/download/latest/skani chmod +x skani ./skani -h conda 1 2 conda install -c bioconda skani skani -h compile 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 Requirements: ------ 1.rust programming language and associated tools such as cargo are required and assumed to be in PATH. 2.A c compiler (e.g. GCC) 3.make Steps: ------ git clone https://github.com/bluenote-1577/skani cd skani # If default rust install directory is ~/.cargo cargo install --path . --root ~/.cargo skani dist refs/e.coli-EC590.fasta refs/e.coli-K12.fasta # If ~/.cargo doesn\u0026#39;t exist use below commands instead #cargo build --release #./target/release/skani dist refs/e.coli-EC590.fasta refs/e.coli-K12.fasta Usage Skani 使用帮助页面 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 $ skani -h skani 0.2.1 快速、稳健的ANI计算和用于宏基因组片段和组装的数据库搜索。 快速ANI计算： skani dist genome1.fa genome2.fa 内存高效的数据库搜索： skani sketch genomes/* -o database; skani search -d database query1.fa query2.fa ... 全对全比较： skani triangle genomes/* USAGE: 使用方法： skani [SUBCOMMAND] OPTIONS: 选项： -h, --help 打印帮助信息 -V, --version 打印版本信息 SUBCOMMANDS: 子命令： dist 计算查询基因组与参考fasta文件或预先计算的草图文件的ANI。 用法：skani dist query.fa ref1.fa ref2.fa ... 或使用 -q/--ql 和 -r/--rl 选项。 search 在内存高效的方式下，搜索查询基因组与预先草绘的参考基因组数据库。 用法：skani search -d sketch_folder query1.fa query2.fa ... sketch 草绘（索引）基因组。 用法：skani sketch genome1.fa genome2.fa ... -o new_sketch_folder triangle 计算下三角形的ANI/AF矩阵。 用法：skani triangle genome1.fa genome2.fa genome3.fa ... 一对一计算 计算单个查询基因组与单个参考基因组之间的ANI：\n1 2 3 # 比较两个基因组的ANI。skani是对称的，所以顺序不影响ANI skani dist genome1.fa genome2.fa skani dist genome2.fa genome1.fa 示例：我们可以用skani文件夹中提供的两个大肠杆菌基因组来计算 ANI。\n1 2 3 4 git clone https://github.com/bluenote-1577/skani skani dist skani/refs/e.coli-EC590.fasta skani/refs/e.coli-K12.fasta -o skani.out head skani.out 1 2 Ref_file\tQuery_file\tANI\tAlign_fraction_ref\tAlign_fraction_query\tRef_name\tQuery_name skani/refs/e.coli-K12.fasta\tskani/refs/e.coli-EC590.fasta\t99.39\t91.89\t92.46\tNC_007779.1 Escherichia coli str. K-12 substr. W3110, complete sequenceNZ_CP016182.2 Escherichia coli strain EC590 chromosome, complete genome 多对多计算 1 2 3 4 5 6 7 8 9 10 11 12 # 比较多个基因组；所有选项都可以使用-t进行多线程处理。 skani dist -t 3 -q query1.fa query2.fa -r reference1.fa reference2.fa -o all-to-all_results.txt # 比较单个fasta文件里的每条序列（例如contigs） skani dist --qi -q assembly1.fa --ri -r assembly2.fa # 构建数据库并进行内存高效搜索 skani sketch genomes_to_search/* -o database skani search query1.fa query2.fa ... -d database # 使用“skani sketch”输出的草绘作为直接替代 skani dist database/query.fa.sketch database/ref.fa.sketch ANI矩阵 1 2 3 4 5 6 7 # 为文件夹中的所有基因组构建相似性矩阵/边列表 skani triangle genome_folder/* \u0026gt; skani_ani_matrix.txt skani triangle genome_folder/* -E \u0026gt; skani_ani_edge_list.txt # skani作者还提供了一个脚本用于聚类/可视化距离矩阵。 # 需要python3, seaborn, scipy/numpy, 和matplotlib。 python scripts/clustermap_triangle.py skani_ani_matrix.txt 示例：我们可以用skani文件夹中提供的list.txt来计算 ANI矩阵。\n1 2 3 4 cd skani skani triangle -l test_files/list.txt \u0026gt; ../skani_ani_matrix.txt cd .. python skani/scripts/clustermap_triangle.py skani_ani_matrix.txt 1 2 3 4 5 6 7 8 9 8 test_files/e.coli-EC590.fasta test_files/e.coli-K12.fasta\t99.39 test_files/e.coli-W.fasta\t98.58\t98.54 test_files/e.coli-W.fasta.gz\t98.58\t98.54\t100.00 test_files/e.coli-h5.fasta\t98.90\t98.91\t98.61\t98.61 test_files/e.coli-o157.fasta\t98.14\t98.09\t98.05\t98.05\t98.03 test_files/o157_plasmid.fasta\t0.00\t0.00\t0.00\t0.00\t0.00\t100.00 test_files/o157_reads.fastq\t92.81\t93.05\t93.15\t93.15\t92.84\t95.55\t94.64 输出格式 如果两个基因组的对齐比例低于15%，将不会输出结果。\n实际上，这意味着只有ANI大于约82%的结果才会可靠地输出（使用默认参数）。有关如何比较低ANI基因组的信息，需要参阅skani高级使用指南。\n默认的search和dist命令输出如下：\n1 2 Ref_file\tQuery_file\tANI\tAlign_fraction_ref\tAlign_fraction_query\tRef_name\tQuery_name skani/refs/e.coli-K12.fasta\tskani/refs/e.coli-EC590.fasta\t99.39\t91.89\t92.46\tNC_007779.1 Escherichia coli str. K-12 substr. W3110, complete sequenceNZ_CP016182.2 Escherichia coli strain EC590 chromosome, complete genome 列解释：\nRef_file: 参考文件的文件名。 Query_file: 查询文件的文件名。 ANI: 平均核苷酸一致性（ANI）。 Align_fraction_query/reference: 查询/参考序列的对齐覆盖比例。 Ref/Query_name: 参考/查询文件中第一个记录的ID。 当查询基因组数量超过5000时，结果的顺序取决于命令，不保证顺序是确定的。dist和search命令会尝试将最高ANI的结果放在前面。\n","date":"2024-05-19T00:00:00Z","image":"/p/ani/images/ani3_hu_7dc5cab70bf3e23b.png","permalink":"/p/ani/","title":"使用FastANI与Skani计算平均核苷酸一致性(ANI)"},{"content":"Introduction European Nucleotide Archive (ENA) 是一个由欧洲分子生物学实验室 (EMBL) 欧洲生物信息学研究所 (EBI) 维护的公共数据库。ENA 收集、存储和提供核酸序列数据，是全球生物学和生物信息学研究的重要资源之一。以下是 ENA 的几个关键点：\n数据收集和存储：ENA 接收并存储来自全球各地的核酸序列数据。这些数据包括DNA和RNA的序列，以及相关的元数据，如序列的来源、生物学特征和实验信息。\n数据访问：ENA 提供公开访问接口，允许研究人员和公众免费下载和检索数据。用户可以通过网页界面、编程接口 (API) 和批量下载工具访问数据。\n数据整合：ENA 与其他主要的生物序列数据库（如美国的GenBank和日本的DDBJ）合作，确保数据在全球范围内的整合和共享。这种合作被称为国际核酸序列数据库协作 (INSDC)。\n数据提交：研究人员可以向 ENA 提交他们的核酸序列数据。ENA 提供了详细的指南和工具，帮助研究人员提交数据并确保数据的质量和一致性。\n用途广泛：ENA 中的数据被广泛用于各种生物学研究领域，包括基因组学、转录组学、宏基因组学和进化生物学等。\n数据提交 由于项目需要，我们要把测序原始数据上传至ENA数据库。在此以双端fastq测序文件的提交流程为例，讲解具体步骤。\n官方教程： https://ena-docs.readthedocs.io/en/latest/submit/general-guide.html\n在 European Nucleotide Archive (ENA) 提交数据时，有三种不同的提交方式，每种方式适用于不同类型的数据提交。 根据你的需求，可能需要使用一种或多种提交方式：\n交互式提交 (Interactive Submissions)：\n方法：通过在浏览器中直接填写网页表单，并下载可以离线填写的模板电子表格，然后将其上传到 ENA。 适用场景：这是最易于访问的提交方式，适合大多数用户，尤其是那些不熟悉命令行或编程的用户。 优点：操作简单，界面友好，适合初次提交或数据量较少的提交者。 命令行提交 (Command Line Submissions)：\n方法：使用 ENA 的专用程序 Webin-CLI 进行提交。这个工具可以在提交之前完全验证你的数据，确保数据的准确性和完整性。 适用场景：适合需要高控制力和数据验证的用户，特别是有一定技术背景的用户。 优点：提供最大化的控制和数据验证，适合批量提交和大规模数据。 编程提交 (Programmatic Submissions)：\n方法：通过准备 XML 文档来完成提交，可以使用 cURL 程序或 Webin Portal 将数据发送到 ENA。 适用场景：适合需要自动化提交的用户，尤其是那些有编程能力并且需要频繁提交数据的用户。 优点：支持自动化和高效的数据提交流程，适合大规模数据和高频率的提交需求。 我们这里使用的是1+2方法，这样是最通用，灵活且方便的流程。 使用网页注册project和sample，再使用Webin-CLI提交数据。\nInstall Webin-CLI 使用 Webin-CLI 提交数据到 European Nucleotide Archive (ENA) 需要按以下步骤进行。确保你已经安装了 Java 1.8 或更高版本，并下载了最新版本的 Webin-CLI。\n步骤 1: 安装 Java 如果你还没有安装 Java，请从以下链接下载并安装 Java 1.8 或更新版本： 下载 Java\n检查版本：\n1 java -version 步骤 2: 下载 Webin-CLI 从 GitHub 下载最新版本的 Webin-CLI： 下载 Webin-CLI\n在终端或命令行中使用 java 命令运行 Webin-CLI。 运行 Webin-CLI 并显示帮助信息：\n1 java -jar webin-cli-2.0.0.jar -help -context： 提交类型： `-context genome `-context transcriptome `-context sequence `-context reads -userName：Webin 提交帐户名称。 -password：Webin 提交帐户密码。 -centerName：提交者的中心名称（对于经纪商账户是强制性的）。 -manifest：清单文件名。 -outputDir：输出文件的目录。 -inputDir：清单文件中声明的文件的输入目录。 -validate：验证清单文件中定义的文件。 -submit：验证并提交清单文件中定义的文件。 -test：使用 Webin 测试服务而不是生产服务。请注意， Webin 上传区域在测试和生产服务之间共享，并且该测试提交 文件将不会存档。 -ascp：使用 Aspera Cli 而不是 FTP 文件传输（如果可用）。Aspera应该安装，可执行文件“ascp”的路径应该在 PATH 变量中。 -version：打印程序的版本号并存在。 -help：有关不同选项的详细信息。 Submission 准备好软件后，我们就可以开始提交流程了：\nStage 1: Pre-register Study and Sample 首先进入官网The European Bioinformatics Institute \u0026lt; EMBL-EBI，这里一般实验室有自己的账号，登陆。\n我们会进入这个页面：\n注册study 按要求填写，保存好我们的project id文件。\n注册sample 这一步要下载一个checklist（tsv），用excel打开按要求填好每一个sample的信息，注意不要删掉本来的内容。比如：\ntaxid：可在这里查询https://www.ebi.ac.uk/ena/browser/view/408169?show=tax-tree。比如我们是环境样本，空气就是Taxon: 655179 scientific_name：air metagenome sample_alias, sample_title, sample_description, project name 有些是有填写格式的，比如时间，经纬度要注意 都填完以后还是把这个tsv上传回去，提交好后就有每个sample的ACCESSION了。\nStage 2: Prepare the Files 原始fastq文件需要进行压缩(.fq.gz):\n1 2 3 4 5 for i in `ls *.fq` do echo ${i} gzip $i -c \u0026gt; ${i}.gz done 准备manifest文件 作为提交的一部分，每个刚刚注册的Sample（一个单端测序文件，或一对双端测序文件）都必须使用一个清单文件描述。\nmanifest文件使用Webin-CLI的-manifest \u0026lt;filename\u0026gt;参数指定，每个manifest文件需包含以下内容：\n通用实验信息 Study accession or unique name (alias) Sample accession or unique name (alias) Experiment name Sequencing platform Sequencing instrument Library name (optional) Library source Library selection Library strategy Free text library description (optional) Insert size for paired reads (optional) 测序文件，以下的一项 BAM file CRAM file Single Fastq file Paired Fastq files Multi-fastq files 单独填写每一个样本的manifest文件比较麻烦，可以用一段简单的R脚本帮助编写：\n首先，根据我们之前注册时已经得到的信息整理出一个excel（列名不要改变，FASTQ这列如果是双端就用; 隔开）：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 # manifest for ENA fq_submit=readxl::read_excel(\u0026#34;Checklist_GSC-MIxS_human_associated_NULL.xlsx\u0026#34;)%\u0026gt;%as.data.frame() dir.create(\u0026#34;manifest\u0026#34;) for (i in seq_len(nrow(fq_submit))) { df=fq_submit[i,] filename=paste0(df[,\u0026#34;SAMPLE\u0026#34;],\u0026#34;_manifest\u0026#34;) tmp=c() for (i in seq_len(ncol(df))) { name=colnames(df)[i] value=df[1,i] if(grepl(\u0026#34;;\u0026#34;,value))value=strsplit(value,\u0026#34;;\\\\s\u0026#34;)[[1]] tmp=c(tmp,paste0(name,\u0026#34;\\t\u0026#34;,value)) } writeLines(tmp,file.path(\u0026#34;manifest/\u0026#34;,filename),sep = \u0026#34;\\n\u0026#34;) } 这样会在manifest文件夹下生成每一个样本的manifest文件，内容如下：\n1 2 3 4 5 6 7 8 9 10 11 STUDY PRJEB67959 SAMPLE ERS17964118 NAME P9_2C-ILLUMINA sequencing PLATFORM ILLUMINA INSTRUMENT Illumina NovaSeq 6000 INSERT_SIZE 200 LIBRARY_SOURCE METAGENOMIC LIBRARY_SELECTION RANDOM LIBRARY_STRATEGY WGS FASTQ P9_2C.clean.1.fq.gz FASTQ P9_2C.clean.2.fq.gz Stage 3: Validate and Submit Files 终于到了上传的这一步了，ENA建议在上传前先用-validate验证清单文件中定义的文件（只验证不提交）。\n我们拿一个样本试一试，没问题：\n1 2 3 4 5 6 7 i=ERS17964118_manifest java -jar ~/biosoft/webin-cli-6.7.0.jar -context reads \\ -userName Webin-XXXXX -password XXXXXXX \\ -manifest ${i} \\ -outputDir test_submit_out \\ -inputDir ./ \\ -validate 正式提交，用for循环提交每一个样本(-submit也会在提交前验证)：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 for i in `ls manifest/*_manifest` do echo \u0026#34;Processing: $i\u0026#34; echo \u0026#34;Start time: $(date +\u0026#39;%Y-%m-%d %T\u0026#39;)\u0026#34; # 执行上传命令，并捕获退出状态码 java -jar ~/biosoft/webin-cli-6.7.0.jar -context reads \\ -userName Webin-XXXXX -password XXXXXXX \\ -manifest ${i} \\ -outputDir test_submit_out \\ -inputDir ./ \\ -submit # 检查上传是否成功（退出状态码 0 表示成功） if [ $? -eq 0 ]; then echo \u0026#34;Upload SUCCESS: $i\u0026#34; mv \u0026#34;$i\u0026#34; \u0026#34;${i}_done\u0026#34; # 仅在上传成功后重命名 else echo \u0026#34;Upload FAILED: $i (文件未重命名)\u0026#34; fi echo \u0026#34;End time: $(date +\u0026#39;%Y-%m-%d %T\u0026#39;)\u0026#34; echo \u0026#34;----------------------------------\u0026#34; done 上面那个命令validate可以执行并通过，但默认是ftp协议传输，如果你的提交没问题那就跳过下面ascp这部分：\n-ascp 提交 我使用默认的ftp好像有点问题，进度条都没有，应该是我们服务器的问题。\n那就试一下-ascp参数，但是我之前装好的ascp不能用了，好像是最近aspera改过一次：\n1 2 ascp: /lib/libc.so.6: version `GLIBC_2.28\u0026#39; not found (required by ascp) ascp: /lib/libc.so.6: version `GLIBC_2.25\u0026#39; not found (required by ascp) 没办法，重装，官网下载安装没用，应该是服务器配置不匹配。\n只能试试conda，conda install -c hcc aspera-cli -y。 虽然很慢，但最后conda安装的可以用。\n加上-ascp参数，大功告成，上传速度也非常快：\n1 2 3 4 5 6 7 8 9 10 for i in `ls manifest/*_manifest` do java -jar ~/biosoft/webin-cli-6.7.0.jar -context reads \\ -userName Webin-XXXXX -password XXXXXXX \\ -manifest ${i} \\ -outputDir test_submit_out \\ -inputDir ./ \\ -submit -ascp mv ${i} ${i}_done done 最后，我们可以回到官网页面：The European Bioinformatics Institute \u0026lt; EMBL-EBI。点击左侧的Dashboard，再点击Raw Reads里的Runs Report，就可以查看每一个样本提交状态了，没问题：\n","date":"2024-05-17T00:00:00Z","image":"/p/ena/images/ena5_hu_cd401ccf30022ac0.png","permalink":"/p/ena/","title":"上传测序数据至ENA数据库"},{"content":" Introduction TaxonKit是一个用于处理生物分类学数据的命令行工具。 它的主要功能是处理NCBI的生物分类学数据，包括对分类单元（如物种、属、科等）的查找、分类单元的上下位关系查询、分类单元名称的标准化等。\n为了方便R社区用户（自己）使用和流程整合，我把Taxonkit工具整合进了R包pctax，也开发了一些配套的系统发育分析和可视化方法。\nR调用Taxonkit 准备工作 安装pctax pctax稳定版本可在CRAN上获得: 1 install.packages(\u0026#34;pctax\u0026#34;) 或者你可以通过以下方式从GitHub安装pctax的开发版本:\n1 2 # install.packages(\u0026#34;devtools\u0026#34;) devtools::install_github(\u0026#34;Asa12138/pctax\u0026#34;) 安装taxonkit： 1 2 3 4 5 library(pctax) pctax::install_taxonkit(make_sure = TRUE) #成功后taxonkit会安装在下面这个目录👇 tools::R_user_dir(\u0026#34;pctax\u0026#34;) 下载NCBI Taxonomy数据文件: 1 2 3 4 pctax::download_taxonkit_dataset(make_sure = TRUE) #成功后Taxonomy数据文件会在下面这个目录👇 file.path(Sys.getenv(\u0026#34;HOME\u0026#34;), \u0026#34;.taxonkit\u0026#34;) 该函数会下载官网最新版本的Taxonomy数据库，如果需要制定版本的数据库，可以自己在官网下载：https://ftp.ncbi.nih.gov/pub/taxonomy/，然后指定位置：\n1 pctax::download_taxonkit_dataset(make_sure = TRUE,taxdump_tar_gz = \u0026#34;~/Downloads/taxdump.tar.gz\u0026#34;) 使用 1 2 # 下列命令不报错说明可以正常使用 check_taxonkit(print = FALSE) 主要功能与taxonkit一致：\n函数 功能 taxonkit_list 列出指定TaxId下所有子单元的的TaxID taxonkit_lineage 根据TaxID获取完整谱系（lineage） taxonkit_reformat 将完整谱系转化为“界门纲目科属种株”的自定义格式 taxonkit_name2taxid 将分类单元名称转化为TaxID taxonkit_filter 按分类学水平范围过滤TaxIDs taxonkit_lca 计算最低公共祖先(LCA) 并且help(taxonkit_*)可查看详细使用说明。\n1 2 # 列出[genus] Homo下的所有子单元 taxonkit_list(ids = c(9605), indent = \u0026#34;-\u0026#34;, show_name = TRUE, show_rank = TRUE) ## [1] \u0026quot;9605 [genus] Homo\u0026quot; ## [2] \u0026quot;-9606 [species] Homo sapiens\u0026quot; ## [3] \u0026quot;--63221 [subspecies] Homo sapiens neanderthalensis\u0026quot; ## [4] \u0026quot;--741158 [subspecies] Homo sapiens subsp. 'Denisova'\u0026quot; ## [5] \u0026quot;-1425170 [species] Homo heidelbergensis\u0026quot; ## [6] \u0026quot;-2665952 [no rank] environmental samples\u0026quot; ## [7] \u0026quot;--2665953 [species] Homo sapiens environmental sample\u0026quot; ## [8] \u0026quot;-2813598 [no rank] unclassified Homo\u0026quot; ## [9] \u0026quot;--2813599 [species] Homo sp.\u0026quot; ## [10] \u0026quot;\u0026quot; taxonkit_lineage, taxonkit_reformat, taxonkit_name2taxid, taxonkit_filter 与 taxonkit_lca 默认从文件中读取数据，也可通过指定text = TRUE从字符串输入读取输入数据：\n1 2 3 # 查询9606和63221的完整谱系 taxonkit_lineage(\u0026#34;9606\\n63221\u0026#34;, show_name = TRUE, show_rank = TRUE, text = TRUE)%\u0026gt;% pcutils::strsplit2(split = \u0026#34;\\t\u0026#34;,colnames = c(\u0026#34;taxid\u0026#34;,\u0026#34;lineage\u0026#34;,\u0026#34;name\u0026#34;,\u0026#34;level\u0026#34;)) ## taxid ## 1 9606 ## 2 63221 ## lineage ## 1 cellular organisms;Eukaryota;Opisthokonta;Metazoa;Eumetazoa;Bilateria;Deuterostomia;Chordata;Craniata;Vertebrata;Gnathostomata;Teleostomi;Euteleostomi;Sarcopterygii;Dipnotetrapodomorpha;Tetrapoda;Amniota;Mammalia;Theria;Eutheria;Boreoeutheria;Euarchontoglires;Primates;Haplorrhini;Simiiformes;Catarrhini;Hominoidea;Hominidae;Homininae;Homo;Homo sapiens ## 2 cellular organisms;Eukaryota;Opisthokonta;Metazoa;Eumetazoa;Bilateria;Deuterostomia;Chordata;Craniata;Vertebrata;Gnathostomata;Teleostomi;Euteleostomi;Sarcopterygii;Dipnotetrapodomorpha;Tetrapoda;Amniota;Mammalia;Theria;Eutheria;Boreoeutheria;Euarchontoglires;Primates;Haplorrhini;Simiiformes;Catarrhini;Hominoidea;Hominidae;Homininae;Homo;Homo sapiens;Homo sapiens neanderthalensis ## name level ## 1 Homo sapiens species ## 2 Homo sapiens neanderthalensis subspecies 从文件中读取数据：\n1 2 3 names \u0026lt;- system.file(\u0026#34;extdata/name.txt\u0026#34;, package = \u0026#34;pctax\u0026#34;) taxonkit_name2taxid(names, name_field = 1, sci_name = FALSE, show_rank = FALSE)%\u0026gt;% pcutils::strsplit2(split = \u0026#34;\\t\u0026#34;,colnames = c(\u0026#34;name\u0026#34;,\u0026#34;taxid\u0026#34;)) ## name taxid ## 1 Homo sapiens 9606 ## 2 Akkermansia muciniphila ATCC BAA-835 349741 ## 3 Akkermansia muciniphila 239935 ## 4 Mouse Intracisternal A-particle 11932 ## 5 Wei Shen ## 6 uncultured murine large bowel bacterium BAC 54B 314101 ## 7 Croceibacter phage P2559Y 1327037 系统发育树 如果是做16S测序的话，在分析过程中就会得到一个带距离的系统发育树。宏基因组分析如果组装MAG后用GTDB-Tk比对数据库后也可以获得有距离的系统发育树。\n但有时候我们想要从物种名或taxid获取整齐的谱系信息，用来一个构建系统发育树（层级树，没有真实的距离，只展示包含关系）。这是一个常见的需求，很多文章都会画一个这样的树图来展示自己的数据。\n可以实现这个需求的工具有一些：\niPhylo：https://iphylo.net/，免费，快速，支持NCBI taxonomy和一些化学物质分类树，赞 R包taxtree，很慢 PhyloT：https://phylot.biobyte.de/，收费 当然可以使用pctax包快速完成，对于分析流程都在R里做的人来说非常方便:\n1 2 3 4 5 6 7 8 9 10 11 12 13 names \u0026lt;- system.file(\u0026#34;extdata/name.txt\u0026#34;, package = \u0026#34;pctax\u0026#34;)%\u0026gt;%readLines() # 首先通过`name_or_id2df`获取整齐的系统发育分类： tax_df=name_or_id2df(names,mode = \u0026#34;name\u0026#34;) # 去除部分NA，原因可能是学名不标准，或者在新数据库里删除了，因为taxonomy数据库是不断变化的 tax_df=na.omit(tax_df) #用`df2tree`将分类层级表转化为树对象 tax_tree=pctax::df2tree(tax_df[,3:9]) # tax_tree是phylo对象，可以用ape包直接简单绘图 ape:::plot.phylo(tax_tree) 可视化 pctax还提供了一些系统发育信息展示方法：\n系统发育树 1 2 3 4 5 6 data(otutab, package = \u0026#34;pcutils\u0026#34;) #otutab是丰度数据，taxonomy是分类层级表（可通过name_or_id2df获得） ann_tree(taxonomy, otutab) -\u0026gt; tree easy_tree(tree, add_abundance = TRUE) -\u0026gt; p p 添加主要Phylum的strip：\n1 2 3 4 5 6 easy_tree(tree, add_abundance = TRUE,add_tiplab = FALSE) -\u0026gt; p some_tax \u0026lt;- table(taxonomy$Phylum) %\u0026gt;% sort(decreasing = TRUE) %\u0026gt;% head(5) %\u0026gt;% names() add_strip(p, some_tax) 当然，更多系统发育树的绘制可以参考我之前写的R绘制优美的进化树（基础）和R绘制优美的进化树（进阶），或者使用iPhylo网站来交互式绘图：iPhylo 生成并绘制优美的分类树\n桑基图： 1 sangji_plot(tree) 3.旭日图\n1 sunburst(tree) TaxonKit 使用 TaxonKit是采用Go语言编写的命令行工具， 提供Linux, Windows, macOS操作系统不同架构（x86-64/arm64）的静态编译的可执行二进制文件。 发布的压缩包不足3Mb，除了Github托管外，还提供国内镜像供下载，同时还支持conda和homebrew安装。\n用户只需要下载、解压，开箱即用，无需配置，仅需下载解压NCBI Taxonomy数据文件解压到指定目录即可。\n源代码 https://github.com/shenwei356/taxonkit ， 文档 http://bioinf.shenwei.me/taxonkit （介绍、使用说明、例子、教程） 选择系统对应的版本下载最新版 https://github.com/shenwei356/taxonkit/releases ，解压后添加环境变量即可使用。或可选conda安装\nconda install taxonkit -c bioconda -y\n表格数据处理，推荐使用 csvtk 更高效：\nconda install csvtk -c bioconda -y\n测试数据下载可直接 https://github.com/shenwei356/taxonkit 下载项目压缩包，或使用git clone下载项目文件夹，其中的example为测试数据\ngit clone https://github.com/shenwei356/taxonkit\nTaxonKit为命令行工具，采用子命令的方式来执行不同功能， 大多数子命令支持标准输入/输出，便于使用命令行管道进行流水作业， 轻松整合进分析流程中。\n输出： 所有命令输出中包含输入数据内容，在此基础上增加列。 所有命令默认输出到标准输出（stdout），可通过重定向（\u0026gt;）写入文件。 或通过全局参数-o或--out-file指定输出文件，且可自动识别输出文件后缀（.gz）输出gzip格式。 输入： 除了list与taxid-changelog之外，lineage, reformat, name2taxid, filter 与 lca 均可从标准输入（stdin）读取输入数据，也可通过位置参数（positional arguments）输入，即命令后面不带 任何flag的参数，如 taxonkit lineage taxids.txt 输入格式为单列，或者制表符分隔的格式，输入数据所在列用-i或--taxid-field指定。 TaxonKit直接解析NCBI Taxonomy数据文件（2秒左右），配置更容易，也便于更新数据，占用内存在500Mb-1.5G左右。 数据下载：\n1 2 3 4 5 6 7 # 有时下载失败，可多试几次；或尝试浏览器下载此链接 wget -c https://ftp.ncbi.nih.gov/pub/taxonomy/taxdump.tar.gz tar -zxvf taxdump.tar.gz # 解压文件存于家目录中.taxonkit/，程序默认数据库默认目录 mkdir -p $HOME/.taxonkit cp names.dmp nodes.dmp delnodes.dmp merged.dmp $HOME/.taxonkit Taxonkit的作者大大贴心地提供了中文文档：https://bioinf.shenwei.me/taxonkit/chinese/，非常详细，大家可以参考使用。\n","date":"2024-05-16T00:00:00Z","image":"/p/taxonkit-r/index.en_files/figure-html/unnamed-chunk-11-1_hu_253b0dae229bc5b3.png","permalink":"/p/taxonkit-r/","title":"R调用Taxonkit展示系统发育信息"},{"content":"Introduction 首先这不是一个广告，哈哈哈，我目前还没有接过任何广告。\n感觉这个软件确实比较好用且适合自己（我是在macOS上使用，但它的跨平台做的不错，大部分功能都适配于Windows/macOS/Linux）。我用了大概2个多月，有种相见恨晚的感觉，想着分享一下。\nuTools 是一个免费的桌面插件平台，具有强大的搜索、管理和拓展功能。 不仅能够提高工作效率，还可以通过各种插件满足我们的多种需求。 无论你是程序员、设计师，还是普通的办公人员，感觉uTools 都能提供有力的帮助。\nuTools 主要特点 我自己比较喜欢的点：\n即用即走： 我觉得这个设计理念挺好的，我一般用它也就是一些常用的小事，任何时候都可以用快捷键呼出它，使用完后移到别的地方它就自己消失了，有点像Ctrl+C，Ctrl+V，用的挺顺手的。\n超级面板： 我可以在任何界面呼出它，而它会根据我当前的情景提供不同的功能。比如我在文件夹里打开，他会提供终端打开；如果我选中了一个文件，他会提供复制文件路径；如果我选择了一段文字（或者复制一段），他会提供以下这些功能，比如翻译，谷歌学术搜索，问chatGPT；如果我刚刚截了个图，它会提供OCR识别，Google搜图，上传到图床之类的功能（都是我想要的，当然有些要安装插件）\n复制文字： 复制图片： 丰富的插件生态： uTools 提供了一个开放的插件平台，可以根据自己的需要安装各种插件。确实很多刚需插件都能找到，还有一些很有意思的小工具。官方提供了一个论坛 https://yuanliao.info/，可以去里面求大佬开发。对于已有的插件，开发者维护也很积极，有问题提建议，说不定下一个版本就加上你想要的功能了。实在不行自己开发一个😂，官方提供的开发文档和开放API都很详细。 对了，有些官方的插件要付费，然后大佬们自己开发的同功能插件也可以上传到插件市场，官方还是比较大方的，哈哈哈。 下面是官方的说法：\n强大的搜索功能： uTools 的搜索功能类似于 Spotlight 或 Alfred，你只需要按下快捷键，就可以快速找到文件、启动应用程序或执行各种操作。（我都比较少用Spotlight😂）\n高度自定义： 用户可以根据自己的需求，自定义快捷键和工作流程，使得操作更加顺手和高效。\n跨平台支持： uTools 支持 Windows、Mac 和 Linux 等多个操作系统，确保你在不同的设备上都能获得一致的体验。\n免费且开源： uTools 是免费软件，并且是开源的，这意味着你可以放心使用，并根据自己的需求进行二次开发 。\n开始使用 uTools 下载和安装：访问 uTools 官方网站 下载适用于你操作系统的安装包。 设置快捷键：安装完成后，设置一个便捷的快捷键来启动 uTools。 探索插件：在插件市场中浏览和安装适合你的插件，开始定制你的工作流程。 常用插件 下面推荐一些我常用的插件：\n文本类 超级剪切板，这个很好用很强大，比官方的好。对于macOS这种不自带剪切板的来说很有必要 易翻翻译，又是一个比官方好用的。翻译类插件很多的，大家可以自行选择 汉语解释，一个不错的中文字典 特殊符号，补充了自带键盘不好打的一些符号 emoji搜索pro，方便查找各种emoji😆，毕竟也属于常用字符了 图片类 OCR文字识别，免费好用 Latex公式编辑和识别，这个可以截图公式得到Latex代码，写markdown贼好用 图床，快速传图，博客好用 创意截图，有时候截图后想要编辑，但感觉跟复制到PPT里改差不多 随机壁纸，换换心情 图标大师/iconfont搜索，画流程图时用来找免费icon 谷歌按图搜索，这个是插件\u0026rsquo;网页快开\u0026rsquo;里的一个功能，很常用，有时候截一张图就可以很快找到是哪篇论文里的了 手册类 毕竟是程序猿用的多的工具，里面的手册很多很全：\n程序员手册：有linux，python，vim，git，c，js，go，sql等很多语言或工具的手册，查询起来非常方便。这里面没有的还可以自己导入，或者用下面这些其他插件。 HTML文档，CSS文档 C++速查 程序员做饭指南，这个挺不错的，像实验protocol一样讲解许多家常菜，上手很快。 其他 网页快开 可以在选择一段文字（query）后快速打开制定网页搜索。还可以自定义网页，比如我添加了谷歌学术：http://scholar.google.com/scholar?as_q=\u0026amp;as_epq={query}，这样选择一段文字后就可以直接右键在谷歌学术里搜索了。 里面还有个一网搜尽挺好用的，快速在多个平台上了解一个事件，每个子页面都跟刷手机体验一致：\n超级代办，任务管理工具，项目多起来之后还是需要好好管理的。 thesis_tools，一些解决在查看论文中可能产生的诡异需求的工具。我一般用来查期刊的相关信息，比如影响因子之类的： ChatGPT好友，包含了很多大模型的接口，也有很多调教好了的模型，自己酌情付费。 另外还有其他不少有意思的东西，每个人需求不同，那就自己探索吧。\n","date":"2024-05-14T00:00:00Z","image":"/p/utools/images/utools_hu_3bf418d86c41a118.png","permalink":"/p/utools/","title":"使用uTools提高办公效率"},{"content":"Introduction 在生物信息学领域，对（宏）基因组进行生物合成基因簇（BGCs）的挖掘，编码次生代谢产物的生产已成为自然产物发现的关键策略。在单个基因组水平上，这一过程由诸如antiSMASH之类的工具执行。\n当研究大量基因组和宏基因组时，进行大规模分析变得至关重要。BiG-SCAPE（生物合成基因相似性聚类与勘探引擎）是一种计算BGC之间距离的工具，以便将BGC的多样性映射到序列相似性网络上，然后将其用于自动重建基因簇家族，即编码高度相似或相同分子的基因簇组。BiG-SCAPE对这些相似性网络的交互式可视化有助于有效地探索BGC的多样性，并将其与MIBiG存储库中的参考数据知识联系起来。\n简要工作原理 BiG-SCAPE（递归地）从输入文件夹中读取存储为GenBank文件的BGC信息（最好与诸如antiSMASH等工具识别的基因簇相对应）。\n然后，BiG-SCAPE利用Pfam数据库和HMMER套件中的hmmscan来预测每个序列中的Pfam域，从而将每个BGC总结为Pfam域的线性字符串。\n对于集合中的每一对BGC，它们之间的配对距离被计算为Jaccard指数、邻接指数（AI）和域序列相似性（DSS）指数的加权组合。生成两种类型的输出：文本文件，其中包括网络文件，以及交互式可视化。可以在一个或多个运行中考虑不同的距离截止值（即，只有原始距离\u0026lt;截止值的配对才写入最终的.network文件）。\n每个截止值的距离将用于自动定义\u0026rsquo;基因簇家族\u0026rsquo;（Gene Cluster Families，GCFs）和\u0026rsquo;基因簇族\u0026rsquo;（Gene Cluster Clans，GCCs）。\n默认情况下，BiG-SCAPE使用antiSMASH处理的GenBank文件中的/product信息将分析分为八个BiG-SCAPE类别。每个类别都有不同的距离组件权重集。您还可以选择将所有BGC类别合并为单个网络文件（\u0026ndash;mix），并停用默认分类（\u0026ndash;no_classify）。还可以通过使用\u0026ndash;banned_classes参数来阻止分析任何BiG-SCAPE类别。\n下面介绍软件的安装和使用，详细工作原理可以看More details。获取更多详细信息：https://github.com/medema-group/BiG-SCAPE/wiki\nInstallation 因为BiG-SCAPE的input files最好就是antiSMASH的基因簇输出结果。建议先装好antiSMASH，然后再装BiG-SCAPE，可以参考上一篇文章使用conda创建环境安装。\n装好antiSMASH后，可以继续使用conda来安装BiG-SCAPE：\n官方给的安装方式也很简单，首先直接解压整个软件目录即可： 1 2 3 4 cd ~/biosoft # 这里是我自己的软件目录，可以根据自己的情况更改 wget https://github.com/medema-group/BiG-SCAPE/archive/refs/tags/v1.1.5.zip unzip BiG-SCAPE-1.1.5.zip cd BiG-SCAPE-1.1.5 依赖项安装： 如果要新建一个环境： 1 2 conda env create -f bigscape_dependencies.yml conda activate bigscape 我是安装在antiSMASH_5.2.0同一环境下的: 看了一下没什么冲突，所以直接进入BiG-SCAPE目录，装好antiSMASH_5.2.0后，大部分依赖都好了： 1 2 3 conda activate antiSMASH_5.2.0 #装一些python包即可 pip install -r requirements.txt 准备 Pfam 数据库： 直接下载最新的: 1 2 wget https://ftp.ebi.ac.uk/pub/databases/Pfam/current_release/Pfam-A.hmm.gz \u0026amp;\u0026amp; gunzip Pfam-A.hmm.gz hmmpress Pfam-A.hmm 使用antiSMASH自带的： 1 2 3 4 #可以在antiSMASH的目录中找到同一份文件，根据自己的安装路径更改： ll ~/miniconda3/envs/antismash_5.2.0/lib/python3.8/site-packages/antismash/databases/pfam/32.0/ #然后直接软链接到BiG-SCAPE目录即可： ln -s ~/miniconda3/envs/antismash_5.2.0/lib/python3.8/site-packages/antismash/databases/pfam/32.0/* ./ 检查是否安装成功： 1 2 3 # 进入对应的环境 conda activate bigscape python bigscape.py --version Usage 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 ~/biosoft/BiG-SCAPE-1.1.5/bigscape.py -h usage: BiG-SCAPE [-h] [-l LABEL] [-i INPUTDIR] -o OUTPUTDIR [--pfam_dir PFAM_DIR] [-c CORES] [--include_gbk_str INCLUDE_GBK_STR [INCLUDE_GBK_STR ...]] [--exclude_gbk_str EXCLUDE_GBK_STR [EXCLUDE_GBK_STR ...]] [-v] [--include_singletons] [-d DOMAIN_OVERLAP_CUTOFF] [-m MIN_BGC_SIZE] [--mix] [--no_classify] [--banned_classes {PKSI,PKSother,NRPS,RiPPs,Saccharides,Terpene,PKS-NRP_Hybrids,Others} [{PKSI,PKSother,NRPS,RiPPs,Saccharides,Terpene,PKS-NRP_Hybrids,Others} ...]] [--cutoffs CUTOFFS [CUTOFFS ...]] [--clans-off] [--clan_cutoff CLAN_CUTOFF CLAN_CUTOFF] [--hybrids-off] [--mode {global,glocal,auto}] [--anchorfile ANCHORFILE] [--force_hmmscan] [--skip_ma] [--mibig] [--mibig21] [--mibig14] [--mibig13] [--query_bgc QUERY_BGC] [--domain_includelist] [--version] optional arguments: -h, --help show this help message and exit 显示此帮助信息并退出 -l LABEL, --label LABEL An extra label for this run (will be used as part of the folder name within the network_files results) 为此次运行添加一个额外的标签（将在network_files结果文件夹名称中使用） -i INPUTDIR, --inputdir INPUTDIR Input directory of gbk files, if left empty, all gbk files in current and lower directories will be used. gbk文件的输入目录，如果留空，将使用当前和下级目录中的所有gbk文件 -o OUTPUTDIR, --outputdir OUTPUTDIR Output directory, this will contain all output data files. 输出目录，将包含所有输出数据文件 --pfam_dir PFAM_DIR Location of hmmpress-processed Pfam files. Default is same location of BiG-SCAPE hmmpress处理过的Pfam文件的位置。默认是BiG-SCAPE的同一位置 -c CORES, --cores CORES Set the number of cores the script may use (default: use all available cores) 设置脚本可以使用的核心数（默认：使用所有可用的核心） --include_gbk_str INCLUDE_GBK_STR [INCLUDE_GBK_STR ...] Only gbk files with this string(s) will be used for the analysis (default: \u0026#39;cluster\u0026#39;, \u0026#39;region\u0026#39;). Use an asterisk to accept every file (overrides \u0026#39;--exclude_gbk_str\u0026#39;) 仅使用包含此字符串的gbk文件进行分析（默认：\u0026#39;cluster\u0026#39;, \u0026#39;region\u0026#39;）。使用星号(*)接受所有文件（覆盖\u0026#39;--exclude_gbk_str\u0026#39;） --exclude_gbk_str EXCLUDE_GBK_STR [EXCLUDE_GBK_STR ...] If any string in this list occurs in the gbk filename, this file will not be used for the analysis (default: final). 如果gbk文件名中出现此列表中的任何字符串，则该文件不会用于分析（默认：final） -v, --verbose Prints more detailed information. Toggle to activate. 输出更详细的信息。切换以激活 --include_singletons Include nodes that have no edges to other nodes from the network. Toggle to activate. 包含网络中没有与其他节点连接的节点。切换以激活 -d DOMAIN_OVERLAP_CUTOFF, --domain_overlap_cutoff DOMAIN_OVERLAP_CUTOFF Specify at which overlap percentage domains are considered to overlap. Domain with the best score is kept (default=0.1). 指定在何种重叠百分比下域被认为是重叠的。保留得分最高的域（默认=0.1） -m MIN_BGC_SIZE, --min_bgc_size MIN_BGC_SIZE Provide the minimum size of a BGC to be included in the analysis. Default is 0 base pairs 提供要包含在分析中的BGC的最小大小。默认是0个碱基对 --mix By default, BiG-SCAPE separates the analysis according to the BGC product (PKS Type I, NRPS, RiPPs, etc.) and will create network directories for each class. Toggle to include an analysis mixing all classes 默认情况下，BiG-SCAPE根据BGC产物（PKS Type I, NRPS, RiPPs等）分开分析，并为每个类别创建网络目录。切换以包含混合所有类别的分析 --no_classify By default, BiG-SCAPE classifies the output files analysis based on the BGC product. Toggle to deactivate (note that if the --mix parameter is not activated, BiG-SCAPE will not create any network file). 默认情况下，BiG-SCAPE根据BGC产物分类输出文件分析。切换以停用（注意，如果未激活--mix参数，BiG-SCAPE将不会创建任何网络文件） --banned_classes {PKSI,PKSother,NRPS,RiPPs,Saccharides,Terpene,PKS-NRP_Hybrids,Others} [{PKSI,PKSother,NRPS,RiPPs,Saccharides,Terpene,PKS-NRP_Hybrids,Others} ...] Classes that should NOT be included in the classification. E.g. \u0026#34;--banned_classes PKSI PKSOther\u0026#34; 不应包括在分类中的类别。例如：“--banned_classes PKSI PKSOther” --cutoffs CUTOFFS [CUTOFFS ...] Generate networks using multiple raw distance cutoff values. Values should be in the range [0.0, 1.0]. Example: --cutoffs 0.1 0.25 0.5 1.0. Default: c=0.3. 使用多个原始距离截断值生成网络。值应在[0.0, 1.0]范围内。例如：--cutoffs 0.1 0.25 0.5 1.0。默认值：c=0.3 --clans-off Toggle to deactivate a second layer of clustering to attempt to group families into clans 切换以停用第二层聚类以尝试将家族分组为氏族 --clan_cutoff CLAN_CUTOFF CLAN_CUTOFF Cutoff Parameters for which clustering families into clans will be performed in raw distance. First value is the cutoff value family assignments for BGCs used in clan clustering (default: 0.3). Second value is the cutoff value for clustering families into clans (default: 0.7). Average linkage for BGCs in a family is used for distances between families. Valid values are in the range [0.0, 1.0]. Example: --clan_cutoff 0.3 0.7) 用于将家族聚类为氏族的原始距离截断参数。 第一个值是用于氏族聚类的BGC家族分配的截断值（默认：0.3）。 第二个值是将家族聚类为氏族的截断值（默认：0.7）。 家族中BGC的平均链接用于家族之间的距离。有效值在[0.0, 1.0]范围内。例如：--clan_cutoff 0.3 0.7 --hybrids-off Toggle to also add BGCs with hybrid predicted products from the PKS/NRPS Hybrids and Others classes to each subclass (e.g. a \u0026#39;terpene-nrps\u0026#39; BGC from Others would be added to the Terpene and NRPS classes) 切换以将具有PKS/NRPS混合和其他类的混合预测产物的BGC添加到每个子类（例如，将Others中的\u0026#39;萜类-nrps\u0026#39; BGC添加到萜类和NRPS类） --mode {global,glocal,auto} Alignment mode for each pair of gene clusters. \u0026#39;global\u0026#39;: the whole list of domains of each BGC are compared; \u0026#39;glocal\u0026#39;: Longest Common Subcluster mode. Redefine the subset of the domains used to calculate distance by trying to find the longest slice of common domain content per gene in both BGCs, then expand each slice. \u0026#39;auto\u0026#39;: use glocal when at least one of the BGCs in each pair has the \u0026#39;contig_edge\u0026#39; annotation from antiSMASH v4+, otherwise use global mode on that pair 每对基因簇的比对模式。 \u0026#39;global\u0026#39;：比较每个BGC的整个域列表；\u0026#39;glocal\u0026#39;：最长公共子簇模式。 通过尝试查找每个BGC中每个基因的最长公共域内容片段，然后扩展每个片段来重新定义用于计算距离的域子集。 \u0026#39;auto\u0026#39;：当每对中至少有一个BGC具有antiSMASH v4+的\u0026#39;contig_edge\u0026#39;注释时，使用glocal模式，否则对该对使用global模式 --anchorfile ANCHORFILE Provide a custom location for the anchor domains file, default is anchor_domains.txt. 提供锚域文件的自定义位置，默认是anchor_domains.txt --force_hmmscan Force domain prediction using hmmscan even if BiG-SCAPE finds processed domtable files (e.g. to use a new version of PFAM). 即使BiG-SCAPE找到处理过的domtable文件，也强制使用hmmscan进行域预测（例如使用新版本的PFAM） --skip_ma Skip multiple alignment of domains\\\u0026#39;sequences. Use if alignments have been generated in a previous run. 跳过域序列的多重比对。如果比对已在之前的运行中生成，请使用此选项 --mibig Include MIBiG 3.1 BGCs as reference (https://mibig.secondarymetabolites.org/). These BGCs will only be kept if they are connected to a region in the input set (distance \u0026lt; max(cutoffs)). 包含MIBiG 3.1 BGC作为参考（https://mibig.secondarymetabolites.org/ ）。 只有当这些BGC与输入集中的某个区域相连（距离\u0026lt;最大截断值）时才会保留 --mibig21 Include BGCs from version 2.1 of MIBiG 包含MIBiG 2.1版本中的BGC --mibig14 Include BGCs from version 1.4 of MIBiG 包含MIBiG 1.4版本中的BGC --mibig13 Include BGCs from version 1.3 of MIBiG 包含MIBiG 1.3版本中的BGC --query_bgc QUERY_BGC Instead of making an all-VS-all comparison of all the input BGCs, choose one BGC to compare with the rest of the set (one-VS-all). The query BGC does not have to be within inputdir 不进行所有输入BGC的全部对比，而是选择一个BGC与其余的集合进行对比（单一对比全部）。查询BGC不必在inputdir中 --domain_includelist Only analyze BGCs that include domains with the pfam accessions found in the domain_includelist.txt file 仅分析包含domain_includelist.txt文件中pfam登录名的BGC --version show program\\\u0026#39;s version number and exit 显示程序的版本号并退出 Example 1 2 3 4 5 6 7 8 mkdir BiG-SCAPE_example cd BiG-SCAPE_example wget https://zenodo.org/record/1340617/files/gbks.tar.gz?download=1 tar -zxvf gbks.tar.gz tree gbks/ 示例文件里共有23个BGCs：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 gbks/ |-- BGC0000715.1.cluster001.gbk |-- JMGX01000001.1.cluster003.gbk |-- JMGX01000001.1.cluster009.gbk |-- JMQG01000002.1.cluster016.gbk |-- JOBV01000001.1.cluster003.gbk |-- JOBV01000001.1.cluster044.gbk |-- JOBW01000001.1.cluster001.gbk |-- JOBW01000001.1.cluster018.gbk |-- JOBW01000001.1.cluster027.gbk |-- JOES01000001.1.cluster004.gbk |-- JOES01000001.1.cluster049.gbk |-- JOHJ01000001.1.cluster020.gbk |-- JOIW01000001.1.cluster027.gbk |-- JOIW01000001.1.cluster028.gbk |-- JOJM01000001.1.cluster017.gbk |-- JOJM01000001.1.cluster022.gbk |-- JOJM01000001.1.cluster024.gbk |-- JPRA01000006.1.cluster028.gbk |-- KL589150.1.cluster015.gbk |-- LGCX01000001.1.cluster014.gbk |-- LMFT01000001.1.cluster017.gbk |-- MDDK01000001.1.cluster053.gbk `-- NC1.1.cluster031.gbk 运行bigscape：\n1 bigscape -i gbks -o example_output 2核的任务，共耗时635s\nInput files BiG-SCAPE的输入文件是GenBank格式的BGC文件，但是有一些要注意的点：\n从\u0026ndash;inputdir文件夹开始，BiG-SCAPE将递归查找具有.gbk扩展名的文件。以下文件将被排除：\n文件名中包含\u0026ndash;exclude_gbk_str指定的字符串（默认值为“final”。这是为了排除由antiSMASH生成的汇总GenBank文件，文件名以.final.gbk结尾） 路径（包括文件名）中有空格的文件。空格与hmmer不兼容 文件名包含“_ORF”的文件，这是BiG-SCAPE内部使用的标记 名称重复的文件（例如在不同文件夹中） 无法提取蛋白质序列的文件 序列（所有记录的总和）短于min_bgc_size的文件 由于格式问题无法被BioPython解析的文件 默认情况下，仅包括以下文件：\n文件名中包含“cluster”的文件（antiSMASH 4） 文件名中包含“region”的文件（antiSMASH 5以上） 如果需要排除或包括文件名中包含特定字符串的文件，请使用\u0026ndash;exclude_gbk_str和\u0026ndash;include_gbk_str选项。\n如果两个CDS特征重叠（例如剪接事件），BiG-SCAPE的行为是允许最短CDS的最大10%的重叠。如果检测到更多的重叠，BiG-SCAPE将从分析中删除最小的特征。\n文件名（不包括扩展名）将用作BGC名称。请注意，目前BiG-SCAPE对特定分类（即细菌、古菌、真菌或植物BGC）没有任何特殊分析，所有分类处理方式相同。\n对于我们微生物组获得的大量MAG来做分析，我们最好是把所有的bgk文件重命名后放在一个文件夹下，然后运行BiG-SCAPE*即可\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 mkdir gbk_files #MAG_BGC文件夹下是所有的MAG的BGC文件夹，每个文件夹下有多个gbk文件 ls MAG_BGC/ \u0026gt;MAG_list for i in `cat MAG_list` do echo $i #把*region*.gbk提取出来，如果没有region就跳过，如果是cluster就修改一下 find MAG_BGC/$i -name \u0026#34;*region*.gbk\u0026#34; \u0026gt;tmp_list for j in `cat tmp_list` do #重命名成genome_name_region的形式并拷贝到一个目录 cp $j gbk_files/${i}_$(basename $j) done done **而且建议在运行antiSMASH时加上\u0026ndash;allow-long-headers参数，允许长名，不会截短。**这样后续处理会方便很多。\nOutput 输出文件夹结构：\ncache: 存放分析的预计算数据。如果BiG-SCAPE再次运行并指向相同的输出文件夹，它将尝试从该目录读取并重用文件。 domains: 对于分析中发现的每个域，生成三个文件： fasta文件: 包含来自所有BGC中所有蛋白质的相同域的序列。 stk文件: 使用hmmalign对每个序列进行比对，格式为stockholm。 algn文件: fasta格式的比对域序列文件（从stockholm文件解析）。这些是将用于DSS的序列。 domtable: 使用hmmscan对每个BGC的蛋白质序列进行域预测的原始输出。 fasta: 每个BGC的蛋白质序列。从GenBank文件的CDS特征中提取。 pfd: 解析自domtable文件的结果，格式为制表符分隔。这些结果已经过滤了重叠域。列包括：簇名称，（每个域的）得分，基因ID（如果存在），包络坐标开始，包络坐标结束（域预测的氨基酸坐标），pfam ID，pfam描述，基因开始坐标，基因结束坐标，内部cds头。 pfs: 每个BGC文件的预测域列表。 .dict文件: 内部文件 html_content: 所有交互式可视化所需的代码。 logs: 目前仅包含每次运行（指向此输出文件夹）使用的参数和运行时间。 network files: 详见下一节信息。 SVG: 分析中每个BGC的箭头图，格式为svg。每个图都有表示预测域的框。这些框有随机颜色，但用户可以通过修改domains_color_file.tsv文件更改颜色。 network files文件夹\n每次运行都会生成一组输出文件，可以使用其他工具（例如Cytoscape）进行分析：\nNetwork_Annotations_Full.tsv: 一个包含每个成功处理的BGC信息的制表符分隔文件。信息包括： BGC名称 来自GenBank文件的原始登录ID 原始GenBank文件中的描述 antiSMASH产物预测 BiG-SCAPE分类 来自原始GenBank文件的生物体标签 来自GenBank文件的分类字符串 表格展示上面example输出结果的前三行，有这个表后我们就可以对样本的BGCs情况做一些整体情况的可视化了：\nBGC Accession.ID Description Product Prediction BiG-SCAPE class Organism Taxonomy BGC0000715.1.cluster001 BGC0000715.1 Spectinomycin biosynthetic gene cluster amglyccycl Saccharides . NA JMGX01000001.1.cluster003 JMGX01000001.1 Streptomyces rimosus strain R6-500MV9 contig001, whole genome shotgun sequence nrps NRPS . NA JMGX01000001.1.cluster009 JMGX01000001.1 Streptomyces rimosus strain R6-500MV9 contig001, whole genome shotgun sequence cf_fatty_acid.indole.nrps Others . NA 每个BiG-SCAPE分类的文件夹，包含： .network文件: 每个选择的截断值对应一个文件。 网络注释文件，包含用于该特定分类的BGC。 聚类文件：这些文件包含每个截断值的BGC名称，第一列是BGC名称，第二列（用制表符分隔）是表示BGC被分配到的簇（GCF编号）的标签。 此外，结果还可以进行交互式探索：通过点击index.html文件或用任何网页浏览器打开该文件来启动交互式输出。\n打开可视化页面时，会显示概览页面。\n我们可以在网站顶部点击选择一个类（比如NRPS），屏幕将显示该类中BGC族的网络可视化：\n对于example data的这个结果，NRPS类包含10个BGCs，分别在一个有三个成员的基因簇家族中，一个有两个成员的家族和五个单体。\n在这个网络中选择一个家族（比如FAM006），可视化BGCs并通过CORASON进行对齐：\n这个家族有3个成员，结构类似。 More details 我们可以了解以下概念以便对BiG-SCAPE的结果有更深的理解：\nBiG-SCAPE 分类 默认情况下，BiG-SCAPE 会尝试将簇分为八类。这是基于 antiSMASH 的产品注释进行的（详见此处）。antiSMASH 5 和 6 中引入的新标签用上标标注。\n目前遵循的规则如下：\nantiSMASH 注释 BiG-SCAPE 分类 t1pks, T1PKS5 PKS I transatpks, t2pks, t3pks, otherks, hglks, transAT-PKS5, transAT-PKS-like5, T2PKS5, T3PKS5, PKS-like5, hglE-KS5, prodigiosin 以及与 {t1pks, T1PKS5} 或自身组合的 PKS other nrps, NRPS5, NRPS-like5, thioamide-NRP5, NAPAA6 NRPS lantipeptide, thiopeptide, bacteriocin, linaridin, cyanobactin, glycocin, LAP, lassopeptide, sactipeptide, bottromycin, head_to_tail, microcin, microviridin, proteusin, guanidinotides, lanthipeptide5, lipolanthine5, RaS-RiPP5, fungal-RiPP5, thioamitides5.1, lanthipeptide-class-i6, lanthipeptide-class-ii6, lanthipeptide-class-iii6, lanthipeptide-class-iv6, lanthipeptide-class-v6, ranthipeptide6, redox-cofactor6, RRE-containing6, epipeptide6, cyclic-lactone-autoinducer6, spliceotide6, crocagin 以及与这些组合的 RiPPs amglyccycl, oligosaccharide, cf_saccharide, saccharide5 以及与这些组合的 Saccharides terpene Terpene {PKS I} 中的任意一个 + {NRPS} 中的任意一个 PKS/NRPS Hybrids acyl_amino_acids, arylpolyene, aminocoumarin, ectoine, butyrolactone, nucleoside, melanin, phosphoglycolipid, phenazine, phosphonate, other, cf_putative, resorcinol, indole, ladderane, PUFA, furan, hserlactone, fused, cf_fatty_acid, siderophore, blactam, fatty_acid5, PpyS-KS5, CDPS5, betalactone5, PBDE5, tropodithietic-acid5, NAGGN5, halogenated5, pyrrolidine6, mycosporine-like 以及任何组合注释 Others * \u0026lt; mix \u0026gt; Hybrids： 如果启用hybrids模式，某些簇可能会在不同类别中进行分析（如果这些是有效类别）：\n如果簇属于PKS-NRP_Hybrids BiG-SCAPE分类：该簇还将被放入NRPS类别和PKS类别之一（PKS I 或 PKS other）。如果簇包含t1pks注释，它将始终被放入PKS I 类别。 如果簇被分类为Others，且BiG-SCAPE检测到这是由于多重注释（例如terpene-t1pks），BiG-SCAPE还会将该簇放入每个不同的单独类别。 Domain 预测 从输入文件中找到的所有BGC的蛋白质序列被存储在一个fasta文件（\u0026lt;bgc.fasta\u0026gt;）中。然后，BiG-SCAPE使用HMMER套件中的hmmscan工具从Pfam数据库中预测域。实际使用的命令是：\n1 hmmscan --cpu 0 --domtblout \u0026lt;bgc.domtable\u0026gt; --cut_tc \u0026lt;path-to-PfamA.hmm\u0026gt; \u0026lt;bgc.fasta\u0026gt; 其中，--cut_tc选项根据hmmscan官方文档：\n使用模型中的TC（可信阈值）比特得分阈值来设置每个序列（TC1）和每个域（TC2）的报告和包含阈值。TC阈值通常被认为是最低得分的已知真阳性分数，高于所有已知的假阳性。\n用于提取和处理域序列的坐标是包络坐标。同样来自HMMER指南：\n（“env from”和“env to”）定义了目标序列上域位置的包络。包络几乎总是比HMMER选择显示的可信比对要宽一些。正如前面提到的，包络代表了包含给定同源域的大部分后验概率的子序列，即使精确的端点只是模糊地可推断。\n在域预测之后，会执行一个过滤步骤，基于每个域的得分丢弃重叠的域。当比较同一CDS内的域对时，如果任何域的序列的氨基酸重叠百分比（即氨基酸重叠数/域长度）高于overlap_cutoff（由--domain_overlap_cutoff参数设置，默认为0.1），则会触发域过滤。\nGCFs 和 GCCs 一旦为数据集计算出距离矩阵，就会根据 --cutoffs 参数选择的每个截止距离执行基因簇家族（GCF）的分配。\n对于每个截止值，BiG-SCAPE 会创建一个网络，使用所有小于或等于当前截止值的距离。Affinity Propagation 聚类算法将应用于从此过程中出现的每个连接组件的子网络。Affinity Propagation 的相似度矩阵包括子网络成员之间的所有距离（即包括那些大于当前截止值的距离）。\n基因簇氏族（GCC）设置（默认启用）将在 GCFs 上执行第二层聚类。为此，将再次应用 Affinity Propagation（即在子连接组件的网络上），但网络节点由在 --clan_cutoff 参数的第一个值（默认：0.3）指定的截止水平定义的 GCFs 表示。聚类将应用于所有 GCFs 连接的网络，距离小于或等于 GCC 截止值（--clan_cutoff 参数的第二个值；较大的距离将被舍弃，默认：0.7）。GCFs 之间的距离计算为两个家族内 BGCs 之间的平均距离。\n两层聚类中使用的 Affinity Propagation 参数：damping=0.9, max_iter=1000, convergence_iter=200。\n","date":"2024-05-13T00:00:00Z","image":"/p/big-scape-bgcs/images/big3_hu_c9357bc38aabe25d.png","permalink":"/p/big-scape-bgcs/","title":"使用BiG-SCAPE挖掘微生物组BGCs"},{"content":"Introduction 上次简要介绍过了微生物组中生物合成基因簇（BGCs）分析，这次具体讲解使用antiSMASH数据库及软件分析的流程。\nantiSMASH（antibiotics \u0026amp; Secondary Metabolite Analysis Shell）是一个用于识别和分析微生物中生物合成基因簇（BGCs）的工具。BGCs是一组编码生物合成途径的基因，这些途径用于合成生物活性化合物，如抗生素、抗肿瘤药物等。通过分析BGCs，可以帮助研究者发现新的生物活性化合物，并了解这些化合物的生物合成途径。\n网址：https://antismash.secondarymetabolites.org\nantiSMASH 使用基于规则的方法来识别 SM 生产中涉及的许多不同类型的生物合成途径。对编码非核糖体肽合成酶（non-ribosomal peptide synthetases，NRPS）、I型和II型聚酮合酶（polyketide synthases，PKS）、羊毛肽（lanthipeptides）、套索肽（sactipeptides）、活性肽（sactipeptides）和硫肽（thiopeptides）的BGC进行更深入的分析，针对这些簇特异性分析可以提供更多信息有关所执行的生物合成步骤的信息，从而还可以提供对所产生的化合物的更详细的预测（下图）：\n网页版 antiSMASH网页版提供细菌、真菌和模式植物三类生物的BGC分析页面。 细菌和真菌类似，模式植物则差异较大。\n这是 antiSMASH 的最新稳定细菌版本的屏幕截图如下：\n注册antiSMASH作业 如果希望在完成工作后收到电子邮件提醒您可以选择在“通知设置”面板中提供电子邮件地址。一旦顺利完成或不幸发生任何错误，将收到一封电子邮件，其中包含已完成作业的链接。\n如果没有提供电子邮件地址，则应该为作业提交页面的链接添加书签，否则将无法再访问结果。\nantiSMASH 输入数据 有注释的核苷酸序列 antiSMASH 的理想输入是 Genbank 格式或 EMBL 格式的带注释的核苷酸文件。可以手动上传本地 GenBank/EMBL 文件，也可以直接输入序列的 GenBank/RefSeq 登录号，以便 antiSMASH 上传。\n可以在“数据输入”面板中切换该选项，其中默认为accession number，antiSMASH 将尝试直接从 NCBI 下载数据。\n2. 无注释的核苷酸序列 如果上传的序列没有可用的基因注释，建议通过 RAST 等注释管道处理序列，以获得具有高质量注释的 GBK/EMBL 文件。\n或者可以提供包含单个序列的 FASTA 文件，antiSMASH 将使用 Prodigal 生成初步注释，并使用注释结果来运行其余的分析。\n或者可以提供包含单个序列的 FASTA 文件和 GFF3 格式的基因注释。\nantiSMASH 默认和额外功能 在按下提交按钮之前，您必须指出您想要运行哪些 antiSMASH 功能。\n默认情况下，antiSMASH 将运行以下功能：\nKnownClusterBlast 分析：根据 MIBiG 存储库搜索已识别的集群。 MIBiG 是一个手工策划的生物合成基因簇数据集合，这些数据已经过实验表征。 Subcluster Blast 分析：根据数据库搜索识别出的簇，该数据库包含参与常见次级代谢产物构建块（例如非蛋白氨基酸的生物合成）生物合成的操纵子。 以下 antiSMASH 功能始终在后台运行：\nsmCOG 分析：次级代谢基因家族 (smCOG) 分析尝试使用特定于该家族保守序列区域特征的轮廓隐马尔可夫模型，将检测到的基因簇中的每个基因分配到次级代谢特异性基因家族。换句话说，将簇中的每个基因与参与次级代谢的蛋白质直系同源组簇的数据库进行比较。此外，系统发育树由每个基因以及 smCOG 种子比对的（最多 100 个）序列构建。然后可以使用该信息来提供基因产物的假定功能的注释。 smCOG分析结果可用于基因的功能预测和系统发育分析。 Active site finder：检测几种高度保守的生物合成酶的活性位点并报告活性位点的变化。 Detect TTA codons：含有高 GC 的细菌序列（默认情况下 antiSMASH \u0026gt;65%），例如来自链霉菌的细菌序列，含有罕见的亮氨酸密码子“TTA”，作为通过限制/控制 TTA 量进行转录后调节的手段-细胞中的tNRA。 这种类型的调节常见于次级代谢产物 BGC。此功能将在已识别的 BGC 中注释此类 TTA 密码子。 额外功能：\n以下三个功能默认关闭，被认为对高级用户有用，或者在发现有趣的生物合成基因簇需要进一步详细分析时有用:\nClusterBlast分析：根据综合基因簇数据库搜索已识别的簇，并识别相似的簇。这里使用的算法受到 MultiGeneBlast 的启发。它使用检测到的基因簇中的每个氨基酸序列运行 BlastP，作为对来自次级代谢物生物合成基因簇的预测蛋白质序列的大型数据库的查询，并汇集结果以识别与所检测的基因簇最同源的基因簇。 Cluster Pfam 分析：根据 PFAM 数据库对检测到的 BGC 中编码的每个基因产物进行分析。命中结果在最终的 Genbank/EMBL 文件中进行了注释，分析完成后可以下载这些文件。这些结果不会显示在 antiSMASH HTML 结果页面上，但它们存在于可下载的结果 genbank 文件中。 Pfam-based GO term annotation：这是用 GO 术语注释来注释上述 Cluster Pfam 分析。请注意，这些结果不会显示在 antiSMASH HTML 结果页面上，但它们存在于可下载的结果 genbank 文件中。 提交antiSMASH作业 设置在线 antiSMASH 作业后，点击页面底部的提交，基因簇识别和分析的计算将在antiSMASH服务器上进行。 当工作完成后，用户会收到一封通知电子邮件。或者转到已添加书签的链接来检查分析是否已完成。\n本地版 安装 官方教程：https://docs.antismash.secondarymetabolites.org/install/\n请选择以下四种方式的一种即可！\nBioconda，依赖项很多，安装很慢 1 2 3 4 5 6 7 8 9 # 创建环境 conda create -n antismash antismash conda activate antismash # 下载数据库 download-antismash-databases # 想运行 antiSMASH，只需调用 antismash my_input.gbk Docker，有些集群环境无法使用Docker 1 2 3 4 mkdir ~/bin curl -q https://dl.secondarymetabolites.org/releases/latest/docker-run_antismash-full \u0026gt; ~/bin/run_antismash chmod a+x ~/bin/run_antismash run_antismash \u0026lt;input file\u0026gt; \u0026lt;output directory\u0026gt; [antismash options] Manual, 大部分没有root权限用不了 1 2 3 4 5 6 7 sudo apt-get update sudo apt-get install -y apt-transport-https sudo wget http://dl.secondarymetabolites.org/antismash-stretch.list -O /etc/apt/sources.list.d/antismash.list sudo wget -q -O- http://dl.secondarymetabolites.org/antismash.asc | sudo apt-key add - sudo apt-get update sudo apt-get install hmmer2 hmmer diamond-aligner fasttree prodigal ncbi-blast+ muscle glimmerhmm 半手动安装 如果可以一次性bioconda安装成功那便是极好的，但我在安装过程中遇到了不少问题，最后参考https://github.com/BioGavin/wlab_antismash提供的方法比较顺利地成功了：\n首先下载该github仓库下的文件（不同版本的antiSMASH）\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 conda create -n antismash_5.2.0 python=3.8 # 创建环境 conda activate antismash_5.2.0 #激活环境 # 将antismash_5.2.0/bin 文件夹中的两个脚本文件（Unix可执行文件）放置到 ~/miniconda3/envs/antismash_5.2.0/bin/ 目录下 cp antismash_5.2.0/bin/* ~/miniconda3/envs/antismash_5.2.0/bin/ # 将目标版本5.2.0的 antismash 包文件放置到 ~/miniconda3/envs/antismash_5.2.0/lib/python3.8/site-packages/ 目录下 cp -r antismash_5.2.0/antismash ~/miniconda3/envs/antismash_5.2.0/lib/python3.8/site-packages/ # 根据环境配置文件安装依赖 conda env update --file antismash_5.2.0/antismash.yaml pip install -r antismash_5.2.0/requirements.txt # 如果上述步骤顺利，此时可以运行成功 antismash -h # 进一步检查 antismash --check-prereqs # 下载数据库速度较慢，放后台慢慢下载，我花了4小时 nohup download-antismash-databases \u0026amp; 运行参数 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 $ antismash -h ########### antiSMASH 5.2.0 ############# 用法: antismash [-h] [options ..] sequence 参数: SEQUENCE 包含DNA序列的GenBank/EMBL/FASTA文件。 -------- 选项 -------- -h, --help 显示此帮助文本。 --help-showall 在此帮助文本上显示所有参数的完整列表。 -c CPUS, --cpus CPUS 并行使用的CPU数量。 (默认值: 64) 基本分析选项: --taxon {bacteria,fungi} 输入序列的分类学分类。 (默认值: bacteria) 附加分析: --fullhmmer 运行全基因组HMMer分析。 --cassis 基于模体的SM基因簇区域预测。 --cf-borders-only 仅注释现有簇的边界。 --cf-create-clusters 查找额外的簇。 --clusterhmmer 运行基于簇的HMMer分析。 --smcog-trees 生成次级代谢物簇正交基因组的系统发育树。 --tta-threshold TTA_THRESHOLD 注释TTA密码子的最低GC含量 (默认值: 0.65)。 --cb-general 将识别的簇与antiSMASH预测的簇数据库进行比较。 --cb-subclusters 将识别的簇与负责合成前体的已知子簇进行比较。 --cb-knownclusters 将识别的簇与MIBiG数据库中已知的基因簇进行比较。 --asf 运行活性位点查找分析。 --pfam2go 运行Pfam到基因本体映射模块。 输出选项: --output-dir OUTPUT_DIR 写入结果的目录。 --output-basename OUTPUT_BASENAME 用于输出目录中输出文件的基本文件名。 --html-title HTML_TITLE HTML输出页面的自定义标题（默认为输入文件名）。 --html-description HTML_DESCRIPTION 要添加到输出的自定义描述。 --html-start-compact 默认情况下使用紧凑视图的概览页面。 基因查找选项 (当ORFs已注释时被忽略): --genefinding-tool {glimmerhmm,prodigal,prodigal-m,none,error} 指定用于基因查找的算法: GlimmerHMM、Prodigal、Prodigal Metagenomic/Anonymous模式或无。\u0026#39;error\u0026#39;选项将在尝试基因查找时引发错误。\u0026#39;none\u0026#39;选项不会运行基因查找。 (默认值: error)。 --genefinding-gff3 GFF3_FILE 指定要从中提取特征的GFF3文件。 运行示例 默认参数运行 默认的 antiSMASH 将运行核心检测模块和那些运行速度相当快的分析。\n更耗时的选项（例如 ClusterBlast 分析、Pfam 注释、smCoG 树生成等）将不会运行。 在四核机器上，跑完天蓝色链霉菌的基因组大约需要两分钟。\n1 2 # 本地运行 antismash streptomyces_coelicolor.gbk minimal模式运行 使用 --minimal 参数运行 antiSMASH 将仅运行核心检测模块，而不会运行其他模块。\n如果需要，可以使用其匹配选项显式重新启用由此禁用的任何模块（例如 HTML 输出）（参阅 --help-showall）。\n在四核机器上，以minimal模式运行天蓝色链霉菌基因组大约需要一分钟。 一般来建议在不加 --minimal，因为默认运行只需额外一分钟的运行时间即可生成更有用的结果。\n处理MAG 一般分箱得到的MAG是没有功能注释的纯fasta文件，可以使用 --genefinding-tool prodigal 参数运行 prodigal，这样可以生成初步注释。\n1 antismash test_MAG.fa --genefinding-tool prodigal 重用上次运行的结果 先前由 antiSMASH 生成的 JSON 输出文件可以重复使用以重新生成其他输出文件。通过添加选项，可以为新运行启用其他分析。\n1 antismash --reuse-results strepomyces_coelicolor.json 结果解读 Overview 页面左上方是antiSMASH版本信息（1）。 antiSMASH 结果之间的直接比较应使用相同版本以保持一致性，因为结果可能会因版本而异。 页面右上角是可能有用的辅助链接。 Download允许您下载结果的各个部分。 AboutantiSMASH 信息（包括出版物）的链接。 Help指向这些文档页面的帮助链接。 ``Contact`链接到一个包含表单的页面，用于向 antiSMASH 开发人员发送反馈或问题。 顶部栏下方是Region按钮 (2)。这些按钮在所有 antiSMASH HTML 页面上都可见，并且可用于在区域之间快速跳转。如果正在查看某个区域，该区域的匹配按钮将突出显示。区域按钮的形式为 X.Y.例如，5.7 将是第五条记录中的第七个区域。区域按钮按预测的次要代谢物类型进行颜色编码。单击Overview按钮将使您返回此页面。 这些Region按钮下方是每条记录的摘要，每个按钮均以输入文件中给出的记录名称 (3) 开头。 顶部是一个图像 (4)，显示区域在记录中的位置。 图像下是一个表，其中包含记录中找到的每个区域的摘要，每行 (5) 具有以下字段： Region：Region编号 Type：antiSMASH 检测到的产品类型（单击类型将带您进入这些帮助页面中的描述） From、To：区域的位置（以核苷酸为单位） Most similar known cluster：MiBIG 数据库中最接近的化合物（单击此按钮将带您进入 MiBIG 条目）及其类型（例如 t1pks+t3pks） Similarity：最接近的已知化合物中对当前区域内的基因具有显着 BLAST 命中的基因的百分比 仅当使用 KnownClusterBlast 选项运行 antiSMASH 时，才会显示包含与 MiBIG 数据库比较的最后两列。\nResult 在上图“基因簇描述”中，给出了有关检测到的每个基因簇的信息。\n上面一行显示了基因簇的生物合成类型和位置。在此标题行下方，概述了检测到的基因簇中存在的所有基因。基因簇的边界是使用每个基因簇类型指定的不同贪婪选择的截止值来估计的。\n基因按预测功能进行颜色编码。预测的生物合成基因为红色，运输相关基因为蓝色，调节相关基因为绿色。这些预测取决于 smCOG 功能，如果您选择不运行 smCOG 预测，这些预测将会丢失。\n将鼠标悬停在某个基因上，基因名称会显示在该基因上方。\n单击基因将提供有关该基因的更多信息：标识符、现有产物注释、基因功能（包括 smCOG 或次级代谢基因家族）、其位置以及特定于该基因的交联。\nRegion概念 目前还没有好的方法可以纯粹根据提交的序列数据准确预测基因簇边界。因此，antiSMASH 预测的是输入基因组上的感兴趣\u0026quot;Region\u0026quot;。\nantiSMASH 5 及更高版本中的 Region 对应于 antiSMASH 4 及更早版本中的 gene cluster 注释。\nRegion是如何定义的？\n第一步，根据高度保守的酶 HMM 图谱（核心酶）数据库搜索所分析序列的所有基因产物，这些图谱指示特定的 BGC 类型。 第二步，采用预定义的聚类规则来定义在该区域中编码的各个原聚类。它们构成了一个核心，并由其邻近区域延伸，这些邻近区域由核心上游和下游编码的基因组成。 以下是检测 I 型 PKS 的原集群的规则示例：\n当 antiSMASH 发现编码具有 PKS_AT 结构域和各种亚型的 PKS_KS 结构域的蛋白质的基因时，就会在该区域内生成新的“I 型 PKS 原簇”特征；\n该特征包括触发规则的核心基因产物（即 PKS 编码基因），并将核心基因的左右邻域向左和右扩展 20 kb（由 EXTENT 参数定义）\n不同簇类型的值是根据经验确定的，通常倾向于过度预测，即在分配原簇特征后（注意：单个区域内可以有多个原簇特征），它们是检查重叠（由 CUTOFF 参数定义）并分为几种类型的候选簇，以反映许多 BGC 实际上包含几类生物合成机制的观察结果。\n例如万古霉素或巴希霉素（如上图所示）等糖肽是通过 NRPS 合成的。还包含 III 型 PKS 作为前体途径。\n因此，显示的区域包含 NRPS 原簇（绿色条）和 T3PKS 原簇（黄色条）。当它们的邻域重叠时，它们被分配到候选簇。 化学杂化 这些候选簇包含共享簇定义 CDS/基因/基因产物的原簇。它们还将包括该共享范围内不共享 CDS 的原星团，前提是它们完全包含在超星团边界内。例如上图中的情况A。 在示例中，CDS 1 和 2 定义类型 A 的原簇，CDS 2 和 4 定义类型 B 的原簇。由于两个原簇共享定义这些原簇的 CDS，因此创建了化学混合候选簇。如果 CDS 4 和一些后来的 CDS 也对第三种原簇类型做出了贡献，那么它将被合并到同一个候选簇中。如果 CDS 3 定义了另一个未超出 CDS 1 或 4 的原簇，那么假设新的原簇与其他原簇相关，那么该新的原簇也将包含在化学混合中。\n交错 这些候选簇包含不共享簇定义 CDS 特征的原簇，但它们的核心位置重叠，例如上图中的情况 B。\n邻接 这些候选簇是混合候选簇的最弱形式。它们包含与化学变体或交错变体都不匹配的原簇，但在其邻域中传递重叠。 “相邻候选簇”中的每个原簇也将属于其他类型的候选簇之一，包括下面描述的单一类型，除非它是单个候选簇并且具有相邻候选簇的精确坐标的情况。\nSingle 这种候选簇存在于仅包含一个原簇的地方，例如情况D。它的存在只是为了内部一致性。对于包含在化学杂合体或交错候选簇中的原簇来说，将不存在单个候选簇，但对于相邻候选簇内的每个原簇来说，将存在单个候选簇。例如，情况 C 中的两个原簇都将有一个独立的单个候选簇以及邻近的候选簇。\n尝试将微生物组项目中的MAGs跑完antiSMASH并进行下游的统计分析和可视化，下次再分享\n","date":"2024-05-07T00:00:00Z","image":"/p/antismash/images/clusterrules_hu_274f457f97ab201c.png","permalink":"/p/antismash/","title":"使用antiSMASH数据库及软件分析微生物组"},{"content":" Introduction 天然产物（natural product，NP）是指生物体内的组成成分或其代谢产物，具有广泛的应用价值。 其中，来源于微生物的次级代谢产物，在生物医学、工业和农业中扮演着重要角色[1]。\n生物合成基因簇（biosynthetic gene cluster，BGC） 是一类非常重要的基因集合类型。 一个BGC通常包含数个到上百个功能基因，共同产生一个或者若干个小分子代谢物。\n从序列上来说，一个BGC所囊括的基因一般在染色体上成簇排列。例如，青霉素的合成由三个基因控制，分别是pcbAB、pcbC和penDE，这三个基因位于同一条染色体上。 从功能上来说，一个BGC所囊括的基因通常共同产生一个或者若干个小分子化合物。次生代谢产物（secondary metabolites，SM）是BGC合成的主要产物，大部分具有生物活性，通常是低分子量的化合物，在生长和发育的特定阶段产生。例如，抗生素，翻译后修饰核糖体多肽（RiPP，核糖体合成，经由翻译后修饰得到的一大类天然产物）。 生物合成基因簇（BGCs）可以根据它们所编码产生的次级代谢物类型来分类[2]。以下是一些主要类型：\n聚酮类合成酶基因簇（Polyketide Synthases, PKSs）： 这类基因簇负责产生大量的聚酮类化合物，这些化合物通常具有抗生素、抗癌或其他生物活性。 非核糖体肽合成酶基因簇（Nonribosomal Peptide Synthetases, NRPSs）： NRPS基因簇编码非核糖体肽合成酶，这些合成酶可以生产多肽类次级代谢物，如抗生素和免疫抑制剂。 核糖体合成肽基因簇（Ribosomal Synthesized and Post-translationally Modified Peptides, RiPPs）： 这类基因簇编码通过核糖体合成并在翻译后进行修饰的肽类化合物。 萜类合成基因簇（Terpene Synthases）： 萜类基因簇编码合成萜类化合物的酶，这些化合物广泛存在于植物中，具有多种生物学和药理作用。 碱性化合物基因簇（Alkaloid Synthases）： 碱性化合物基因簇负责生产碱性化合物，这些化合物通常具有药理活性，如镇痛和抗癌效果。 混合型基因簇： 混合型基因簇包含多种类型的合成酶，能够生产具有复杂生物活性的混合次级代谢物。 从大量环境微生物分离培养，挖掘生物合成基因簇（biosynthetic gene cluster，BGC）以检验并生产新型NP十分困难。 但随着高通量测序技术和生物大数据处理工具的快速发展，直接从宏基因组（metagenome）中探索BGC的策略已经越来越成熟：\nMethods 重要的BGC通常通过干湿实验共同确定：\n生信方法: 从宏基因组数据中挖掘 BGC 包括两大类方法：BGC 的挖掘方法和 BGC 的优化方法。 BGC 的挖掘方法主要分为序列比对和特征比对。序列比对采用诸如 BLAST 等方法，而特征比对则包括传统的隐马尔科夫模型(HMM)比对以及基于数据模型的深度学习等方法。 而 BGC 的优化方法主要有数据库搜索和进化分析。 数据库搜索涉及 BGC 序列数据库和 BGC 相关小分子质谱数据库的搜索，进化分析的主要目标是分析 BGC 的演化和变异模式。\n湿实验: 分离培养，基因簇表达，产物富集与鉴定。\nDatabases BGC的分析和比对，主要是建立在BGC数据库基础之上：\nantiSMASH 是有关次生代谢物 BGC 的综合资源，集成了各种分析工具。\nMIBiG 定义了生物合成基因簇的最低信息 (MIBiG)：一种标准化数据格式，描述了唯一表征 BGC 所需的最低信息。 同时构建了一个附带的 BGC 在线数据库，详细记录了来自于上千个微生物物种的上千个经实验验证的非冗余BGC。\nBactibase 主要包括细菌及其产生的抗菌肽、细菌素等。\nBiG-FAM 将同源 BGCs 分组到生物合成基因簇家族 (GCF) ，这是生物合成基因簇 (BGC)“同源”组的在线存储库，这些生物合成基因簇 (BGC) 假定编码相似的专门代谢物的产生。通过将从当前可用的基因组和 MAG 中鉴定出的大规模全球 BGC 集合作为数据源，BiG-FAM 提供了可探索的微生物次生代谢多样性“图集”，以浏览和搜索跨类群的生物合成多样性。\nIMG-ABC 集成微生物基因组 - 生物合成基因簇图谱 (IMG-ABC) 是次级代谢物化合物 (SM) 生物合成基因簇 (BGC) 的综合数据集市，根据 IMG 中的所有分离基因组进行预测。此外，从宏基因组衍生的支架箱预测的 BGC 揭示了来自不同环境的稀有或未培养的类群中潜在的新型 SM。\nTools antiSMASH antiSMASH是一套常用的BGCs搜索工具集，其利用人工智能计算工具在数据库基础上进行操作。 其主要功能是基于代谢途径中生物合成酶的基因在染色体上通常成簇排列的原理，通过特定类型的模型来识别已知的次级代谢基因簇。 在antiSMASH中，次级代谢基因簇被分为多个类别，然后通过序列比对等方法进行同源比对和发现BGC。通过分析与目的基因相似的BGC结果，可以大致解读目的基因的功能。\n此外，antiSMASH还提供了一些独立的工具，例如由质谱引导的肽挖掘工具Pep2Path、抗生素耐药性靶标搜寻器ARTS和sgRNA设计工具CRISPy-web等。\nClusterFinder ClusterFinder利用隐马尔可夫模型（HMM）将BGC的核苷酸序列转换为一系列连续的Pfam结构域，因此能够更准确地识别新型BGC。相比之前的算法，ClusterFinder不仅能够识别少数BGC类别，而且基于732个手动汇总的BGC训练集，能够检测出多种特征明确的基因簇类别，为基因簇识别问题提供了更通用的解决方案。\nMetaBGC MetaBGC是一种基于“读段”的算法，能够从人类微生物组中发掘之前未被报道过的BGC。该算法不需要分离培养细菌或进行测序，可以直接在人类微生物组衍生的宏基因组测序数据中识别BGC。通过构建基于群落画像的隐马尔可夫模型，可以在单一的宏基因组读取水平上识别、定量和聚集微生物组衍生的BGC。\nDeepBGC DeepBGC采用深度学习技术来检测细菌和真菌基因组中的BGC。该方法利用双向长期短期记忆递归神经网络和类似word2vec的Pfam蛋白域嵌入，使用随机森林分类器预测产品类别和检测到的BGC的活性。\nExamples 2019年，一项人类肠道微生物宏基因组挖掘工作发现了未培养的细菌基因组编码数百种新的生物合成基因簇，并具有独特功能[3]。通过从11850个人类肠道微生物群中重建92143个宏基因组组装基因组，识别了1952个未培养的候选细菌物种。这些未经培养的细菌物种及其基因组大大扩展了人类肠道微生物群的已知物种库，增加了系统发育多样性281%。这些候选物种编码数百个新的生物合成基因簇，并在铁-硫和离子结合等代谢方面具有独特功能，揭示了未培养肠道细菌的多样性，为肠道微生物群的分类和功能特征提供了前所未有的解决方案。 2018年，基于草原土壤的宏基因组数据[4]，研究人员重建了上千个基因组，其中几百个近乎完整，并鉴定了未被研究过的微生物(一类酸杆菌)，这些微生物编码多种聚酮化合物和非核糖体肽的基因组簇。研究者鉴定出了两个来自不同谱系类群的酸杆菌基因组，每个基因组都拥有一个异常庞大的生物合成基因库，并含有多达15个大型聚酮化合物和非核糖体肽生物合成基因位点。通过微观操作实验，收集了120个时间点的样品，使用转录组学的手段，发现基因簇对不同环境扰动的响应情况并不相同。通过对微生物的转录共表达网络分析，发现生物合成基因的表达与双组分系统、转录激活、假定抗微生物剂抗性和铁调节模块的基因相关，这一结果将代谢物生物合成与环境感知和生态竞争过程联系起来。 2022年，瑞士苏黎世联邦理工学院的研究团队利用基因组学技术和大数据挖掘方法，在全球215个采样点的不同深度层共1038个海水样本中发现了多种海洋细菌生物合成基因簇[5]。他们创建了海洋微生物组学数据库（OMD），发现了39055个生物合成基因簇，参与了约6873种化合物的生物合成过程。进一步的实验验证表明，部分基因簇在亚磷酸盐等化合物的生物合成中发挥关键作用。该研究通过基因组学方法发现了新型海洋细菌和生物合成基因簇，并对部分BGC进行了实验验证，对海洋生态、生物进化和天然产物等领域的研究具有重要意义。 2024年，研究人员分析了来自 9 个不同深海冷泉区域的 81 个宏基因组、33 个宏转录组和 7 个代谢组，以研究它们的次生代谢物[6]。冷泉微生物组编码多样且丰富的生物合成基因簇（BGC）。大多数 BGC 与未被充分研究的细菌和古细菌有关，包括甲烷和硫循环的关键介质。 BGC 编码多种可能影响群落动态的抗菌化合物和预计影响生物地球化学循环的各种代谢物。主要参与者的 BGC 分布广泛且表达量高，其丰度和表达水平随沉积物深度而变化。沉积物代谢组学揭示了独特的天然产物，突出了未知的化学潜力并证实了这些沉积物中的 BGC 活性。 尝试将BGC挖掘流程应用在自己的微生物组项目中，下次再分享具体的分析流程代码。\nReferences LAI Qilong，YAO Shuai，ZHA Yuguo，BAI Hong，NING Kang. Microbiome-based biosynthetic gene cluster data mining techniques and application potentials[J]. Synthetic Biology Journal，2023，4(3):611-627 Barbara R Terlouw, Kai Blin, Jorge C Navarro-Muñoz, Nicole E Avalon, et al., MIBiG 3.0: a community-driven effort to annotate experimentally validated biosynthetic gene clusters, Nucleic Acids Research, Volume 51, Issue D1, 6 January 2023, Pages D603–D610 A. Almeida, A. L. Mitchell, M. Boland, S. C. Forster, G. B. Gloor, A. Tarkowska, T. D. Lawley, R. D. Finn, A new genomic blueprint of the human gut microbiota. Nature 568, 499–504 (2019). A. Crits-Christoph, S. Diamond, C. N. Butterfield, B. C. Thomas, J. F. Banfield, Novel soil bacteria possess diverse genes for secondary metabolite biosynthesis. Nature 558, 440–444 (2018). L. Paoli, H.-J. Ruscheweyh, C. C. Forneris, F. Hubrich, et al., Biosynthetic potential of the global ocean microbiome. Nature 607, 111–118 (2022). X. Dong, T. Zhang, W. Wu, Y. Peng, X. Liu, Y. Han, X. Chen, Z. Gao, J. Xia, Z. Shao, C. Greening, A vast repertoire of secondary metabolites potentially influences community dynamics and biogeochemical processes in cold seeps. Science Advances 10, eadl2281 (2024). ","date":"2024-05-07T00:00:00Z","image":"/p/bgcs/images/BGC_overview_hu_7ffd8fb7378bc024.png","permalink":"/p/bgcs/","title":"微生物组的生物合成基因簇（BGCs）分析"},{"content":"我们实验室的子诺师姐开发了一种新型的用于个体生物和化学暴露组纵向测绘的可穿戴被动采样器：AirPie。 目前可以在一个驱蚊扣差不多大小的device上分析出数千种化合物和微生物信号，非常🐮。\n我们将该采样器应用于某封闭环境，对19名参与者的个体化学和生物暴露组进行了全面的纵向剖析，并与相应的转录组数据进行了整合分析，以揭示环境暴露对个体健康的影响。\n我完成了其中生物暴露部分的实验与分析工作。这项研究目前已经发表在ES\u0026amp;T上：\nPaper Info 标题：Longitudinal Mapping of Personal Biotic and Abiotic Exposomes and Transcriptome in Underwater Confined Space Using Wearable Passive Samplers 译名：使用可穿戴被动采样器对水下密闭空间中个人生物和非生物暴露组及转录组的纵向测绘 期刊：Environmental Science \u0026amp; Technology (IF：11.4) 发表时间：2024年3月11日 第一作者：黄子诺、彭晨 通讯作者：蒋超、谢长勇 通讯单位：浙江大学生命科学研究院 链接：https://pubs.acs.org/doi/10.1021/acs.est.3c09379 图片摘要 成果简介 近日，浙江大学生命科学研究院蒋超课题组受邀并联合海军军医大学谢长勇团队在著名期刊Environmental Science \u0026amp; Technology上在线发表了题为“Longitudinal Mapping of Personal Biotic and Abiotic Exposomes and Transcriptome in Underwater Confined Space Using Wearable Passive Samplers”的研究论文。该工作开发并使用个体可穿戴被动采样器，用非靶向技术纵向分析了个体化学暴露和微生物暴露组，并结合转录组数据，揭示了环境暴露组与人类健康之间错综复杂的联系。\n引言 人类的健康是由基因和环境共同决定的，明确个体所接触的环境生物和化学暴露因素及接触方式，对于推动环境暴露组和精准医学研究至关重要。但是由于暴露组自身的复杂性，使其难以被全面测量，而能准确测量个体水平暴露组的方法技术更是少之又少。现有不少研究使用有机硅被动采样器来评估个人的化学暴露，但通常只使用气质联用(GC-MS)法，该方法只能检测到挥发性有机化合物暴露。研究团队开发了一种名为AirPie（中文名：气派）的聚二甲基硅氧烷（PDMS）可穿戴被动采样器，该设备具有轻便、价格低廉、无侵入性的特点，可以与非靶向液相色谱-高分辨率串联质谱分析（LC-HRMS/MS）、非靶向气相色谱-高分辨率质谱（GC-HRMS）和宏基因组鸟枪测序法相结合，实现对个体空气微生物和化学暴露组的全面解码。\n图文导读 图1 （A）AirPie采样器结构图。（B）AirPie采样器的穿戴方式。（C）个体暴露和血液样本收集分析流程。（D）纵向研究采样时间点，不同颜色表示表示不同的采集阶段：暴露前阶段（A，蓝色）、暴露阶段（B，绿色；C，黄色；D，红色）和暴露后阶段（E，紫色）。\n研究团队设计并开发了AirPie可穿戴被动采样器，并将该采样器应用于某封闭环境，对19名参与者的个体化学和生物暴露组进行了全面的纵向剖析，并与相应的转录组数据进行了整合分析，以揭示环境暴露对个体健康的影响。\n图2 化学和生物暴露组注释概览。（A和B）GC-MS和LC-MS/MS测量的化学暴露组注释概览，根据Schymanski框架进行置信度分级。（C和D）根据化合物InChIKey对GC-MS和LC-MS/MS的注释结果进行比较。（E和F）对GC-MS和LC-MS/MS注释结果使用ClassyFire分类后绘制的化学分类树。（G）微生物暴露组系统分类树。（H）微生物暴露组门水平的丰度热图。\n研究团队将非靶向GC-MS和非靶向LC-MS/MS技术相结合，以最大限度地扩大化学暴露组的检测范围。经过数据清洗和质量控制后，使用LC-MS/MS共检测到3729个化合物，使用GC-MS共检测到661个化合物。研究团队使用数据库比对和计算机算法辅助等多种方法对这些化合物进行注释，并根据Schymanski等人提供的框架，对不同方法得到的注释结果进行置信度分级。在LC-MS/MS检测到的化合物中，有344个化合物得到了“Level 2”较高置信度注释结果；在GC-MS检测到的化合物中，有237个化合物获得了同样高置信度的注释结果。LC-MS/MS检测到的主要是有机酸和酯类化合物；GC-MS检测到的主要是苯类化合物。只有3个化合物能同时被这两种方法检测到，说明了这两个技术的高度互补性。\n对于微生物暴露组分析，研究团队从AirPie采样器中提取了宏基因组DNA后进行鸟枪测序法进行测序。去除人源DNA后，在物种水平上共鉴定到2955 种微生物，包括细菌、古菌、真核生物和病毒。其中细菌和真菌占主导地位，在检测到的31种病毒中噬菌体占主要部分。在门水平上，放线菌门、变形菌门、厚壁菌门和拟杆菌门是检测到最多的细菌。\n图3 化学暴露组的时间动态和毒性分析。(A)对 LC-MS/MS 和GC-MS 结果的普鲁克分析。(B 和 C)分别对 GC-MS和 LC-MS/MS测量的化合物进行模糊C均值聚类分析。（D）对Level 2注释结果进行差异分析，发现进入封闭环境后大量化学物质信号强度显著增加。（E）使用ToxPi模型对化合物进行优先级排序，并额外标注出了化合物是否存在于某些毒物清单中，和化合物对具体身体部位的毒性。（F）使用Significance Analysis of Microarrays方法分析在整个暴露期间显著变化的化合物。（G）暴露阶段信号显著增加的化合物热图。（H）对暴露阶段信号显著增加的化合物进行KEGG富集分析。\n主成分分析显示，化学暴露组在每个采样期间均发生了显著变化（p=0.001）。普鲁克分析结果显示GC-MS与LC-MS/MS数据显著相关联。模糊C均值聚类分析和差异分析结果均显示在进入封闭环境后大量化合物信号强度显著增加，其中包括苯类化合物和多环芳烃（PAHs）等污染物。研究团队使用了ToxPi模型系统地评估了这些化合物的暴露毒性。ToxPi模型整合了化合物的B时期相对于A时期的信号差异倍数、来自ToxCast数据库的内分泌毒性，包括雌激素、雄激素、甲状腺毒性等、以及一些由毒理学模型预测的毒性和物理性质，包括大鼠口服致死性、致癌性、生物半衰期、生物浓缩因子等性质来对所有化合物进行优先级排序，发现N-phenyl-1-naphthylamine、lauryl gallate等是该环境内最值得关注的化合物。\n图4 微生物暴露组的时间动态分析。（A）样本的主成分分析。（B）对物种丰度进行模糊C均值聚类分析。（C）从A到B时期显著增加的部分微生物丰度条形图。（D）桑基图，显示相对丰度排名前5的ARG，以及部分ARG的耐药类别与ARG的耐药机制。（E）从A时期到B时期发生显著变化的部分ARG丰度条形图。（F）微生物暴露相关性子网络的动态变化。\n与化学暴露组类似，生物暴露组在采样期间也发生了显著变化，其中由A至B时期的变化最为显著。模糊C均值聚类将微生物暴露物分成了两组，在进入暴露阶段后相对丰度分别增加或减少。进入暴露阶段后增加的微生物物质包括Corynebacterium propinquum和Janibacter melonis等致病菌。接下来，研究团队进行对测序数据进行组装和基因注释，鉴定到了1305517个非冗余基因，包括245个非冗余抗生素抗性基因（ARG）。在耐药类别方面，多药耐药ARG的相对丰度最高，其次是氟喹诺酮类、四环素类。同样，ARG的相对丰度在进入暴露阶段前后也发生了显著的变化。最后，研究团队构建了一个纵向微生物相关性网络，计算了各种拓扑指标，再次观察到了微生物暴露组A到 B时期的显著变化。\n图5 转录组分析揭示了暴露后免疫和神经退行性疾病相关途径的变化。（A）A与B时期的差异基因分析。（B）KEGG富集分析。（C-E）部分发生显著改变的通路的基因表达模式。（F）A与E时期的差异基因分析。（G）KEGG富集分析。\n研究团队还纵向采集了参与者的血液样本并进行转录组分析。发现参与者进入暴露环境后，大量基因表达发生了显著变化。其中，由A进入B时期后，与多种疾病相关的通路内基因发生上调，而部分和免疫途径相关的基因发生了下调。有趣的是，随着时间的推移，大多数基因的表达逐渐恢复到暴露前的水平，但有一些基因仍受到影响。\n图6 暴露组-转录组相关性分析显示外暴露影响多种疾病。（A）化学暴露组和转录组之间的相关性网络。（B）化学暴露物、基因和信号通路之间的部分相关性网络。（C）微生物暴露组和转录组之间的相关性网络。（D）微生物暴露物、基因和信号通路之间的部分相关性网络。\n接下来，研究团队对外暴露组与转录组进行关联分析，来探究暴露组对人体健康的影响。首先通过spearman相关性，分析了化学暴露与基因表达间的关联，结果发现约有一千个基因与约200多种化学暴露物质显著相关，且主要是负相关；同样，约有500多种微生物与一千多个基因显著相关。对这些基因进行富集分析后发现，化学暴露和生物暴露影响的疾病通路并不一致：与化学暴露相关的基因主要富集到与神经退行性疾病相关的通路，以及一些内分泌相关通路，比如甲状腺激素相关等；而受到生物暴露因素影响的基因主要富集到的是与免疫的负向调控相关通路。\n小结 本研究开发了经济实惠的可穿戴AirPie被动采样器，结合其配套的LC-HRMS/MS、GC-HRMS和宏基因组鸟枪测序法，可以全面解析个体微生物和化学暴露组。研究团队将AirPie采样器应用于特殊封闭环境，并绘制了该环境内的全面纵向暴露组图谱。本研究共注释到4390 种化学物和2955 种微生物暴露，并观察到暴露组在进入该环境前后发生了显著变化，大量污染物如苯类化合物、PAHs、机会致病菌及其相关的ARGs的暴露量显著增加。转录组分析进一步揭示了与化学暴露相关的神经退行性疾病相关途径的激活，以及与生物和化学暴露均相关的免疫相关途径的抑制。本研究揭示了环境暴露与人类健康之间错综复杂的联系，AirPie采样器及其相关的分析方法将在暴露组学和精准医学领域中有广泛的应用。\n本项目得到了浙江大学生命科学研究院启动资金的资助。\n作者简介 通讯作者：蒋超，现任浙江大学生命科学研究院研究员、博导，兼聘浙江大学附属第一医院。长期致力于环境空气暴露组、微生物组、微生物进化、精准医学研究以及相关的分子实验和生信分析方法开发及应用。已在国际知名期刊Cell、Nature、Nature Protocols、Cell Reports、ES\u0026amp;T、Briefings in Bioinformatics、Cell Discovery、mSystems、iMeta、STOTEN、Nature Biotechnology、Circulation Research、Current Biology、Cell Host \u0026amp; Microbe、Microbiome、Genome Research等杂志发表多篇研究论文，获得国内外专利若干。目前任iMeta、Current Microbiology、Bio-protocols副主编、The Innovation Life编委。\n第一作者：黄子诺，本科毕业于厦门大学化学工程与工艺专业，浙江大学生命科学研究院2021级直博生，研究方向为环境暴露组以及多组学联合分析的开发与应用。\n第一作者：彭晨，本科毕业于浙江大学生物科学专业，浙江大学生命科学研究院2022级直博生，研究方向为微生物生态学和生物信息学，探究塑造微生物多样性模式、分布和动态的机制，开发各类生信分析方法和软件。以第一作者或共同一作在ES\u0026amp;T和Briefings in Bioinformatics期刊上发表论文2篇。\n","date":"2024-04-03T00:00:00Z","image":"/p/es-t/images/qt_graphical_abstract_hu_89b731869655972a.png","permalink":"/p/es-t/","title":"浙江大学蒋超课题组合作ES\u0026T：开发使用可穿戴被动采样器对个体生物和化学暴露组与转录组进行纵向测绘"},{"content":" 最近，我开发的R包ReporterScore（GRSA方法）发表在Briefings in Bioinformatics上了，这是一种灵活的，可用于复杂多组学数据的功能富集新方法。\nR包主页：https://github.com/Asa12138/ReporterScore\nGRSA具有比GSEA等常用富集方法更好的sensitivity以获取更多的testable hypotheses。 GRSA可以直接适用于multi-group and longitudinal 实验设计，而不需要重复做两两比较分析，可以直接对复杂实验设计进行富集分析。 我们将GRSA应用于转录组、代谢组、微生物组等数据并有了新的发现。 我们预计该富集方法可以替代常用富集分析方法用在各类组学数据上。 并且这个R包内置了各类主流可视化方法以及主要功能学数据库，属于一站式解决方案。 欢迎大家下载使用，提出宝贵意见。\n下面对这篇文章进行简要地介绍：\nPaper Info 标题：Generalized reporter score-based enrichment analysis for omics data 译名：基于广义报告评分的富集分析可用于各类组学数据 期刊：Briefings in Bioinformatics (IF：9.5) 发表时间：2024年3月27日 第一作者：彭晨 通讯作者：蒋超 通讯单位：浙江大学生命科学研究院 链接：https://doi.org/10.1093/bib/bbae116 图片摘要 关键点 我们开发了广义报告评分富集分析(GRSA)和R软件包ReporterScore，将经典RSA的功能扩展到多组和纵向实验设计，并与各种类型组学数据兼容。 与常用的富集分析方法相比，GRSA具有更高的灵敏度。我们在4个案例研究中证实了之前的主要发现，并获得了新的生物学见解。 GRSA可以应用于各种关系数据库，并执行自定义的富集分析，如物种分类富集分析。 引言 功能富集分析是一种常用的生物信息学方法，用于理解大型组学数据集（如转录组、宏基因组和代谢组数据）的生物学意义。通过识别富集的功能类别（如基因本体术语或生物通路），我们可以洞察底层的生物过程和功能，并提出下游实验研究的假设。功能富集分析方法可以根据统计方法大致分为三类：（i）过表示分析（ORA）、（ii）功能类别评分（FCS）和（iii）通路拓扑（PT）。Goeman和Bühlmann将富集分析方法根据底层零假设归类为“竞争性”或“自包含”。在“竞争性”方法中，将基因集与不在该集合中的所有基因背景进行比较，以评估统计差异水平是否超过背景水平；而“自包含”方法则分析每个基因集的孤立情况。\n基于报告评分的分析（RSA）算法最初由Patil和Nielsen于2005年开发，用于识别与代谢网络的调控热点相关的代谢物。RSA近年来因其在微生物组研究中功能富集分析方面的扩展应用而备受青睐。RSA是一种基于报告评分的竞争性FCS方法，基于选择的统计分析的P值解析，没有先验截止值（无阈值）。其基本原理是，P值可以被视为标准化的统计量，反映了不同基因或特征之间的差异，而不受平均表达值的影响。与背景P值分布相比，具有显著较低P值的通路被认为是富集的。\n然而，由于缺乏特定工具和对算法的系统理解，RSA经常被误用。此外，经典RSA中每条通路的报告评分的符号（正负号）并不是表示通路表达趋势的增加或减少；而是报告评分（包括负值）低于指定阈值表示相应的通路未显著富集。这经常导致结果的错误解释。\n受经典RSA启发，我们开发了改进的广义报告评分分析（GRSA）方法，并在R包ReporterScore中实现了该方法，还集成了全面的可视化方法和通路数据库。 GRSA是一种无阈值方法，适用于所有类型的生物医学特征，如基因、化合物和微生物物种。GRSA可在mixed模式（经典RSA）和directed模式（增强RSA）下工作。directed模式使用报告评分的符号区分上调或下调的通路，所以更直观。 重要的是，GRSA支持多组和纵向实验设计，因为它包含了与多组和纵向实验设计兼容的统计方法。 ReporterScore包还支持自定义的分层和关系数据库，为高级用户提供额外的灵活性。 在本研究中，我们描述了GRSA的全面实用性：我们在多个数据集上将GRSA与其他流行的富集方法进行了基准测试，并展示了GRSA在各种组学数据集上的应用。\n方法 图1:ReporterScore包中GRSA的整体工作流程。\nGRSA算法简要流程如下（细节请参见原文）：\n(1) 计算P值\n使用统计方法（Wilcox, t-test, ANOVA, pearson,\u0026hellip;）获得特征（feature，即$KO_i$,可以是基因，代谢物，KO等等）的P值。 这里简单地用KO表示不同的特征。\n(2) 将P值转换为Z分数\n对于经典的mixed RSA，使用逆正态累积分布函数 ($\\theta^{- 1}$) 将KO的P值转换为Z分数。因此，假设在随机数据假设范围内，P值均匀分布，得到的Z分数将遵循标准正态分布。\n对于新的directed RSA，首先将P值除以2，将P值范围从$(0,1\\rbrack$转换为$(0,0.5\\rbrack$。然后使用逆正态累积分布函数将KO的P值转换为Z分数。当P值为0.5时，转换后的Z分数等于0。\n确定KO是上调还是下调，并计算$\\Delta KO_{i}$：\n对于差异丰度分析（两组设计）：\n$$ \\Delta KO_i=\\overline {KO_{i_{g1}}}-\\overline {KO_{i_{g2}}} $$\n对于相关性分析（两组、多组和纵向设计）：\n$$ \\Delta KO_{i} = \\rho_{KO_{i}} $$\n给每个Z分数分配正负号，如果$\\Delta KO_{i}$小于0，则Z分数取负值；否则取正值。\n(3) 评分通路\n使用KO的Z分数对通路进行评分。首先选择通路数据库作为参考。对于选定数据库中的每个通路，计算通路的Z分数。接下来，对Z分数进行校正，以评估富集的显著性。最后，计算通路的报告评分和相关的P值。\n我们使用了50个基准数据集（41个人类基因表达数据集和9个小鼠基因表达数据集）比较了GRSA和六种常用的富集分析方法（Fisher’s exact test，GSEA，SAFE，GSA，PADOG，GSVA）。我们使用了不同的统计方法对特征进行P值计算，并使用Benjamini和Hochberg方法进行了P值调整。我们评估了每种方法在确定目标通路方面的性能。\nGRSA可应用于多组和纵向组学数据 GRSA的一个重要特征是新开发的directed模式。directed模式与mixed模式（经典RSA）的主要区别在于，在directed模式中，报告评分的正负符号表示通路的增长或减少趋势。相比之下，在mixed模式中，报告评分的符号不表示通路的趋势。我们在公共的ex_KO_profile数据集上以两种模式（directed模式和mixed模式）进行了GRSA。在directed模式中富集的通路中，大多数KO具有相同的趋势。具有一致增加（减少）KO的通路将获得比背景更大（更小）的聚合Z分数。相反，如果通路内的KO具有相反的趋势，那么带符号的Z分数将互相抵消，导致结果不显著。与之相比，在mixed模式中，无法确定富集通路的增长和减少趋势。因此，directed模式有助于发现具有一致变化KO的通路。一些先前的研究旨在使用directed模式的结果，但错误地使用了经典RSA（mixed模式）。\nGRSA的另一个主要优势是支持多组和纵向组学数据。ReporterScore包使用差异丰度分析或相关性分析计算组间每个特征的P值。Kruskal–Wallis检验或ANOVA评估特征丰度是否在多个组之间显著变化。默认的相关性分析将组分配视为有序的（例如，组‘G1’、‘G2’和‘G3’将转换为1、2和3），因此相关性分析可以评估特征丰度是否呈线性增加或减少。此外，ReporterScore包还支持任何指定的模式。例如，如果期望出现指数增长趋势，可以将组‘G1’、‘G2’和‘G3’设置为1、10和100。为了探索数据中的潜在模式，可以使用聚类方法，例如C均值聚类。\n作为一般规则，用户必须确保所选的统计方法适用于数据集和实验设计。我们在多个基准数据集上使用不同的统计方法应用了GRSA。对于经典的两组设计，参数方法的Jaccard相似度超过了0.84，非参数方法超过了0.78，但参数方法与非参数方法之间的Jaccard相似度低于0.63。主要差异主要源于参数方法与非参数方法之间的差异。对于多组数据，如果目标是在组间显著改变的通路中富集，用户可以选择差异丰度分析。如果目标是富集显示一致增加或减少模式的通路，则相关性分析是首选。最后，GRSA还支持其他统计测试，例如‘DESeq2’、‘Edger’、‘Limma’、‘ALDEX’和‘ANCOM’，以计算报告评分。\nGRSA具有较高的灵敏度 图2:GRSA与其他常用富集分析方法的比较。(A-B)箱型图显示了在24个基因表达数据集上通过多种方法得到的目标通路的排名(A)和矫正p值(B)。(C-D)箱形图显示了多种方法在9个野生型/敲除基因表达数据集上的敏感性(C)和特异性(D)。数字表示每种方法的中位数。\n接下来，我们评估了GRSA的性能，并将其与其他常用的富集分析方法在几个基准数据集上进行了比较。在某些情况下，基于通路拓扑结构的方法可能比非基于拓扑结构的方法更好地识别具有生物意义的通路。然而，基于拓扑结构的方法需要通路的全面结构，限制了它们在其他非人类生物中的应用。因此，我们将重点放在与非基于拓扑结构的富集分析方法的比较上。Nguyen等人提出了几种比较富集方法的方法，我们采用了他们的方法，并使用相同的通路数据库（KEGG v109.0）评估了GRSA与其他流行的富集分析方法的性能。\n首先，我们比较了不同方法在识别与已知人类疾病相关的24个基因表达数据集中的目标疾病通路的能力。由于每个数据集都与特定的疾病相关联的KEGG通路（即目标通路），因此一个好的富集分析方法应该将目标通路排名在所有342个通路的前列，并且以较小的矫正P值富集目标通路。结果表明，在给定一个较小的排名给目标通路方面，PADOG、GSA、GRSA、GSEA和SAFE的表现相似，因为它们的中位数排名都落在前20%内。此外，GRSA实现了目标通路的最低中位数矫正P值。我们还使用了由‘GSEABenchmarkeR’包提供的GEO数据集进行进一步的基准测试，并发现了类似的结果。总体而言，GRSA在无阈值的FCS方法中表现良好，优于传统的ORA方法。\n接下来，我们评估了不同方法在检测基因敲除实验中受扰动通路的能力。在基因敲除实验中，敲除基因是已确认的扰动源。在这些假设下，我们可以计算方法的敏感性和特异性。GRSA在考虑的方法中显示了最高的中位数敏感性，尽管其特异性略低于其他方法。 我们认为方法的敏感性更有意义，因为对于包含敲除基因的通路，敲除它应该会对通路产生相当大的影响；然而，对于不包含敲除基因的通路，鉴于通路和基因数据库的潜在不完整性，仅将这些富集的通路归因为假阳性可能并不总是恰当的。\n最后，我们评估了不同方法富集具有生物意义通路的能力。我们比较了GRSA、竞争工具和两者都富集到的通路的比例，以所有显著通路的数量作为分母。在这些数据集中，GRSA一致识别出比ORA方法更多的通路，并且与GSEA的重叠程度很大。例如，在肾细胞癌数据集中，仅有GRSA富集到与细胞因子-细胞因子受体相互作用、IL-17信号和PI3K-Akt信号相关的通路。因此，GRSA具有识别出与研究的疾病相关的更多生物学上相关通路的潜力。\n组学数据实例 接下来，我们展示了GRSA在不同类型组学数据中的通用应用。\n案例研究1:皮肤微生物群的功能分析和与年龄相关动态 图3:GRSA在IHSMGC数据集皮肤微生物组中的应用。(A)KO-Module网络富集于M型(绿色)和C型(蓝色)。只显示了与维生素生物合成相关的模块。大点代表模块;小点代表ko。小点的颜色代表原型。阴影表示参与同一种维生素生物合成的模块。深浅颜色表示富含M型剪切型(绿色)或富含C型剪切型(蓝色)的模块。(B-C)模块“M00866”(B)和“M00061”(C)不同年龄的箱型图。线条的颜色代表了KO在模块中相对丰度的趋势。“M00866”的阳性报告评分最大(增加)，而“M00061”的报告评分为负，且绝对值最大(减少)。(D)柱状图显示随着年龄的增长，模块显著丰富;报告评分阈值为2.5，对应的置信度约为0.995，这些模块根据KEGG进行分组。颜色表示随着年龄增长而上调(红色)或下调(绿色)的模块。\n案例研究2:心肌细胞分化过程中的功能转录动力学 图4:GRSA在心肌细胞分化过程转录组数据集中的应用。(A)四个分化阶段基因丰度谱的c均值聚类结果。每条线的透明度与其membership相关，y轴表示标准化丰度。(B)箱形图显示了“GO:0003015”(心脏过程)在四个时间点上的基因丰度;线的颜色表示每个基因与聚类6在GO项内的相关显著性。\u0026lsquo;GO:0003015\u0026rsquo;是簇6的代表性术语。(C)柱状图显示了每个与分化阶段相对应的聚类模式的GO项显著丰富。条形图的颜色表示聚类信息，并显示每个聚类中报告评分较高的代表性GO术语。左侧的文本标签根据具有最高表达的阶段上色。总的来说，簇2对应第0天，簇4和5对应第2天，簇1对应第4天，簇3和6对应CM。\n案例研究3:与孕龄相关的母体系统性代谢组变化 图5:GRSA在丹麦妊娠队列代谢数据中的应用及IHSMGC数据集的物种富集分析。(A)珠包图显示了代谢组学研究中GRSA发现的显著富集通路的层次关系。圆圈的大小表示报告评分的绝对值，圆圈的颜色表示报告评分的符号。正报告评分表示该通路增加(橙色)，负报告评分表示该通路减少(紫色)。(B)热图显示了“类固醇激素生物合成”途径中代谢物的丰度。列是按孕龄递增排序的样本。(C)柱状图显示分别在C-cutotype和M-cutotype显著富集的属。(D)网络图显示了g_Moraxella和g_Cutibacterium中富含M-cutotype(绿色)或C-cutotype(蓝色)的物种。\n案例研究4:GRSA在功能富集分析之外的应用 GRSA算法可以将任何组织在层次关系中的特征用作富集数据库。例如，我们可以利用微生物的系统发育关系，如属-种关系，进行物种分类富集分析。我们使用了IHSMGC数据集的物种丰度表，并查找了在两种cutotype中富集的属。我们发现在M-cutotype中富集的有Psychrobacter、Paracoccus、Chryseobacterium、Elizabethkingia、Deinococcus和Microbacterium，而在C-cutotype中富集的有Acidipropionibacterium、Staphylococcus、Corynebacterium和Cutibacterium（图5C），其中一些与前期研究中通过共存网络发现的差异物种模块高度一致。然而，我们额外发现了一些属，如Brevundimonas和Rhodobacter，在M-cutotype中富集，而Pahexavirus（丙酸杆菌和皮脂杆菌的噬菌体）在C-cutotype中富集（图5C），可能是由于GRSA的更高灵敏度。\n在先前研究中，使用了两种物种Moraxella osloensis和Cutibacterium acnes来定义cutotype。 有趣的是，虽然Cutibacterium属在cutotype之间是一个很好的生物标志物，但Moraxella属不是，因为包含的物种没有共享相同的趋势（图5D）。因此，除了功能富集分析外，GRSA还可以扩展到任何层次关系数据结构。\n讨论与结论 我们开发了ReporterScore包，并展示了GRSA富集分析的广泛应用。 我们改进了经典的RSA方法，以便更容易解释Reporter Score的加减符号。 更重要的是，我们将GRSA的范围从两组设计扩展到多组和纵向设计。 我们用metagenomic、transcriptomic和metabolomic数据进行了案例研究验证了先前的关键发现，并获得了新的生物学见解。 总之，我们认为，GRSA和ReporterScore包可以极大地促进多种类型的组学数据的功能富集分析，因为其具有更高的灵敏度、与多组和纵向设计的兼容性，以及对定制数据库的灵活性。\n蒋超实验室博士生彭晨为论文的第一作者，蒋超研究员为论文的通讯作者，参与该研究的还有蒋超实验室博士后陈琼，华大研究员谭上进和斯坦福大学博士后申小涛。该研究得到了国家自然科学基金等项目资助，以及生命科学研究院NECHO高性能计算集群的支持。\n","date":"2024-03-30T00:00:00Z","image":"/p/grsa-bib/images/BIB_hu_a69a6e0e0971b307.png","permalink":"/p/grsa-bib/","title":"ReporterScore包(GRSA方法)正式发表于杂志Briefings in Bioinformatics"},{"content":" Introduction Mermaid是一个基于 JavaScript 的图表绘制工具，可渲染 Markdown 启发的文本定义以动态创建和修改图表，允许使用文本和代码创建图表和可视化。\n官方文档：https://mermaid.js.org/intro/\n中文版：https://mermaid.nodejs.cn/intro/\n使用方法 对于大多数用户来说，使用 在线编辑器 就足够了，但是你也可以选择将 mermaid 部署为依赖或使用 Mermaid API。\n在线编辑器 Mermaid的在线编辑器是其主要特色之一，如https://mermaid.live/。用户可以直接在网页上创建和渲染图表，无需安装任何软件。这对于大多数用途来说是一个快速且简便的选择。\nR包 DiagrammeR Mermaid也可以通过R的DiagrammeR包进行使用。这对于数据分析师和统计师特别有用，因为它允许在R环境中直接创建和集成图表，本篇post也是使用该包渲染的。\n1 2 3 4 5 6 7 8 library(DiagrammeR) mermaid(\u0026#34;graph TD; A[Start] --\u0026gt; B{Is it?}; B -- Yes --\u0026gt; C[OK]; C --\u0026gt; D[Rethink]; D --\u0026gt; B; B -- No --\u0026gt; E[End];\u0026#34;) 其他支持的编辑器 Mermaid还支持其他编辑器和平台的集成，例如Quarto，Jupyter Notebook和一些开源文档工具，使得在不同的环境中使用Mermaid成为可能。\n图表类型 1. 饼形图 (Pie Chart) 用途: 饼形图用于展示数据的比例分布，常用于表示各部分占总量的百分比。\n语法示例:\n1 2 3 4 5 pie title Pets adopted by volunteers \u0026#34;Dogs\u0026#34; : 386 \u0026#34;Cats\u0026#34; : 85 \u0026#34;Rats\u0026#34; : 15 解释: 这里定义了一个饼形图，标题为”志愿者领养的宠物”，包括三个部分：狗、猫和鼠，以及各自的数量。 在Mermaid中，绘制饼形图的语法相对简单。主要的步骤和可配置参数如下：\n开始: 使用pie关键字开始图表。 显示数据（可选）: 通过showData关键字，可以在图例文本后显示实际的数据值。 标题（可选）: 使用title关键字和其字符串值为饼形图添加标题。 数据集: 饼形图的每个部分以标签和值的形式定义，标签用引号括起来，后面跟一个冒号和数值（支持到两位小数）。 此外，Mermaid允许对饼形图进行一些配置，例如：\ntextPosition: 这个参数用于设置饼形图中每个切片标签的轴向位置，从0.0（圆心）到1.0（圆的外缘）。 示例代码和进一步的信息可以在Mermaid官方文档中找到。\n2. 流程图 (Flow Chart) 用途: 流程图用于展示过程或系统中步骤的顺序。\n语法示例:\n1 2 3 4 5 graph LR A[Start] --\u0026gt; B{Decision} B --\u0026gt;|Yes| C[Do Something] B --\u0026gt;|No| D[Do Something Else] C --\u0026gt; D 解释: 这个流程图开始于”Start”，接着是一个决策节点”Decision”，根据条件分为”Yes”和”No”两个分支，最终都会合流到”Do Something Else”。\n3. 时序图 (Sequence Diagram) 用途: 时序图展示对象之间交互的顺序。\n语法示例:\n1 2 3 4 5 sequenceDiagram participant Alice participant Bob Alice-\u0026gt;\u0026gt;Bob: Hello Bob, how are you? Bob--\u0026gt;\u0026gt;Alice: I am good thanks! 解释: 这个时序图描述了Alice和Bob之间的对话。Alice首先问候Bob，Bob随后回答Alice。\n4. 状态图 (State Diagram) 用途: 状态图描述系统的状态以及状态之间的转换。\n语法示例:\n1 2 3 4 5 6 7 stateDiagram [*] --\u0026gt; Still Still --\u0026gt; [*] Still --\u0026gt; Moving Moving --\u0026gt; Still Moving --\u0026gt; Crash Crash --\u0026gt; [*] 解释: 这个状态图展示了一个简单的系统，它从开始状态（）进入静止状态（Still），然后可以移动（Moving）或返回结束状态（）。移动状态可以转回静止，或者进入崩溃状态（Crash）。 5. 甘特图 (Gantt Diagram) 用途: 甘特图展示项目时间线和进度。\n语法示例:\n1 2 3 4 5 6 7 8 9 gantt title A Gantt Diagram dateFormat YYYY-MM-DD section Section A task :a1, 2014-01-01, 30d Another task :after a1 , 20d section Another Task in sec :2014-01-12 , 12d another task : 24d 解释: 这个甘特图包括两个部分，每个部分包含不同的任务，每个任务都有明确的开始时间和持续天数。 6. 类图 (Class Diagram) 用途: 类图展示类之间的关系，常用于面向对象的设计。\n语法示例:\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 classDiagram Animal \u0026lt;|-- Duck Animal \u0026lt;|-- Fish Animal \u0026lt;|-- Zebra Animal : +int age Animal : +String gender Animal: +isMammal() Animal: +mate() class Duck{ +String beakColor +swim() +quack() } class Fish{ -int sizeInFeet -canEat() } class Zebra{ +bool is_wild +run() } 解释: 这个类图定义了一个基类”Animal”和三个派生类”Duck”，”\n“Fish”和”Zebra”。基类包含一些共有属性和方法，而每个派生类则有其特有的属性和行为。\n7. 用户旅程图 用途: 用户旅程图用于表示用户在产品或服务中的体验和行为路径。\n语法示例:\n1 2 3 4 5 6 7 8 9 10 11 journey title My working day section Go to work Make tea: 5: Me Go by car: 3: Me section Work Do programming: 1: Me, Cat Review meetings: 2: Me section Go home Go by car: 2: Me Relax: 4: Me 解释: 这个用户旅程图以”我的工作日”为主题，分为”去工作”、“工作”和”回家”三个部分。每个部分包括不同的活动，活动旁边的数字表示优先级，而后面则标明了参与者。\n以上是Mermaid中不同图表类型的详细介绍和示例。这些示例提供了基本的语法结构和使用方法。要更深入地了解Mermaid及其高级功能，建议访问Mermaid官方文档和社区资源，那里有更多的示例和详细的教程。\n","date":"2024-01-29T00:00:00Z","image":"/p/mermaid/images/mermaid_hu_7e14c23887eac969.png","permalink":"/p/mermaid/","title":"Mermaid 入门"},{"content":"Introduction 文献管理工具是科研必不可少的伙伴，我自己用的是Zetero。在学术写作中，\u0026ldquo;文内引用\u0026rdquo;（citation）和\u0026quot;参考文献列表\u0026quot;（bibliography）是两个重要的概念，学会管理它们十分重要。\n文内引用（Citation）是文章正文中用来指向引用的源材料的标记，目的是表明你引用了哪些资料。主要有两种常见格式： 作者-日期（Author-Date）：假设你正在引用由Smith在2020年出版的一篇文章，文内引用将会是这样的：(Smith, 2020)。 数字（Numeric）：如果你引用的文献是参考文献列表中的第五个条目，那么文内引用将会是这样的：[5]。 参考文献列表（Bibliography）是文章末尾列出的所有引用和参考作品的详细信息清单，包括作者、标题、出版年份等，使读者能够找到和查阅这些源材料。 不同期刊对于参考文献格式具有不同要求，我们一般可以通过设置CSL文件来快速获得想要的引文风格。Zotero Style Repository:https://www.zotero.org/styles 收录了10,000多种预设好的，各种期刊的引文风格，可以很方便地获取和设置。\n但有时候我们需要自定义一个引文风格。比如我们在PPT里一般不需要给出作者-标题-期刊-年份-卷号页码这么详细的内容，而是作者-期刊-年份即可。或者说我们想要控制作者显示前多少个，标题要不要斜体等等细节。这时就需要我们对CSL文件有一定的了解，并进行合适的编辑了。\nCitation Style Language（CSL）是一种用于描述引文风格的 XML 文件。它定义了文内引用和参考文献列表的外观和格式。CSL 文件告诉引文管理器（如 Zotero、Mendeley 等）如何渲染文内引用和文献列表。CSL 支持各种风格，包括 APA、MLA、Chicago 等。\n官方文档：https://docs.citationstyles.org/en/stable/primer.html\nCitation Style Language XML basic XML（可扩展标记语言）是一种用于存储和传输数据的标记语言。以下是 XML 的一些基本特征和用法：\n标记语言： XML 是一种标记语言，使用标签来标识文档中的数据。标签通常是成对出现的，有起始标签和结束标签。 1 2 3 4 \u0026lt;book\u0026gt; \u0026lt;title\u0026gt;Introduction to XML\u0026lt;/title\u0026gt; \u0026lt;author\u0026gt;John Doe\u0026lt;/author\u0026gt; \u0026lt;/book\u0026gt; 层次结构： XML 文档具有层次结构，由嵌套的元素组成。每个元素可以包含子元素，形成树状结构。 1 2 3 4 5 6 7 8 9 10 \u0026lt;library\u0026gt; \u0026lt;book\u0026gt; \u0026lt;title\u0026gt;XML Basics\u0026lt;/title\u0026gt; \u0026lt;author\u0026gt;Jane Smith\u0026lt;/author\u0026gt; \u0026lt;/book\u0026gt; \u0026lt;book\u0026gt; \u0026lt;title\u0026gt;Advanced XML\u0026lt;/title\u0026gt; \u0026lt;author\u0026gt;John Doe\u0026lt;/author\u0026gt; \u0026lt;/book\u0026gt; \u0026lt;/library\u0026gt; 属性： XML 元素可以包含属性，提供有关元素的额外信息。 1 2 3 4 \u0026lt;book category=\u0026#34;programming\u0026#34;\u0026gt; \u0026lt;title\u0026gt;Python Programming\u0026lt;/title\u0026gt; \u0026lt;author\u0026gt;Guido van Rossum\u0026lt;/author\u0026gt; \u0026lt;/book\u0026gt; XML 被广泛用于配置文件、数据交换、Web 服务和许多其他用途。它的可读性和可扩展性使其成为许多应用程序之间进行数据交换的理想选择。\n在引文风格的 CSL 文件中，XML 用于定义引文的样式和格式。\n整体结构 我们来看一个官方给出的极简CSL文件例子：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 \u0026lt;?xml version=\u0026#34;1.0\u0026#34; encoding=\u0026#34;utf-8\u0026#34;?\u0026gt; \u0026lt;style xmlns=\u0026#34;http://purl.org/net/xbiblio/csl\u0026#34; class=\u0026#34;in-text\u0026#34; version=\u0026#34;1.0\u0026#34;\u0026gt; \u0026lt;info\u0026gt; \u0026lt;title\u0026gt;Example Style\u0026lt;/title\u0026gt; \u0026lt;id\u0026gt;http://www.zotero.org/styles/example\u0026lt;/id\u0026gt; \u0026lt;link href=\u0026#34;http://www.zotero.org/styles/example\u0026#34; rel=\u0026#34;self\u0026#34;/\u0026gt; \u0026lt;link href=\u0026#34;http://www.zotero.org/styles/apa\u0026#34; rel=\u0026#34;template\u0026#34;/\u0026gt; \u0026lt;link href=\u0026#34;http://www.example.com/style-guide/\u0026#34; rel=\u0026#34;documentation\u0026#34;/\u0026gt; \u0026lt;author\u0026gt; \u0026lt;name\u0026gt;John Doe\u0026lt;/name\u0026gt; \u0026lt;email\u0026gt;JohnDoe@example.com\u0026lt;/email\u0026gt; \u0026lt;/author\u0026gt; \u0026lt;contributor\u0026gt; \u0026lt;name\u0026gt;Jane Doe\u0026lt;/name\u0026gt; \u0026lt;/contributor\u0026gt; \u0026lt;contributor\u0026gt; \u0026lt;name\u0026gt;Bill Johnson\u0026lt;/name\u0026gt; \u0026lt;/contributor\u0026gt; \u0026lt;category citation-format=\u0026#34;author-date\u0026#34;/\u0026gt; \u0026lt;category field=\u0026#34;science\u0026#34;/\u0026gt; \u0026lt;updated\u0026gt;2014-10-15T18:17:09+00:00\u0026lt;/updated\u0026gt; \u0026lt;rights license=\u0026#34;http://creativecommons.org/licenses/by-sa/3.0/\u0026#34;\u0026gt;This work is licensed under a Creative Commons Attribution-ShareAlike 3.0 License\u0026lt;/rights\u0026gt; \u0026lt;/info\u0026gt; \u0026lt;locale xml:lang=\u0026#34;en\u0026#34;\u0026gt; \u0026lt;terms\u0026gt; \u0026lt;term name=\u0026#34;no date\u0026#34;\u0026gt;without date\u0026lt;/term\u0026gt; \u0026lt;/terms\u0026gt; \u0026lt;/locale\u0026gt; \u0026lt;macro name=\u0026#34;author\u0026#34;\u0026gt; \u0026lt;names variable=\u0026#34;author\u0026#34;\u0026gt; \u0026lt;name initialize-with=\u0026#34;.\u0026#34;/\u0026gt; \u0026lt;/names\u0026gt; \u0026lt;/macro\u0026gt; \u0026lt;macro name=\u0026#34;issued-year\u0026#34;\u0026gt; \u0026lt;choose\u0026gt; \u0026lt;if variable=\u0026#34;issued\u0026#34;\u0026gt; \u0026lt;date variable=\u0026#34;issued\u0026#34;\u0026gt; \u0026lt;date-part name=\u0026#34;year\u0026#34;/\u0026gt; \u0026lt;/date\u0026gt; \u0026lt;/if\u0026gt; \u0026lt;else\u0026gt; \u0026lt;text term=\u0026#34;no date\u0026#34;/\u0026gt; \u0026lt;/else\u0026gt; \u0026lt;/choose\u0026gt; \u0026lt;/macro\u0026gt; \u0026lt;citation et-al-min=\u0026#34;3\u0026#34; et-al-use-first=\u0026#34;1\u0026#34;\u0026gt; \u0026lt;sort\u0026gt; \u0026lt;key macro=\u0026#34;author\u0026#34;/\u0026gt; \u0026lt;key macro=\u0026#34;issued-year\u0026#34;/\u0026gt; \u0026lt;/sort\u0026gt; \u0026lt;layout prefix=\u0026#34;(\u0026#34; suffix=\u0026#34;)\u0026#34; delimiter=\u0026#34;; \u0026#34;\u0026gt; \u0026lt;group delimiter=\u0026#34;, \u0026#34;\u0026gt; \u0026lt;text macro=\u0026#34;author\u0026#34;/\u0026gt; \u0026lt;text macro=\u0026#34;issued-year\u0026#34;/\u0026gt; \u0026lt;/group\u0026gt; \u0026lt;/layout\u0026gt; \u0026lt;/citation\u0026gt; \u0026lt;bibliography\u0026gt; \u0026lt;sort\u0026gt; \u0026lt;key macro=\u0026#34;author\u0026#34;/\u0026gt; \u0026lt;key macro=\u0026#34;issued-year\u0026#34;/\u0026gt; \u0026lt;key variable=\u0026#34;title\u0026#34;/\u0026gt; \u0026lt;/sort\u0026gt; \u0026lt;layout suffix=\u0026#34;.\u0026#34;\u0026gt; \u0026lt;group delimiter=\u0026#34;, \u0026#34;\u0026gt; \u0026lt;group delimiter=\u0026#34;. \u0026#34;\u0026gt; \u0026lt;text macro=\u0026#34;author\u0026#34;/\u0026gt; \u0026lt;text macro=\u0026#34;issued-year\u0026#34;/\u0026gt; \u0026lt;text variable=\u0026#34;title\u0026#34;/\u0026gt; \u0026lt;text variable=\u0026#34;container-title\u0026#34;/\u0026gt; \u0026lt;/group\u0026gt; \u0026lt;group\u0026gt; \u0026lt;text variable=\u0026#34;volume\u0026#34;/\u0026gt; \u0026lt;text variable=\u0026#34;issue\u0026#34; prefix=\u0026#34;(\u0026#34; suffix=\u0026#34;)\u0026#34;/\u0026gt; \u0026lt;/group\u0026gt; \u0026lt;text variable=\u0026#34;page\u0026#34;/\u0026gt; \u0026lt;/group\u0026gt; \u0026lt;/layout\u0026gt; \u0026lt;/bibliography\u0026gt; \u0026lt;/style\u0026gt; 把整个代码的一二级结构提取出来如下：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 \u0026lt;?xml version=\u0026#34;1.0\u0026#34; encoding=\u0026#34;utf-8\u0026#34;?\u0026gt; \u0026lt;style xmlns=\u0026#34;http://purl.org/net/xbiblio/csl\u0026#34; class=\u0026#34;in-text\u0026#34; version=\u0026#34;1.0\u0026#34;\u0026gt;//style组件开始 \u0026lt;info\u0026gt;//info组件用于描述style的信息 \u0026lt;/info\u0026gt; \u0026lt;locale xml:lang=\u0026#34;en\u0026#34;\u0026gt;//locale组件用于声明语言信息 \u0026lt;/locale\u0026gt; \u0026lt;macro name=\u0026#34;author\u0026#34;\u0026gt;//macro组件是功能组件，这里声明了author的信息 \u0026lt;/macro\u0026gt; \u0026lt;macro name=\u0026#34;issued-year\u0026#34;\u0026gt;//macro组件是功能组件，这里声明了出版年的信息 \u0026lt;/macro\u0026gt; \u0026lt;citation et-al-min=\u0026#34;3\u0026#34; et-al-use-first=\u0026#34;1\u0026#34;\u0026gt;//citation组件声明了文内引用的格式 \u0026lt;/citation\u0026gt; \u0026lt;bibliography\u0026gt;//bibliography组件声明了参考文献的格式 \u0026lt;/bibliography\u0026gt; \u0026lt;/style\u0026gt; style是整个CSL样式的根元素。它包含了样式的所有定义，属性如class=\u0026ldquo;in-text\u0026quot;和version=\u0026ldquo;1.0\u0026quot;定义了样式的类型和版本。\n接下来介绍 CSL 文件通常包含的基本部分：\n信息部分（Info Section）：包含了样式的基本信息，如作者、标题、发布信息等。\n宏（Macros）：这部分定义了一系列的模板，用于渲染不同类型的文献信息（如作者、标题、出版年份等）。在引用和参考文献中会重复使用这些模板。\n引用（Citation）：定义文内引用的格式。这部分可以包含多种布局（layout），用于不同类型的引用（如作者-日期、数字等）。\n参考文献（Bibliography）：定义了参考文献列表的格式。这里设置了整个列表的格式，以及单个参考文献的显示方式。\ninfo info 元素： 包含了引文样式的元信息，如样式的名称、版本、授权信息等。示例：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 \u0026lt;info\u0026gt; \u0026lt;!-- 标题: 定义了CSL样式的名称 --\u0026gt; \u0026lt;title\u0026gt;Example Style\u0026lt;/title\u0026gt; \u0026lt;!-- 标识符: 提供了CSL样式的唯一URL标识 --\u0026gt; \u0026lt;id\u0026gt;http://www.zotero.org/styles/example\u0026lt;/id\u0026gt; \u0026lt;!-- 链接: 指向CSL样式本身、基于的模板和相关文档的链接 --\u0026gt; \u0026lt;link href=\u0026#34;http://www.zotero.org/styles/example\u0026#34; rel=\u0026#34;self\u0026#34;/\u0026gt; \u0026lt;link href=\u0026#34;http://www.zotero.org/styles/apa\u0026#34; rel=\u0026#34;template\u0026#34;/\u0026gt; \u0026lt;link href=\u0026#34;http://www.example.com/style-guide/\u0026#34; rel=\u0026#34;documentation\u0026#34;/\u0026gt; \u0026lt;!-- 作者信息: 定义了CSL样式的主要作者和联系方式 --\u0026gt; \u0026lt;author\u0026gt; \u0026lt;name\u0026gt;John Doe\u0026lt;/name\u0026gt; \u0026lt;email\u0026gt;JohnDoe@example.com\u0026lt;/email\u0026gt; \u0026lt;/author\u0026gt; \u0026lt;!-- 贡献者: 列出对CSL样式有贡献的其他人 --\u0026gt; \u0026lt;contributor\u0026gt; \u0026lt;name\u0026gt;Jane Doe\u0026lt;/name\u0026gt; \u0026lt;/contributor\u0026gt; \u0026lt;contributor\u0026gt; \u0026lt;name\u0026gt;Bill Johnson\u0026lt;/name\u0026gt; \u0026lt;/contributor\u0026gt; \u0026lt;!-- 分类信息: 描述了CSL样式的引用格式和适用领域 --\u0026gt; \u0026lt;category citation-format=\u0026#34;author-date\u0026#34;/\u0026gt; \u0026lt;category field=\u0026#34;science\u0026#34;/\u0026gt; \u0026lt;!-- 更新日期: 显示CSL样式最后的更新时间 --\u0026gt; \u0026lt;updated\u0026gt;2014-10-15T18:17:09+00:00\u0026lt;/updated\u0026gt; \u0026lt;!-- 版权信息: 描述了CSL样式的版权和许可信息 --\u0026gt; \u0026lt;rights license=\u0026#34;http://creativecommons.org/licenses/by-sa/3.0/\u0026#34;\u0026gt;This work is licensed under a Creative Commons Attribution-ShareAlike 3.0 License\u0026lt;/rights\u0026gt; \u0026lt;/info\u0026gt; 这些信息帮助用户了解CSL样式的来源、作者、适用范围，以及如何合法使用这个样式。\ncitation citation 元素： 描述了如何渲染引文。这包括引用哪些字段（作者、标题等）、字段的顺序、标点符号等。示例：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 \u0026lt;citation et-al-min=\u0026#34;3\u0026#34; et-al-use-first=\u0026#34;1\u0026#34;\u0026gt; \u0026lt;!-- 当一个引用的作者数超过3时，只显示第一个作者并加上\u0026#34;et al.\u0026#34; --\u0026gt; \u0026lt;sort\u0026gt; \u0026lt;!-- 定义引用的排序方式，首先是按作者，然后是按发行年份 --\u0026gt; \u0026lt;key macro=\u0026#34;author\u0026#34;/\u0026gt; \u0026lt;key macro=\u0026#34;issued-year\u0026#34;/\u0026gt; \u0026lt;/sort\u0026gt; \u0026lt;layout prefix=\u0026#34;(\u0026#34; suffix=\u0026#34;)\u0026#34; delimiter=\u0026#34;; \u0026#34;\u0026gt; \u0026lt;!-- 定义文内引用的整体格式 --\u0026gt; \u0026lt;!-- 引用以圆括号包围，多个引用之间用分号和空格分隔 --\u0026gt; \u0026lt;group delimiter=\u0026#34;, \u0026#34;\u0026gt; \u0026lt;!-- 定义引用内的信息组，信息之间用逗号和空格分隔 --\u0026gt; \u0026lt;text macro=\u0026#34;author\u0026#34;/\u0026gt; \u0026lt;!-- 引用作者信息 --\u0026gt; \u0026lt;text macro=\u0026#34;issued-year\u0026#34;/\u0026gt; \u0026lt;!-- 引用发行年份 --\u0026gt; \u0026lt;/group\u0026gt; \u0026lt;/layout\u0026gt; \u0026lt;/citation\u0026gt; 综上，这个元素定义了一个文内引用的格式，其中包括作者和出版年份，用圆括号包围，各部分之间用逗号分隔，多个引用之间用分号分隔。例如，如果有一个文献由三个作者在2020年出版，文内引用将显示为“(Smith et al., 2020)”。\nmacro macro 元素： 包含一组可以在引文样式中引用的宏定义，上面的citation中就用到了macro。示例中有两个macro元素：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 \u0026lt;macro name=\u0026#34;author\u0026#34;\u0026gt; \u0026lt;!-- 定义了如何显示作者信息的宏 --\u0026gt; \u0026lt;names variable=\u0026#34;author\u0026#34;\u0026gt; \u0026lt;!-- 引用了文献条目中的作者信息 --\u0026gt; \u0026lt;name initialize-with=\u0026#34;.\u0026#34;/\u0026gt; \u0026lt;!-- 设置了作者姓名的格式，这里是用点\u0026#34;.\u0026#34;来初始化名字（例如，J. Doe） --\u0026gt; \u0026lt;/names\u0026gt; \u0026lt;/macro\u0026gt; \u0026lt;macro name=\u0026#34;issued-year\u0026#34;\u0026gt; \u0026lt;!-- 定义了如何显示出版年份的宏 --\u0026gt; \u0026lt;choose\u0026gt; \u0026lt;!-- 使用条件语句来确定显示什么内容 --\u0026gt; \u0026lt;if variable=\u0026#34;issued\u0026#34;\u0026gt; \u0026lt;!-- 如果有出版年份信息 --\u0026gt; \u0026lt;date variable=\u0026#34;issued\u0026#34;\u0026gt; \u0026lt;!-- 引用了文献条目中的出版日期 --\u0026gt; \u0026lt;date-part name=\u0026#34;year\u0026#34;/\u0026gt; \u0026lt;!-- 只显示年份部分 --\u0026gt; \u0026lt;/date\u0026gt; \u0026lt;/if\u0026gt; \u0026lt;else\u0026gt; \u0026lt;!-- 如果没有出版年份信息 --\u0026gt; \u0026lt;text term=\u0026#34;no date\u0026#34;/\u0026gt; \u0026lt;!-- 显示“no date” --\u0026gt; \u0026lt;/else\u0026gt; \u0026lt;/choose\u0026gt; \u0026lt;/macro\u0026gt; 在这段代码中， 定义了显示作者姓名的方式，而 则定义了如何显示出版年份，包括处理没有年份信息的情况。这些宏在整个CSL文件中可以被重复引用，确保了样式的一致性和易于维护。\nbibliography bibliography 元素： 描述了如何渲染参考文献列表。和 citation 类似，但可能额外包含一些特定于文献列表的元素。示例：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 \u0026lt;bibliography\u0026gt; \u0026lt;!-- 参考文献列表部分 --\u0026gt; \u0026lt;sort\u0026gt; \u0026lt;!-- 定义参考文献的排序方式 --\u0026gt; \u0026lt;key macro=\u0026#34;author\u0026#34;/\u0026gt; \u0026lt;!-- 首先按作者排序 --\u0026gt; \u0026lt;key macro=\u0026#34;issued-year\u0026#34;/\u0026gt; \u0026lt;!-- 然后按出版年份排序 --\u0026gt; \u0026lt;key variable=\u0026#34;title\u0026#34;/\u0026gt; \u0026lt;!-- 最后按标题排序 --\u0026gt; \u0026lt;/sort\u0026gt; \u0026lt;layout suffix=\u0026#34;.\u0026#34; delimiter=\u0026#34;, \u0026#34;\u0026gt; \u0026lt;!-- 定义参考文献条目的布局 --\u0026gt; \u0026lt;!-- 每个条目以句点结束，条目内部的元素用逗号分隔 --\u0026gt; \u0026lt;group delimiter=\u0026#34;. \u0026#34;\u0026gt; \u0026lt;!-- 定义一个组合，各元素之间以句点和空格分隔 --\u0026gt; \u0026lt;text macro=\u0026#34;author\u0026#34;/\u0026gt; \u0026lt;!-- 显示作者 --\u0026gt; \u0026lt;text macro=\u0026#34;issued-year\u0026#34;/\u0026gt; \u0026lt;!-- 显示出版年份 --\u0026gt; \u0026lt;text variable=\u0026#34;title\u0026#34;/\u0026gt; \u0026lt;!-- 显示标题 --\u0026gt; \u0026lt;text variable=\u0026#34;container-title\u0026#34;/\u0026gt; \u0026lt;!-- 显示包含该作品的容器（例如期刊或书籍的标题） --\u0026gt; \u0026lt;/group\u0026gt; \u0026lt;group\u0026gt; \u0026lt;!-- 定义另一个组合 --\u0026gt; \u0026lt;text variable=\u0026#34;volume\u0026#34;/\u0026gt; \u0026lt;!-- 显示卷号 --\u0026gt; \u0026lt;text variable=\u0026#34;issue\u0026#34; prefix=\u0026#34;(\u0026#34; suffix=\u0026#34;)\u0026#34;/\u0026gt; \u0026lt;!-- 显示期号，前后加括号 --\u0026gt; \u0026lt;/group\u0026gt; \u0026lt;text variable=\u0026#34;page\u0026#34;/\u0026gt; \u0026lt;!-- 显示页码 --\u0026gt; \u0026lt;/layout\u0026gt; \u0026lt;/bibliography\u0026gt; 在这个 部分中，首先定义了参考文献的排序规则，然后定义了参考文献每条记录的具体布局，包括作者、出版年份、标题、容器标题、卷号、期号和页码等信息的显示方式。这种格式确保了参考文献列表的信息完整性和易于阅读。\nlocale \u0026lt;locale\u0026gt; 部分用于定制特定语言环境下的术语表示：\n1 2 3 4 5 6 7 8 9 10 11 \u0026lt;locale xml:lang=\u0026#34;en\u0026#34;\u0026gt; \u0026lt;!-- 定义英语环境下的本地化设置 --\u0026gt; \u0026lt;terms\u0026gt; \u0026lt;!-- 术语定义部分 --\u0026gt; \u0026lt;term name=\u0026#34;no date\u0026#34;\u0026gt;without date\u0026lt;/term\u0026gt; \u0026lt;!-- 定义特定术语的表示方式 --\u0026gt; \u0026lt;!-- 这里将“no date”这个术语在英语环境下表示为“without date” --\u0026gt; \u0026lt;/terms\u0026gt; \u0026lt;/locale\u0026gt; 在这个 \u0026lt;locale\u0026gt; 部分中，它指定了在英语环境下应如何展示特定的术语。这里的示例只是对“no date”这个术语进行了本地化处理，将其改为“without date”。这对于适应不同语言环境中术语的变化非常有用，尤其是在多语言文档或出版物中使用不同的CSL样式时。\n比如：\n1 2 3 4 5 6 7 \u0026lt;locale xml:lang=\u0026#34;ch\u0026#34;\u0026gt; \u0026lt;!-- 定义本地化设置,这里是中文 --\u0026gt; \u0026lt;terms\u0026gt; \u0026lt;term name=\u0026#34;no date\u0026#34;\u0026gt;没有日期\u0026lt;/term\u0026gt; \u0026lt;!-- 呈现no date的地方，转变为呈现“没有日期” --\u0026gt; \u0026lt;/terms\u0026gt; \u0026lt;/locale\u0026gt; 在线编辑器 其实Zotero直接就支持CSL文件的编辑，还能实时渲染修改后的结果。\n但还有一些在线编辑器，如Visual CSL Editor https://editor.citationstyles.org/visualEditor/，提供了一种直观、用户友好的方式来创建和修改CSL样式。\n提供了一个图形界面，使用户能够通过点击和选择来编辑CSL样式，而无需直接编写或编辑XML代码。用户可以直观地调整样式的各个元素，如作者格式、日期显示、排序规则等。 用户可以搜索现有的CSL样式并将其作为起点，然后根据自己的需求进行修改。 许多在线编辑器提供实时预览功能，使用户可以立即看到他们的更改对引用和参考文献列表的影响。 实用例子 最开始讲到的在PPT里放参考文献的例子，我们来尝试一下实现：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 \u0026lt;?xml version=\u0026#34;1.0\u0026#34; encoding=\u0026#34;utf-8\u0026#34;?\u0026gt; \u0026lt;style xmlns=\u0026#34;http://purl.org/net/xbiblio/csl\u0026#34; version=\u0026#34;1.0\u0026#34; class=\u0026#34;in-text\u0026#34;\u0026gt; \u0026lt;info\u0026gt; \u0026lt;title\u0026gt;Simple PPT Style\u0026lt;/title\u0026gt; \u0026lt;id\u0026gt;http://www.example.org/styles/simple-ppt\u0026lt;/id\u0026gt; \u0026lt;author\u0026gt; \u0026lt;name\u0026gt;Peng Chen\u0026lt;/name\u0026gt; \u0026lt;email\u0026gt;pengchen2001@zju.edu.cn\u0026lt;/email\u0026gt; \u0026lt;/author\u0026gt; \u0026lt;category citation-format=\u0026#34;numeric\u0026#34;/\u0026gt; \u0026lt;category field=\u0026#34;generic\u0026#34;/\u0026gt; \u0026lt;updated\u0026gt;2024-01-23T00:00:00+00:00\u0026lt;/updated\u0026gt; \u0026lt;/info\u0026gt; \u0026lt;!-- Author macro --\u0026gt; \u0026lt;macro name=\u0026#34;author\u0026#34;\u0026gt; \u0026lt;names variable=\u0026#34;author\u0026#34;\u0026gt; \u0026lt;name form=\u0026#34;short\u0026#34; and=\u0026#34;symbol\u0026#34; initialize-with=\u0026#34;. \u0026#34;/\u0026gt; \u0026lt;label form=\u0026#34;short\u0026#34; prefix=\u0026#34;, \u0026#34;/\u0026gt; \u0026lt;/names\u0026gt; \u0026lt;/macro\u0026gt; \u0026lt;!-- Issued Year macro --\u0026gt; \u0026lt;macro name=\u0026#34;issued-year\u0026#34;\u0026gt; \u0026lt;date variable=\u0026#34;issued\u0026#34; date-parts=\u0026#34;year\u0026#34;\u0026gt; \u0026lt;date-part name=\u0026#34;year\u0026#34;/\u0026gt; \u0026lt;/date\u0026gt; \u0026lt;/macro\u0026gt; \u0026lt;!-- Citation layout --\u0026gt; \u0026lt;citation collapse=\u0026#34;citation-number\u0026#34;\u0026gt; \u0026lt;!-- 这是一个使用数字引用的样式，collapse会将连续引用折叠 --\u0026gt; \u0026lt;sort\u0026gt; \u0026lt;key variable=\u0026#34;citation-number\u0026#34;/\u0026gt; \u0026lt;/sort\u0026gt; \u0026lt;layout prefix=\u0026#34;(\u0026#34; suffix=\u0026#34;)\u0026#34; delimiter=\u0026#34;, \u0026#34;\u0026gt; \u0026lt;text variable=\u0026#34;citation-number\u0026#34;/\u0026gt; \u0026lt;/layout\u0026gt; \u0026lt;/citation\u0026gt; \u0026lt;!-- Bibliography layout --\u0026gt; \u0026lt;bibliography et-al-min=\u0026#34;1\u0026#34; et-al-use-first=\u0026#34;1\u0026#34;\u0026gt; \u0026lt;!-- 定义了作者的显示格式。当作者数量大于1时，只显示第一个作者并跟随“et al.” --\u0026gt; \u0026lt;layout\u0026gt; \u0026lt;group delimiter=\u0026#34;, \u0026#34;\u0026gt; \u0026lt;text macro=\u0026#34;author\u0026#34;/\u0026gt; \u0026lt;text variable=\u0026#34;container-title\u0026#34; font-style=\u0026#34;italic\u0026#34;/\u0026gt; \u0026lt;!-- 期刊名以斜体显示 --\u0026gt; \u0026lt;text macro=\u0026#34;issued-year\u0026#34; font-weight=\u0026#34;bold\u0026#34;/\u0026gt; \u0026lt;!-- 加粗显示的出版年份 --\u0026gt; \u0026lt;/group\u0026gt; \u0026lt;/layout\u0026gt; \u0026lt;/bibliography\u0026gt; \u0026lt;/style\u0026gt; 把整个代码保存成ppt-short.csl文件，导入到Zotero 我一般就直接选中文献，右键选择Create Bibliography from item Style选择Simple PPT Style，就是上面代码保存的 output mode选Bibliography output method选择Copy to Clipboard 这样就可以直接粘贴到PPT中了。 比如：X. Zhu, T. Xu, C. Peng, S. Wu, Advances in MALDI Mass Spectrometry Imaging Single Cell and Tissues. Front. Chem. 9, 782432 (2022).\n导出后粘贴就会变为 Zhu et al., Frontiers in Chemistry, 2022\n","date":"2024-01-23T00:00:00Z","image":"/p/csl/images/csl_editor_hu_74f3c74a2afa8735.png","permalink":"/p/csl/","title":"CSL格式原理和应用"},{"content":"Motivation 在数据分析中，有时候面对大量的英文单词描述可能无法快速获得全部信息，需要去进一步查询或翻译。\n我们可以用代码自行调用一些翻译api完成这一步，CRAN和github上有不少帮助翻译的R包，比如fanyi, ecce, translateR 等。\nfanyi Y叔最近写了一个不仅仅是翻译的fanyi包：https://github.com/YuLab-SMU/fanyi。支持多种翻译服务：百度翻译，必应翻译，有道智云，火山引擎，彩云小译，腾讯翻译君，智谱清言等。还有小词典，翻译ggplot图，翻译基因信息等功能。功能强大，未来可期。\n但翻译api一般会限制调用速度，有些用户就遇到了如以下问题：\n我当时回复了一个我自己常用的快速翻译的思路，但有时候也会有分隔符不对，一次输入超上限等问题。最近把这些问题解决了，写成了一个在pcutils包中使用的函数。\n另外，fanyi::translate_ggplot函数支持直接将ggplot的x，y轴label替换为其他语言：\n但是，并不是在所有机器上都能直接达到想要的效果的，需要考虑我们机器字体对其他语言（以中文为例）的支持。\n快速翻译 使用pcutils::translator实现快速翻译。最近还没有同步到CRAN上(2024/1/17)，所以先从github安装吧。\n1 2 3 4 5 6 7 8 if(!require(pcutils))remotes::install_github(\u0026#34;Asa12138/pcutils\u0026#34;) words=c(\u0026#34;Metabolic pathways - Homo sapiens (human)\u0026#34;, \u0026#34;Carbon metabolism - Homo sapiens (human)\u0026#34;, \u0026#34;2-Oxocarboxylic acid metabolism - Homo sapiens (human)\u0026#34;, \u0026#34;Fatty acid metabolism - Homo sapiens (human)\u0026#34;, \u0026#34;Biosynthesis of amino acids - Homo sapiens (human)\u0026#34;) translator(words) 1 2 3 4 5 6 7 8 9 10 ## Metabolic pathways - Homo sapiens (human) ## \u0026#34;代谢途径-智人（人类）\u0026#34; ## Carbon metabolism - Homo sapiens (human) ## \u0026#34;碳代谢-智人（人类）\u0026#34; ## 2-Oxocarboxylic acid metabolism - Homo sapiens (human) ## \u0026#34;2-草酸代谢-智人（人类）\u0026#34; ## Fatty acid metabolism - Homo sapiens (human) ## \u0026#34;脂肪酸代谢-智人（人类）\u0026#34; ## Biosynthesis of amino acids - Homo sapiens (human) ## \u0026#34;氨基酸的生物合成-智人（人类）\u0026#34; 主要解决了以下两个问题：\n当我们查询的是一大堆term时，使用换行符可以保证翻译结果的整齐，且这属于一次查询，所以速度非常快。 类似这样： 代码实现也不难，用换行符paste0输入到api后，返回的结果就已经是分隔好的向量了：\n1 2 3 4 5 6 #baidu_translate是内置函数，下列代码运行不了，仅作参考 input_words=paste0(words,collapse = \u0026#34;\\n\u0026#34;) res=baidu_translate(input_words, from = from, to = to) names(res)=words res api查询一次输入字符有上限（参见api描述），比如百度翻译api大约5000个字符。 所以对于上述的思路，将大量term合并在一起查询，可能会达到上限，所以我另外写了一个函数split_text将大段字符按照换行符\u0026quot;\\n\u0026quot;分隔成不同部分，保证每个部分不超过上限，然后分别查询后，返回结果合并，达到的效果就是几乎没有上限，且非常快速。\n1 2 original_text \u0026lt;- paste0(sample(c(letters,\u0026#34;\\n\u0026#34;),200,replace = TRUE),collapse = \u0026#34;\u0026#34;) print(original_text) 1 ## [1] \u0026#34;lxnj\\nulhhrtjwklnzixrsjplflptfiuezuyjkhppfphtkpkkb\\nknvafdtdjzetph\\nvrdktwmfijizfoefpnwzzqjyuwqankbtdcobgsosvxzyagvgskeymiutgv\\npux\\nawpxrpqwlkbnjnw\\nuxefkffydizfdgmogclmzjfukhsfhrctqykovdlivcgnkycnixajbqtw\u0026#34; 1 parts \u0026lt;- split_text(original_text, nchr_each = 50) 1 ## Characters number of this paragraph is more than 50 1 print(parts) 1 2 3 4 5 6 7 8 9 10 11 12 13 14 ## [[1]] ## [1] \u0026#34;lxnj\\nulhhrtjwklnzixrsjplflptfiuezuyjkhppfphtkpkkb\u0026#34; ## ## [[2]] ## [1] \u0026#34;knvafdtdjzetph\u0026#34; ## ## [[3]] ## [1] \u0026#34;vrdktwmfijizfoefpnwzzqjyuwqankbtdcobgsosvxzyagvgskeymiutgv\u0026#34; ## ## [[4]] ## [1] \u0026#34;pux\\nawpxrpqwlkbnjnw\u0026#34; ## ## [[5]] ## [1] \u0026#34;uxefkffydizfdgmogclmzjfukhsfhrctqykovdlivcgnkycnixajbqtw\u0026#34; 1 2 3 4 5 6 #baidu_translate是内置函数，下列代码运行不了，仅作参考 split_words=split_text(input_words,nchr_each = 5000) if(length(split_words)\u0026gt;1){ res_ls=lapply(split_words, baidu_translate, from = from, to = to, split=FALSE) return(do.call(c,res_ls)) } 中文支持 在R基础图或者ggplot绘图中默认使用的都是英文字体，想要支持中文字体的方法也有不少，关键就是family要指定中文字体。\n但我觉得最好用的还是使用showtext包来实现（在macOS和Windows上亲测有效）:\nWindows字体文件存放位置: C:\\Windows\\Fonts\\ macOS字体文件存放位置:/Users/XXX/Library/Fonts/; /System/Library/Fonts/ 1 library(showtext) 1 ## Loading required package: sysfonts 1 ## Loading required package: showtextdb 1 2 3 4 5 6 7 8 9 library(ggplot2) #开启showtext，一定要这行 showtext_auto() #添加字体文件，\u0026#34;simhei.ttf\u0026#34;改成你需要的字体文件位置，simhei是我们给该字体的命名 font_add(\u0026#34;simhei\u0026#34;, \u0026#34;/System/Library/Fonts/STHeiti Medium.ttc\u0026#34;) #查看系统字体，如果出现了simhei说明导入成功 font_families() 1 ## [1] \u0026#34;sans\u0026#34; \u0026#34;serif\u0026#34; \u0026#34;mono\u0026#34; \u0026#34;wqy-microhei\u0026#34; \u0026#34;simhei\u0026#34; 1 2 3 4 5 6 #然后就可以绘图了： p=ggplot(data.frame(x = rnorm(100))) + geom_histogram(aes(x), fill = \u0026#39;purple\u0026#39;, alpha = 0.6) + labs(x = \u0026#39;X 取值\u0026#39;, y = \u0026#39;频数 Count\u0026#39;, title = \u0026#39;标题 Title\u0026#39;) + theme(text = element_text(family = \u0026#39;simhei\u0026#39;)) p 1 ## `stat_bin()` using `bins = 30`. Pick better value with `binwidth`. 有些中文字体的英文支持不太好，如果要中英文混合显示可以使用中英文混合字体，比如知名度很高的YaHei Consolas混合字体。或者使用开源项目: FontForge, 来合并中英文字体。\n我上次写了一个简单的函数用来“画”春联chunlian(见R画春联)，就是这样来调用一个下载好的毛笔字体的：\n1 chunlian(c(\u0026#34;新年快乐\u0026#34;),bg_shape = 23,bg_size = 50,text_size = 25) 我也写了一个用来翻译ggplot的各种文字（包括x，y，label，legend，title等）的函数pcutils::ggplot_translator()，并且内置了showtext_auto，所以一般可以直接画出正常显示的其他语言。\n1 2 3 4 5 6 7 df \u0026lt;- data.frame(Subject = c(\u0026#34;English\u0026#34;,\u0026#34;Math\u0026#34;), Score = c(59,98), Motion=c(\u0026#34;sad\u0026#34;,\u0026#34;happy\u0026#34;)) ggp \u0026lt;- ggplot(df, mapping = aes(x = Subject, y = Score,label=Motion)) + geom_text()+ geom_point()+labs(x=\u0026#34;Subject\u0026#34;,y=\u0026#34;Score\u0026#34;,title=\u0026#34;Final Examination\u0026#34;) ggplot_translator(ggp,which = \u0026#34;all\u0026#34;,keep_original_label = TRUE) 1 2 ## Please set the font family to make the labels display well. ## see `how_to_set_font_for_plot()`. ","date":"2024-01-16T00:00:00Z","image":"/p/translator/images/fanyi_hu_f7b8badf7add4462.png","permalink":"/p/translator/","title":"R快速翻译和绘图中文支持"},{"content":"Introduction CRISPR规律成簇间隔短回文重复：clustered regularly interspaced short palindromic repeats\nCRISPR是存在于细菌基因组中的一种元件，其中含有曾经攻击过该细菌的病毒的基因片段。细菌透过这些基因片段来侦测并抵抗相同病毒的攻击，并摧毁其DNA，这类基因组是细菌（和古菌）免疫系统的关键组成部分。CRISPR-Cas 系统存在于大约 40% 的细菌和 85% 的古细菌基因组中，但不存在于真核生物基因组中。\nWork mechanism CRISPR整体工作流程基本如下 (1)：\n阶段1. 外源DNA采集\n外来核酸被Cas蛋白识别，入侵DNA的短片段（30-50个碱基对）（称为原型间隔子）被插入宿主的CRISPR基因座作为间隔序列，由重复序列分隔。在I型和II型系统中，原型间隔子选自侧翼有2-5称为PAM（protospacer adjacent motif）的核苷酸(nt)基序。原型间隔子通常结合在CRISPR基因座的一端，称为领导者，通过涉及Cas1、Cas2和原型间隔子上的游离3’羟基的机制。Protospacer整合伴随着重复前导末端重复序列，可能涉及宿主聚合酶和DNA修复机制。\n阶段2. crRNA生物合成\nCRISPR RNA生物合成始于转录，然后将初级转录本（pre-crRNA）核解加工成短的CRISPR衍生RNA文库(crRNAs)，每个都包含与先前遇到的外来DNA互补的序列。crRNA指导序列的两侧是相邻重复区域。在I型和III型系统中，初级CRISPR转录物由在重复序列内切割的CRISPR特异性内切核糖核酸酶（Cas6或Cas5d）处理。在许多I型系统中，重复序列是回文序列，并且Cas6与crRNA3’端的茎环稳定相关。在III型系统中，Cas6与CRISPR RNA瞬时结合，crRNA的3’端被未知核酸酶进一步修剪。CRISPR RNA加工类型II系统依赖于反式作用crRNA(tracrRNA)，它包含与重复序列互补的序列。这些双链区域在Cas9存在的情况下由RNase III处理。在II型系统中，tracrRNA和crRNA都是目标干扰所需的。该系统的两个RNA已融合成一个单向导RNA(sgRNA)，Cas9已成为一个强大的工具用于在多种细胞类型和多细胞生物中进行靶向基因组工程。\n阶段3. 目标干扰\n成熟的crRNA将Cas蛋白引导至互补目标。目标序列被专用Cas核酸酶降解，但目标降解的机制多种多样。I型和II型系统均以包含PAM和互补原型间隔子的dsDNA底物为目标顺序。II型系统中的目标切割由单个蛋白质(Cas9)和两个RNA执行，而I型系统依赖于多亚基监视复合物结合dsDNA底物然后募集Cas3，这是一种反式作用核酸酶，通常与ATP依赖性解旋酶融合。像I型系统，III型系统还依赖多亚基复合物进行目标检测，但与I型系统不同，这些复合物表现出内源性核酸酶活性，以转录依赖性方式降解互补RNA和靶DNA。III型系统不依赖PAM进行目标识别；相反，碱基配对延伸超出指导序列并进入crRNA信号”自身”的5’句柄（CRISPR基因座包含与指导和5’互补的序列handle)并防止目标切割。\nPAM 使用CRISPR/Cas9系统进行基因编辑时需要考虑PAM，PAM的含义和重要性：\nProtospacer adjacent motif（PAM）原间隔序列邻近模块序列。\nCRISPR/Cas9 (或 gRNA)所靶向的 DNA 序列称为 protospacer，PAM 是与之紧邻的一小段 DNA 序列(常用的 SpCas9 识别的 PAM 为 NGG)。\nCas9/sgRNA 不能结合、切割没有 PAM 的靶向序列。\nPAM 是细菌区分自身 DNA 与外源 DNA 的重要标志。\n改变 PAM 或与其相邻的 protospacer/target DNA 序列会严重影响核酸酶(Cas9, Cpf1 等) 对 DNA 的切割效率。\n某些基因编辑操作(如敲入点突变)可能需要人为将 PAM 或与其相邻的 DNA 序列进行突变，以避免核酸酶对该位点的反复切割，从而提高编辑效率。\nClass, Type, Subtype 1类 2类 原核生物的CRISPR-Cas适应性免疫系统根据效应子模块组织分为两个不同的类别。 1类CRISPR-Cas系统利用多蛋白效应复合物 (2)，而2类CRISPR-Cas系统利用单一蛋白效应器 (3)。\n基于不同的效应蛋白家族，1类系统分为3种类型和12种亚型。1类系统代表CRISPR-Cas基因座的约90％，并且存在于不同的细菌和古菌门中;嗜热菌富含III型系统。除效应子基因之外，大部分1类基因座编码适应模块蛋白质Cas1和Cas2，以及多种辅助蛋白质，例如Cas4，逆转录酶，CARF（CRISPR相关的Rossmann折叠）结构域蛋白质等。 III型和IV型系统在其各自的基因座中经常缺少适应性模块基因和/或CRISPR阵列。所有I型系统也编码DNA解旋酶Cas3，其通常与HD家族核酸酶结构域融合。在I型系统中，PAM在不同亚型之间变化，位于（原型）间隔区的5’或3’，对于适应和干扰都是必需的。\n基于不同的效应蛋白家族，第2类系统可分为3种类型和9个亚型。第十亚型（V-U）包括许多假定的系统，其免疫（或可能是调节）功能仍有待证明。 2类系统占CRISPR-Cas基因座的约10％，在不同的细菌被发现，但在古细菌中几乎不存在。除了效应器蛋白质，大部分2类基因组编码适应性模块蛋白质，Cas1和Cas2以及辅助蛋白质，例如Cas4。 II型和V-B型基因座还包括tracrRNA（反式激活CRISPR RNA），其与重复部分互补并涉及CRISPR（cr）RNA加工和干扰。然而，某些2类系统，特别是类型6的系统仅由CRISPR阵列和效应蛋白组成。\nbeyond adaptive immunity 一篇比较新的综述总结讨论了 CRISPR-Cas 系统的一些众所周知的和一些最近建立的非规范功能及其在其他生物过程中的快速扩展应用 (4)。它们在基因调控、细菌病理生理学、毒力和进化中的替代作用已经开始揭示。\nPathogenicity and virulence CRISPR-Cas系统在多种病原菌中不仅用于自适应免疫，还参与调控病原性和毒力。比如，Francisella novicida 利用Cas9和其他RNA分子减少宿主免疫反应，从而在宿主体内生存。类似的，Neisseria meningitis 和 Streptococcus pyogenes 也依赖Cas9侵染宿主并在其中繁殖。Campylobacter jejuni 的研究表明，Cas9参与调控毒力因子，影响其生物膜形成和宿主体内的生存能力。在 Legionella pneumophila 中，Cas2被发现对感染过程至关重要，具有核酸酶活性，且在 Acinetobacter baumannii 中，CRISPR-Cas系统与高生物膜生成能力有关。\nBacterial physiology 在 Myxococcus xanthus 中，cas基因（如cas8、cas7和cas5）对孢子形成和子实体发育至关重要。Salmonella typhi 的研究表明，删除I-E型系统的cas基因会影响外膜蛋白的表达，进而影响生理过程和毒力。在 Pseudomonas aeruginosa 和 Aggregatibacter actinomycetemcomitans 中，CRISPR间隔区的自靶向可能改变病原菌的生理或代谢。在 Listeria monocytogenes 中，尽管CRISPR基因簇缺乏相关的cas基因，但仍能抑制特定基因的表达，影响铁运输和其他生理过程。\nResponse to stress 在许多细菌中，CRISPR-Cas系统的表达会在应对压力时被激活。例如，在 Escherichia coli 中，膜应激可以诱导CRISPR-Cas系统的表达。同样，Streptococcus thermophilus 和 Sulfolobus islandicus 在噬菌体引发的应激后也会激活该系统。在 Streptococcus mutans 中，不同类型的CRISPR系统在温度和膜应激条件下表现出不同的调控模式，受双组分应激反应调节器VicK/R的影响。研究表明，CRISPR-Cas系统不仅参与适应性免疫，还与压力响应机制密切相关，但具体的分子机制仍需进一步研究。\nEndogenous gene regulation CRISPR-Cas系统在内源性基因调控中发挥作用。例如，在 Escherichia coli 中，I-E型CRISPR-Cas系统被发现有较高的倾向靶向自身染色体的转录活跃区域，表明其参与基因调控。Francisella novicida 利用CRISPR-Cas系统调节毒力相关蛋白的表达，帮助细菌躲避宿主免疫反应。在 Pelobacter carbinolicus 中，CRISPR间隔区自靶向特定基因，影响了该基因的转录。此外，III型系统通过靶向mRNA来调节基因表达，展示了CRISPR-Cas系统在基因调控中的多样性功能。\nBacterial genome remodeling 在细菌中，为了避免由于CRISPR-Cas系统自靶向间隔区导致的细胞死亡，细菌会通过基因组重塑来应对。这种重塑通常包括删除原靶序列或整个靶区域。例如，在 Pectobacterium atrosepticum 中，自靶向导致了整个100 kb的水平获取岛（HAI2）区域的删除。类似的情况在其他细菌中也被观察到，如 Escherichia coli 和 Streptococcus thermophilus，自靶向导致了基因组中多达35 kb和37.4 kb的大片段缺失。这些研究表明，自靶向事件会促使细菌通过基因组重塑来进化和适应环境变化。\nAssociation with DNA repair system CRISPR-Cas系统与DNA修复系统在不同层面上存在密切关联，尤其是在适应阶段。Escherichia coli 的I-E型CRISPR-Cas系统在获取新间隔区时会利用DNA修复通路中的DNA聚合酶。此外，CRISPR-Cas系统中的一些蛋白质与DNA修复蛋白共享同源结构域，如Cas3的解旋酶域和Cas4的核酸酶域。Cas1 蛋白与多种细胞修复蛋白（如RecB、RecC和RuvB）相互作用，帮助修复复制过程中的DNA断裂，同时也促进了新间隔区的适应。尽管CRISPR-Cas系统与DNA修复系统在多个层面协同工作，但也存在一定的对抗关系。例如，II型系统与非同源末端连接（NHEJ）重组路径呈负相关。这种复杂的关系可能解释了CRISPR-Cas系统在细菌中的分布和多样性。\napplication Inhibition of horizontal gene transfer CRISPR-Cas系统正被探索用于抑制抗生素抗性基因的水平转移。研究表明，CRISPR系统能够降低多药耐药（MDR）菌株中抗生素抗性决定因子的浓度。例如，在 Enterococcus faecalis 中，CRISPR系统减少了移动遗传元件（如前噬菌体和质粒）的传播。在 Streptococcus pyogenes 中，CRISPR间隔区的数量增加也降低了整合前噬菌体的频率。通过设计靶向抗药性基因的CRISPR间隔区，可以有效针对带有病原岛的菌株，从而减少抗生素耐药和致病性基因的传播。此外，将CRISPR-Cas系统引入溶原噬菌体中来靶向抗生素抗性基因，以及添加靶向裂解噬菌体的间隔区，有望进一步保护抗生素敏感的细胞免受噬菌体的裂解感染。\nTyping tool CRISPR-Cas系统最早被用于细菌种群的分型，以揭示其多样性。例如，在Mycobacterium tuberculosis中，CRISPR系统的间隔区变异常用于流行病学研究和类型学分析。与此不同的是，在Campylobacter jejuni中（使用的是类型II CRISPR系统），单靠CRISPR分型无法充分揭示进化关系，因此常与其他工具如扩增片段长度多态性（AFLP）和多位点序列分型（MLST）联合使用。\nGenome editing CRISPR-Cas系统因其在基因组编辑中的高效性而受到广泛关注。尽管所有CRISPR系统都具备识别和靶向DNA的功能，但并非所有系统都适用于基因组编辑。以下是一些关键点：\n系统类型的适用性： I型和III型CRISPR：这类系统的DNA降解过程不够清晰，需要额外的Cas6蛋白来生成crRNA，因此不适用于基因组编辑。 II型CRISPR：以CRISPR-Cas9为代表，仅需少量组件即可执行所有功能，这使其成为理想的基因组编辑工具。Type II系统通过引入双链断裂（DSBs）在哺乳动物细胞中表现出色，这对基因组编辑至关重要。 CRISPR-Cas9技术： 构建：CRISPR-Cas9系统使用Cas9蛋白和单导RNA（sgRNA）来靶向特定DNA序列。sgRNA通过将自然存在的tracrRNA和crRNA融合形成，具备与靶标序列的互补性。 优势：CRISPR-Cas9技术相比于传统的基因组编辑工具，如转录激活因子样核酸酶（TALENs）和锌指核酸酶（ZFNs），展现了更高的效率和简便性。 应用：在进行基因组编辑时，将Cas9-sgRNA构建体引入细胞，同时转化合成的重组DNA模板，可以提高靶位点的突变几率。重组DNA模板应具有突变以防止Cas9核酸酶的持续片段化。 效率：CRISPR-Cas9技术因其操作简单、高效，被广泛应用于多种真核和原核模型生物的基因组编辑。 Pangenomes 大部分的CRISPR array中的spacer尚未与它们识别的病毒相关联，被命名为 CRISPR 暗物质。\nmembranome and CRISPR-Cas systems 最新的这篇文章分析了被称为 ESKAPE 的细菌组的数千个基因组, 看有crispr系统的基因组比没有的基因组多的特殊功能 (5)\n总体crispr概况 cirspr type 分布，spacer到plasmid/phage的比例。。。\n在肠沙门氏菌中，已表明这些系统可以调节鞭毛基因的表达，最终与生物膜形成有关。\n平均而言，具有 CRISPR-Cas 系统的基因组呈现出较少数量的抗性和毒力基因。\ncrispr phylogeny CRISPR-Cas 系统似乎遍布整个系统发育树\nCRISPR-Cas 系统不会出现在具有固定辅助基因集合的基因组中\n具有 CRISPR-Cas 系统的基因组是否以比没有这些系统的基因组更高的频率呈现特定基因？\nCRISPR-Cas 相关基因富集膜蛋白\n具有 CRISPR-Cas I 型系统和特定膜蛋白的基因组显示出独特的spacer和噬菌体基因\nhCRISPR or repeat? CRISPR-Cas 系统存在于大约 40% 的细菌和 85% 的古细菌基因组中，但不存在于真核生物基因组中。最近，Communications Biology 上发表的一篇文章报道了在人类基因组中鉴定出 12,572 个推定的 CRISPR，他们称之为“hCRISPR” (6)。\n但感觉人类怎么会有这么多CRISPR系统，所以又看到一篇文章怼他的： (7)。\nReference 1. J. Carter, B. Wiedenheft, SnapShot: CRISPR-RNA-Guided Adaptive Immune Systems. Cell. 163, 260–260.e1 (2015).\n2. K. S. Makarova, F. Zhang, E. V. Koonin, SnapShot: Class 1 CRISPR-Cas Systems. Cell. 168, 946–946.e1 (2017).\n3. K. S. Makarova, F. Zhang, E. V. Koonin, SnapShot: Class 2 CRISPR-Cas Systems. Cell. 168, 328–328.e1 (2017).\n4. V. Devi, K. Harjai, S. Chhibber, CRISPR-Cas systems: Role in cellular processes beyond adaptive immunity. Folia Microbiologica. 67, 837–850 (2022).\n5. A. Rubio, M. Sprang, A. Garzón, A. Moreno-Rodriguez, et al., Analysis of bacterial pangenomes reduces CRISPR dark matter and reveals strong association between membranome and CRISPR-Cas systems. Science Advances. 9, eadd8911 (2023).\n6. J. van Riet, C. Saha, N. Strepis, R. W. W. Brouwer, et al., CRISPRs in the human genome are differentially expressed between malignant and normal adjacent to tumor tissue. Communications Biology. 5, 1–13 (2022).\n7. M. Buyukyoruk, W. S. Henriques, B. Wiedenheft, Clarifying CRISPR: Why Repeats Identified in the Human Genome Should Not Be Considered CRISPRs. The CRISPR Journal (2023), doi:10.1089/crispr.2022.0106.\n","date":"2023-12-31T00:00:00Z","image":"/p/crispr/images/stress_hu_596fbf8e433939c1.png","permalink":"/p/crispr/","title":"CRISPR 相关内容学习"},{"content":"2023年已逝，2024年龙年将至。\n祝一同攀登科研之峰的大家，新年快乐🎉🐉🎉！\n愿大家在新的一年，实验蓬勃发展，代码优雅流畅，数据如音符，奏响科研交响曲。\n祝大家新年里科研路上有更多的收获，事业腾飞，身体健康！\n对了，我在R里写了个简单的函数用来“画”春联，再次给大家送上祝福。当然用在农历新年会更好，哈哈!\n函数 chunlian 放在R包pcutils里了，可以输入长度为3的字符向量，第一个是横批，第二三个是上下联。\n1 2 3 4 if(!require(pcutils))remotes::install_github(\u0026#34;Asa12138/pcutils\u0026#34;) library(pcutils) chunlian(c(\u0026#34;科研顺利\u0026#34;,\u0026#34;数据分析好到爆\u0026#34;,\u0026#34;文章投哪哪都要\u0026#34;)) 1 ## Loading required namespace: sysfonts 1 ## Loading required namespace: showtext 1 2 3 #也可以不输入上下联，把bg_shape换成23也很好看。 chunlian(c(\u0026#34;新年快乐\u0026#34;),bg_shape = 23,bg_size = 50,text_size = 25) 1 2 3 #还可以通过调节文字属性，画一个倒福。 chunlian(c(\u0026#34;福\u0026#34;),bg_shape = 23,bg_size = 80,text_size = 40,text_params = list(angle=180)) 还和群青同学一起做了个蛋糕，happy new year！\n","date":"2023-12-31T00:00:00Z","image":"/p/new_year/index.en_files/figure-html/unnamed-chunk-2-2_hu_b6e09d03e5ad4a92.png","permalink":"/p/new_year/","title":"龙年启科研新篇"},{"content":"Introduction 扩增子测序是一种主要用于研究微生物群落结构的分子生物学技术。它主要用于分析环境样本中的微生物群落，特别是对细菌和古菌的16S rRNA基因以及真菌的18S rRNA基因进行测序。这项技术广泛用于研究土壤、水体、空气、生物体内等不同环境中微生物的多样性和丰度。\n基本步骤：\nDNA提取： 从样本中提取总DNA。\n目标基因扩增： 使用聚合酶链式反应（PCR）扩增目标基因片段。对于细菌和古菌，通常选择16S rRNA基因的特定区域；对于真菌，选择18S rRNA基因。\n文库构建： 将扩增的DNA片段构建成文库，通常通过添加适配器序列。\n高通量测序： 使用高通量测序技术，如Illumina、454、Ion Torrent等，对文库进行测序。\n数据分析： 对测序得到的数据进行生物信息学分析，包括去除低质量序列、去除冗余、聚类分析、物种注释等。\n生态学分析： 利用得到的数据，进行微生物群落的多样性、丰度、结构等生态学研究。\n更详细的代码流程可以参考刘永鑫老师的EasyAmplicon (1)\n除了16S和18S rRNA，还有其他一些常用的核酸序列，特别是在研究微生物和生物多样性时。以下是一些常见的核酸序列：\nITS序列（Internal Transcribed Spacer）： 位于真核生物的核糖体RNA基因间区域，尤其在真菌中常被用于物种鉴定。\n23S和28S rRNA： 与16S和18S rRNA相对应，用于更大型的细胞器，如线粒体和真核细胞的核糖体。\nCOI（Cytochrome c Oxidase subunit I）： 用于动物的分子鉴定，尤其在动物界中是一种广泛使用的DNA条形码。\nrpoB基因： 编码细菌和古细菌RNA聚合酶β亚基，常被用于分子鉴定。\nITS2序列： 在ITS序列中的亚单位，同样用于真菌的物种鉴定。\nDatabase 涉及到16S rRNA基因的序列数据库时，有三个主要的数据库是常用的：Greengenes、SILVA 和 RDP。\nGreengenes 特点： Greengenes 是一个由 Berkeley 国家实验室创建的数据库，长期以来一直是16S序列数据库中的重要参考。 内容： 包含细菌和古菌的16S rRNA基因序列，提供了丰富的分类信息，便于微生物群落的分析。 分类： 使用七级分类（界、门、纲、目、科、属、种），易于理解和使用。 更新： 今年更新了！！！数据库升级，称为Greengenes2，相关介绍已见刊于nature biotechnology (2)。 应用： 被广泛用于微生物群落结构和功能的分析。 https://greengenes2.ucsd.edu/\nGreengenes2\n标准化的分类系统： Greengenes2沿用了Greengenes的分类系统，即GTDB（Genome Taxonomy Database），这意味着在不同研究之间，微生物分类的结果更加一致和可比较。\n系统发育的一致性： 该数据库允许直接整合16S rRNA和宏基因组数据集，将它们统一在一个参考树中。分析表明，由相同样本生成的16S rRNA和宏基因组数据在主坐标空间、分类学和表型效应大小方面一致。\n系统发育覆盖率的提高： Greengenes2的系统发育覆盖率远大于过去的资源，包括SILVA、Greengenes和GTDB。这提供了更全面的分类信息，有助于更好地理解微生物群落的结构。\n高分辨率结果： 对于16S rRNA基因V4区域的研究，Greengenes2允许直接从系统发育中获得分类结果，无需使用朴素贝叶斯方法，并可能产生更高的分辨率结果。\n良好的一致性： 与Silva数据库相比，Greengenes2在属水平和物种水平上提供了良好的一致性，这有助于确保研究结果的可靠性和可重复性。\n总体而言，Greengenes2的全面性和一致性提高了使用不同数据类型进行微生物组研究的可重复性。这对于确定影响微生物组变化的变量，并在不同人群中可靠地进行比较，具有重要的科研意义。\nSILVA https://www.arb-silva.de/\n特点： SILVA 是由德国马普研究所和 Ribocon 主持的数据库，它专注于提供全面和高质量的核糖体rRNA注释信息 (3)。 内容： 包含了细菌、古菌和真菌的小亚基（SSU）和大亚基（LSU）rRNA序列。提供了很多不同的部分，根据不同的序列长度和相似性来生成。 分类： SILVA 采用了多级分类系统，提供更详细的分类信息，但其物种注释采用14级，与其他数据库不同。 更新： 定期更新，保持其信息的时效性。 应用： 在微生物分类和系统发育研究中广泛应用，也在16S和18S序列分析中被许多软件包如mothur所采用。 RDP (Ribosomal Database Project) https://lcsciences.com/documents/sample_data/16S_sequencing/src/html/top1.html\n特点： RDP 是一个由 Ribosomal Database Project 团队创建和维护的数据库，专注于提供核糖体相关的数据和服务 (4)。 内容： 包括细菌的16S rRNA序列，也包括真菌的28S rRNA序列。是一个全面的16S rRNA序列数据库。 分类： 提供16S rRNA序列的比对、分类、树构建等多种功能。 更新： 最近更新在 May 26, 2015。 应用： 作为16S rRNA序列数据库中最早的之一，RDP 在微生物多样性和进化方面有着深远的影响，也在一些16S rRNA分析软件中被广泛采用。 UNITE https://unite.ut.ee/\n用途： UNITE数据库是用于真菌鉴定和多样性检测的主要marker基因数据库。ITS（核糖体基因内转录间隔区）是最常用的真菌标记基因之一。\n数据库更新： 最近一次的更新是在2023-11-30。数据库的更新对于确保其中包含最新的、全面的真菌序列是非常重要的。\n阈值聚类： 数据库提供了阈值聚类的选项，用户可以根据需要选择不同的阈值，以调整序列的聚类水平。这对于控制数据的复杂度和提高分析效率很有帮助。\n包含singleton序列： 用户可以选择是否包含singleton序列，即那些在数据库中没有与其碱基完全相同的物种序列。这个选择可能影响到数据的多样性分析。\n物种统计信息： 用户可以通过在第三个方框中填入感兴趣的物种，查看数据库中该物种的序列统计信息。这包括左下角展示的物种序列统计信息和右下角对应的扇形图。\n内置blast功能： UNITE数据库还内置了blast功能，用户可以通过数据库的右上角菜单栏 “Run Analysis” 进行操作。这个功能允许用户通过blast来进行序列的比对和相似性搜索。\nReferences 1. Y.-X. Liu, L. Chen, T. Ma, X. Li, et al., EasyAmplicon: An easy-to-use, open-source, reproducible, and community-based pipeline for amplicon data analysis in microbiome research. iMeta. 2, e83 (2023).\n2. D. McDonald, Y. Jiang, M. Balaban, K. Cantrell, et al., Greengenes2 unifies microbial data in a single reference tree. Nature Biotechnology, 1–4 (2023).\n3. C. Quast, E. Pruesse, P. Yilmaz, J. Gerken, et al., The SILVA ribosomal RNA gene database project: Improved data processing and web-based tools. Nucleic Acids Research. 41, D590–D596 (2013).\n4. B. L. Maidak, G. J. Olsen, N. Larsen, R. Overbeek, et al., The Ribosomal Database Project (RDP). Nucleic Acids Research. 24, 82–85 (1996).\n","date":"2023-12-08T00:00:00Z","image":"/p/amplicon/images/nbt1_hu_da84805d76d958af.png","permalink":"/p/amplicon/","title":"常用扩增子数据库"},{"content":"Introduction The Earth Microbiome Project (EMP) 是一个旨在描述和解释地球上微生物多样性的国际性科学计划。这个项目的目标是通过对地球各种环境中的微生物群落进行大规模的DNA测序和元数据采集，构建一个全球微生物群落的参考数据库，以更好地理解和研究微生物的生态学、功能和进化。\n全球性研究： EMP 的目标是收集世界各地不同环境的微生物数据，包括土壤、水体、空气、植被、动物等。\nDNA测序： 项目使用高通量的DNA测序技术，基本都是16S rRNA基因测序，以研究微生物的遗传信息。\n元数据采集： 除了DNA数据，项目还关注采集样本的相关元数据，如环境条件、地理位置、季节等，以更好地理解微生物与环境之间的关系。\n开放数据： EMP 采用开放科学的理念，旨在使其数据对全球科学家社群开放，以促进更广泛的研究和合作。\n生态学和生物多样性： 通过研究微生物群落，该项目有助于揭示地球各个生态系统中微生物的生态学角色，并促使对生物多样性的更深入理解。\n技术和计算工具的发展： 除了数据的收集，该项目还致力于发展新的技术和计算工具，以更好地处理和分析大规模的微生物组学数据。\nEMP 的工作对于我们理解地球上微生物的分布、演变和功能，以及它们与生态系统健康的关系都具有重要的意义。\n官方网址：https://earthmicrobiome.org/\n首发成果 原文链接： https://www.nature.com/articles/nature24621 (Nature 2017 (1))\n主要介绍了微生物世界的重要性和多样性与对其基本结构的有限理解之间的对比。尽管最近DNA测序技术取得了重大进展，但缺乏标准化的研究方法和共同的分析框架阻碍了研究之间的比较，从而妨碍了对地球微生物生命的全球推断的发展。\n本研究通过对地球微生物计划中收集的微生物群落样本进行荟萃分析。通过协调的研究方法和新的分析方法，特别是使用精确序列而不是聚类的操作分类单元，我们能够跨多个研究跟踪细菌和古菌核糖体RNA基因序列，并探索前所未有的规模下的多样性模式。结果是一个提供全球背景的参考数据库，为将来的研究数据提供框架，并促进对地球微生物多样性的越来越完整的描述。\n方法与结果\n1.样品收集\nEMP向全球科学界征集环境样本和相关数据，跨越不同的环境，空间、时间和物理化学变量。 来自97个独立研究的27751个样本代表了不同的环境类型(图a)、地理位置(图b)。所有样品进行了DNA提取和16S rRNA测序，并对细菌和古菌部分进行了分析。 2.DNA提取，PCR扩增，测序和序列预处理\n使用 MO BIO PowerSoil DNA 提取试剂盒进行 DNA 提取。\n采用 16S rRNA V4 区域的引物对（515F-806R）进行 PCR 扩增。\n序列测定阶段选择 Illumina HiSeq 或 MiSeq 测序平台。\n利用 QIIME 1.9.1 脚本 split_libraries_fastq.py 对测序得到的数据进行拆分，使用默认参数进行质量控制，并生成 FASTA 序列文件。\n3.序列标记、OTU筛选以及群落分析方法\n在这项研究中，考虑到与植物相关的样本和无宿主影响的样本中有三分之一以上的序列不能与现有的 rRNA 数据库匹配，研究采用了一种无需参考序列的方法，即 Deblur。这种方法通过去除错误的序列并提供单核酸精度上的子操作单元（sOTU，sub-OTU），在文章中被称为“标记序列”（tag sequence）。由于早期 EMP 计划中的测序长度为90bp，为了进行跨时期的序列结果比较，研究将所有序列都截断至90bp，相应的结果表明了90bp、100bp 和150bp 等不同长度对研究结果的影响不大。\n在与参考数据库（Greengenes 13.8 和 Silva 128）的全长序列进行比对时，使用了 VSEARCH 工具进行全局比对，并要求100%的相似性（类似现在常用的ASV）。 对于90bp 的 Deblur 结果，每个样本随机抽取了5000个观测到的序列，用于分析微生物群落的 alpha 多样性（observed_otus、shannon、chao1、faith_pd）和 beta 多样性（基于 UniFrac 距离矩阵，进行 PCoA 分析）。\n对于16S rRNA 基因拷贝数的计算，使用了基于 PICRUSt 1.1.0 的命令行脚本“normalize_by_copy_number.py”，将每个OTU的丰度除以相应推测出的16S rRNA基因的拷贝数。\n针对 Deblur 90 bp 结果中的2000个样本，采用随机森林分类树的方法进行样本分类分析，将不同环境下的样本划分至相应的环境标签中。在这一方法中使用了 R 语言下的 caret 和 randomForest 包。\n为了确定 tag sequence 在多个环境样本中的分布程度，研究使用 SourceTracker 分析。在进行分析之前，对每个样本的序列总数进行了稀释至1000。\n多样性模式与环境的关系 通过使用微生物环境的结构化分类变量 EMPO，研究分析了 EMP 目录中的多样性，包括观察到的标签序列数量（α多样性）、类群周转和嵌套性（β多样性）以及预测的基因组特性（生态策略）。\n宿主关联是区分微生物群落的基本环境因素，而盐水群落和非盐水群落之间存在主要组成差异。环境因素对α和β多样性的影响表明环境类型和宿主物种对多样性贡献较大。\n监督机器学习结果显示仅根据群落组成即可将样本准确区分为动物相关、植物相关、含盐自由生活或非含盐自由生活，而对环境进行更详细分类的准确度也相对较高。源追踪分析支持对环境类型的高度分类。\n另外，16S rRNA 基因的预测平均群落拷贝数 (ACN) 是区分宿主相关群落和自由生活群落中微生物群落的另一个指标。这个指标反映了不同环境之间的生态策略差异，尤其在动物宿主中与较高的全基因组 rRNA 操纵子拷贝数相关。\n5.用更为精确的分类单元代替OTU。\n准确序列使我们能够以比传统OTU更精细的分辨率观察和分析微生物分布模式。\n通过Shannon熵分析标签序列和更高的分类群，以测量类群分布中的偏差，我们能够更好地了解不同类群在各种环境中的分布模式。标签序列在环境中表现出很高的特异性，而更高的分类水平则在不同环境中分布更均匀。熵的分布显示了这一模式的普遍性。通过研究熵如何随着系统发育距离的变化而变化，可以更准确地衡量类群对环境的特异性。结果表明，个体16S rRNA序列最好地捕捉了环境特异性，远低于定义微生物物种的典型阈值（16S rRNA基因的97%同一性）。EMP数据集具有跟踪地球微生物群落中个体序列的能力。使用EMP的代表性子集，研究人员生成了序列计数和分布表，包括在不同环境（EMPO）和沿环境梯度（pH、温度、盐度和氧气）中的分布。从中生成的’EMP交易卡’可促进对数据集的探索，并突出了三个普遍或与环境相关的标签序列的分布模式。\nEMP目录可以使用Redbiom软件查询，具有命令行和Web界面，以根据序列、分类或样本元数据查找样本，并导出所选样本数据和元数据。EMP协议生成的用户数据可以轻松整合到该框架中。未来，针对相同基因组区域的不同方法测序的数据集的组合可能是可以接受的，但需要考虑方法学偏差。EMP目录的不断增长预计将在研究和工业中发挥作用，标签序列将用作环境指标，并代表培养、基因组测序和实验室研究的目标。此外，尽管这些工具和方法是为细菌和古细菌开发的，但可以扩展到生命的所有领域。为了增加EMP和类似项目的效用，我们必须不断改进元数据收集和整理、本体论、对多组学数据的支持以及对计算资源的访问。\n微生物生态不再需要OTU聚类，而是一个更为精确的分类单元。这样一来，序列的特异性更高，环境分类也可以更细，使我们能够在更精确的分辨率下观察和分析微生物分布模式。在该文章中，作者以shannon熵值为标准，分别对tag sequence和较高的物种分类在不同环境中的分布进行分析。可以看出，新方法中的标记序列对环境具有较高的特异性，分布偏向于一个或几个环境(低Shannon熵)；相比之下，更高的物种分类学水平往往更均匀地分布在不同的环境(高Shannon熵，低特异性)(图a)。不同物种分类级别上的所有标记序列的熵的分布也证实了这一观点(图b) 。为了精确衡量每个分类单元对环境的差异，作者也探究了熵随着生态系统距离的变化而变化的模式(图c)。\n现在的16S rRNA测序分析用的更多的是ASV (amplicon sequence variant) (2)，符合使用准确序列这一倡议，可以参考 https://www.jianshu.com/p/f31581bbfb80。\n结论：\nEMP框架和全球综合分析的价值超出了各个研究的贡献。但是由于数据主要是为了回答不同问题而收集的，而不是针对一个主题的元分析，因此结论应该谨慎对待，并可以作为未来假设导向研究的起点。\n此外，有必要更均匀地覆盖地理和化学梯度，并使用更全面的元数据收集和整理工具来跟踪环境变化。\n另外，未在本研究中测量的生物因素（例如动物、真菌、植物、病毒和真核微生物）在确定群落结构方面起着重要作用。这个可扩展的框架可以用来解决这些需求：填补生理化学空间中的空白、为微生物真核生物和病毒提供扩增子数据，以及进行全基因组和全代谢组分析。在当前学术和环境学家都意识到生物多样性和生态系统功能的重要性时，这样的研究框架具有重要意义。\n未来肯定会有基于鸟枪法测序和质谱的EMP(Earth Metagenome Project, Earth Metabolome Project)，哈哈。\n衍生成果 基于EMP提供的protocol与软件进行独立研究，或者基于EMP数据进行荟萃分析的研究近些年有很多，这里介绍几篇代表性的。\nA macroecological theory of microbial biodiversity (3) 微生物是地球上最丰富、多样且功能重要的生物。在过去的十年中，微生物生态学家们产生了有史以来最大的群落数据集。然而，这些数据很少被用来揭示普遍性和稀有性的类似定律的模式，检验生物多样性理论，或者探索微生物群落结构的统一解释。\n通过对来自环境和宿主相关生态系统的\u0026gt;20,000个样本的全球范围汇编，我们测试了竞争理论预测微生物丰度和多样性-丰度缩放规律的能力。我们表明，这些模式最好由随机过程的协同作用来解释，这些过程由对数正态动态所捕捉。我们证明对数正态动态在丰度的各个尺度上都具有预测能力，这是生物多样性理论所必需的。通过理解生态过程的乘性和随机性质，科学家们可以更好地了解地球上最大且最多样化的生态系统的结构和动态。\nStandardized multi-omics of Earth’s microbiomes reveals microbial and metabolite diversity (4) 由于缺乏标准化方法，全球范围内比较不同栖息地类型对微生物群落结构和功能的研究面临重大挑战。本研究对地球微生物组项目收集的880个微生物群落样本进行了多组学分析，包括16S、18S和ITS扩增子数据、鸟枪测序数据，以及基于液相和气相色谱-质谱的非靶向代谢组数据。采用标准化的协议和数据处理方法描述微生物群落，重点关注微生物相关代谢物和微生物类群在不同环境中的关系和共现性。\n结果建立了宏基因组和代谢组学数据的参考数据库，并提供了整合其他研究的框架，为跨越尺度探索多样性提供支持。通过验证“每种微生物和代谢物无处不在，但受到环境选择”的假设，证明了数据库的实用性。研究发现代谢物的多样性与微生物群落和环境相关，并揭示了与特定栖息地相关的微生物群共存方式。此外，某些化学物质（如萜类化合物）在区分不同地球环境方面表现出色，为微生物和化学生态学提供深入见解，为宿主和环境的多组学微生物组研究提供了基础和方法。\nEarth microbial co-occurrence network reveals interconnection pattern across microbiomes (5) 背景：微生物相互作用塑造了微生物群落的结构和功能；在特定环境中，微生物共存网络已被广泛构建以探索这些复杂系统，但它们在全球范围内跨各种环境中的互联模式仍未被探索。在这里，我们从地球微生物组项目数据集的23,595个样本和12,646个精确序列变体中推断了一个微生物共存网络。\n结果：这个非随机的无标度地球微生物共存网络包括8个分类学上不同的模块，与不同的环境相连接，具有特定环境的微生物共存关系。从修剪成统一大小的数据集中推断出的亚网络的不同拓扑特征表明在各种环境的微生物群落中存在不同的共存模式。大量专业边的存在突显了环境特异性共存关系是微生物群落中的重要特征。各种环境的微生物群落被聚类成两组，这两组主要由植物和动物表面的微生物群落连接。在大多数亚网络中，酸杆菌Gp2和Nisaea被识别为中心枢纽。负边的比例范围从土壤亚网络的1.9%到非盐性表面亚网络的48.9%，表明各种环境经历了不同强度的竞争或生态位分化。\n结论：这项研究突显了各种环境中微生物群落之间的互联模式，并强调了从网络视角理解微生物群落的共存特征的重要性。\n实际使用 首先应该找到我们希望使用的数据：\nEMP 观测表、元数据以及其他数据和结果可从 Nature 论文的 Zenodo 存档 (https://zenodo.org/record/890000)、FTP 站点 (ftp://ftp.microbio.me/emp/release1)和 Qiita EMP 门户(https://qiita.ucsd.edu/emp/)获取。\nFTP 站点上的内容包括：\n描述存储库的自述文件 描述映射文件和数据集子集的 Markdown 文件 选择最适合您分析的 BIOM 表的流程图 EMP 样本类型本体 (EMPO) 文本文件 映射文件 OTU 观测表 OTU信息：序列和树 OTU分布表 结果：α 和β 多样性 选择最适合您分析的 BIOM 表的流程图：\nemp_studies.csv记录了所有97个研究的信息，包括研究的文章，原始数据在EBI的编号，样本数量等等。\n但是在寻找原始数据的时候发现The soil microbiome influences grapevine-associated microbiota这个研究的数据找不到了（ERP006348），值得注意。\nmetadata metadata可以使用emp_qiime_mapping_release1_20170912.tsv文件，其中标准化地记录了27751的样本非常多的信息，使用的时候关键是这些列：\n#SampleID – unique identifier for sample Ontology\nenv_biome – ENVO biome env_feature – ENVO feature env_material – ENVO material envo_biome_0 – ENVO biome level 0 envo_biome_1 – ENVO biome level 1 envo_biome_2 – ENVO biome level 2 envo_biome_3 – ENVO biome level 3 envo_biome_4 – ENVO biome level 4 envo_biome_5 – ENVO biome level 5 empo_0 – EMPO level 0 empo_1 – EMPO level 1 empo_2 – EMPO level 2 empo_3 – EMPO level 3 如果要结合地理和环境因素分析，就加上这些列：\nGeography\ncollection_timestamp – date and time sample was collected country – country where sample was collected latitude_deg – latitude where sample was collected longitude_deg – longitude where sample was collected depth_m – depth in meters where sample was collected (blank if altitude is given) altitude_m – altitude in meters where sample was collected (blank if depth is given) elevation_m – elevation in meters where sample was collected Environment\ntemperature_deg_c – temperature of sample in degrees Celsius ph – pH of sample salinity_psu – salinity of sample in practical salinity units oxygen_mg_per_l – oxygen concentration of sample in mg/L phosphate_umol_per_l – phosphate concentration of sample in umol/L ammonium_umol_per_l – ammonium concentration of sample in umol/L nitrate_umol_per_l – nitrate concentration of sample in umol/L sulfate_umol_per_l – sulfate concentration of sample in umol/L metadata记录的#sampleID应该是人工整理的结果，如果我们从原始数据分析会发现我们的样本名是EBI数据库里的编号如ERR1591463，所以要用上metadata的话就要找到ERR编号和metadata中的#sampleID的对应关系。\n我们要在EBI数据库中找到每个研究的project，然后看read files里的信息，一般Run Accession和Sample Title对应的就是ERR编号和#sampleID。如果Sample Title有问题的话，一般Run Alias中会包含#sampleID，所以有些需要自己手动map一下。\n其他就可以使用16S的分析流程进一步看了。\nReferences 1. L. R. Thompson, J. G. Sanders, D. McDonald, A. Amir, et al., A communal catalogue reveals Earth’s multiscale microbial diversity. Nature. 551, 457–463 (2017).\n2. B. J. Callahan, P. J. McMurdie, S. P. Holmes, Exact sequence variants should replace operational taxonomic units in marker-gene data analysis. The ISME Journal. 11, 2639–2643 (2017).\n3. W. R. Shoemaker, K. J. Locey, J. T. Lennon, A macroecological theory of microbial biodiversity. Nature Ecology \u0026amp; Evolution. 1, 1–6 (2017).\n4. J. P. Shaffer, L.-F. Nothias, L. R. Thompson, J. G. Sanders, et al., Standardized multi-omics of Earth’s microbiomes reveals microbial and metabolite diversity. Nature Microbiology. 7, 2128–2150 (2022).\n5. B. Ma, Y. Wang, S. Ye, S. Liu, et al., Earth microbial co-occurrence network reveals interconnection pattern across microbiomes. Microbiome. 8, 82 (2020).\n","date":"2023-11-30T00:00:00Z","image":"/p/emp/images/emp1_hu_60acb11e0eb81851.png","permalink":"/p/emp/","title":"地球微生物组计划介绍（EMP）"},{"content":"Introduction ordination analysis（排序分析）是生态学和统计学领域中用于分析和解释多变量数据的方法之一。这个方法通常被用于探索和可视化生态学或生物学数据中的模式，尤其是在物种组成和环境因素之间的关系方面。具体可以参考张金屯老师的《数量生态学》，里面讲的非常详细，然后《数量生态学—R语言的应用》一书中还提供了所有分析的R代码，非常建议阅读。\n排序分析是一种多变量分析的方法，而降维分析是其中的一部分。排序分析的目标是通过降维技术将高维数据转化为更容易理解和解释的低维形式，同时保留主要的数据结构。常见的方法包括主成分分析（Principal Component Analysis，PCA）和对应分析（Correspondence Analysis，CA）等，一般群落beta多样性分析都会用到这些方法。\n排序方法根据有无解释变量可分为两种：限制性排序和非限制性排序。\n限制性排序（Constrained Ordination）： 这种排序方法在降维的过程中考虑了响应变量（通常是生态系统的响应，如物种组成）和解释变量（通常是环境因素）。比如冗余分析（RDA，Redundancy Analysis）就是一种限制性排序方法。\n非限制性排序（Unconstrained Ordination）： 这种排序方法仅仅考虑响应变量，而不考虑解释变量。比如主成分分析（PCA）是一种典型的非限制性排序方法，因为它仅关注如何最大程度地解释数据的总方差。\n当涉及到排序方法时，确实有很多不同的技术，每种都有其独特的优点和应用场景。以下简要介绍常用一些方法（具体的原理和流程网上可以搜到非常多）：\n常用非限制性排序 PCA (Principal Component Analysis) 主成分分析： 通过寻找数据中的主要方差方向，将高维数据转换为低维数据。主成分是原始变量的线性组合。\n主成分分析（Principal Component Analysis, PCA）是一种常用的降维技术，用于分析数据集中的主要变化方向。其基本原理是通过线性变换将原始数据投影到一组新的坐标轴上，使得数据在这些新坐标轴上的方差最大。这些新的坐标轴被称为主成分。\n以下是主成分分析的基本流程：\n数据标准化： 如果原始数据的不同变量有不同的度量单位或变异范围，首先需要对数据进行标准化，以消除这些差异。通常，数据会被减去均值并除以标准差。\n协方差矩阵计算： 对标准化后的数据计算协方差矩阵。协方差矩阵描述了不同变量之间的线性关系。\n特征值分解： 对协方差矩阵进行特征值分解。特征值分解产生了一组特征值和相应的特征向量。特征值表示方差的大小，而特征向量表示对应于这些方差的方向。\n选择主成分： 特征值表示主成分的重要性，通常按照特征值的大小排序。选择最大的k个特征值及其对应的特征向量，其中k是希望保留的主成分的数量。\n构建投影矩阵： 将选定的特征向量构成一个投影矩阵。将原始数据乘以这个投影矩阵，即可将数据投影到新的主成分空间中。\n主成分得分： 计算每个样本在新的主成分空间中的坐标，这些坐标被称为主成分得分。\nPCoA (Principal Coordinates Analysis) 主坐标分析： 与PCA类似，但在距离矩阵的特征分解中使用，主坐标分析（Principal Coordinate Analysis, PCoA），也称为轴比例分析（Metric Multidimensional Scaling, MDS），是一种用于分析样本之间相似性或距离的多变量统计技术。与主成分分析（PCA）类似，PCoA旨在减少数据的维度，但它更专注于样本之间的距离或相似性而不是变量之间的协方差。\n以下是主坐标分析的基本流程：\n距离矩阵计算： 首先，计算样本之间的距离矩阵。这个距离可以是欧氏距离、曼哈顿距离、相关系数等，具体根据数据类型和研究问题而定，可支持的距离算法还有很多,参见?vegan::vegdist(): “manhattan”, “euclidean”, “canberra”, “clark”, “bray”, “kulczynski”, “jaccard”, “gower”, “altGower”, “morisita”, “horn”, “mountford”, “raup”, “binomial”, “chao”, “cao”, “mahalanobis”, “chisq”, “chord”, “hellinger”, “aitchison”等。。\n中心化矩阵： 对距离矩阵进行中心化处理，将每个元素减去对应行和列的均值。\n特征值分解： 对中心化的距离矩阵进行特征值分解。这产生了一组特征值和相应的特征向量。\n选择主坐标： 选择前k个特征值及其对应的特征向量，其中k是希望保留的坐标的数量。\n构建坐标矩阵： 将选定的特征向量构成一个坐标矩阵。每个样本在这些坐标上的投影就构成了主坐标。\n主坐标分析图： 将样本在主坐标上的投影绘制成图表，这就是主坐标分析图。这个图表展示了样本之间的相对位置，反映了它们在多维空间中的相似性或差异。\n主坐标分析通常用于分析生态学数据或其他具有样本相似性结构的数据。通过降低维度，它使得研究者更容易理解和可视化样本之间的关系。\nCA (Correspondence Analysis) 对应分析： 用于分析两个或多个分类变量之间的关系，通常用于探索物种和环境因子之间的关联。\n对应分析（Correspondence Analysis，简称CA）是一种用于分析两个分类变量之间关系的多元统计技术。它可以用于研究分类表格（Contingency Tables），特别是在生态学、社会学、市场调查等领域。\n以下是对应分析的基本流程原理：\n建立列联表： 首先，构建一个列联表，其中包含两个或更多的分类变量的频数或百分比。\n计算期望频数： 对于每个单元格，计算在独立性假设下的期望频数。独立性假设是指假设两个变量之间没有关联。\n计算标准化残差： 对每个单元格的实际频数和期望频数进行比较，计算标准化残差。残差表示实际观察到的频数与期望频数之间的差异，标准化残差则考虑了这种差异相对于整体表格的变异性。\n奇异值分解： 对标准化残差矩阵进行奇异值分解。奇异值分解是一种矩阵分解方法，将一个矩阵分解成三个矩阵的乘积。\n选择主维度： 根据奇异值的大小选择主维度。这些主维度是原始变量的线性组合，通常是用于解释数据中大部分变异的维度。\n计算坐标： 计算每个变量和每个水平与垂直刻度上的坐标，这些坐标用于可视化数据。\n绘制对应图： 使用计算得到的坐标信息，绘制对应图。对应图有助于理解变量之间的关系以及在数据中的结构。\n总的来说，对应分析通过将多维数据映射到低维空间，提供了一个直观的方式来可视化和解释分类数据中的关联关系。\nDCA (Detrended Correspondence Analysis) 去趋势对应分析： CA的一种变体，DCA的目标是消除或减少由于群落数据中的趋势而导致的主坐标轴的拉伸。\n以下是去趋势对应分析的基本流程原理：\n数据标准化： 首先，对群落数据进行标准化，以确保各种生境的贡献相等。这通常包括对物种丰富度进行对数或平方根转换。\n进行初始对应分析： 对标准化后的数据进行初始对应分析，计算初始的主坐标轴。\n去除趋势： 通过拟合一条曲线（通常是第二主坐标轴）来去除数据中的趋势。这可以通过回归分析等方法来完成。\n重新计算坐标： 在去除趋势后，重新计算主坐标轴。\n绘制DCA图： 使用去趋势后的坐标信息，绘制DCA图。DCA图通常是一个双轴图，显示了样点或物种在主坐标轴上的分布。\n解释结果： 根据DCA图的形状和方向，解释物种和样点之间的关系。这有助于理解群落数据的结构，而不受主坐标轴的人为拉伸的影响。\nDCA的优势在于它可以更好地处理生态学数据中常见的非线性趋势。通过去除趋势，DCA提供了更为真实和可解释的关于生态群落结构的信息。\nNMDS (Non-Metric Multidimensional Scaling) 非度量多维缩放： 通过样本间的距离矩阵来构建降维空间，以保持样本之间的相对距离。同样可使用各种距离算法。\n以下是非度量多维缩放的基本流程原理：\n计算相异性矩阵： 首先，根据数据集中的样本或物种的相异性（比如，物种组成的差异）计算相异性矩阵。这可以使用各种相异性或距离指标，如Bray-Curtis距离、Jaccard相异性等。\n初始化配置： 随机或基于一些启发式算法初始化样本或物种在多维空间中的位置。\n迭代寻找最佳位置： 通过迭代，调整样本或物种在多维空间中的位置，使得它们在相异性空间中的相对位置更好地匹配相异性矩阵。这通常通过最小化实际相异性矩阵和在多维空间中的拟合相异性矩阵之间的差异来实现。\n停止准则： 根据一些停止准则，比如迭代次数、梯度大小等，确定算法何时停止。\n输出结果： 最终的结果是样本或物种在低维空间中的坐标。\n绘制NMDS图： 使用NMDS生成的坐标，可以绘制NMDS图，展示样本或物种在低维空间中的位置。\nNMDS的优势在于它能够在保留样本或物种间的相异性的同时，将高维数据映射到低维空间。这有助于可视化数据中的结构，并且对于那些不能满足线性假设的数据而言是一种有用的技术。\nt-SNE (t-distributed Stochastic Neighbor Embedding) t-分布随机邻域嵌入： 主要用于保留样本之间的局部相似性，常用于高维数据的可视化。\n以下是t-SNE的基本流程原理：\n相似性矩阵： 对于给定的高维数据集，首先计算样本之间的相似性，通常使用高斯分布来表示样本之间的相似性。这会生成一个相似性矩阵。\n学习相似性： 在低维空间中，使用t-分布来表示样本之间的相似性。t-SNE尝试保持样本对之间的相似性，使得在高维空间中相似的样本在低维空间中仍然保持相似。\n梯度下降： 使用梯度下降等优化算法，尝试最小化高维空间中的相似性矩阵与低维空间中的相似性分布之间的差异。这个过程会调整低维空间中的样本位置，以更好地反映它们在高维空间中的相似性。\n调整参数： t-SNE有一些参数，比如困惑度（perplexity），用于调整算法的行为。困惑度控制了在生成高维空间中的相似性分布时每个样本可以考虑多少个邻近样本。\n迭代： t-SNE是一个迭代过程，通过多次迭代来优化低维表示，直到满足停止准则。\n输出结果： 最终的结果是样本在低维空间中的坐标。\nt-SNE广泛用于数据可视化，尤其是在深度学习中，以及在发现高维数据的结构和簇时。然而，对于大型数据集，计算成本可能较高。\nUMAP (Uniform Manifold Approximation and Projection) 统一流形逼近和投影： 与t-SNE类似，用于高维数据的降维和可视化，但在某些情况下可能比t-SNE更快、更保持全局结构。\n统一流形逼近和投影是一种用于学习高维数据的低维表示的方法。这一方法旨在找到一个低维流形，可以保持数据的局部结构。以下是它的基本原理：\n数据表示： 假设我们有一个高维数据集，可以用$X \\in \\mathbb{R}^{n \\times m}$ 表示，其中$n$ 是样本数，$m$ 是特征数。\n流形假设： 统一流形假设认为高维数据集$X$ 实际上是嵌入在一个低维流形中的，该流形在高维空间中扭曲和弯曲。\n局部保持： 统一流形逼近和投影的目标是找到一个低维表示$Y \\in \\mathbb{R}^{n \\times k}$，其中$k$ 是目标低维度，以便在这个低维表示中，原始数据的局部结构得以保持。\n数学形式： 通常，这可以通过最小化两个项的和来实现：\n重构误差项： 衡量在低维空间中的表示$Y$ 如何能够准确地重构原始数据$X$。 流形保持项： 衡量$Y$ 中的点是如何在原始数据空间中保持局部结构的。 优化问题： 统一流形逼近和投影可以被建模为一个优化问题，通过调整$Y$ 来最小化重构误差和流形保持项。\n这种方法的目标是在低维空间中找到一个紧凑的表示，以便原始数据集的结构得以保持。在实际应用中，这对于高维数据的可视化和特征学习非常有用。常见的统一流形逼近和投影的方法包括 t-SNE（t-Distributed Stochastic Neighbor Embedding）和UMAP（Uniform Manifold Approximation and Projection）。\n分组变量排序 LDA (Linear Discriminant Analysis) 线性判别分析： 用于降低数据维度，同时最大化不同类别之间的差异，通常用于分类问题。 其基本思想是将数据投影到一个低维空间中，以便在这个低维空间中更容易区分不同类别的数据点。\n下面是LDA的基本流程和原理：\n计算类内散度矩阵和类间散度矩阵： 对于给定的数据集，首先计算每个类别内部的散度矩阵（表示类别内部数据点的分散程度）和整个数据集的类间散度矩阵（表示不同类别之间数据点的分散程度）。\n计算特征向量和特征值： 对于矩阵的逆矩阵乘以类内散度矩阵，然后计算这个结果的特征向量和特征值。通常，选择最大的特征值对应的特征向量。\n选择投影方向： 将特征向量按照对应的特征值大小排序，选择前k个特征向量构成投影矩阵，其中k是新的特征空间的维度。\n投影： 将原始数据集乘以投影矩阵，得到新的、低维的数据集。\nLDA的目标是通过最大化类间散度和最小化类内散度，从而在降维的同时保留类别信息。由于其考虑了类别信息，因此LDA通常在分类问题中效果很好。\n总体而言，LDA是一种监督学习的降维技术，与PCA（主成分分析）等无监督学习的降维方法有所不同。PCA关注的是数据整体的方差，而LDA关注的是不同类别之间的差异。\nPLSDA (Partial Least Squares Discriminant Analysis) 偏最小二乘判别分析： 用于处理分类问题，特别是在多变量数据中，它将变量分解为与响应变量相关的成分。\n偏最小二乘判别分析（Partial Least Squares Discriminant Analysis, PLS-DA）是一种用于处理多变量数据、进行降维和分类的方法，特别适用于高度相关的解释变量和存在分类问题的情境。\n以下是PLS-DA的基本流程和原理：\n选择类别： 确定数据集中的类别信息。\n数据标准化： 对输入数据进行标准化，以确保不同变量的尺度相同。\n初始化： 初始化权重和载荷，这些是通过对类别信息建模而优化的参数。\n交替优化： 通过交替地最小化预测误差来优化权重和载荷。\n计算成分： 基于最优权重和载荷，计算新的成分。这些成分是原始变量的线性组合，被用于构建新的特征。\n重复步骤： 重复上述步骤，直到达到预定的成分数量或满足某个停止准则。\n分类： 使用获得的成分进行分类。在PLS-DA中，通常采用阈值将样本分配给不同的类别。\nPLS-DA与普通的PLS回归方法相似，但其主要目标是区分类别而不是建立回归模型。在数据有潜在结构、且类别信息存在的情况下，PLS-DA通常比传统的判别分析方法表现更好。\n常用限制性排序 限制性排序方法在生态学和其他领域中经常用于研究响应变量和解释变量之间的关系。\nRDA (Redundancy Analysis) 冗余分析： 简介： RDA 是一种用于解释响应变量的多变量技术，通过最大化解释响应变量的方差来找到解释变量中的线性组合。 应用： 通常用于生态学中研究物种丰富度、组成或其他响应变量与环境因子之间的关系。 以下是冗余分析的基本流程和原理：\n数据收集： 收集包括响应变量（依赖变量）和预测变量（自变量）的多变量数据。\n数据标准化： 对数据进行标准化，以确保不同变量的尺度相同。\n构建模型： RDA基于线性模型，试图找到一个线性关系，最大程度地解释响应变量的方差。\n分解方差： 将响应变量的方差分解为与预测变量直接相关的部分和不相关的部分。冗余分析的关键是找到与预测变量相关的冗余分量。\n排序和解释： 对于冗余分量，可以进行排序以了解哪些预测变量对解释响应变量的变异最为重要。\n检验显著性： 使用统计检验来确定模型的显著性。这包括检验模型整体的显著性以及每个预测变量对模型的个别贡献。\n冗余分析的主要优势在于它可以处理多个响应变量和多个预测变量，同时考虑它们之间的相关性。这使得它在解释生态系统中多变量关系方面非常有用。\ndb-RDA (distance-based Redundancy Analysis) 基于距离冗余分析： 简介： db-RDA 是一种基于距离矩阵的 RDA 方法，适用于非线性和非对称关系。 应用： 适用于样本间的非线性相似性关系，比如在物种组成数据中。 基于距离的冗余分析（Distance-based Redundancy Analysis, dbRDA）是冗余分析（RDA）的一种扩展形式，主要应用于处理非欧几里得的生态数据。在传统的RDA中，数据通常被假设为多元正态分布，但这在处理生态学数据时可能不合适，特别是在存在非对称性、离群值或多重共线性等情况下。\n以下是基于距离的冗余分析的基本流程和原理：\n距离矩阵的计算： 首先，需要计算响应变量和预测变量之间的距离矩阵，以代替传统RDA中使用的协方差矩阵。这通常涉及到计算 Bray-Curtis 距离、Euclidean 距离或其他适用于非欧几里得空间的距离。\n模型构建： 类似于传统的RDA，基于距离的冗余分析也是通过构建一个线性模型来描述响应变量和预测变量之间的关系。这个模型的目标是最大化解释响应变量的方差。\n模型解释： 解释模型的冗余分量，理解每个预测变量对响应变量的贡献。这涉及到排序和解释冗余分量的过程。\n检验显著性： 对模型整体和每个预测变量的显著性进行统计检验。\n基于距离的冗余分析的优势在于它能够处理生态学数据的非正态性和异方差性，同时不需要假设线性关系。这使得它更具灵活性，适用于更广泛的生态学和环境数据。\nCCA (Canonical Correspondence Analysis) 典型对应分析： 简介： CCA 是对应分析 (CA) 的扩展，以解释响应变量的变异性。 应用： 常用于研究生态学中物种丰富度和环境因子之间的关系。 典型对应分析（Canonical Correspondence Analysis, CCA）是一种用于分析两个表之间关系的多变量统计技术。它将两个数据表之间的行和列之间的关系通过最大化它们之间的典型相关性来建模。这个方法通常应用于生态学和环境科学，用于研究环境因素（如温度、湿度等）与物种分布之间的关系。\n以下是典型对应分析的基本流程和原理：\n数据准备： 收集两个表的数据，一个表包含环境变量（如温度、湿度等），另一个表包含生物群落数据（物种的存在与否、丰度等）。\n计算典型变量： 使用环境变量和生物群落数据来计算典型变量。这通常涉及到将数据进行标准化和转换。\n典型对应分析模型： 构建一个模型，通过最大化环境变量和生物群落数据之间的典型相关性。这个模型可视为一个对生态系统中生物群落和环境变量之间关系的描述。\n解释结果： 解释模型的典型相关系数，了解环境因子如何与生物群落结构相关。通常，通过查看典型变量的负载ings（loadings）来解释环境和生物群落之间的关系。\n显著性检验： 对模型整体和每个典型轴的显著性进行检验。\n典型对应分析的主要目标是帮助解释生态系统中环境因素和生物群落之间的关系。它通常用于揭示环境梯度如何影响生物多样性和生态系统结构。\n分析与绘图 vegan包是生态群落研究中最常用的包之一，里面包含了大部分的分析函数。\npctax包提供了快速完成各种排序分析及可视化（bi-plot，tri-plot）的函数：b_analyse用于常用非限制性排序和分组响应变量排序，myRDA, myCAP, myCCA用于常用限制性排序。\n1 2 3 4 5 6 #安装pctax包 if(!requireNamespace(\u0026#34;pctax\u0026#34;))remotes::install_github(\u0026#34;Asa12138/pctax\u0026#34;) library(pctax) #查看帮助 ?pctax::b_analyse b_analyse的参数也非常简单：\notutab: an otutab data.frame, samples are columns, taxs are rows. 这是我们要输入的高维响应变量数据。\nnorm: should normalized or not? (hellinger) 是否进行标准化，我们一般做物种丰度数据时会使用hellinger进行转化。\nmethod: one of “pca”, “pcoa”, “ca”, “dca”, “nmds”, “plsda”, “tsne”, “umap”, “lda”, “all”，选择以下方法的一种或几种，选”all”就全部跑完。\ngroup: if use lda or plsda, give a group vector，如果用分组响应变量排序，那就输入分组变量，注意和输入的otutab的列对应。\ndist: if use pcoa or nmds, your can choose a dist method (default: euclidean)，如果用的是基于距离的pcoa和nmds，那就可以选择距离计算方法。\n比如我们做一个PCA试试，产生的b_res包含4个内容：1是两个轴的解释度，2是每个样本的位置，2是每个变量的位置，4是每个变量的贡献度（不是所有方法都能计算贡献度）。\n1 2 data(otutab,package = \u0026#34;pcutils\u0026#34;) head(otutab) ## NS1 NS2 NS3 NS4 NS5 NS6 WS1 WS2 WS3 WS4 ## s__un_f__Thermomonosporaceae 1092 1920 810 1354 1064 1070 1252 1597 1330 941 ## s__Pelomonas_puraquae 1962 1234 2362 2236 2903 1829 644 495 1230 1284 ## s__Rhizobacter_bergeniae 588 458 889 901 1226 853 604 470 1070 1028 ## s__Flavobacterium_terrae 244 234 1810 673 1445 491 318 1926 1493 995 ## s__un_g__Rhizobacter 1432 412 533 759 1289 506 503 590 445 620 ## WS5 WS6 CS1 CS2 CS3 CS4 CS5 CS6 ## s__un_f__Thermomonosporaceae 1233 1011 2313 2518 1709 1975 1431 1527 ## s__Pelomonas_puraquae 953 635 1305 1516 844 1128 1483 1174 ## s__Rhizobacter_bergeniae 846 670 1029 1802 1002 1200 1194 762 ## s__Flavobacterium_terrae 577 359 1080 1218 754 423 1032 1412 ## s__un_g__Rhizobacter 657 429 1132 1447 550 583 1105 903 ## [ reached 'max' / getOption(\u0026quot;max.print\u0026quot;) -- omitted 1 rows ] 1 b_analyse(otutab,method = \u0026#34;pca\u0026#34;)-\u0026gt;b_res 要对结果进行可视化也非常简单，直接plot就行。这里给所有的样本映射了一个分组值，metadata是包含样本分组设计和各种环境因素的表格，“Group”是metadata的一列：\n1 plot(b_res,Group = \u0026#34;Group\u0026#34;,metadata = metadata) 对于这种分组的显著性（怎么说明三组的群落组成存在显著差异？），具体有adonis/mrpp/anosim/mantel等方法（可参考https://blog.csdn.net/qq_42830713/article/details/129073120）,一般用vegan包的adonis2函数（又叫PERMANOVA，Permutational Multivariate Analysis of Variance Using Distance Matrices）来检验。\npctax::permanova函数也整合了几种方法，可以获得对应的R方和p值，然后标在PCA图上。注意这几种方法都是基于距离的，建议检验方法和降维方法使用的距离保持一致\n1 pctax::permanova(otutab,metadata[\u0026#34;Group\u0026#34;],method = \u0026#34;adonis\u0026#34;) ## group r2 p_value sig ## 1 Group 0.1843 0.001 TRUE 1 pctax::permanova(otutab,metadata[\u0026#34;Group\u0026#34;],method = \u0026#34;mrpp\u0026#34;) ## group r p_value sig ## 1 Group 0.0382 0.001 TRUE 1 pctax::permanova(otutab,metadata[\u0026#34;Group\u0026#34;],method = \u0026#34;anosim\u0026#34;) ## group r p_value sig ## 1 Group 0.3984 0.001 TRUE 1 2 adonis_res=pctax::permanova(otutab,metadata[\u0026#34;Group\u0026#34;],method = \u0026#34;adonis\u0026#34;) plot(b_res,Group = \u0026#34;Group\u0026#34;,metadata = metadata,permanova_res = adonis_res) 也可以将连续变量映射到颜色上：\n1 plot(b_res,Group = \u0026#34;env1\u0026#34;,metadata = metadata) 绘图有很多可以灵活调节的参数：\n?pctax:::plot.b_res\nmode 是绘图风格，1～3都是我常用的：\n1 2 plot(b_res,Group = \u0026#34;Group\u0026#34;,metadata = metadata,mode = 2) plot(b_res,Group = \u0026#34;Group\u0026#34;,metadata = metadata,mode = 3) 把bi设为true的话，会画出一部分贡献度最高的变量：\n1 2 plot(b_res,Group = \u0026#34;Group\u0026#34;,metadata = metadata,bi = T,Topn = 10, permanova_res = adonis_res,text_param = list(x=-0.3,y=-0.4)) margin 可以画出点的分布密度图或箱形图:\n1 plot(b_res,Group = \u0026#34;Group\u0026#34;,metadata = metadata,margin = T,mode = 3) 1 plot.b_res(b_res,Group = \u0026#34;Group\u0026#34;,metadata = metadata,margin = T,box_margin = F) 限制性排序则需要输入响应变量数据和我们要研究的环境数据：\n以RDA分析为例：\n1 2 3 4 data(otutab,package = \u0026#34;pcutils\u0026#34;) env=metadata[,6:10] #RDA myRDA(otutab,env)-\u0026gt;phy.rda ## ==================================Check models================================== ## DCA analysis, select the sorting analysis model according to the first value of the Axis lengths row. ## - If it is more than 4.0 - CCA (based on unimodal model, canonical correspondence analysis); ## - If it is between 3.0-4.0 - both RDA/CCA; ## - If it is less than 3.0 - RDA (based on linear model, redundancy analysis) ## ## Call: ## vegan::decorana(veg = dat.h) ## ## Detrended correspondence analysis with 26 segments. ## Rescaling of axes with 4 iterations. ## Total inertia (scaled Chi-square): 0.3192 ## ## DCA1 DCA2 DCA3 DCA4 ## Eigenvalues 0.03142 0.02276 0.01927 0.017818 ## Additive Eigenvalues 0.03142 0.02276 0.01927 0.017881 ## Decorana values 0.03169 0.02142 0.01511 0.009314 ## Axis lengths 0.73929 0.72605 0.52357 0.666913 ## ## =================================Initial Model================================== ## Initial cca, vif\u0026gt;20 indicates serious collinearity: ## env4 env5 env6 lat long ## 2.574997 2.674671 1.252002 1.381839 1.211392 ## Initial Model R-square: 0.04828743 ## ===================================Statistics=================================== ## 0.3282029 constrained indicates the degree to which environmental factors explain differences in community structure ## 0.6717971 unconstrained means that the environmental factors cannot explain the part of the community structure 1 RDA_plot(phy.rda,\u0026#34;Group\u0026#34;,metadata) 对于这里每一个环境因素的检验，我们仍然可以使用adonis，或者envfit，bioenv等检验方式：\n1 2 adonis_res=pctax::permanova(otutab,env,method = \u0026#34;adonis\u0026#34;) plot(adonis_res) 1 2 envfit_res=pctax::envfitt(phy.rda,env) plot(envfit_res,mode=1) 限制性排序比较复杂，如果输入的环境因素较多具有共线性，还应该对得到的结果使用ordistep进行forward，backward，both等方式的筛选，得到最合适的模型。\n","date":"2023-11-17T00:00:00Z","image":"/p/ordination-analysis/index.en_files/figure-html/unnamed-chunk-9-1_hu_af977ac6e397fb02.png","permalink":"/p/ordination-analysis/","title":"降维/排序分析（ordination analysis）"},{"content":"Introduction 土壤是地球上最重要的生态系统之一，其中包含着丰富的微生物群落。土壤微生物群落是土壤生态系统中的重要组成部分，对土壤的生物地球化学循环和生态系统功能具有重要影响。土壤微生物群落与土壤性质之间存在着复杂的相互作用，这些相互作用对土壤生态系统的稳定性和功能产生了重要影响。\nThe interplay between microbial communities and soil properties L. Philippot, C. Chenu, A. Kappler, M. C. Rillig, N. Fierer, The interplay between microbial communities and soil properties. Nat Rev Microbiol, 1–14 (2023). 本文综述了土壤微生物组与土壤性质之间的相互作用，以及这些相互作用对土壤生态系统的影响。强调土壤微生物对土壤性质的影响的重要性。\n土壤微生物与土壤性质的关系 土壤微生物如何影响土壤pH\n土壤微生物通过不同的生物化学和生物物理机制对土壤酸碱度产生影响。首先是碳循环过程中，微生物呼吸所产生的二氧化碳会溶解成碳酸，释放出质子，导致土壤酸化。光合自养细菌（如蓝藻等）则通过二氧化碳固定活动使其生活环境碱化。此外，细菌和真菌也可以产生和分泌有机酸（如草酸或柠檬酸），这些有机酸的分泌可以导致土壤酸化。另一方面，有些细菌的草酸代谢与土壤pH的升高有关，可以使土壤的pH增加2.5个单位。\n其次是在氮循环过程中，细菌和古细菌氧化铵生成硝酸盐的过程产生了质子，是一个已知的降低土壤酸碱度的过程。\n此外，微生物还通过改变土壤中二氧化碳和碳酸盐浓度，以及土壤pH来诱导碳酸盐矿物的沉淀，从而影响土壤酸碱度。\n综上所述，土壤微生物通过上述生物化学过程和生物物理机制直接或间接地影响土壤的酸碱度。\n土壤微生物如何与矿物质相互作用\n土壤微生物与矿物质之间存在多种相互作用。在土壤中，微生物通过生化和生物物理机制积极地改变土壤环境，并影响矿物质的性质。\n例如，微生物可以通过酸化作用加速矿物质的溶解，促进矿物质的风化作用。微生物还可以通过生物结核的形成，将根际环境中的氧气与铁离子反应，形成含铁氧化物的结核，从而改变土壤的结构。此外，微生物还可以通过氧化草酸和草酸盐矿物为能源和碳源，促进土壤碱化和碳酸盐沉淀。这些微生物介导的修改作用对微生物群落的组装和土壤生态系统产生了影响。\n总的来说，土壤微生物与矿物质之间的相互作用非常复杂，这些相互作用对土壤性质和生态系统的影响具有重要意义.\n土壤微生物与土壤金属的关系\n土壤微生物通过生物化学和生物物理机制，不仅参与营养循环和有机物转化，还能主动改变土壤环境，从而影响土壤金属的存在形式和可利用性。例如，微生物可以通过酸化土壤环境增加金属的溶解度，或者合成并排出金属络合剂来增加金属的生物利用度。另外，微生物还可以通过微生物诱导的碳酸盐沉淀过程改变土壤结构，影响土壤金属的存在状态和迁移行为。此外，一些微生物还能够通过加快岩石和矿物的风化过程，释放金属元素到土壤中。\n土壤微生物与土壤结构的关系\n土壤结构是指土壤颗粒的三维排列和对应的孔隙空间，而微生物能够通过生化和生物物理机制来主动改变土壤环境。它们不仅参与养分循环和有机物转化，还能通过影响土壤颗粒的空间排列、通过细胞和代谢产物稳定土壤结构来改变土壤环境。这些微生物介导的改变会对微生物群落的组装产生局部影响，并导致生态后果的出现。\n土壤微生物与土壤水份的关系\n微生物可以通过多种机制改变土壤水力学特性，包括分泌能够直接改变土壤水动力学的化合物，例如增加土壤的水保持能力和减少水的渗透性。此外，微生物还可以改变土壤中的水分分布和运动，促进水分在土壤中的传输。具体来说，真菌和菌根真菌在某些条件下能够增加根部对水分的吸收，通过菌丝帮助水分在植物之间的传输，并改变土壤剖面中的水分分布。这些对土壤水分的影响可以在一定程度上减轻干旱对植物生产力的影响。需要注意的是，非菌根微生物对土壤水分在土壤中的运输的贡献尚未得到充分研究，还需要进一步的研究来了解它们在此过程中的作用。\n土壤微生物的生态后果 微生物介导的土壤性质改变产生生态反馈\n微生物通过介导土壤性质的改变，对生态系统产生生态反馈的方式有多种。首先，微生物可以通过改变土壤中的有机物和营养物质的可利用性，影响其他生物的生存和繁殖。例如，一些微生物可以分解有机物质，释放出营养物质，从而促进植物生长。其次，微生物通过氧化还原作用，可以改变土壤的化学性质，例如通过氧化反应将有机物质氧化为二氧化碳和水，从而改变土壤的酸碱性和氧含量。最后，微生物通过分解岩石和矿物，进行微生物风化作用，可以改变土壤中的矿物组成和结构，从而改变土壤的物理性质。这些微生物介导的土壤性质的改变可以对其他生物产生直接或间接的选择压力，并导致生态系统中不同生物种群的演化响应。因此，微生物的介导作用在生态学和进化生物学研究中具有重要意义。\n间接正反馈回路和负反馈回路\n在土壤中生活的生物形成了多样且复杂的群落，存在着多种互动作用。因此，一些群落成员通过壮大或改变当地环境条件来改变其他生物的适应性。微生物的生态位构建也可以转化为与受影响的物种竞争或合作的适应性变化。\n已有研究报道了由于微生物介导的环境条件转变而导致的微生物互作变化引起的间接反馈回路在土壤聚集体中的存在。例如，当氧气扩散受限时，聚集体内由于微生物呼吸引起的从氧化到缺氧条件的转变，会给能够利用氧化态氮作为替代电子受体的细菌提供竞争优势，并导致脱氮活性增加。同样，研究人员已经表明通过操纵氧气浓度以及减少一株假单胞菌菌株改变其修改氧气环境的能力可以改变适应性辐射动力学，从而为微生物通过生态位构建进化提供了实验证据。\n由于真菌通常被认为对于干旱不那么敏感，因此真菌产生的减少土壤水分渗透的疏水化合物可能使其相对于细菌具有优势。许多土壤微生物通过产生铁载体来影响金属生物可用性，这些铁载体是一种能够螯合固相三价铁的复杂有机分子，从而使铁溶解并通过铁载体受体吸收。因此，通过铁载体产生的土壤铁的隔离通过使铁对竞争者不可用来提供适应性优势。相反，一些铁载体-铁络合物可以被“作弊者”侧生物吸收，这些作弊者通过寻找并利用他人产生的铁载体而不产生自己的铁载体，因此能够胜过非独占铁载体产生者。\n改变土地利用和气候 土地管理实践对于微生物介导的土壤性质变化的重要性\n土地管理实践的影响是通过微生物群落的改变间接地影响土壤性质的，现有研究方法仍难以从变化的土壤生物群落中区分变化的土壤性质。例如，耕作和翻耕等土地管理实践会对土壤中的真菌纤维网络和细菌外多糖的产生产生不利影响，从而导致土壤团聚稳定性降低。因此，了解微生物对土壤性质的影响对于土地管理和处理全球性土地问题至关重要。整体而言，土地管理实践对微生物介导的土壤性质变化具有重要性，对保护和恢复土壤健康以及应对其他环境挑战都具有潜在应用价值。\n利用微生物群落应对土壤威胁和全球变化\n文章还提到了利用微生物群落来应对土壤威胁和全球变化的多种方法。例如，通过微生物诱导钙化作用可以减少有机质和富含营养的表层土壤层因侵蚀而流失。此外，微生物也可以降解污染物，如农药和重金属，或通过细菌的解和碳酸盐共沉淀来清除土壤污染物。微生物还参与养分循环，并可以通过微生物侵蚀来提高土壤肥力。然而，利用微生物群落来处理土壤威胁和全球变化仍面临一些挑战，如大规模生产和应用微生物接种剂，以及对土壤本土微生物群落可能产生的意外后果的担忧。\n综上所述，了解微生物对土壤性质的影响以及如何利用微生物群落来应对土壤威胁和全球变化的方式具有重要意义。目前，微生物接种和操纵土壤微生物群落是一个新兴的研究领域，需要更深入的研究来揭示微生物对土壤性质的调节机制，并开发出更有效的方法来保护和恢复土壤。\n总结 总的来说，该综述强调了土壤微生物和土壤性质之间的相互作用的复杂性，以及这些相互作用的生态学意义。未来的研究应该集合土壤科学、生态学、生物地球化学、进化学和微生物学等多学科，通过综合研究来推进该领域的发展。此外，需要更多的实验研究来直接操纵微生物群落，以进一步了解微生物介导的土壤性质变化的功能作用。通过利用微生物的应用对土壤进行定向改造是一项新兴的研究领域，需要更深入地理解微生物介导的土壤性质变化如何应对土壤健康和其他环境挑战。\n","date":"2023-11-15T00:00:00Z","image":"/p/soil-microbiome/images/soil2_hu_430e9860f9332f58.png","permalink":"/p/soil-microbiome/","title":"土壤微生物组综述（soil microbiome）"},{"content":"十年巨人落下帷幕，谨以此文记录，感谢陪伴\nIntroduction 《进击的巨人》（進撃の巨人，Attack on Titan）是一部由日本漫画家谏山创（Hajime Isayama）创作的漫画作品。 这部漫画首次于2009年开始在讲谈社的漫画杂志《别册少年Magazine》上连载，一直持续到2021年4月9日，共计139话。 《进击的巨人》因其引人入胜的故事情节、复杂的人物关系、哲学性质的探讨以及不断的悬念而备受欢迎。 它不仅仅是一部充满冒险与战斗的漫画，还包括了一些关于社会政治、人性和自由意志的深刻主题。\n这部漫画也被改编成了电视动画、小说、电子游戏等多种媒体形式，并在全球范围内积累了广泛的粉丝基础。 它的完结也引发了广泛的讨论和反响，成为了漫画界的经典之一。\n动画是这部作品我最先接触到的形式，这也是给我留下最深印象的，我最爱的一部动画。 《进击的巨人》自2013年首播以来，一直备受全球观众喜爱，被认为是现代动画界的杰出作品之一。前三季由WIT Studio （霸权社）制作，荒木哲郎（Tetsuro Araki）执导，受到了广泛的赞誉。粗线条的画风，精彩的战斗和紧张的情节，还有今井有文等作画监督创作出了非常多经典的场面，历历在目。最终季由MAPPA制作，林祐一郎执导，动画风格对应着剧情一起发生了巨大转变，也给巨人画上了一个完美的句号，令人直呼，MAPPA太懂巨人了。\n《进击的巨人》动画的音乐也备受称赞，为这部动画的氛围和情感增色了许多。其主题音乐主要是由音乐家澤野弘之（Hiroyuki Sawano）创作的。澤野弘之以其壮丽和情感充沛的配乐闻名，为巨人创作的音乐成为了这部动画的标志之一，诞生了各种神曲。此外，巨人的每一首OP，ED风格多变，都令人印象深刻。Revo和他的音乐团队Linked Horizon在前三季的音乐方面发挥重要作用，如《紅蓮の弓矢》，《暁の鎮魂歌 》等；神聖かまってちゃん（Shinsei Kamattechan）创作了一些备受欢迎的主题曲，如《僕の戦争》，《夕暮れの鳥》；还有ヒグチアイ唱出的《悪魔の子》，《いってらっしゃい 》等让我们重新审视艾伦三笠的人生\u0026hellip;\n总之，感谢谏山创创作出如此精彩的故事，感谢动画工作室的爆棚厨力让我们拥有如此视听盛宴，感谢澤野弘之等所有音乐人送给我们的每一首神曲，感谢每一位声优的倾情演绎\u0026hellip;\n感谢巨人，再见。\nSTORIES Season 1 （2013.04.07-2013.09.29）: 1 二千年後の君へ （致两千年后的你） その日、人類は思い出した\n奴らに支配された恐怖を\n鳥籠の中に囚われていた, 屈辱を\n兵士が活躍するってことは、それこそ最悪の時だ\nオレ達が役立たずの「タダメシ食らい」だって、バカにされてる時のほうが、\nみんなは平和に暮らせるんだぞ\n行かないで\n2 その日 （那一天） エレン、お前が母さんを助けられなかったのは、お前に力がなかったからだ\nオレが, 巨人に立ち向かわなかったのは, オレに勇気がなかったからだ\nあいつら, この世から, 駆逐してやる,\nこの世から, 一匹残らず\n3 絶望の中で鈍く光る （绝望之中的暗淡光芒） んーん, それは、なにゆえ人が芋を食べるのかという話でしょうか？・・\nああ, 、チッ, 、半分どうぞ\nオレは、帰れなくなった故郷に帰る。オレの中にあるのはこれだけだ。\n絶対に, 何としてもだ。\n4 解散式の夜 （解散式之夜） 大丈夫ですよ, 土地を奪還すれば、また, 牛も羊も飼えますから\n5 初陣 （初战） 6 少女が見た世界 （少女看见的世界） エレン：やるよ、これ。あったかいだろ？\nミカサ：, あったかい\nエレン, あなたがいれば、私は何でもできる。\n7 小さな刃 （小刀） 私は, 強い, あなた達より強い, すごく強い！\nこの世界は, 残酷だ, そして, とても美しい。\n8 心臓の鼓動が聞える （听见心跳声） 9 左腕の行方 （左臂的下落） 10 応える （回应） 11 偶像 （偶像） 我々はこれより奥の壁で死んではならん！！どうかここで——ここで死んでくれ！！\n12 傷 （伤） 13 原初の欲求 （欲望的起点） オレ達はみんな　生まれた時から　自由だ。\nそれを拒む者が　どれだけ強くても, 関係無い。\n炎の水でも, 氷の大地でも, 何でもいい。\nそれを見た者はこの世界で一番の自由を手に入れた者だ。\n戦え！, そのためなら　命なんか惜しくない！\nどれだけ世界が恐ろしくても, 関係無い。\nどれだけ世界が残酷でも, 関係無い！\n戦え！戦え！！戦え！！！戦え！！！！\n人類が今日, 初めて, 巨人に勝ったよ,\n14 まだ目を見れない （依旧无法直视对方） しゃがんでるから丁度蹴りやすいしな。\n15 特別作戦班 （特别作战班） 君には何が見える？, 敵は何だと思う？\n16 今、何をすべきか （现在，该做什么） あ, ありがとう。アニってさ, 実はけっこう優しいよね。\nでは今！\nここにいる者を　新たな調査兵団として迎え入れる！\nこれが本物の敬礼だ！\n心臓を捧げよ！\n17 女型の巨人 （女巨人） 18 巨大樹の森 （巨树之森） 19 噛みつく （紧咬不放） お前は間違ってない, やりたきゃやれ。\n俺にはわかる。コイツは本物の化け物だ。「巨人の力」とは無関係にな。\nどんなに力で押さえようとも、どんな檻に閉じ込めようとも、\nコイツの意識を服従させることは, 誰にもできない。\n俺にはわからない, ずっとそうだ,\n自分の力を信じても, 信頼に足る仲間の選択を信じても, 結果は誰にもわからなかった,\nだから, まぁせいぜい, 悔いが残らない方を自分で選べ。\n20 エルヴィン・スミス （艾尔文·史密斯） 何も捨てることができない人には、何も変えることはできないだろう。\n21 鉄槌 （铁槌） 22 敗者達 （败者们） 23 微笑み （微笑） 24 慈悲 （慈悲） 25 壁 （壁） 今度は我々が進撃する番です。\n最后一幕吓我一跳，悬念满满，迫不及待想看第二季了。\nSeason 2 （2017.04.01-2017.06.17）： 26 獣の巨人 （兽之巨人） 人は　戦うことをやめた時　初めて敗北する。戦い続ける限りは　まだ負けてない。\n27 ただいま （我回来了） ねぇ、聞いて。\n大丈夫だから　この道を走って\nオ・・・アエリ\n28 南西へ （往西南） 29 兵士 （士兵） 30 ヒストリア （希斯特莉亚） お前は・・・元の名前を名乗って生きろ\nユミル・・・私の名前・・・ヒストリアって言うの\n31 戦士 （战士） 32 打・投・極 （打・投・极） 33 追う者 （追击者） あの何でもない日常を取り戻すためだったら・・・俺は何でもする\n34 開口 （开口） 35 子供達 （孩子们） 36 突撃 （突击） 進め！！\n37 叫び （怒吼） 人のために生きるのはやめよう。私達はこれから！私達のために生きようよ！ お前・・・何を・・・笑ってやがる\nSeason 3 Part 1 （2018.07.22-2018.10.14）： 38 狼煙 （狼烟） 大丈夫か・・・あいつ　絶対オレに似てねぇのに・・・馬面・・・なのに\n39 痛み （痛楚） ・・・順番だ\nこういう役には・・・多分　順番がある・・・\n役を降りても・・・誰かがすぐに代わりを演じ始める\nどうりでこの世からなくならねぇわけだ・・・\nがんばれよ・・・ハンジ・・・\n40 昔話 （往事） 41 信頼 （信赖） 42 回答 （回答） 43 罪 （罪孽） 44 願い （愿望） 巨人を駆逐するって！？誰がそんな面倒なことやるもんか！！\n45 オルブド区外壁 （欧尔布德区外墙） 46 壁の王 （城墙之王） 47 友人 （友人） 知りてぇ・・・一体どんな気分なんだ？そこから一体・・・どんな景色が見える？\nみんな何かに酔っ払ってねぇと　やってられなかったんだな・・・\nみんな・・・何かの奴隷だった・・・あいつでさえも・・・\n48 傍観者 （旁观者） 49 奪還作戦の夜 （夺还作战之夜） Season 3 Part 2 （2019.04.28-2019.06.30）： 50 はじまりの街 （初始之城） 51 雷槍 （雷枪） 52 光臨 （光临） 53 完全試合 （完全比赛） ・・・だが、リヴァイ。見えるか？俺達の仲間が・・・仲間達は俺らを見ている\n捧げた心臓がどうなったか　知りたいんだ・・・まだ戦いは終わってないからだ\n俺は選ぶぞ。夢を諦めて死んでくれ、新兵達を地獄に導け、「獣の巨人」は　俺が仕留める\nあの兵士達に意味を与えるのは我々だ！\nあの勇敢な死者を！哀れな死者を！\n想うことができるのは！生者である我々だ！！我々はここで死に、次の生者に意味を託す！\nそれこそ唯一・・・この残酷な世界に抗う術なのだ！！\n兵士よ怒れ！兵士よ叫べ！兵士よ戦え！！\n54 勇者 （勇者） さっきはずいぶんと楽しそうだったな・・・もっと楽しんでくれよ！\nオイ・・・どこに行く？止まれ\n待てよ・・・俺はあいつにに誓ったんだ・・・必ずお前を殺すと・・・誓った！！\n耐えろ・・・まだ離すな 55 白夜 （白夜） 先生・・・壁の外に人類がいないって・・・どうやって調べたんですか？\n56 地下室 （地下室） 57 あの日 （那一天） グリシャ・・・私は・・・どんな姿になっても・・・あなたを探し出すから\n58 进撃の巨人 （进击的巨人） その巨人は　いついかなる時代においても、自由を求めて　進み続けた。自由のために　戦った\n名は　進撃の巨人\n59 壁の向こう側 （墙的那头） The Final Season Part 1 （2020.12.06-2021.03.28）: 60 海の向こう側 （海的那头） 61 闇夜の列車 （暗夜列车） 62 希望の扉 （希望之门） 63 手から手へ （手手相传） 64 宣戦布告 （宣战公告） 65 戦鎚の巨人 （战锤巨人） 66 強襲 （强袭） 67 凶弾 （凶弹） 68 義勇兵 （义勇兵） 69 正論 （正论） 70 偽り者 （虚伪之人） 71 導く者 （引导者） 72 森の子ら （森林里的孩子们） 73 暴悪 （残暴） 74 唯一の救い （唯一的救赎） 75 天地 （天地） The Final Season Part 2 （2022.01.09-2022.04.03）: 76 断罪 （断罪） 77 騙し討ち （暗算） 78 兄と弟 （兄与弟） 79 未来の記憶 （未来的记忆） 80 二千年前の君から （致两千年前的你） 81 氷解 （冰释） 82 夕焼け （晚霞） 83 矜持 （尊严） 84 終末の夜 （结束之夜） 85 裏切り者 （背叛者） 86 懐古 （回首） 87 人類の夜明け （人类的黎明） 完结篇 \u0026mdash;\u0026mdash;前篇\u0026mdash;\u0026mdash; （2023.03.03） 第一章 地鳴らし （地鸣） 第二章 罪人達 （罪人们） 完结篇 \u0026mdash;\u0026mdash;后篇\u0026mdash;\u0026mdash; （2023.11.04） 第三章 天と地の戦い （天地之战） 第四章 長い夢 （长梦） 最终章 あの丘の木に向かって （向着山丘上的那棵树） OAD 0.5 悔いなき選択 （无悔的选择） 3.25 突然の来訪者 （突然的来访者） \u0026mdash;苛まれる青春の呪い\u0026mdash;\n\u0026mdash;挥之不去的青春魔咒\u0026mdash;\n3.5 イルゼの手帳 （伊尔泽的笔记） \u0026mdash;ある調査兵団員の手記\u0026mdash;\n\u0026mdash;某位调查兵团团员的笔记\u0026mdash;\n3.75 困難 （困难） 16.5 LOST GIRLS, Wall Sina,Goodbye （再见，希娜之墙） ??? LOST GIRLS, Lost in the cruel world （迷失在残酷世界之中） SETTINGS Roles 艾伦·耶格尔 (梶裕贵)\n三笠·阿克曼 (石川由依)\n阿明·阿诺德 (井上麻里奈)\n第104期训练兵团 基斯·夏迪斯\n莱纳·布朗 (细谷佳正,榎木淳弥)\n贝特霍尔德·胡佛\n阿尼·利昂纳德\n让·基尔希斯坦\n马可·博特\n康尼·斯普林格\n萨莎·布劳斯\n赫里斯塔·兰斯（希丝特莉亚·雷斯）\n尤弥尔\n托马斯·瓦格纳\n米娜·卡罗莱纳\n塞缪尔·林克-杰克森\n达兹\n法兰兹·凯夫卡\n汉娜·迪亚曼特\n奈克·提亚斯\n米利乌斯·塞姆斯基\n调查兵团 艾尔文·史密斯 (小野大辅)\n利威尔·阿克曼 (神谷浩史)\n韩吉·佐耶 (朴璐美) 米克·扎卡利亚斯\n埃尔德·琴\n佩特拉·拉鲁\n奥路欧·博查特\n衮达·舒尔茨\n莫塞斯·布朗\n迪塔·尼斯\n纳拿巴\n格鲁噶\n驻扎兵团 多托·匹西斯\n汉尼斯\n奇兹·威尔曼\n伊恩·迪特里希\n里柯·布列切安斯卡\n米塔比·亚尔那哈\n宪兵团 奈尔·德克\n丹尼斯·伊布林格\n马尔洛·弗洛丁贝格\n希琪·德利斯\n鲍里斯·富尔纳\n罗格\n中央宪兵 凯尼∙阿克曼\n特劳特·卡芬\n杰尔·萨内斯\n王政府、兵团高层 达里斯·扎卡里\n弗里茨王\n奥利耶\n尼克拉斯·罗伯夫\n雷斯家 罗德·雷斯\n弗丽达·雷斯\n乌利·雷斯\n耶格尔派 弗洛克·福斯特\n路易洁\n史尔玛\n墙内居民 格里沙·耶格尔\n卡尔菈·耶格尔\n三笠·阿克曼的父母\n阿明·阿诺德的祖父\n尼克神父\n迪墨·利布斯·爱德华\n弗雷盖尔·利布斯\n罗伊\n亚瑟·布劳斯\n丽莎·布劳斯\n卡亚\n卡亚的母亲\n康尼·斯普林格的母亲\n凯尼·阿克曼的祖父\n让·基尔希斯坦的母亲\n卡莉·施特拉特曼\n马莱战士 吉克·耶格尔 (子安武人,山下大辉)\n皮克·芬格尔\n马赛‧加里亚德\n波尔克·加里亚德\n汤姆·库沙瓦\n战士候补生 法尔克·格莱斯 (花江夏树)\n贾碧·布朗 (佐仓绫音)\n柯特·格莱斯\n索菲亚·莱契\n乌德·博克\n戴巴家族 威利·戴巴\n拉拉·戴巴\n马莱军队 卡尔维\n迪奥·马加特\n科斯洛\n古洛斯\n艾伦·克鲁格\n艾尔迪亚复权派 戴娜·弗里茨\n格莱斯\n反马莱义勇兵 伊雷娜\n欧良果彭\n尼柯洛\n葛立斯\n马莱居民 格里沙·耶格尔的父母\n菲·耶格尔\n卡丽娜·布朗\n阿尼·利昂纳德的父亲\n莱纳·布朗的父亲\n皮克·芬格尔的父亲\n贾碧·布朗的父母\n格莱斯兄弟的父母\n拉姆吉\n哈利尔\n拉姆吉的祖父\n艾尔迪亚王国 初代弗利茨王\n始祖尤弥尔\n其他国家 奇优宓·亚兹玛比特\n欧古威诺大使\n南碧雅\nTitans 九大巨人（九つの巨人）：九大巨人能力分割自始祖尤弥尔死后，它们包括\u0026quot;始祖巨人\u0026quot;、\u0026ldquo;进击的巨人\u0026rdquo;、\u0026ldquo;超大型巨人\u0026rdquo;、\u0026ldquo;铠之巨人\u0026rdquo;、\u0026ldquo;女巨人\u0026rdquo;、\u0026ldquo;兽之巨人\u0026rdquo;、\u0026ldquo;车力巨人\u0026rdquo;、\u0026ldquo;鄂之巨人\u0026quot;以及\u0026quot;战锤巨人\u0026rdquo;。只有尤弥尔的子民能够继承这些力量，但继承者的能力持续期限是13年。\n始祖巨人（始祖の巨人）：历代由弗里茨王和雷斯家传承的巨人，它拥有统治其他所有巨人的力量。它具有影响尤弥尔的子民的记忆和身体结构的能力，只有弗里茨王室的成员可以发挥这种力量。\n进击的巨人（進撃の巨人）：这是一位为自由而战的巨人，不论时代如何。它能够看到历代继承者的过去和未来记忆。\n超大型巨人（超大型巨人）：这个巨人高达60米，超过帕拉迪岛的三重墙高度。它的变身伴随爆炸风，可以造成广泛的破坏。尽管行动不够迅速，但它可以使用巨大的身体进行高破坏性的攻击。除此之外，它还能够燃烧肌肉释放高温风。\n铠之巨人（鎧の巨人）：这个巨人全身覆盖着坚硬如铠甲的皮肤，具有极高的耐久性。马莱通常扮演\u0026quot;盾牌\u0026quot;的角色。\n女巨人（女型の巨人）：这个巨人以女性形态示人，具有再现其他\u0026quot;九大巨人\u0026quot;特性的能力。\n兽之巨人（獣の巨人）：这个巨人全身覆盖着野兽般的体毛，能够再现各种动物特征。吉克成为继承者后，展现出灵长类特性，不仅可以使用长臂进行远距离投掷攻击，还可以通过\u0026quot;呐喊\u0026quot;使吞噬了吉克脊髓液的尤弥尔的子民变成纯洁巨人。\n车力巨人（車力の巨人）：这个四足巨人可以长时间执行任务，具有出色的持久力。它具备协作作战，包括使用重机枪等武器的能力。\n鄂之巨人（顎の巨人）：这个巨人具有强力下颚和爪子。尽管体型较小，但它有着卓越的机动性。强韧的下颚和爪子能够粉碎包括硬质物在内的一切。\n战锤巨人（戦鎚の巨人）：这个巨人是戴巴家族代代相传的巨人，拥有始祖巨人的最高权力。除了能够使用硬化的战锤和剑等武器，它还能再现弩等复杂武器。然而，由于其巨大的力量，持久性较差。\n终结的巨人（終尾の巨人）：这是艾伦最终形态，拥有始祖巨人的力量。其身体大部分由骨头构成，远比超大型巨人巨大。它领导成千上万的巨人走向大地。\n纯洁巨人（無垢の巨人）：尤弥尔的子民在巨人化后的形态，与\u0026quot;九大巨人\u0026quot;不同，它们是没有理智的巨人。它们能够执行简单的行为，如感知人类和吞食。少数离经叛道的个体被称为\u0026quot;奇行种\u0026quot;。吞食\u0026quot;九大巨人\u0026quot;能力者后，它们可以继承其能力并变回人类。\nALL MUSICS OP \u0026amp; ED Season 1 紅蓮の弓矢 - Linked Horizon\n美しき残酷な世界 - 日笠陽子\n自由の翼 - Linked Horizon\ngreat escape - cinema staff\nSeason 2 心臓を捧げよ! - Linked Horizon\n夕暮れの鳥 - 神聖かまってちゃん\nSeason 3 Part 1\nRed Swan - YOSHIKI/HYDE\n暁の鎮魂歌 - Linked Horizon\nPart 2\n憧憬と屍の道 - Linked Horizon\nName of Love - cinema staff\nThe Final Season Part 1\n僕の戦争 - 神聖かまってちゃん\n衝撃 - 安藤裕子\nPart 2\nThe Rumbling - SiM\n悪魔の子 - ヒグチアイ (HiguchiAi)\nOST Season 1 at\u0026rsquo;aek ON taitn - 澤野弘之 / 小林未郁 (变身神曲) The Reluctant Heroes - 澤野弘之 / mpi eye-water - 澤野弘之 立body機motion - 澤野弘之 counter・attack-m\u0026rsquo;aenkaind - 澤野弘之 army⇒G♂ - 澤野弘之 Vogel im Käfig - 澤野弘之 / Cyua DOA - 澤野弘之 / Aimee Blackschleger 凸】♀】♂】←巨人 - 澤野弘之 E・M・A - 澤野弘之 巨♀~9地区 - 澤野弘之 Bauklotze - 澤野弘之 / 小林未郁 2chi城 - 澤野弘之 XL-TT - 澤野弘之 Call your name - 澤野弘之 / mpi / CASG omake-pfadlib - 澤野弘之 Season 2 attack音D - 澤野弘之 2Volt - 澤野弘之 ERENthe標 - 澤野弘之 APETITAN - 澤野弘之 Call of Silence - 澤野弘之 son2seaVer - 澤野弘之 Vogel im Käfig - 澤野弘之 Barricades - 澤野弘之 So ist es immer - 澤野弘之 theDOGS - 澤野弘之 YouSeeBIGGIRL/T:T - 澤野弘之 YAMANAIAME - 澤野弘之 TWO-lives - 澤野弘之 The Weight of Lives - 澤野弘之 Season 3 Zero Eclipse - 澤野弘之 / Laco K2- - 澤野弘之 K21 - 澤野弘之 AoTs3-3spens/21石 - 澤野弘之 AoTs3-PF1 - 澤野弘之 T-KT - 澤野弘之 A1Gう - 澤野弘之 tooth-i: - 澤野弘之 LENぞ97n10火巨説MAHLE - 澤野弘之 Apple Seed - 澤野弘之 Before Lights Out - 澤野弘之 The Final Season Ashes on The Fire - 山本康太 The Other Side of the Sea Splinter Wolf Nightmare Guilty Hero The Successor Memory Lane Liberio at Night Liberio Festival True History The Warriors The Fall of Marley Zeek\u0026rsquo;s Plan Nowhere to go Atonement Cold Light The Reason Friendships Memory Lane Vln ver. Liberio at Night Pf\u0026amp;Vln ver. AOTF-s1 AOTF-s2 AOTF-s3 完结篇 UNDER THE TREE - SiM Splinter Wolf - 山本康太 まっさらな大地 - ヒグチアイ 最後の巨人 - Linked Horizon いってらっしゃい - ヒグチアイ 二千年\u0026hellip; 若しくは\u0026hellip; 二万年後の君へ, - Linked Horizon ","date":"2023-11-09T00:00:00Z","image":"/p/attack-on-titan/images/titan_hu_3e37eecd5d740fb3.jpg","permalink":"/p/attack-on-titan/","title":"Attack on Titan"},{"content":"Introduction Gene Set Enrichment Analysis (GSEA) 是一种用于分析基因表达数据的计算生物学方法，旨在揭示与特定生物学过程、通路或功能相关的基因表达模式。GSEA 最初由麻省理工学院的研究人员开发 (1)，它不同于传统的基因差异分析方法，如 t 检验或ANOVA，这些方法通常关注单个基因的表达差异。 相反，GSEA 专注于整个基因集的表达趋势，这些基因集通常与特定的生物学过程或通路相关联。\n在典型的实验中，从属于两类之一的样本集合中生成数千个基因的 mRNA 表达谱，例如，对药物敏感和耐药的肿瘤。 基因可以根据它们在类别之间的差异表达在排序列表L中排序。挑战在于从这个列表中提取含义。 一种常见的方法是关注 L 顶部和底部的少数基因（即那些表现出最大差异的基因），以辨别明显的生物学线索。这种方法有一些主要的局限性:\n在校正多个假设检验后，没有任何单个基因可以满足统计显著性的阈值，因为相对于微阵列技术固有的噪声，相关的生物学差异是适度（不是很明显）的。\n或者，人们可能会留下一长串具有统计学意义的基因（太多了），而没有任何统一的生物学主题。解释可能是令人畏惧的和临时的，取决于生物学家的专业领域。\n单基因分析可能会错过对通路的重要影响。细胞过程常常影响协同作用的基因组。编码代谢途径成员的所有基因增加 20% 可能会显着改变通过该途径的通量，并且可能比单个基因增加 20 倍更重要。\n当不同的群体研究相同的生物系统时，两项研究中具有统计学意义的基因列表可能显示出令人沮丧的很少的重叠（但是通路可能有重叠）。\n以下是 GSEA 的简要介绍和工作原理：\n基因集定义：首先，GSEA 需要一个事先定义好的基因集合，这些基因通常按照其在特定生物学通路、功能类别或疾病过程中的作用进行组织。这些基因集可以来自公共数据库，如Gene Ontology、KEGG Pathway、Reactome，或者是研究者自己根据文献和领域知识构建的。\n基因表达数据：GSEA 需要分析的基因表达数据，通常是从微阵列或RNA测序实验中获得的。这些数据包括不同条件或样本中基因的表达水平。\n排列(permutation)检验：GSEA 的核心思想是通过对基因集的成员在整个基因表达数据中的排列来确定它们的富集程度。具体来说，GSEA 将所有基因根据其在不同条件下的表达水平进行排序。然后，它从基因集的一端开始，计算该基因集中的基因在排序列表中的偏离程度。如果基因集中的基因在排序列表的某个位置中集中排列，说明该基因集富集在特定的生物学过程或通路中。这个过程通过构建一个富集分数（Enrichment Score）来量化。\n统计显著性：对于每个基因集，GSEA 计算一个富集分数，并基于随机排列检验来估计其统计显著性。如果一个基因集的富集分数在随机排列中的分布表现出显著差异，那么就认为这个基因集在样本中富集。\n结果可视化：最后，GSEA 会生成结果报告，其中包括富集分数、基因集的统计显著性以及相关通路或功能的信息。这些结果可视化为富集图谱，用于展示不同基因集的富集情况。\n图1 总之，GSEA 是一种用于揭示基因表达数据中生物学意义的强大工具，它可以帮助研究人员理解不同生物学过程、通路或功能在不同条件下的活动变化。它已经广泛应用于生物医学研究中，特别是在基因表达分析和疾病机制研究中发挥了重要作用。\nAlogrithm • Step 1: 计算富集分数（Enrichment Score，ES）。计算一个富集分数（ES），反映了一个基因集合S在整个排序列表L的极端位置（顶部或底部）上过度表示的程度。分数的计算是通过遍历列表L来实现的，在遇到基因集S中的基因时，增加一个运行总和统计量；在遇到不在基因集S中的基因时，减少这个统计量。增量的大小取决于基因与表型的相关性。富集分数是在随机漫步中遇到的与零的最大偏差；它对应于一种加权的Kolmogorov–Smirnov-like统计量。\n• Step 2: 估计ES的显著性水平。通过使用经验性的基于表型的置换测试过程来估计ES的统计显著性（名义P值），该过程保留了基因表达数据的复杂相关结构。具体来说，对表型标签进行排列并重新计算基因集在排列后数据中的ES，这样生成了ES的零分布。然后，计算观察到的ES的经验性名义P值相对于这个零分布。重要的是，类别标签的排列保留了基因与基因之间的相关性，因此提供了一个更符合生物学的显著性评估，而不是通过排列基因而获得的评估。\n实际上GSEA好像提供了两种排列方法 (2)，另一种是基因排列，直接将观察到的路径 ES 与通过使用匹配大小（例如 1,000 次）的随机采样基因集重复分析而获得的分数分布进行比较，表型排列应与大量重复一起使用（例如，每个条件至少十次）。 与基因集排列方法相比，表型排列方法的主要优点是，它在排列过程中保持了具有生物学重要基因相关性的基因集结构。 表型排列的计算成本很高，并且对于当前版本的 GSEA，需要自定义编程来分别计算数千个表型随机化的 ES 和差异表达统计数据。\n• Step 3: 多重假设检验的调整。当评估整个基因集合数据库时，会调整估计的显著性水平以考虑多重假设检验。首先，对每个基因集的ES进行归一化，以考虑集合的大小，得到一个归一化富集分数（NES）。然后，通过计算与每个NES相对应的虚假发现率（FDR）来控制假阳性比例。FDR是给定NES的一个集合代表虚假阳性发现的估计概率；它是通过比较观察到的NES和零分布的尾部来计算的。\nLeading-Edge Subset 基因集可以通过使用多种方法来定义，但并非基因集的所有成员通常都会参与生物过程。通常，提取有助于 ES 的高分基因集的核心成员是有用的。\n将Leading-Edge Subset (前沿子集)定义为基因集 S 中出现在排序列表 L 中或之前运行总和达到与零的最大偏差的那些基因（图 1B）。前沿子集可以解释为解释富集信号的基因集的核心。\nMSigDB 他们在发表GSEA时同时创建了MSigDB (Molecular Signatures Database)，分子特征数据库 (MSigDB) 是一个包含数以万计的注释基因集的资源，可与 GSEA 软件一起使用，分为人类和小鼠集合。\n比如说人类分子特征数据库 (MSigDB) 中的 33591 个基因集分为 9 个主要集合和几个子集合，可以自己去下载研究相关的重要基因集：\nCollection Description H: hallmark gene sets Hallmark gene sets summarize and represent specific well-defined biological states or processes and display coherent expression. These gene sets were generated by a computational methodology based on identifying overlaps between gene sets in other MSigDB collections and retaining genes that display coordinate expression. details C1: positional gene sets Gene sets corresponding to human chromosome cytogenetic bands. details C2: curated gene sets Gene sets in this collection are curated from various sources, including online pathway databases and the biomedical literature. Many sets are also contributed by individual domain experts. The gene set page for each gene set lists its source. The C2 collection is divided into the following two subcollections: Chemical and genetic perturbations (CGP) and Canonical pathways (CP). details C3: regulatory target gene sets Gene sets representing potential targets of regulation by transcription factors or microRNAs. The sets consist of genes grouped by elements they share in their non-protein coding regions. The elements represent known or likely cis-regulatory elements in promoters and 3’-UTRs. The C3 collection is divided into two subcollections: microRNA targets (MIR) and transcription factor targets (TFT). details C4: computational gene sets Computational gene sets defined by mining large collections of cancer-oriented microarray data. The C4 collection is divided into two subcollections: CGN and CM. details C5: ontology gene sets Gene sets that contain genes annotated by the same ontology term. The C5 collection is divided into two subcollections, the first derived from the Gene Ontology resource (GO) which contains BP, CC, and MF components and a second derived from the Human Phenotype Ontology (HPO). details C6: oncogenic signature gene sets Gene sets that represent signatures of cellular pathways which are often dis-regulated in cancer. The majority of signatures were generated directly from microarray data from NCBI GEO or from internal unpublished profiling experiments involving perturbation of known cancer genes. details C7: immunologic signature gene sets Gene sets that represent cell states and perturbations within the immune system. details C8: cell type signature gene sets Gene sets that contain curated cluster markers for cell types identified in single-cell sequencing studies of human tissue. details Table 1: Gene sets in the Human Molecular Signatures Database .\nExample 这里介绍在R中完成GSEA的方法\n对GSEA分析的geneList排序 明确我们用来排序的指标（metric）。 目前大部分分析是只比较两组间差异的，所以会将基因按照在两类样本中的差异表达程度（一般是log2FoldChange）排序，但实际上这里可以使用多种指标比如相关性，p值，也可以直接进行多组的分析比较（当然一定要明确排序两端代表的生物学意义）。尽量不要进行原始基因表格的筛选，比如只取DEGs，因为GSEA本身就是一个无阈值的富集方法，相比fisher.test等阈值方法考虑的会更多一些。\n1 2 3 4 #直接使用DOSE提供的一个geneList，已经通过log2FoldChange从大到小排序过了，而且这个向量的name是每一个entrez gene id, value是log2FoldChange值。 library(DOSE) data(geneList, package = \u0026#34;DOSE\u0026#34;) head(geneList) ## 4312 8318 10874 55143 55388 991 ## 4.572613 4.514594 4.418218 4.144075 3.876258 3.677857 使用R包进行GSEA富集 如果要使用GSEA官网提供的带GUI软件，可以参考这篇nature protocol，里面详细介绍了每一步的操作 (2)。\n这里我们使用更方便一点的R包来进行。clusterProfiler包内的gseGO()和gseKEGG()函数可以很方便地对GO与KEGG通路进行GSEA。 如果明确我们要富集的基因集的话，也可以自己构建并使用clusterProfiler::GSEA()富集。\n1 2 3 library(clusterProfiler) KEGG_kk_entrez \u0026lt;- gseKEGG(geneList = geneList, organism = \u0026#34;hsa\u0026#34;,pvalueCutoff = 0.25) #实际为padj阈值,可调整。 但上面这行代码在我的机器上结果是– No gene can be mapped….，可能是我机器上的clusterProfiler包内部数据库问题。\n但是没有关系，我一般也会自己从kegg上把想分析的通路信息都爬下来，操作见上一篇关于kegg api的介绍， 具体的代码都集成在ReporterScore里面了，下面直接使用ReporterScore进行GSEA分析。\n1 2 3 4 5 6 library(ReporterScore) #加载human kegg数据库 load_org_pathway(org = \u0026#34;hsa\u0026#34;) #这里包含了human所有gene-kegg_pathway的对应关系，可以使用download_org_pathway()进行更新。 head(hsa_kegg_pathway$all_org_gene) ## pathway_id kegg_gene_id gene_symbol gene_desc KO_id ## 1 hsa00010 3101 HK3 hexokinase 3 K00844 ## 2 hsa00010 3098 HK1 hexokinase 1 K00844 ## 3 hsa00010 3099 HK2 hexokinase 2 K00844 ## 4 hsa00010 80201 HKDC1 hexokinase domain containing 1 K00844 ## 5 hsa00010 2645 GCK glucokinase K12407 ## 6 hsa00010 2821 GPI glucose-6-phosphate isomerase K01810 1 2 3 4 5 # 假设我们的gene table如下，行名是gene symbol，使用t.test比较WT-OE两组差异 ko.test(genedf,\u0026#34;Group\u0026#34;,metadata,method = \u0026#34;t.test\u0026#34;)-\u0026gt;da_res # 统计结果如下 head(da_res) ## KO_id average_WT sd_WT average_OE sd_OE ## MME MME 0.0026728975 0.0011094132 0.0020694937 0.0014922004 ## PEX11A PEX11A 0.0004554658 0.0001951678 0.0024480601 0.0014916566 ## DSC2 DSC2 0.0027767713 0.0006253559 0.0025519275 0.0004966801 ## PLIN5 PLIN5 0.0005779169 0.0008952163 0.0005197504 0.0001435245 ## MIRLET7A2 MIRLET7A2 0.0020807307 0.0007731661 0.0014321838 0.0004273716 ## NCBP2L NCBP2L 0.0021064422 0.0005243558 0.0017419317 0.0005382770 ## diff_mean Highest p.value p.adjust ## MME -0.00060340387 WT 0.2200529827 0.321714887 ## PEX11A 0.00199259427 OE 0.0001376795 0.001449258 ## DSC2 -0.00022484380 WT 0.2852910552 0.392962886 ## PLIN5 -0.00005816647 WT 0.8072016928 0.865027977 ## MIRLET7A2 -0.00064854693 WT 0.0095033556 0.028624565 ## NCBP2L -0.00036451047 WT 0.0707452991 0.134260284 1 2 3 4 5 # GSEA富集,logFC排序,从gene水平富集到hsa的通路 gsea_res=KO_gsea(da_res,weight = \u0026#34;logFC\u0026#34;,type = \u0026#34;hsa\u0026#34;,feature = \u0026#34;gene\u0026#34;) # GSEA结果如下： head(gsea_res@result) ## ID ## hsa05235 hsa05235 ## hsa05162 hsa05162 ## hsa05323 hsa05323 ## hsa05322 hsa05322 ## hsa04660 hsa04660 ## hsa04142 hsa04142 ## Description ## hsa05235 PD-L1 expression and PD-1 checkpoint pathway in cancer - Homo sapiens (human) ## hsa05162 Measles - Homo sapiens (human) ## hsa05323 Rheumatoid arthritis - Homo sapiens (human) ## hsa05322 Systemic lupus erythematosus - Homo sapiens (human) ## hsa04660 T cell receptor signaling pathway - Homo sapiens (human) ## hsa04142 Lysosome - Homo sapiens (human) ## setSize enrichmentScore NES pvalue p.adjust qvalue rank ## hsa05235 13 0.8015443 1.885221 0.005680812 0.3204232 0.3178287 118 ## hsa05162 18 0.7355862 1.857939 0.006161984 0.3204232 0.3178287 14 ## hsa05323 14 0.7751069 1.850851 0.005438948 0.3204232 0.3178287 1 ## hsa05322 15 0.7364826 1.787932 0.011670053 0.3798506 0.3767749 101 ## hsa04660 15 0.7348533 1.783977 0.012174699 0.3798506 0.3767749 43 ## hsa04142 20 -0.5462876 -1.628928 0.018884445 0.4909956 0.4870199 40 ## leading_edge core_enrichment ## hsa05235 tags=46%, list=12%, signal=41% CD28/TICAM1/MAPK13/ALK/RPS6KB2/TLR9 ## hsa05162 tags=11%, list=1%, signal=11% CD28/TAB2 ## hsa05323 tags=7%, list=0%, signal=7% CD28 ## hsa05322 tags=27%, list=10%, signal=24% CD28/H4C13/H3C15/H2BW2 ## hsa04660 tags=13%, list=4%, signal=13% CD28/MAPK13 ## hsa04142 tags=15%, list=4%, signal=15% AP1M2/SLC17A5/SLC11A2 ID：某条通路基因集的名字\nDescription：通路的文字描述\nsetSize：gene set（S）中的基因数目（经过条件筛选后的值）\nenrichmentScore：富集评分\nNES：校正后的归一化的ES值\npvalue：对富集得分ES的统计学分析，用来表征富集结果的可信度\np.adjust：对pvalue进行BH调整后的值\nqvalue：即多重假设检验校正之后的pvalue。对NES可能存在的假阳性结果的概率估计，因此FDR越小说明富集越显著；\nrank：取到ES值时，对应基因在排序好的基因列表中所处的位置\nleading_edge：该处有3个统计值\nES\u0026gt;0在左边，ES\u0026lt;0在右边\ntags=xx%表示peak gene在S中的位置。指示有贡献的gene数量。\nlist=xx%表示peak gene在L中的位置。指示ES在哪里得到。\nsignal计算：$(Tag%)(1-Gene%)(\\frac{N}{N-Nh})$\nN：L中的gene数量\nNh：S中的gene数量\n结果可视化 使用enrichplot包对富集结果进行可视化。 1 2 #对于单条通路 enrichplot::gseaplot(gsea_res,geneSetID = \u0026#34;hsa05235\u0026#34;) 1 2 #多条通路展示 enrichplot::gseaplot2(gsea_res,geneSetID = c(\u0026#34;hsa05235\u0026#34;,\u0026#34;hsa05162\u0026#34;,\u0026#34;hsa04660\u0026#34;)) 第1部分 - ES折线图：在ES折线图中，离垂直距离x=0轴最远的峰值便是基因集的ES值。峰出现在排序基因集的前端（ES值大于0）则说明通路上调，出现在后端（ES值小于0）则说明通路下调。\n第2部分 - 基因集成员位置图：在该图中，用竖线标记了基因集中各成员出现在基因排序列表中的位置。若竖线集中分布在基因排序列表的前端或后端，说明该基因集通路上调或下调；若竖线较均匀分布在基因排序列表中，则说明该基因集通路在比较的两个数据中无明显变化。 红色部分对应的基因在实验组中高表达，蓝色部分对应的基因在对照组中高表达， leading edge subset 是（0,0）到曲线峰值ES出现对应的这部分基因成员。\n第3部分 - 排序后所有基因rank值分布：该图展示了排序后的所有基因rank值（由log2FoldChange值计算得出）的分布，以灰色面积图显展示。\nReference links：\nhttps://zhuanlan.zhihu.com/p/581172803\nhttps://zhuanlan.zhihu.com/p/518144716\n1. A. Subramanian, P. Tamayo, V. K. Mootha, S. Mukherjee, et al., Gene set enrichment analysis: A knowledge-based approach for interpreting genome-wide expression profiles. Proceedings of the National Academy of Sciences. 102, 15545–15550 (2005).\n2. J. Reimand, R. Isserlin, V. Voisin, M. Kucera, et al., Pathway enrichment analysis and visualization of omics data using g:Profiler, GSEA, cytoscape and EnrichmentMap. Nature Protocols. 14, 482–517 (2019).\n","date":"2023-09-13T00:00:00Z","image":"/p/gsea/images/gsea_intro_hu_75a956ac3bdd8990.jpg","permalink":"/p/gsea/","title":"基因集富集分析(GSEA)简介"},{"content":"Introduction KEGG（Kyoto Encyclopedia of Genes and Genomes）是一个广泛使用的生物信息学数据库，用于研究基因组、代谢组、信号通路和生物化学反应等方面的信息。它提供了基因、蛋白质、代谢物和信号通路等生物分子的综合信息，帮助研究人员理解生物体内分子之间的相互作用和功能。\n上一篇文章已经介绍了各种KEGG重要的子数据库，在这里就要介绍非常重要的操作：通过api查询和下载KEGG数据库内容。\nAPI for download KEGG API是和KEGG内核数据库进行交互的程序界面，允许用户基于该界面检索KEGG数据库，该界面的运行基于用户电脑的浏览器，在浏览器地址栏书写相应的地址指令即可检索KEGG数据库条目，该地址指令的编写规则如下所示：\nhttp://rest.kegg.jp/\u0026lt;operation\u0026gt;/\u0026lt;argument \u0026gt;[/\u0026lt;argument2\u0026gt;...]\n其中operation可选info、list、find、get、conv、link、ddi，后面的参数可以是数据库名称以及选项。\n包含的database有:\n1 2 3 4 5 6 7 8 9 10 11 \u0026lt;database\u0026gt; = KEGG databases (Table 1) and Outside databases integrated in KEGG (Table 2) = pathway | brite | module | ko | \u0026lt;org\u0026gt; | vg | vp | ag | genome | compound | glycan | reaction | rclass | enzyme | network | variant | disease | drug | dgroup | disease_ja | drug_ja | dgroup_ja | compound_ja | genes | ligand | kegg | \u0026lt;outside_db\u0026gt; \u0026lt;org\u0026gt; = KEGG organism code \u0026lt;outside_db\u0026gt; = pubmed | ncbi-geneid | ncbi-proteinid | uniprot | pubchem | chebi | atc | jtc | ndc | yj 所有操作的输出都是文本格式: - list, find, conv and link返回的制表符分隔文本 - get 返回平面文件数据库格式 - info 返回普通txt\ninfo info操作显示数据库发布信息以及数据库的统计信息。除了kegg、genes和ligand之外，该操作还显示可以在link操作中使用的链接数据库列表。\n示例 : 查看pathway 数据库的基本信息，命令http://rest.kegg.jp/info/pathway\n1 2 url=\u0026#34;http://rest.kegg.jp/info/pathway\u0026#34; httr::GET(url) 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 ## Response [https://rest.kegg.jp/info/pathway] ## Date: 2023-08-17 06:07 ## Status: 200 ## Content-Type: text/plain; charset=utf-8 ## Size: 471 B ## pathway KEGG Pathway Database ## path Release 107.0+/08-17, Aug 23 ## Kanehisa Laboratories ## 1,073,907 entries ## ## linked db module ## ko ## \u0026lt;org\u0026gt; ## genome ## compound ## ... list list操作可用于获取每个数据库中所有条目的列表。 可用genes, ligand and kegg以外的数据库。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 1.https://rest.kegg.jp/list/\u0026lt;database\u0026gt; \u0026lt;database\u0026gt; = pathway | brite | module | ko | \u0026lt;org\u0026gt; | vg | vp | ag | genome | compound | glycan | reaction | rclass | enzyme | network | variant | disease | drug | dgroup | organism 2.https://rest.kegg.jp/list/pathway/\u0026lt;org\u0026gt; 3.https://rest.kegg.jp/list/brite/\u0026lt;option\u0026gt; \u0026lt;option\u0026gt; = br | jp | ko | \u0026lt;org\u0026gt; 4.https://rest.kegg.jp/list/\u0026lt;dbentries\u0026gt; \u0026lt;dbentries\u0026gt; = Entries of the following \u0026lt;database\u0026gt; \u0026lt;database\u0026gt; = pathway | brite | module | ko | \u0026lt;org\u0026gt; | vg | vp | ag | genome | compound | glycan | reaction | rclass | enzyme | network | variant | disease | drug | dgroup 第一种，查看数据库中所有的记录:http://rest.kegg.jp/list/ko\n1 2 3 4 5 6 7 K00001\tE1.1.1.1, adh; alcohol dehydrogenase [EC:1.1.1.1] K00002\tAKR1A1, adh; alcohol dehydrogenase (NADP+) [EC:1.1.1.2] K00003\thom; homoserine dehydrogenase [EC:1.1.1.3] K00004\tBDH, butB; (R,R)-butanediol dehydrogenase / meso-butanediol dehydrogenase / diacetyl reductase [EC:1.1.1.4 1.1.1.- 1.1.1.303] K00005\tgldA; glycerol dehydrogenase [EC:1.1.1.6] K00006\tGPD1; glycerol-3-phosphate dehydrogenase (NAD+) [EC:1.1.1.8] ... 当生物体代码已知时，可以使用第二种形式来获取生物体特异性途径的列表，仅在list操作中允许使用特殊数据库名称\u0026quot;organism\u0026quot;，可用于获取具有三或四字母生物体代码的 KEGG 生物体列表: https://rest.kegg.jp/list/pathway/hsa\n1 2 3 4 5 6 hsa01100\tMetabolic pathways - Homo sapiens (human) hsa01200\tCarbon metabolism - Homo sapiens (human) hsa01210\t2-Oxocarboxylic acid metabolism - Homo sapiens (human) hsa01212\tFatty acid metabolism - Homo sapiens (human) hsa01230\tBiosynthesis of amino acids - Homo sapiens (human) ... 第三种形式是 brite 层次结构的类似选项: https://rest.kegg.jp/list/brite/br\n1 2 3 4 5 6 br08901\tKEGG pathway maps br08902\tBRITE hierarchy files br08904\tBRITE table files br08906\tBRITE binary relation files br08907\tKEGG networks ... 第四种形式可以用于获取给定的一组数据库条目标识符的定义列表: http://rest.kegg.jp/list/map00010+map00040。可以给出的标识符的最大数量为{.uri} 10。\n1 2 map00010\tGlycolysis / Gluconeogenesis map00040\tPentose and glucuronate interconversions find find是一个搜索操作,查找具有匹配查询关键字或其他查询数据的条目。\n1 2 3 4 5 6 7 8 9 10 1.https://rest.kegg.jp/find/\u0026lt;database\u0026gt;/\u0026lt;query\u0026gt; \u0026lt;database\u0026gt; = pathway | brite | module | ko | genes | \u0026lt;org\u0026gt; | vg | vp | ag | genome | ligand | compound | glycan | reaction | rclass | enzyme | network | variant | disease | drug | dgroup 2.https://rest.kegg.jp/find/\u0026lt;database\u0026gt;/\u0026lt;query\u0026gt;/\u0026lt;option\u0026gt; \u0026lt;database\u0026gt; = compound | drug \u0026lt;option\u0026gt; = formula | exact_mass | mol_weight | nop 第一种形式搜索如下所示的条目标识符和关联字段以查找匹配的关键字：http://rest.kegg.jp/find/genes/shiga+toxin 。\n1 2 3 4 5 ece:Z1464\tstx2A; shiga-like toxin II A subunit encoded by bacteriophage BP-933W ece:Z1465\tstx2B; shiga-like toxin II B subunit encoded by bacteriophage BP-933W ece:Z3343\tstx1B; shiga-like toxin 1 subunit B encoded within prophage CP-933V ece:Z3344\tstx1A; shiga-like toxin 1 subunit A encoded within prophage CP-933V ... 在第二种形式中，化学式搜索是部分匹配，与给定的原子顺序无关：http://rest.kegg.jp/find/compound/C7H10O5/formula 。通过四舍五入到与查询数据相同的小数位来检查精确的质量（或分子量）。 也可以使用减号 (-) 指定值的范围。\n1 2 3 4 5 6 7 cpd:C00493\tC7H10O5 cpd:C04236\tC7H10O5 cpd:C16588\tC7H10O5 cpd:C17696\tC7H10O5 cpd:C18307\tC7H10O5 cpd:C18312\tC7H10O5 ... get 此操作以平面文件格式或带有选项的其他格式检索给定的数据库条目。平面文件格式适用于除 brite 之外的所有 KEGG 数据库。\n输入最多 10 个条目。选项允许检索选定字段，包括基因条目中的序列数据、化合物、聚糖和药物条目中的化学结构数据或 gif 图像文件、途径条目中的 png 图像文件或 kgml 文件。输入仅限于带有图像选项的一种化合物/聚糖/药物条目，以及带有图像或 kgml 选项的一种通路条目。\n例子1: http://rest.kegg.jp/get/C01290+G00092 检索人类基因条目和大肠杆菌 O157 基因条目\n1 2 3 4 5 6 7 8 9 ENTRY C01290 Compound NAME Lactosylceramide; beta-D-Galactosyl-(1-\u0026gt;4)-beta-D-glucosyl-(1\u0026lt;-\u0026gt;1)-ceramide; beta-D-Galactosyl-1,4-beta-D-glucosylceramide; Gal-beta1-\u0026gt;4Glc-beta1-\u0026gt;1\u0026#39;Cer; LacCer; Lactosyl-N-acylsphingosine; D-Galactosyl-1,4-beta-D-glucosylceramide ... 例子2: http://rest.kegg.jp/get/hsa:10458/aaseq 检索人类基因的氨基酸序列, 支持 aaseq 和 ntseq\n1 2 3 4 5 6 7 8 9 10 11 \u0026gt;hsa:10458 K05627 BAI1-associated protein 2 | (RefSeq) BAIAP2, BAP2, FLAF3, IRSP53, WAML; BAR/IMD domain containing adaptor protein 2 (A) MSLSRSEEMHRLTENVYKTIMEQFNPSLRNFIAMGKNYEKALAGVTYAAKGYFDALVKMG ELASESQGSKELGDVLFQMAEVHRQIQNQLEEMLKSFHNELLTQLEQKVELDSRYLSAAL KKYQTEQRSKGDALDKCQAELKKLRKKSQGSKNPQKYSDKELQYIDAISNKQGELENYVS DGYKTALTEERRRFCFLVEKQCAVAKNSAAYHSKGKELLAQKLPLWQQACADPSKIPERA VQLMQQVASNGATLPSALSASKSNLVISDPIPGAKPLPVPPELAPFVGRMSAQESTPIMN GVTGPDGEDYSPWADRKAAQPKSLSPPQSQSKLSDSYSNTLPVRKSVTPKNSYATTENKT LPRSSSMAAGLERNGRMRVKAIFSHAAGDNSTLLSFKEGDLITLLVPEARDGWHYGESEK TKMRGWFPFSYTRVLDSDGSDRLHMSLQQGKSSSTGNLLDKDDLAIPPPDYGAASRAFPA QTASGFKQRPYSVAVPAFSQGLDDYGARSMSRNPFAHVQLKPTVTNDRCDLSAQGPEGRE HGDGSARTLAGR 例子3: http://rest.kegg.jp/get/hsa00600/image 检索通路图的 png 图像文件, 支持 image ,image2x， conf， kgml，但是一次只允许查询1条记录\nconv conv操作可用于将外部数据库的条目标识符（登录号）转换为 KEGG 标识符，反之亦然。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 1.https://rest.kegg.jp/conv/\u0026lt;target_db\u0026gt;/\u0026lt;source_db\u0026gt; (\u0026lt;target_db\u0026gt; \u0026lt;source_db\u0026gt;) = (\u0026lt;kegg_db\u0026gt; \u0026lt;outside_db\u0026gt;) | (\u0026lt;outside_db\u0026gt; \u0026lt;kegg_db\u0026gt;) For gene identifiers: \u0026lt;kegg_db\u0026gt; = \u0026lt;org\u0026gt; \u0026lt;org\u0026gt; = KEGG organism code or T number \u0026lt;outside_db\u0026gt; = ncbi-geneid | ncbi-proteinid | uniprot For chemical substance identifiers: \u0026lt;kegg_db\u0026gt; = compound | glycan | drug \u0026lt;outside_db\u0026gt; = pubchem | chebi 2.https://rest.kegg.jp/conv/\u0026lt;target_db\u0026gt;/\u0026lt;dbentries\u0026gt; For gene identifiers: \u0026lt;dbentries\u0026gt; = database entries of the following \u0026lt;database\u0026gt; \u0026lt;database\u0026gt; = \u0026lt;org\u0026gt; | genes | ncbi-geneid | ncbi-proteinid | uniprot \u0026lt;org\u0026gt; = KEGG organism code or T number For chemical substance identifiers: \u0026lt;dbentries\u0026gt; = database entries of the following \u0026lt;database\u0026gt; \u0026lt;database\u0026gt; = compound | glycan | drug | pubchem | chebi 第一种形式允许数据库到数据库的映射：https://rest.kegg.jp/conv/eco/ncbi-geneid 。\n1 2 3 4 5 6 7 ncbi-geneid:944742\teco:b0001 ncbi-geneid:945803\teco:b0002 ncbi-geneid:947498\teco:b0003 ncbi-geneid:945198\teco:b0004 ncbi-geneid:944747\teco:b0005 ncbi-geneid:944749\teco:b0006 ... 而第二种形式允许转换选定数量的条目：https://rest.kegg.jp/conv/ncbi-proteinid/hsa:10458+ece:Z5100 。\u0026ldquo;genes\u0026quot;数据库只能以第二种形式使用。\n1 2 hsa:10458\tncbi-proteinid:NP_059345 ece:Z5100\tncbi-proteinid:AAG58814 link link操作允许检索所有 KEGG 数据库内以及 KEGG 数据库与外部数据库之间的交叉引用。 它对于寻找各种关系非常有用，例如基因和通路之间的关系。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 1.https://rest.kegg.jp/link/\u0026lt;target_db\u0026gt;/\u0026lt;source_db\u0026gt; \u0026lt;target_db\u0026gt; = \u0026lt;database\u0026gt; \u0026lt;source_db\u0026gt; = \u0026lt;database\u0026gt; \u0026lt;database\u0026gt; = pathway | brite | module | ko | \u0026lt;org\u0026gt; | vg | vp | ag | genome | compound | glycan | reaction | rclass | enzyme | network | variant | disease | drug | dgroup | \u0026lt;outside_db\u0026gt; \u0026lt;outside_db\u0026gt; = pubmed | atc | jtc 2.https://rest.kegg.jp/link/\u0026lt;target_db\u0026gt;/\u0026lt;dbentries\u0026gt; \u0026lt;dbentries\u0026gt; = KEGG database entries of the following \u0026lt;database\u0026gt; \u0026lt;database\u0026gt; = pathway | brite | module | ko | \u0026lt;org\u0026gt; | vg | vp | ag | genome | compound | glycan | reaction | rclass | enzyme | network | variant | disease | drug | dgroup | \u0026lt;outside_db\u0026gt; \u0026lt;outside_db\u0026gt; = pubmed | atc | jtc 第一种形式允许检索数据库到数据库的交叉引用：https://rest.kegg.jp/link/pathway/hsa 或https://rest.kegg.jp/link/hsa/pathway 。\n1 2 3 4 5 6 7 8 hsa:10327\tpath:hsa00010 hsa:124\tpath:hsa00010 hsa:125\tpath:hsa00010 hsa:126\tpath:hsa00010 hsa:127\tpath:hsa00010 hsa:128\tpath:hsa00010 hsa:130\tpath:hsa00010 ... 而第二种形式允许检索选定数量的条目：https://rest.kegg.jp/link/pathway/hsa:10458+ece:Z5100 。 \u0026ldquo;genes\u0026quot;数据库只能用于第二种形式中的\u0026quot;ko\u0026quot;条目。\n1 2 3 4 5 hsa:10458\tpath:hsa04520 hsa:10458\tpath:hsa04810 hsa:10458\tpath:hsa05130 hsa:10458\tpath:hsa05135 ece:Z5100\tpath:ece05130 ddi ddi操作搜索 KEGG 药物相互作用数据库，其中提取日本药品标签中指定为禁忌症 (CI) 和预防措施 (P) 的药物相互作用，通过 KEGG 标识符进行标准化，并用任何可能的分子机制进行注释。\n1 2 3 4 5 6 7 8 9 1.https://rest.kegg.jp/ddi/\u0026lt;dbentry\u0026gt; \u0026lt;dbentry\u0026gt; = Single entry of the following \u0026lt;database\u0026gt; \u0026lt;database\u0026gt; = drug | ndc | yj 2.https://rest.kegg.jp/ddi/\u0026lt;dbentries\u0026gt; \u0026lt;dbentries\u0026gt; = Multiple entries in one of the following \u0026lt;database\u0026gt; \u0026lt;database\u0026gt; = drug | ndc | yj 第一种形式报告所有已知的相互作用：https://rest.kegg.jp/ddi/D00564 。\n1 2 3 4 5 6 dr:D00564\tcpd:C00304\tP\tunclassified dr:D00564\tcpd:C01946\tP\tunclassified dr:D00564\tcpd:C04931\tP\tunclassified dr:D00564\tcpd:C06624\tP\tunclassified dr:D00564\tcpd:C07005\tP\tunclassified ... 而第二种形式可用于检查给定药物组中的任何药物对是否为 CI 或 P：https://rest.kegg.jp/ddi/ndc:0078-0401 。\n1 2 3 4 ndc:0078-0401\tndc:0703-5656\tP\tunclassified ndc:0078-0401\tndc:0143-9510\tP\tunclassified ndc:0078-0401\tndc:0143-9511\tP\tunclassified ... Rpackge for KEGG 我们有时候肯定还是想用代码来完成KEGG的查询或者下载的，上面给的API用爬虫其实就很好访问，但也有一些现成的R包帮忙完成且更加简便。\nKEGGREST KEGGREST 允许访问 KEGG REST API。由于 KEGG 于 2012 年 12 月 31 日禁用了 KEGG SOAP 服务器（这意味着 KEGGSOAP 包将不再工作），因此 KEGGREST 充当替代者。\nKEGGREST 的接口比 KEGGSOAP 更简单，并且在某些方面更强大；但是，并非通过 SOAP API 提供的所有功能都已在 REST API 中公开。如果服务器端公开更多功能，则此包将被更新以利用它。\nKEGG REST API 基于一些简单的操作构建：info, list, find, get, conv, and link。 KEGGREST 中对应的 R 函数有：keggInfo()、keggList()、keggFind()、keggGet()、keggConv 和 keggLink()。\n1 2 3 4 5 6 if (!require(\u0026#34;KEGGREST\u0026#34;, quietly = TRUE)) BiocManager::install(\u0026#34;KEGGREST\u0026#34;) library(KEGGREST) # 查看KEGG包含的子数据库 listDatabases() 1 2 3 4 ## [1] \u0026#34;pathway\u0026#34; \u0026#34;brite\u0026#34; \u0026#34;module\u0026#34; \u0026#34;ko\u0026#34; \u0026#34;genome\u0026#34; \u0026#34;vg\u0026#34; ## [7] \u0026#34;ag\u0026#34; \u0026#34;compound\u0026#34; \u0026#34;glycan\u0026#34; \u0026#34;reaction\u0026#34; \u0026#34;rclass\u0026#34; \u0026#34;enzyme\u0026#34; ## [13] \u0026#34;disease\u0026#34; \u0026#34;drug\u0026#34; \u0026#34;dgroup\u0026#34; \u0026#34;environ\u0026#34; \u0026#34;genes\u0026#34; \u0026#34;ligand\u0026#34; ## [19] \u0026#34;kegg\u0026#34; 1 2 3 # 获取KEGG数据库中某个物种的所有通路（如人类） tmp=keggList(\u0026#34;pathway\u0026#34;,\u0026#34;hsa\u0026#34;) head(tmp) 1 2 3 4 5 6 7 8 9 10 11 12 ## hsa01100 ## \u0026#34;Metabolic pathways - Homo sapiens (human)\u0026#34; ## hsa01200 ## \u0026#34;Carbon metabolism - Homo sapiens (human)\u0026#34; ## hsa01210 ## \u0026#34;2-Oxocarboxylic acid metabolism - Homo sapiens (human)\u0026#34; ## hsa01212 ## \u0026#34;Fatty acid metabolism - Homo sapiens (human)\u0026#34; ## hsa01230 ## \u0026#34;Biosynthesis of amino acids - Homo sapiens (human)\u0026#34; ## hsa01232 ## \u0026#34;Nucleotide metabolism - Homo sapiens (human)\u0026#34; 1 2 3 # 获取某一条KEGG通路的全部信息。 tmp=keggGet(\u0026#34;hsa00020\u0026#34;) print(tmp[[1]]$DESCRIPTION) 1 ## [1] \u0026#34;The citrate cycle (TCA cycle, Krebs cycle) is an important aerobic pathway for the final steps of the oxidation of carbohydrates and fatty acids. The cycle starts with acetyl-CoA, the activated form of acetate, derived from glycolysis and pyruvate oxidation for carbohydrates and from beta oxidation of fatty acids. The two-carbon acetyl group in acetyl-CoA is transferred to the four-carbon compound of oxaloacetate to form the six-carbon compound of citrate. In a series of reactions two carbons in citrate are oxidized to CO2 and the reaction pathway supplies NADH for use in the oxidative phosphorylation and other metabolic processes. The pathway also supplies important precursor metabolites including 2-oxoglutarate. At the end of the cycle the remaining four-carbon part is transformed back to oxaloacetate. According to the genome sequence data, many organisms seem to lack genes for the full cycle [MD:M00009], but contain genes for specific segments [MD:M00010 M00011].\u0026#34; 1 # KEGG通路的基因、代谢物等信息就包含在keggGet()函数获得的结果中 1 2 3 4 5 6 7 8 9 10 # 获取某一条KEGG通路的全部信息 path \u0026lt;- keggGet(\u0026#34;hsa00010\u0026#34;) gene.info \u0026lt;- path[[1]]$GENE gene.info genes \u0026lt;- unlist(lapply(gene.info,function(x) strsplit(x,\u0026#34;;\u0026#34;))) gene.symbol \u0026lt;- genes[seq(1,length(genes),2)] gene.id \u0026lt;- genes[seq(2,length(genes),2)] gene.symbol # 生成gene symbol和Entrez ID匹配的数据框 data.frame(gene.symbol = gene.symbol,gene.id = gene.id) 通路-基因信息 比如我想要获得人类所有通路-基因信息（参考）\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 hsa_pathway \u0026lt;- keggList(\u0026#34;pathway\u0026#34;,\u0026#34;hsa\u0026#34;)# 获取KEGG数据库中所有人类通路 hsa_path \u0026lt;- data.frame(hsa_pathway) # 转成数据框,方便后续分析 hsa_path$pathID \u0026lt;- rownames(hsa_path) # 提取pathway ID hsa_gene \u0026lt;- list() for (i in 1:nrow(hsa_path)) { print(hsa_path[i,\u0026#34;pathID\u0026#34;]) hsa_info \u0026lt;- keggGet(hsa_path[i,\u0026#34;pathID\u0026#34;]) hsa_gene[[i]] \u0026lt;- hsa_info[[1]] } names(hsa_gene)=hsa_path$pathID pre_gene_in_pathway=function(pathway){ genes=pathway[[\u0026#34;GENE\u0026#34;]] if(is.null(genes))return(NULL) kegg_gene_id=genes[seq(1,length(genes),2)] input_strings=genes[seq(2,length(genes),2)] data \u0026lt;- data.frame( gene = sub(\u0026#34;;.*\u0026#34;, \u0026#34;\u0026#34;, input_strings), name = sub(\u0026#34;.*;\\\\s*(.*?)\\\\s+\\\\[.*\u0026#34;, \u0026#34;\\\\1\u0026#34;, input_strings), KO_id = sub(\u0026#34;.*\\\\[KO:(.*?)\\\\].*\u0026#34;, \u0026#34;\\\\1\u0026#34;, input_strings) #EC = sub(\u0026#34;.*\\\\[EC:(.*?)\\\\].*\u0026#34;, \u0026#34;\\\\1\u0026#34;, input_strings) ) data=data.frame(pathway_id=pathway$ENTRY,kegg_gene_id=kegg_gene_id,data,row.names = NULL) data } pre_gene_in_pathway(hsa_gene$hsa00020) all_hsa_gene=lapply(hsa_gene,pre_gene_in_pathway) all_hsa_gene1=do.call(rbind,all_hsa_gene) rownames(all_hsa_gene1)=NULL ReporterScore 因为很多富集方法都基于KEGG数据库，所有我写的ReporterScore包中也包含很多下载并处理KEGG数据库的函数。\n1 2 3 4 5 6 7 8 library(ReporterScore) #get_org_pathway函数可以获取某个organism的全部通路信息，及每条通路与基因，代谢物的关系。 get_org_pathway(org = \u0026#34;hsa\u0026#34;) #load_*系列函数可以获取KEGG重要模块的层级信息，也可以用update_htable()更新 load_KO_htable() load_Pathway_htable() load_Compound_htable() load_Module_htable() ","date":"2023-08-12T00:00:00Z","image":"/p/kegg-api2/images/hsa00600_hu_65ddad588db7563f.png","permalink":"/p/kegg-api2/","title":"KEGG 数据库及API (2)"},{"content":"Introduction KEGG（Kyoto Encyclopedia of Genes and Genomes）是一个广泛使用的生物信息学数据库，用于研究基因组、代谢组、信号通路和生物化学反应等方面的信息。它提供了基因、蛋白质、代谢物和信号通路等生物分子的综合信息，帮助研究人员理解生物体内分子之间的相互作用和功能。\nKEGG数据库包含以下几个主要模块：\nKEGG PATHWAY：包括生物体内的代谢通路、信号通路和细胞过程等信息。\nKEGG BRITE：提供了BRITE（Biomolecular Relations in Information Transmission and Expression）层次结构和表格，用于组织生物分子的功能和层次。\nKEGG MODULE：涵盖了代谢通路中的功能模块。\nKEGG ORTHOLOGY：提供基因的功能同源分析，帮助进行基因功能注释。\nKEGG GENES：包括基因和蛋白质的信息。\nKEGG GENOME：提供各个物种的基因组信息，包括基因组大小、结构、功能注释等。\nKEGG COMPOUND：包括小分子化合物的信息。\nKEGG GLYCAN：提供糖类的信息。\nKEGG REACTION：包括生物化学反应的信息。\nKEGG ENZYME：提供酶的命名和功能信息。\nKEGG NETWORK：包括与疾病相关的网络变异信息。\nKEGG DISEASE：提供与人类疾病相关的基因和通路信息。\nKEGG DRUG：提供药物的信息，包括药物作用靶点、药物代谢途径等。\n研究人员可以使用KEGG数据库来进行各种生物信息学分析，如基因注释、通路富集分析、基因调控网络构建等。KEGG数据库的数据和工具有助于揭示生物体内分子之间的相互关系，从而深入理解生物学过程和疾病机制。\n接下来将从逻辑顺序介绍这些模块：\nORTHOLOGY KO（KEGG Orthology）数据库是一个以功能性同源基因为代表的分子功能数据库，这是KEGG的基础。该数据库基于同源基因具有相似功能的假设，对基因的功能进行了扩充。\n对于在某个物种中功能已经研究明确的基因，在不同物种中搜索具有相似功能的同源基因，将这些同源基因定义为一个orthology，以该基因的功能作为该orthology的功能。这样，可以利用不同物种中基因功能的研究成果，构建了一个全面研究基因功能的数据库。\u0026ldquo;功能\u0026quot;的细节因上下文而异，因此所得到的KO分组可能对应于在某些物种中高度相似的序列集，也可能对应于更为分散的序列集。\nKO在KEGG PATHWAY、BRITE和MODULE等网络中具有重要作用。网络中的每个节点，例如在KEGG通路图中的方框，都被赋予了一个KO标识符（称为K号），作为功能性同源基因的代表。\n在官网检索任意一个K号，如K00077，就能够获取一系列信息：如gene symbol，KO的名字（描述），参与了哪些Pathway，module，在brite的哪个位置，这个KO包含的所有来自不同物种的gene以及参考文献等。\n我们如果有新发现的基因，功能未知，我们只需要根据序列比对查找对应的功能已知的同源基因就可以了。KEGG官网也提供了一个在线的工具，BlastKOALA，这个工具基于blast比对，将输入的基因序列和KEGG Gene数据库中的序列去比对，查找最佳匹配的一个gene, 将该基因对应的K number 赋予查询的基因。\n所有ko的层级信息都在ko00001中，地址为https://www.genome.jp/kegg-bin/get_htext?ko00001.keg\nBRITE KEGG BRITE是一个层次分类系统的集合，捕捉了各种生物对象的功能层次结构，特别是那些以KEGG对象表示的对象。它们以BRITE层次文件的形式呈现，也称为分层文本（htext）文件，还使用HTML表格来补充BRITE表格文件。BRITE层次文件可以与包含KEGG对象各种属性的二进制关系文件关联。BRITE浏览器允许在左侧面板中选择显示为层次结构中附加列的这些二进制关系。BRITE表格文件更侧重于多列属性，而不是层次关系。与仅涵盖分子相互作用和反应的KEGG PATHWAY相比，KEGG BRITE包含了许多不同类型的关系，包括：\n基因和蛋白质\n化合物和反应\n药物\n疾病\n有机体和病毒\nBRITE标识符 每个BRITE层次/表格由2-4字母前缀代码和5位数字的组合标识（见KEGG标识符）。前缀的含义如下：\nbr：非基因/蛋白质参考层次或表格\njp：非基因/蛋白质参考层次或表格的日语版本\nko：基因/蛋白质参考层次，用于KO扩展\n\u0026lt;org\u0026gt;：通过将KO转换为基因标识符生成的有机体特异层次\nKEGG BRITE与KEGG PATHWAY相比，涵盖了更广泛的生物对象关系，提供了丰富的层次分类系统，帮助研究人员理解基因、蛋白质、化合物、反应、药物、疾病、有机体和病毒等多个生物学领域的关系。\nKEGG BRITE提供了两种格式的文件用于下载，htext 对应的后缀为 keg， json 对应json。 keg是文本文件，分层列表的感觉，看起来也不是非常直观，我们可以转化成表格形式来看\n比如具体的ko层级信息都在ko00001中，下载地址为https://www.genome.jp/kegg-bin/download_htext?htext=ko00001\u0026format=htext，用下列R代码就可以转化为表格形式便于分析。或者用kegg 提供的keggHier 程序，专门用于查看brite中的分类信息\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 ko00001_htext2df=function(input_file, output_file,header_num = 0) { # Read the input file input \u0026lt;- readLines(input_file) # Open the output file output \u0026lt;- file(output_file, \u0026#34;w\u0026#34;) count \u0026lt;- list() while (header_num \u0026gt; 0) { input \u0026lt;- input[-1] header_num \u0026lt;- header_num - 1 } # Process the input file for (line in input) { if (grepl(\u0026#34;^A\u0026#34;, line)) { a \u0026lt;- line a \u0026lt;- sub(\u0026#34; \u0026#34;, \u0026#34;\\t\u0026#34;, a) next } if (grepl(\u0026#34;^B \u0026#34;, line)) { b \u0026lt;- line b \u0026lt;- sub(\u0026#34;B \u0026#34;, \u0026#34;\u0026#34;, b) b \u0026lt;- sub(\u0026#34; \u0026#34;, \u0026#34;\\t\u0026#34;, b) next } if (grepl(\u0026#34;^C \u0026#34;, line)) { c \u0026lt;- line c \u0026lt;- sub(\u0026#34;C \u0026#34;, \u0026#34;\u0026#34;, c) c \u0026lt;- sub(\u0026#34; \u0026#34;, \u0026#34;\\t\u0026#34;, c) next } if (grepl(\u0026#34;^D \u0026#34;, line)) { d \u0026lt;- line d \u0026lt;- sub(\u0026#34;D \u0026#34;, \u0026#34;\u0026#34;, d) d \u0026lt;- sub(\u0026#34; \u0026#34;, \u0026#34;\\t\u0026#34;, d) writeLines(paste(a, b, c, d, sep = \u0026#34;\\t\u0026#34;), output) } } # Close the output file close(output) } PATHWAY KEGG PATHWAY是一个手工绘制的通路图集合，代表了对以下分子相互作用、反应和关系网络的了解：\nlevelA 描述 1. Metabolism 代谢 （全局/概述, 碳水化合物, 能量, 脂质, 核苷酸, 氨基酸, 其他氨基酸, 糖类, 辅因子/维生素, 萜类/多酮, 其他次生代谢物, 异生素, 化学结构） 2. Genetic Information Processing 遗传信息加工 3. Environmental Information Processing 环境信息处理 4. Cellular Processes 细胞过程 5. Organismal Systems 有机体系统 6. Human Diseases 人类疾病 7. Drug Development 药物开发 通路标识符： 每个通路图由2-4字母前缀代码和5位数字的组合标识（参见KEGG标识符）。前缀具有以下含义：\nmap：手工绘制的参考通路 reference pathway\nko：参考通路，突出显示KOs\nec：参考代谢通路，突出显示EC编号\nrn：参考代谢通路，突出显示反应\n\u0026lt;org\u0026gt;：由将KO转换为基因标识符而生成的特定于物种的通路，KO是跨物种的概念，所以每个pathway 会对应有多个物种。\n以以下数字开头的标识符：\n011：全局图（链接到KO）\n012：概述图（链接到KO）\n010：化学结构图（无KO扩展）\n07：药物结构图（无KO扩展）\n其他：常规图（框与KO链接）\nKEGG PATHWAY与MODULE和NETWORK数据库集成，如下所示。\nM - 模块\nR - 反应模块\nN - 网络\n在通路图中，官方提供的图例如下：\n在一个通路图中，存在以下三种基本对象：\n矩形代表KO： 这些矩形表示KEGG Orthology（KO），即基因、蛋白质或其他生物分子。它们在通路中扮演着特定的角色，可能参与反应、催化化学转化或在通路中发挥其他功能。\n圆角矩形代表另外的通路图： 这些圆角矩形表示链接到其他通路图，帮助将不同的通路图连接起来，以呈现更复杂的生物学关系和相互作用。\n圆形代表化学物质： 这些圆形表示化学物质，如代谢产物、底物或其他分子。它们在通路中参与不同的反应和交互作用。\n箭头表示这些对象之间的相互作用关系，其中包括蛋白质间的相互作用、基因表达的调节、酶的催化等。箭头上可能有不同的修饰符，用于表示不同类型的相互作用和调控方式。\nKEGG PATHWAY提供了丰富的图表，涵盖多个生物学领域的分子交互和功能，帮助研究人员更深入地理解代谢、信号通路、遗传信息处理、细胞过程、有机体系统、人类疾病和药物开发等生物学过程。\npathway层级信息都在br08901中，地址为https://www.genome.jp/kegg-bin/get_htext?br08901.keg\nMODULE KEGG MODULE数据库由M号标识的KEGG模块和RM号标识的KEGG反应模块组成，分别是手动定义的基因集和反应集的功能单元。 KEGG模块进一步分为通路模块和特征模块，如下所示。\npathway modules 通路模块\u0026mdash;\u0026mdash;代谢通路中基因组的功能单元，包括分子复合物\nsignature modules 特征模块\u0026mdash;\u0026mdash;表征表型特征的基因集功能单元\nreaction modules 反应模块\u0026mdash;\u0026mdash;代谢通路中连续反应步骤的功能单元\nKEGG 模块和 KEGG 反应模块的完整列表可以从 BRITE 层次结构文件中查看：https://www.kegg.jp/brite/ko00002\n具有相同功能的基因被归类到kegg orthology中，每个KO代表具体的一个功能。在生命活动中，往往需要多个功能单位共同发挥作用，比如多个蛋白质构成复合体来发挥调控作用，此时多个KO就整合在了一起。KEGG Module 数据库中的每条记录代表一个功能单元，是多个KO的集合,叫做kegg module。\n和pathway 类似，对于每条module的记录，也会有一个模块图，通路模块由K号的逻辑表达式定义，而特征模块由K号和M号的逻辑表达式定义。 以M00007为例，直接查询会得到模块名称，相关通路和反应等信息，左下角就是模块图：\n模块图就是根据Definition来生成的：\u0026ldquo;K00615 (K00616,K13810) K01783 (K01807,K01808)\u0026rdquo;\n这里的连接K号的空格或加号被视为AND运算符，逗号用于表示OR运算符。 有的时候会出现减号，指定复合物中的可有可无的部分。\n每个以空格分隔的单元称为块（block），圆括号内为1个block，M00007有4个block，4个block一起发挥作用：\n由于module是基于KO的，所以module也是跨物种的概念。对于每个物种而言都有自己对应的module, 比如M00007在human中对应的记录为hsa_M00007,其高亮了K00615，K00616，K01783，K01807四个KO，说明人体完成M00007功能使用了这四个KO。\nmodule层级信息都在ko00002中，地址为https://www.genome.jp/kegg-bin/get_htext?ko00002.keg\nGENES KEGG GENES 是从公开资源（主要来自NCBI RefSeq和GenBank） 生成的细胞生物和病毒完整基因组中基因和蛋白质的集合，KEGG会使用自己定义的ID 唯一区别每个基因（kegg gene ID），并以 KO（KEGG Orthology）分配的形式进行注释。 该集合还补充了来自已发表文献的KEGG原始功能表征蛋白质集合。 所有GENES条目的蛋白质序列和RNA序列均经过KOALA工具的SSDB(Sequence Similarity DataBase)计算和KO分配。\n目前gene数据库的统计数据：https://www.kegg.jp/kegg/docs/genes_statistics.html\n比如人类的，总共20,568个蛋白编码基因，15,778有KO注释，非编码基因有4,148个（好像比前几年少了很多，之前接近两万了吧）。其中pathway 相关基因只有8,577个。\nGrp Genus Species Org Protein RNA Pathway EC E.AniM Homo Homo sapiens hsa 20568 15778 4148 1266 KEGG GENES 的注释涉及 KO 标识符（K 编号）的分配，可以使用几种工具进行注释：\nBlastKOALA automatic KO assignment by BLASTP sequence similarity search\nGhostKOALA automatic KO assignment by GHOSTX sequence similarity search\nKofamKOALA automatic KO assignment by HMM profile search\nGENOME KEGG GENOME是KEGG生物体的集合，这些生物体是具有完整基因组序列的生物体，并且每个生物体都由三或四字母的生物体代码来识别（比如人是hsa，小鼠是mmu）。\n\u0026ldquo;Selected Viruses\u0026quot;数据库收录了与人类或植物病理相关的病毒信息，使用T编号对不同病毒进行区分。 \u0026ldquo;KEGG viruses\u0026quot;数据库还提供了病毒的宿主、相关疾病等详细信息。 \u0026ldquo;Metagenomes\u0026quot;数据库则收录了环境微生物的相关信息，主要涵盖口腔、肠道、空气、皮肤以及泌尿生殖系统等五大领域，得到了 MGENOME 的补充，MGENOME 是来自环境和生物样本的宏基因组序列的集合。对于环境微生物，每个物种的T编号都以T3开头。\nCategory DBGET Identifiers DBGET Annotation (genome) (genes) KEGG organisms GENOME T0 numbers / three- or four- GENES KOALA/manual (Complete genomes) letter organism codes Selected viruses T4 numbers KEGG viruses Taxonomy IDs (Vtax category) Metagenomes MGENOME T3 numbers MGENES GhostKOALA COMPOUND KEGG COMPOUND是一个收集了与生物系统相关的小分子、生物聚合物和其他化学物质的数据库。每个条目都由C号标识，例如L-赖氨酸的C00047，并包含化学结构和相关信息，以及与其他KEGG数据库和外部数据库的各种链接。一些COMPOUND条目也可以通过\u0026quot;Same as\u0026quot;链接表示为GLYCAN和DRUG条目。在\u0026quot;KEGG COMPOUND\u0026quot;中，代表性条目的分类可以在以下的BRITE层次文件中找到。\nKEGG COMPOUND 是 KEGG 项目启动时引入的四个原始数据库之一，其他数据库包括 KEGG PATHWAY、KEGG GENES 和 KEGG ENZYME。它的作用始终是实现从个体分子数据到分子网络数据的链接。 化合物条目是 KEGG pathway和KEGG module的组成部分，它们用于分析代谢组学数据等，化合物条目现在还用于表示 KEGG NETWORK 中与疾病相关的扰动网络，例如先天性代谢障碍。\ncompound层级信息都在br08001中,地址为https://www.genome.jp/kegg-bin/get_htext?br08001.keg\nlevelA 名称 Organic acids 有机酸 Lipids 脂质 Carbohydrates 碳水化合物 Nucleic acids 核酸 Peptides 肽 Vitamins and cofactors 维生素和辅因子 Steroids 类固醇 Hormones and transmitters 激素和递质 Antibiotics 抗生素 以甲酸C00058为例:http://www.genome.jp/dbget-bin/www_bget?cpd:C00058\n会提供至少以下信息：\nEntry C Number, 在数据库中的唯一标识符 Name 名称 Formula 化学式 Extract Mass 质量 Mol weight 分子量 structure 结构 Reaction 该分子涉及到的的Reaction Pathway 该分子参与的通路 Module 该分子参与的module Enzyme 该分子相关的酶 DB 第三方数据库的链接 GLYCAN KEGG GLYCAN是一个收集了糖链结构的数据库，首先从CarbBank中选取独特的结构，然后根据已发表的资料进行扩展，特别是那些在KEGG通路中存在的结构。每个结构都由G号标识，例如sialyl Lewis x的G00242，并用预定义的单糖代码进行显示。\n对于复合糖而言，了解结构是最基础的研究，我们更加关注其在生命活动中的意义。KEGG将与复合糖相关的基因、代谢途径、疾病等信息关联在一起，通过通路的形式进行展示。在KEGG的通路数据库中，有一个专门描述复合糖的代谢通路信息的类别，称为\u0026quot;Glycan biosynthesis and metabolism\u0026rdquo;:\nKEGG还提供KCaM，KCaM是一个类似聚糖结构的数据库搜索程序。它可用于搜索 KEGG GLYCAN 或 CarbBank。可以使用 KegDraw 工具输入查询聚糖结构。\nREACTION KEGG Reaction是一个收录酶促反应相关信息的数据库，主要包含代谢通路中的所有反应，以及只出现在酶命名中的一些额外反应。每条记录都由R号唯一标识，例如乙酰化L-谷氨酸的R00259。这些反应与由KO数据库定义的酶KOs相关联，从而实现了基因组（酶基因）和化学（化合物对）信息的集成分析。\n反应类别（KEGG RCLASS）包含基于底物-产物对（反应物对）的化学结构转变模式的反应分类，这些模式由所谓的 RDM 模式表示。例如，R00259 是由以下定义的反应：\nAcetyl-CoA + L-Glutamate \u0026lt;=\u0026gt; CoA + N-Acetyl-L-glutamate\n一般来说，一个反应由多个反应物对组成，出现在 KEGG 代谢途径图上的称为主对，在本例中是 L-谷氨酸 (C00025) 和 N-乙酰基-L-谷氨酸对（C00624）。如图所示，根据化合物对C00025_C00624的RDM模式，所以反应R00259被分配给反应类别RC00064。\n为了区分原子的官能团，KEGG将C、N、O、S、P原子种类分为68种，称为KEGG原子类型。它们最初被引入用于通过基于图形的化学结构比较来检测生化相似性。 KEGG 原子类型链接：https://www.kegg.jp/kegg/reaction/KCF.html\nENZYME KEGG ENZYME 是 IUBMB/IUPAC 生化命名委员会制定的酶命名法（EC 编号系统）的实施。 KEGG ENZYME 基于 ExplorEnz数据库，并在KEGG关系数据库中维护，并附加反应层次结构和序列数据链接的注释。\n提供信息：\nEntry 酶编号，EC number Name 酶的名称 Class 所属的分类 Sysname 其他名称 Reaction 酶催化的反应 Substrate 底物 Product 产物 Comment 注释 History 修订记录 Pathway 参与的通路 Orthology 对应的KO 信息 Genes 在各种物种中对应的基因 Reference 参考文献 Other DBs 其他数据库的链接 EC number与KO的对应关系比较复杂，可以通过基因来理解它们之间的对应关系：参考\n一种酶对应的多个基因属于同一个KO, 比如 1.1.1.388 一种酶虽然有实验证据表明存在，但是缺乏对应的基因信息，也就没有对应的KO注释，比如1.1.1.46, 就没有对应的KO信息 一种酶在多个物种中都存在，也就有对应的多个基因，这些基因可能分属不同的KO，即1个EC Number对应多个KO的情况， 比如1.1.1.376 多个酶对应同一个KO, 多个酶对应的基因被归类到了同一个KO下，比如1.1.1.49 和 1.1.1.363。 NETWORK KEGG NETWORK 代表了KEGG对于以受扰动的分子网络参见（KEGG DISEASE的背景）来捕获疾病和药物知识的更新尝试。\n与pathway, brite, module 等数据库不同，network数据库针对human，除了提供了基因的功能和相互作用以外，还把基因的变异信息包含进来，更进一步与疾病相关联。\u0026ldquo;KO\u0026quot;是基于不同物种的基因具有同源性而建立的数据库，而pathway则利用KO的注释信息提供了跨物种的通路信息。在\u0026quot;network\u0026quot;数据库中，每条记录用N号唯一标识。这些记录描述了基因之间的相互作用网络，\u0026ldquo;network\u0026quot;数据库是在pathway数据库的基础上发展而来，在保留通路信息的基础上，还包括了基因的变异信息（如SNP、基因融合等结构变异和基因表达量的变化），为人类基因变异与疾病的研究提供更详细的参考。\n网络图颜色：\n网络元素 着色 参考网络 绿色 变异网络，包含 人类基因变异 红色 病原体基因/蛋白质 紫色 环境因素 蓝色 药物靶标关系 海军蓝 网络中边的类型：\n边 互作/反应 → 激活 ⊣ 抑制 ＝ 形成复合 ⌿ 缺失的互动或反应 ↗ 功能增益 ⇒ 表达 ⫤ 抑制 --- 底物结合酶或转运蛋白 → 酶促反应或运输过程 ⇉ 酶-酶关系的连续反应 DISEASE KEGG DISEASE 是仅关注干扰因素的疾病条目集合，因为大多数疾病的分子网络细节都是未知的。每个条目均由 H 编号标识，并包含已知遗传因素（疾病基因）、环境因素、病原体和治疗药物的列表（例如，参见慢性粒细胞白血病 H00004 的疾病条目）。\n在 KEGG 中，疾病被视为分子网络系统的扰动状态。疾病的遗传和环境因素以及药物被认为是该系统的干扰因素。 不同类型的疾病，包括单基因疾病、多因素疾病和传染病，都是通过累积这些扰动及其相互作用来统一治疗的。\nhuman disease 的详细分类：https://www.kegg.jp/kegg-bin/get_htext?br08402.keg\n所有物种（包括human）的疾病信息的分类对应以下两个文件：\n第一个文件为kegg 自己定义的分类标准, 主要依据物种分类信息:http://www.kegg.jp/kegg-bin/get_htext?br08401_genome.keg\n第二个文件为国际上对疾病的分类标准 ICD-10 分类系统:http://www.kegg.jp/kegg-bin/get_htext?br08403.keg\nDRUG KEGG DRUG 是日本、美国和欧洲批准药物的综合药物信息资源，基于化学结构和/或活性成分的化学成分进行统一。 每个KEGG DRUG条目均由D号标识，并与KEGG原始注释相关联，包括治疗靶点、药物代谢和其他分子相互作用网络信息。\n提供信息：\n字段 含义 Entry D number Name 通用名和注册的商品名 Products Generic DailyMed 数据库的链接 Formula 分子式 Exact mass 质量 Mol Weight 分子量 Structure 化学结构 Simcomp 结构相近的其他分子 Class DGROUP 数据库定义的分类 Efficacy Diseasee 作用的疾病 Target Pathway 药物的靶标对应的人类基因和这些靶标参与的通路 Metabolism 药物代谢相关的酶 Structure map pathway数据库的通路图 Brite 在brite 数据库中的分类信息 KEGG DGROUP包含了在KEGG DRUG中的一组具有结构和功能关联的D号条目。有五种类型的药物组。\n化学组 - 被归类为具有相同化学结构但有轻微变化的药物，如盐、水合状态等。\n结构组 - 被归类为具有相似化学结构且具有相同骨架等的药物。\n靶点组 - 根据药物的靶点进行归类。\n类别组 - 药物类别通常代表相似的作用机制。\n代谢组 - 根据药物代谢酶和转运蛋白的底物、抑制剂和诱导剂进行归类。\n化学组通常用于识别在不同国家中的药物中本质上相同的活性成分。\nAPI for download KEGG API是和KEGG内核数据库进行交互的程序界面，允许用户基于该界面检索KEGG数据库，该界面的运行基于用户电脑的浏览器，在浏览器地址栏书写相应的地址指令即可检索KEGG数据库条目，该地址指令的编写规则如下所示：\nhttp://rest.kegg.jp/\u0026lt;operation\u0026gt;/\u0026lt;argument \u0026gt;[/\u0026lt;argument2\u0026gt;...]\n其中operation可选info、list、find、get、conv、link、ddi，后面的参数可以是数据库名称以及选项，下一篇具体讲解。\n","date":"2023-08-11T00:00:00Z","image":"/p/kegg-api/images/M00007_hu_7756457bbd4b9f10.png","permalink":"/p/kegg-api/","title":"KEGG 数据库及API (1)"},{"content":"Introduction 上次已经在一篇推文中介绍过了微生物组分析常用的功能富集分析方法以及reporter score方法的原理，并且也介绍了我开发的R包ReporterScore。\n但时那个时候R包写的还比较粗糙，功能也不多，最近进一步优化了这个包的各种功能，支持两种模式，多种统计检验方法，支持两组甚至更多组的实验设计（这个挺好用的），KEGG数据库的同步做的也比较好了，还增加了一些可视化形式。\n以下是我给这个R包github主页（https://github.com/Asa12138/ReporterScore）下写的介绍和用法，这里简单翻译一下贴过来了。但其实里面还有不少功能没在下面写出，可以在R包里探索一下，哈哈。\nCitation 这个包暂时还没有在刊物上发表，要在出版物中引用 ReporterScore，请使用：\nChen Peng, Chao Jiang. ReporterScore: an R package for Reporter Score-based Microbial Enrichment Analysis. R package (2023), https://github.com/Asa12138/ReporterScore\n🤗也欢迎在GitHub上点个star⭐️\nInstall 1 2 3 4 if(!require(\u0026#34;devtools\u0026#34;))install.packages(\u0026#34;devtools\u0026#34;) devtools::install_github(\u0026#39;Asa12138/pcutils\u0026#39;,dependencies=T) devtools::install_github(\u0026#39;Asa12138/ReporterScore\u0026#39;,dependencies=T) library(ReporterScore) Usage 1. Inputdata (KO abundance table and metadata) 通常，我们可以使用KEGG数据库来注释我们的微生物组测序数据，特别是环境微生物组，因为KEGG相对来说更全面（当然大部分还是unknown）。\n具体方法包括直接使用blast对KEGG序列数据库进行比对，使用KEGG官方mapper软件，使用EggNOG数据库并将结果转化为KEGG注释。\n这样我们就可以得到一个KO丰度表（行是KO，列是样本）用于我们的富集分析：\n1 2 data(\u0026#34;KO_abundance_test\u0026#34;) head(KO_abundance[,1:6]) ## WT1 WT2 WT3 WT4 WT5 WT6 ## K03169 0.002653545 0.005096380 0.002033923 0.000722349 0.003468322 0.001483028 ## K07133 0.000308237 0.000280458 0.000596527 0.000859854 0.000308719 0.000878098 ## K03088 0.002147068 0.002030742 0.003797459 0.004161979 0.002076596 0.003091182 ## K03530 0.003788366 0.000239298 0.000445817 0.000557271 0.000222969 0.000529624 ## K06147 0.000785654 0.001213630 0.001312569 0.001662740 0.002387006 0.001725797 ## K05349 0.001816325 0.002813642 0.003274701 0.001089906 0.002371921 0.001795214 还需要提供实验设计的元数据metadata（行是样本，列是组）。\n1 head(metadata) ## Group Group2 ## WT1 WT G3 ## WT2 WT G3 ## WT3 WT G3 ## WT4 WT G3 ## WT5 WT G3 ## WT6 WT G1 2. Pathway database ReporterScore内置了KEGG 通路和模块数据库（2023-08 版）用于KO 丰度表分析。\n你可以使用 load_KOlist() 查看并使用 update_KO_file() 更新这些数据库（通过 KEGG API），因为使用最新的数据库非常重要。\n或者你可以使用custom_modulelist()自定义你自己的通路数据库（感兴趣的基因集）。\n1 2 load_KOlist() head(KOlist$pathway) 3. One step enrichment 使用函数reporter_score可以一步得到reporter score结果。\n有一些重要的参数可供调节：\nmode: “mixed” 或 “directed”（仅适用于两组差异分析或多组相关分析），详细信息参见pvalue2zs。 方法：统计检验类型。 默认为”wilcox.test”： t.test （参数）和 wilcox.test （非参数）。 对两组样品进行比较。 如果分组变量包含两个以上水平，则执行成对比较。 - anova（参数）和 kruskal.test（非参数）。 执行比较多个组的单向方差分析测试。 “pearson”、“kendall”或”spearman”（相关分析），请参见cor。 p.adjust.method：用于测试结果的p.adjust.method，参见p.adjust。 type/modulelist：选择通路数据库，默认数据库为”pathway”或”module”，或使用自定义的模块列表。 group作为因子变量，第一个水平将被设置为对照组，你可以更改因子水平来改变你的比较。\n例如，我们想要比较两组”WT-OE”，并使用”directed”模式，因为我们只想知道 OE 组 中哪些通路被富集或耗尽：\n1 2 3 4 cat(\u0026#34;Comparison: \u0026#34;,levels(factor(metadata$Group))) ## Comparison: WT OE reporter_score_res=reporter_score(KO_abundance,\u0026#34;Group\u0026#34;,metadata,mode=\u0026#34;directed\u0026#34;) 结果是一个”reporter_score”对象：\nelements description kodf 你的输入 KO_abundance 表 ko_pvalue ko 统计结果包含 p.value ko_stat ko统计结果包含p.value和z_score reporter_s 在每个途径中的reporter score modulelist 默认 KOlist 或自定义模块列表数据框 group 你的数据中的比较组 metadata 示例信息数据框包含组 4. Visualization 绘制最显著富集的通路：\n1 2 #View(reporter_score_res$reporter_s) plot_report(reporter_score_res,rs_threshold = c(-2,2)) 当我们聚焦于一条通路时，例如 “map00780”：\n1 plot_KOs_in_pathway(reporter_score_res,map_id = \u0026#34;map00780\u0026#34;) 或者显示为网络：\n1 plot_KOs_network(reporter_score_res,map_id = \u0026#34;map00780\u0026#34;,main=\u0026#34;\u0026#34;) 我们也可以查看通路中每个 KO 的丰度：\n1 plot_KOs_box(reporter_score_res,map_id = \u0026#34;map00780\u0026#34;,only_sig = TRUE) 或者热图形式呈现：\n1 plot_KOs_heatmap(reporter_score_res,map_id = \u0026#34;map00780\u0026#34;,only_sig = TRUE,heatmap_param = list(cutree_rows=2)) example for “mixed” 如果我们的实验设计超过两组，我们可以选择多组比较和“mixed”模式：\n1 2 3 4 5 6 7 cat(\u0026#34;Comparison: \u0026#34;,levels(factor(metadata$Group2))) ## Comparison: G1 G2 G3 reporter_score_res2=reporter_score(KO_abundance,\u0026#34;Group2\u0026#34;,metadata,mode=\u0026#34;mixed\u0026#34;, method = \u0026#34;kruskal.test\u0026#34;,p.adjust.method1 = \u0026#34;none\u0026#34;) plot_KOs_in_pathway(reporter_score_res2,map_id = \u0026#34;map00541\u0026#34;) Details Step by step 一步函数 reporter_score 由三部分组成：\nko.test：此函数有助于通过各种内置方法计算 KO_abundance 的 p-value，例如差异分析（t.test、wilcox.test、kruskal.test、anova）或相关分析（pearson 、spearman、kendall）。 你还可以通过其他方法计算 KO_abundance 的 p-value，例如“DESeq2”、“Edger”、“Limma”、“ALDEX”、“ANCOM”，并自行进行 p值矫正，然后跳过ko.test 步骤转到步骤2… pvalue2zs：该函数将 KO 的 p-value 转换为 Z-score（选择模式: “mixed” 或 “directed”）。 get_reporter_score 该函数计算特定数据库中每个通路的reporter score。 你可以在此处使用自定义数据库。 这样你就可以一步一步得到reporter score。\nOther enrichment methods ReporterScore 还提供了其他丰富方法，如 KO_fisher(fisher.test)、KO_enrich(fisher.test, from clusterProfiler)、KO_gsea (GSEA, from clusterProfiler)，输入数据来自 reporter_score，并且也支持自定义数据库，因此你可以轻松比较各种富集方法的结果并进行全面分析：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 data(\u0026#34;KO_abundance_test\u0026#34;) reporter_score_res2=reporter_score(KO_abundance,\u0026#34;Group\u0026#34;,metadata,mode=\u0026#34;mixed\u0026#34;) #View(reporter_score_res2$reporter_s) #reporter_score reporter_score_res2$reporter_s$p.adjust=p.adjust(reporter_score_res2$reporter_s$p.value,\u0026#34;BH\u0026#34;) filter(reporter_score_res2$reporter_s,(ReporterScore)\u0026gt;1.64,p.adjust\u0026lt;0.05)%\u0026gt;%pull(ID)-\u0026gt;RS #fisher ko_pvalue=reporter_score_res2$ko_pvalue fisher_res=KO_fisher(ko_pvalue) filter(fisher_res,p.adjust\u0026lt;0.05)%\u0026gt;%pull(ID)-\u0026gt;Fisher #enricher enrich_res=KO_enrich(ko_pvalue) filter(enrich_res,p.adjust\u0026lt;0.05)%\u0026gt;%pull(ID)-\u0026gt;clusterProfiler #GESA set.seed(1234) gsea_res=KO_gsea(ko_pvalue) filter(gsea_res@result,p.adjust\u0026lt;0.05)%\u0026gt;%pull(ID)-\u0026gt;GSEA venn_res=list(RS=RS,Fisher=Fisher,CP=clusterProfiler,GSEA=GSEA) library(pcutils) venn(venn_res) 1 venn(venn_res,\u0026#34;network\u0026#34;,vertex.label.cex=c(rep(1,4),rep(0.5,22))) KO levels KEGG BRITE 是一个层次分类系统的集合，捕获各种生物对象的功能层次结构，特别是那些表示为 KEGG 对象的功能层次结构。\n我们收集了 k00001 KEGG Orthology (KO) 表，以便你可以总结每个级别的丰度。 使用 load_KO_htable 获取 KO_htable 并使用 update_KO_htable 进行更新。 使用 up_level_KO 可以升级到“pathway”、“module”、“level1”、“level2”、“level3”、“module1”、“module2”、“module3”之一中的特定级别。\n1 2 load_KO_htable() head(KO_htable) ## # A tibble: 6 × 8 ## level1_id level1_name level2_id level2_name level3_id level3_name KO_id ## \u0026lt;chr\u0026gt; \u0026lt;chr\u0026gt; \u0026lt;chr\u0026gt; \u0026lt;chr\u0026gt; \u0026lt;chr\u0026gt; \u0026lt;chr\u0026gt; \u0026lt;chr\u0026gt; ## 1 A09100 Metabolism B09101 Carbohydrate meta… map00010 Glycolysis… K008… ## 2 A09100 Metabolism B09101 Carbohydrate meta… map00010 Glycolysis… K124… ## 3 A09100 Metabolism B09101 Carbohydrate meta… map00010 Glycolysis… K008… ## 4 A09100 Metabolism B09101 Carbohydrate meta… map00010 Glycolysis… K250… ## 5 A09100 Metabolism B09101 Carbohydrate meta… map00010 Glycolysis… K018… ## 6 A09100 Metabolism B09101 Carbohydrate meta… map00010 Glycolysis… K068… ## # ℹ 1 more variable: KO_name \u0026lt;chr\u0026gt; 1 plot_KO_htable() 1 2 KO_level1=up_level_KO(KO_abundance,level = \u0026#34;level1\u0026#34;,show_name = TRUE) pcutils::stackplot(KO_level1[-which(rownames(KO_level1)==\u0026#34;Unknown\u0026#34;),]) Reference Patil, K. R. \u0026amp; Nielsen, J. Uncovering transcriptional regulation of metabolism by using metabolic network topology. Proc Natl Acad Sci U S A 102, 2685–2689 (2005).\nL. Liu, R. Zhu, D. Wu, Misuse of reporter score in microbial enrichment analysis. iMeta. 2, e95 (2023).\nhttps://github.com/wangpeng407/ReporterScore\n","date":"2023-07-04T00:00:00Z","image":"/p/reporterscore-package/index.en_files/figure-html/unnamed-chunk-7-1_hu_5225f4d481c55d1f.png","permalink":"/p/reporterscore-package/","title":"使用ReporterScore包进行富集分析"},{"content":"pctax pctax provides a comprehensive suite of tools for analyzing microbiome data.\nInstall 1 2 3 4 install.packages(\u0026#34;devtools\u0026#34;) devtools::install_github(\u0026#39;Asa12138/pcutils\u0026#39;,dependencies=T) devtools::install_github(\u0026#39;Asa12138/pctax\u0026#39;,dependencies=T) Usage It includes functionalities for α-diversity analysis, β-diversity analysis, differential analysis, community assembly, visualization of phylogenetic tree and functional enrichment analysis\u0026hellip;\nLook at the test data:\n1 2 3 4 5 6 7 8 library(pctax) library(pcutils) data(otutab,package = \u0026#34;pcutils\u0026#34;) #help(otutab) head(otutab) head(metadata) head(taxonomy) α-diversity analysis Calculate a_diversity of otutab then link to experiment group or environment variable.\n1 2 3 a_diversity(otutab)-\u0026gt;a_res plot(a_res,metadata,\u0026#34;Group\u0026#34;) plot(a_res,metadata,\u0026#34;env1\u0026#34;) β-diversity analysis There are a range of dimensionality reduction methods available for analysis, including Constrained and non-Constrained.\nLike PCA, PCoA, NMDS, RDA, CCA\u0026hellip; For example:\nPCA:\n1 2 3 b_analyse(otutab,method = \u0026#34;pca\u0026#34;)-\u0026gt;b_res plot(b_res,\u0026#34;Group\u0026#34;,metadata,bi = T,rate=0.5) plot(b_res,\u0026#34;Group\u0026#34;,metadata,mode = 3) RDA:\n1 2 3 4 env=metadata[,6:10] #RDA myRDA(otutab,env)-\u0026gt;phy.rda RDA_plot(phy.rda,\u0026#34;Group\u0026#34;,metadata) Differential analysis There are also lots of statistic methods for differential analysis: ALDEX, ANCOM2, randomForest, t.test, wilcox.test\u0026hellip; or deseq2, limma\u0026hellip;(Commonly used in transcriptome)\n1 2 3 diff_da(otutab,metadata[\u0026#34;Group\u0026#34;])-\u0026gt;res volcano_p(res) volcano_p(res,mode=2) Community assembly Community assembly in microbiome refers to the processes that shape the composition, diversity, and structure of microbial communities in a particular environment or host. Microbiome consist of diverse microbial populations that interact with each other and their surroundings, and understanding how these communities assemble is crucial for comprehending their ecological dynamics and functional implications.\n1 2 ncm(otutab)-\u0026gt;ncm_res plot(ncm_res) Phylogenetic tree 1 2 ann_tree(taxonomy,otutab)-\u0026gt;tree easy_tree(tree,add_abundance=FALSE) Cite Please cite:\nChen P (2023). pctax: Professional Comprehensive Microbiome Data Analysis. R package, https://github.com/Asa12138/pctax.\n","date":"2023-06-20T00:00:00Z","image":"/p/r-pctax/index.en_files/figure-html/rda-1_hu_39a47c04abfeecf3.png","permalink":"/p/r-pctax/","title":"R微生物组分析流程（pctax包）"},{"content":" 我自己在用R做各种分析时有不少需要反复用到的基础功能，比如一些简单的统计呀，画一些简单的图如柱形图，箱形图等等，虽说具体实现的代码也不麻烦，但有一些细节如给箱形图加上显著性分组，将柱形图按照metadata合并或分面等事情还是不太想每次用的时候去找之前的代码。\n索性将常用的各种函数整成了一个包：pcutils， 网址：https://github.com/Asa12138/pcutils\n最近也成功将pcutils提交到CRAN了。将包提交到CRAN或Bioconductor也是一件有意思的事（有机会下次讲讲）。\n但目前还是建议从github安装，包含的功能会多一些:\n1 2 install.packages(\u0026#34;devtools\u0026#34;) devtools::install_github(\u0026#39;Asa12138/pcutils\u0026#39;,dependencies=T) 当然，今天主要要来讲的是柱形图以及其各种变换形式图形的绘制。\nIntroduction 柱形图（Bar chart）是一种常用的数据可视化图表，用于展示离散类别数据的分布和比较不同类别之间的数量或频率关系。柱形图通过在水平或垂直轴上绘制矩形柱来表示数据。\n在柱形图中，每个类别对应一个矩形柱，其高度表示该类别的数据量或频率。类别通常显示在水平轴上，而数量或频率则显示在垂直轴上。矩形柱的宽度通常是固定的，相互之间没有间隔，这样便于比较不同类别之间的差异。\n柱形图常用于以下情况：\n展示不同类别的数量或频率关系。 比较多个类别之间的数据。 强调特定类别的重要性或异常值。 之前强力推荐过的绘图教程网站：https://r-graph-gallery.com/ ，上面也提供了很多柱形图从基础到不断美化的画法：\nFrom data to Viz 示例柱形图 From data to Viz 示例柱形图2 再次建议大家在上面看看具体实现的代码。\nPlot Stackplot 因为常做的是微生物组等组学数据的分析，所以一般会用到两个表，一个是abundance table（行为基因名/物种名，列为样本名），另一个是metadata（行为样本名，列为各种实验分组或表型数据）， 要做的柱形图也经常是堆积柱形图，用来看composition的情况。\n我们都知道要用ggplot画图，一般都要把我们的表格从宽格式变为长格式， 具体的转换方法也有很多，我常用的是reshape2的melt， 但是柱形图太常用了，我便把格式转换和分组映射包含在了函数stackplot中，方便自己的每一次画图。\n1 2 3 4 5 6 7 8 library(pcutils) library(ggplot2) #?stackplot data(otutab) #将species level表上升到class level class=hebing(otutab,taxonomy$Class,1,\u0026#34;sum\u0026#34;) head(class) ## NS1 NS2 NS3 NS4 NS5 NS6 WS1 WS2 WS3 WS4 WS5 WS6 CS1 CS2 ## c__Acidobacteria_Gp10 0 10 2 12 0 0 15 0 27 0 36 11 30 0 ## c__Acidobacteria_Gp11 9 0 15 0 7 8 21 0 2 0 5 10 1 12 ## c__Acidobacteria_Gp17 8 12 3 4 7 0 11 4 0 12 9 9 11 14 ## c__Acidobacteria_Gp25 11 18 2 0 3 0 0 0 2 5 9 5 3 0 ## c__Acidobacteria_Gp3 13 0 10 0 12 18 16 14 14 0 20 12 8 5 ## CS3 CS4 CS5 CS6 ## c__Acidobacteria_Gp10 20 13 3 19 ## c__Acidobacteria_Gp11 9 0 0 0 ## c__Acidobacteria_Gp17 3 16 0 14 ## c__Acidobacteria_Gp25 23 0 3 6 ## c__Acidobacteria_Gp3 8 0 10 9 ## [ reached 'max' / getOption(\u0026quot;max.print\u0026quot;) -- omitted 1 rows ] 1 head(metadata) ## Id Group env1 env2 env3 env4 env5 env6 ## NS1 NS1 NS 3.057248 10.23571 5.554576 8.084997 25.00795 -1.15456682 ## NS2 NS2 NS 4.830219 11.13453 5.613455 8.556829 16.67690 0.81168745 ## NS3 NS3 NS 3.753133 10.06232 5.582916 10.226572 21.68926 1.40733211 ## NS4 NS4 NS 4.262264 10.84401 5.258419 9.002256 24.81046 1.47805320 ## NS5 NS5 NS 2.476135 7.52584 6.255314 9.357587 19.70553 0.05813095 ## NS6 NS6 NS 5.131004 10.82761 5.180966 8.141506 18.39021 -1.70032569 ## lat long ## NS1 38.72412 118.2493 ## NS2 38.31086 115.2322 ## NS3 36.82439 118.1361 ## NS4 37.59774 117.1563 ## NS5 35.94188 118.9504 ## NS6 37.68713 116.2984 1 2 #基础绘制，无分组信息，单纯展示每个样本Top7的相对丰度,Top7以外的自动归为Other stackplot(class,legend_title =\u0026#34;Class\u0026#34;)+scale_fill_manual(values =get_cols(10)) 1 2 3 #按分组合并丰度值，展示合并后的相对丰度变化 stackplot(class, metadata, group = \u0026#34;Group\u0026#34;,legend_title =\u0026#34;Class\u0026#34;)+ scale_fill_manual(name=\u0026#34;Class\u0026#34;,values =get_cols(10)) 1 2 3 4 #geom_bar可指定的参数可以传入bar_params中 stackplot(class, metadata, group = \u0026#34;Group\u0026#34;,bar_params = list(position=position_dodge()), legend_title =\u0026#34;Class\u0026#34;)+ scale_fill_manual(values =get_cols(10)) 1 2 3 #展示每一个部分的数字？number = T stackplot(class, metadata, group = \u0026#34;Group\u0026#34;,number = T)+ scale_fill_manual(name=\u0026#34;Class\u0026#34;,values =get_cols(10)) 1 2 3 #如果想把分组中的单个样本展示出来的话，可以设置style = \u0026#34;sample\u0026#34; stackplot(class, metadata, group = \u0026#34;Group\u0026#34;,style = \u0026#34;sample\u0026#34;)+ scale_fill_manual(name=\u0026#34;Class\u0026#34;,values =get_cols(10)) 1 2 3 #如果想看的是绝对量而不是相对丰度：relative = F stackplot(class, metadata, group = \u0026#34;Group\u0026#34;,style = \u0026#34;sample\u0026#34;,relative = F)+ scale_fill_manual(name=\u0026#34;Class\u0026#34;,values =get_cols(10)) 1 2 3 #我们有时候可以希望按照某个物种/基因的丰度排序，设置group_order： stackplot(class, metadata, group = \u0026#34;Id\u0026#34;,group_order = \u0026#34;c__Actinobacteria\u0026#34;)+ scale_fill_manual(name=\u0026#34;Class\u0026#34;,values =get_cols(10)) 1 2 3 #或者是直接更改每一个fill的上下顺序，设置stack_order： stackplot(class, metadata, group = \u0026#34;Id\u0026#34;,stack_order = \u0026#34;Other\u0026#34;)+ scale_fill_manual(name=\u0026#34;Class\u0026#34;,values =get_cols(10)) 1 2 3 #或是做出流动的效果，时间数据最佳：flow=T stackplot(class, metadata, group = \u0026#34;Id\u0026#34;,group_order = \u0026#34;c__Actinobacteria\u0026#34;,flow = T)+ scale_fill_manual(name=\u0026#34;Class\u0026#34;,values =get_cols(10)) Polar coordinate ggplot2没有提供直接绘制饼图的geom对象，但柱形图可以通过极坐标变换生成饼图或环形图等图形，使用coord_polar()函数可以实现极坐标变换。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 library(ggplot2) # 创建示例数据 data \u0026lt;- data.frame( category = c(\u0026#34;A\u0026#34;, \u0026#34;B\u0026#34;, \u0026#34;C\u0026#34;, \u0026#34;D\u0026#34;), value = c(30, 20, 15, 35) ) # 绘制饼图 p \u0026lt;- ggplot(data, aes(x = \u0026#34;\u0026#34;, y = value, fill = category)) + geom_bar(width = 1, stat = \u0026#34;identity\u0026#34;) + theme_void() # 显示图形 p 1 p+coord_polar(theta = \u0026#34;y\u0026#34;) 为了方便自己日常使用，我将这一类通过柱形图极坐标变换得到的图形整合进了gghuan函数中：\n1 2 3 4 #help(gghuan) #输入数据格式很简单第一列是类别，第二列是数字（对应的某个值）即可。 a=data.frame(type = letters[1:6], num = c(1, 3, 3, 4, 5, 10)) gghuan(a) + scale_fill_manual(values = get_cols(6, \u0026#34;col3\u0026#34;)) 1 2 3 4 #大胆调节每一个设置 gghuan(a,bar_params=list(col=\u0026#34;black\u0026#34;), text_params=list(col=\u0026#34;#b15928\u0026#34;,size=3), text_params2=list(col=\u0026#34;#006d2c\u0026#34;,size=5))+scale_fill_manual(values = get_cols(6, \u0026#34;col3\u0026#34;)) 1 2 3 #改变绘图风格：mode=1~3 #mode=3就是饼图 gghuan(a,mode=3) + scale_fill_manual(values = get_cols(6, \u0026#34;col3\u0026#34;)) 1 2 #mode=2就是环状柱形图，相当于coord_polar(theta = \u0026#34;x\u0026#34;)的变换 gghuan(a,mode=2) + scale_fill_manual(values = get_cols(6, \u0026#34;col3\u0026#34;)) 多层的环形图一般用来画具有某种层次关系的表格，比如物种分类信息。\n下面使用函数gghuan2来完成多层环形图绘制:\n1 2 3 #提供一个具有一定层级关系的表格（除最后一列外有多少列就有多少个环，最后一列为丰度） cbind(taxonomy,num=rowSums(otutab))[1:10,c(1:3,8)]%\u0026gt;%dplyr::arrange_all()-\u0026gt;test head(test) ## Kingdom Phylum ## s__un_g__Actinoplanes k__Bacteria p__Actinobacteria ## s__Lentzea_flaviverrucosa k__Bacteria p__Actinobacteria ## s__un_g__Streptomyces k__Bacteria p__Actinobacteria ## s__un_f__Thermomonosporaceae k__Bacteria p__Actinobacteria ## s__Flavobacterium_terrae k__Bacteria p__Bacteroidetes ## s__un_g__Rhizobium k__Bacteria p__Proteobacteria ## Class num ## s__un_g__Actinoplanes c__Actinobacteria 8518 ## s__Lentzea_flaviverrucosa c__Actinobacteria 9508 ## s__un_g__Streptomyces c__Actinobacteria 10813 ## s__un_f__Thermomonosporaceae c__Actinobacteria 26147 ## s__Flavobacterium_terrae c__Flavobacteriia 16484 ## s__un_g__Rhizobium c__Alphaproteobacteria 7789 1 gghuan2(test,percentage = F)+scale_fill_manual(values = get_cols(10)) 这个多层环形图长得跟旭日图也比较像了,不过想画旭日图的话也可以用my_sunburst函数， 输入的数据格式仍然相同：\n1 my_sunburst(test) Streamgraph 我们前面已经用stackplot设置flow=T实现了在柱形图的分割间加上了连接的线， 那我们进一步想想,如果这个连接的线扩展到整个柱子，而柱子越来越细时，就成了一个面积图（areaplot）:\n1 areaplot(class,legend_title =\u0026#34;Class\u0026#34;)+scale_fill_manual(values =get_cols(10)) 更有意思的是，如果连接的线是曲线，并且流动的曲线扩展到整个柱子，就能画出流动图（河流图，Streamgraph）了。\n这里用streamgraph包的例子\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 #Install #devtools::install_github(\u0026#34;hrbrmstr/streamgraph\u0026#34;) library(streamgraph) # Create data: data \u0026lt;- data.frame( year=rep(seq(1990,2016) , each=10), name=rep(letters[1:10] , 27), value=sample( seq(0,1,0.0001) , 270) ) # Basic stream graph: just give the 3 arguments pp \u0026lt;- streamgraph(data, key=\u0026#34;name\u0026#34;, value=\u0026#34;value\u0026#34;, date=\u0026#34;year\u0026#34;, height=\u0026#34;300px\u0026#34;, width=\u0026#34;1000px\u0026#34;) pp Sankey 如果我们的数据是每个柱子间有联系的（层级关系或其他包含关系均可），用柱子间的面作为这种通量的量化， 我们就得到了一个这样的图形，\n1 my_sankey(test,mode = \u0026#34;gg\u0026#34;) 如果柱子之间再拆开一点的话，这便是我们熟悉的桑基图了：\n1 my_sankey(test,mode = \u0026#34;gg\u0026#34;,space = 1e4) 总之，一个简单的柱形图也可以变化出各式各样的衍生图形。\n但所有的可视化方法都是为展示数据服务的， 我整合这些函数也是希望可以更关注数据本身，花更少的精力在调节图形上，先快速对我们的数据有整体的把握。\npcutils的初衷还是迎合我自己的编程与数据分析习惯的，所以可能并不适合所有人，大家也可以直接fork并修改我的源码，欢迎大家提出建议与意见。\n","date":"2023-06-19T00:00:00Z","image":"/p/r-bar-chart/images/barchart_hu_62b89ecfad6d1777.png","permalink":"/p/r-bar-chart/","title":"R绘制柱形图及其变换"},{"content":"Introduction 2023.5.20-5.22，本人有幸参加了2023肠道大会，“CHINAGUT 2023系列活动”，这是我博士期间参加的第一个学术会议，怀着开阔眼界，见识科学前沿，学习新方法新技术的心态，听完了三天的报告，认识了一些大佬，收获颇丰。\n大会持续秉承”爱肠道、爱学习、爱整合”的永久主题，拟设立超过30个学术会场，深度研讨微生物组、医药转化、营养与食品、动物肠道、免疫、 代谢、神经、生理与发育、肿瘤、炎症性肠病、整合肠病学、特殊人群、技术方法、同一健康等科学问题。\n在此记录一些我印象较深，和我研究方向相关的报告。\n组学实验技术 临床低生物量微生物组 香港大学黄适博士报告\n近年来,微生物组不仅在粪便、口腔、皮肤等位点，而且在多种人体组织样品中被发现，揭示其在慢性疾病发生过程中发挥的关键作用。但是，这些样品的低生物量或者高宿主DNA污染的特征使得在株水平分析人体微生物组变得更加具有挑战性、甚至难以实现。\n在当前微生物组研究中，解析微生物群落的物种构成主要依赖于两种高通量研究技术：\n扩增子测序（16S/18S/ITS）存在扩增偏好性、脱靶扩增、分辨率低等问题，且无法同时检测细菌、真菌、古菌。\n鸟枪宏基因组测序（WMS），虽然鸟枪宏基因组测序可以有效避免上述问题，但该方法对样本DNA质量要求高，面对大规模临床样本容易受到成本限制，且不适合于检测含有大量宿主DNA的样本，如石蜡切片、肿瘤切片、肿瘤组织等样品检测。\n2bRDA 实验与分析流程 他们开发了一种简化宏基因组方法（2bRAD）(1)，主要利用IIB型内切酶实现捕获约1%的基因组序列进行DNA测序，因而增加了每个微生物基因组覆盖度，从而实现高精度分析低生物量微生物组的目标。\n配套生信分析流程（Strain2bFunc）用于株水平鉴定和丰度估计分析。\n壁报：Strain-resolved Taxonomic Profiling And Functional Prediction Of Human Microbiota Using Strain2bfunc-2023肠道大会 (chinagut.cn)\n2bRDA 准确度评估 目前感觉缺点是类似16S，只关心物种组成，没有考虑真正的功能信息（鸟枪法能够做到），但是临床低生物量的应用还是非常不错。\nMetaproteomics 李乐园老师报告：深度宏蛋白质组揭示人肠道微生物群蛋白质水平功能冗余度 (chinagut.cn)\n宏蛋白组（metaproteomics）是一种研究微生物群落中蛋白质组的方法。与宏基因组学类似，宏蛋白组学关注的是微生物群落中所有微生物的蛋白质组成。它通过分析和识别微生物群落中的蛋白质，旨在揭示微生物群落的功能和代谢活动。\n宏蛋白组学涉及从样品中提取蛋白质，对蛋白质进行消化（例如使用胰蛋白酶将蛋白质分解为肽段），然后使用质谱技术（如液相色谱-质谱联用，LC-MS/MS）对这些肽段进行分析和鉴定。通过与数据库中的蛋白质序列进行比对和注释，可以确定微生物群落中存在的蛋白质，并进一步了解其功能、代谢通路和生物学特征。\n之前有一篇Nature Ecology \u0026amp; Evolution 文章中提到 (2)：\n群落构建似乎是基于功能基因而不是物种进行的\n功能冗余度是生态系统的关键性质。在生态系统中，不同物种通过表达冗余的功能发挥类似的生态作用。宏基因组数据已被用于人体微生物组功能潜力的冗余度（即基因组水平冗余度FR_g）定量。\n在这次会上，李老师提出了量化微生物组的蛋白质水平功能冗余度FR_p的方法，功能冗余度是一个高度综合性的指标，由功能是否表达、功能蛋白质丰度、功能的分类学来源多因素综合影响。在检测群落对环境因素响应方面，与目前广泛采用的多样性指标相比更为灵敏（目前好像还没找到发表的资料）。\n单细胞微生物组 一篇cell综述总结展望了单细胞微生物组技术 (3)： 总体分析步骤是样品单细胞分离-\u0026gt;培养/功能表征与筛选/测序/荧光\n微生物单细胞技术挑战：\n细胞小 环境：好氧性、竞争、污染 细胞聚集、结块 核酸量少 mRNA无ployA结构 单细胞分离培养技术（主要还是微流控/孔板法）：\n拉曼组 又听到了一个新概念和新技术。\n徐健老师团队提出，“拉曼组”（ramanome）作为一种单细胞精度代谢表型组，有三大内涵：\n每个拉曼组是在特定条件和时间点下一个细胞群体中采集的N个单细胞拉曼光谱的集合，体现的是该细胞群体的”单细胞代谢功能集体照”；\n每张单细胞拉曼光谱上超过1500个拉曼谱峰中，因每个峰或峰的组合均可能代表一个代谢表型（phenotype），故揭示了该细胞在该状态下的代谢表型组；\n一个拉曼组内部的不同单细胞拉曼光谱之间具有与生俱来的异质性，而且这种细胞间差异具有重要的生物学意义。\n已经证明，拉曼组能在单细胞精度，定量检测细胞利用含氢、含碳等底物的代谢速率、测定各种拉曼敏感产物（色素、甘油三酯、淀粉、蛋白等）之多样性及其含量、表征细胞的环境应激性（如微生物药敏、微生物药物应激机制、肿瘤药敏性与药物应激机制等）、检测细胞之间的代谢互作、重建细胞内代谢物相互转化网络（拉曼组内关联分析；IRCA）、也可区分不同的物种。拉曼组能够测量的代谢表型范围仍在不断拓展中。\n针对微生物组样品，运用整合了RAGE技术的RACS-Seq仪器，也实现了临床实际样品（包括尿液、胃粘膜等）或复杂环境（土壤、海水等）菌群中精确到一个细菌细胞的原位代谢功能识别及其对应高质量单细胞基因组的解析。\n单细胞测序 报告：高通量单细胞微生物基因组学 — Microbe-seq (chinagut.cn)\n单细胞测序的挑战：\n微生物群落组成复杂：将单个细胞分离 单菌起始DNA仅1个拷贝：全基因组扩增 背景噪音大：提高信噪比，例如缩小反应体积 群落细胞和物种多样：高通量分析 细胞壁裂解和其他流程不兼容：多步法反应 郑文山老师介绍的Micro-seq技术 (4)：一种基于液滴微流控的高通量单细胞微生物基因组测序技术，将该技术应用于人体肠道微生物样本中。通过对超过2万个单微生物进行测序，组装出了76个物种的基因组，并从10个物种中分辨出多个菌株并对其菌株水平基因组进行组装。在此基础上，构建了人体肠道微生物水平基因转移（HGT）网络并观察到92个不同物种间的HGT。\n非常酷的技术，也肯定是未来微生物组的研究趋势。\n微生物单细胞测序应用与发展：\n通过对28份水样，12715个微生物细胞进行单细胞测序：\n发现细胞与细胞间的基因变异非常常见，指出这对传统的宏基因组分箱分析方法来带巨大挑战。 阐述了C/N代谢、次级代谢合成途径在不可培养微生物重的进化。 构建了海洋浅表层丰富的微生物基因组数据库（GORG-Tropics）。 P. Ma, H. M. Amemiya, et.al, Bacterial droplet-based single-cell RNA-seq reveals antibiotic-associated heterogeneous cellular states. Cell. 186, 877-891.e14 (2023)\n开发了BacDrop，一种高度可扩展的细菌单细胞 RNA 测序技术，它克服了许多阻碍细菌 scRNA-seq 发展的挑战。\n通过对肺炎克雷伯菌在有/无抗生素扰动时的群落内异质性研究:\n发现种群内异质性主要是由促进抗生素耐药性的移动遗传原件的表达驱动。 细菌耐药性的进化可能来源由于高表达MGE基因的亚群 生信分析软件\u0026amp;方法 KMCP 这是沈伟/任红团队开发兼顾原核生物和病毒的宏基因组物种组成分析软件，文章发表在bioinformatics上 (5)，taxonkit这个好用的工具也是他们做的。\n壁报：KMCP: accurate metagenomic profiling of both prokaryotic and viral populations by pseudo-mapping-2023肠道大会 (chinagut.cn)\nKMCP 算法与流程 算法方面我不是特别懂：\nKMCP先将每个微生物基因组分割成n（默认10）等份，每份称为基因组区块（genome chunk）。每个基因组区块的所有k-mer用一个布隆过滤器（Bloom filter）保存，所有Bloom filter保存在一个改进的COBS索引中。\n在reads搜索的时候，将查询序列的所有k-mer去和数据库中所有的Bloom filter比较，返回具有一定共有k-mer数量的基因组区块。\n最终可以知道查询序列与哪些基因组的哪个基因组区块有较高相似度，这个过程称为pseudo-mapping。\n搜索完成后，匹配的参考基因组经过三轮过滤筛选（过滤条件包括k-mer相似性信息与基因组覆盖信息），最后再使用Expectation-Maximization（EM）算法估算匹配的参考基因组的相对丰度。\nKMCP 性能评估 优点：\n看起来建库非常方便（基因组序列库和分类库）。 当参考基因组由来自GTDB的原核生物和来自NCBI的真菌和病毒组成时，还可以合并GTDB和NCBI分类学数据。 KMCP搜索速度与基因组区块的数量线性相关，而且所有基因组区块的索引数据相互独立，用户可以将参考基因组分为多个较小的部分，每个分布分别创建数据库并用来搜索，时间可能长一些，但是内存占用少，时间换空间的策略。 KMCP 准确度评估 在种水平，KMCP优于其它工具：KMCP的Completeness（Recall,召回率，0.915）比Bracken（0.944）略低，比其他都高；而KMCP的Purity（Precision，精确度，0.830）比mOTUs2（0.887）和DUDes（0.871）低。在相对丰度上，KMCP的L1 norm error（越低越好）在属水平排在第二低，而在种水平最低，优于其它软件。\n目前我用的比较多的都是kraken，运行速度快，但是需要将整个数据库导入内存（还好我们的集群目前够大），未来很可能用上，先码住。\nFlex Meta-Storms 壁报：Flex Meta-Storms elucidates the microbiome local beta-diversity under specific phenotypes-2023肠道大会 (chinagut.cn)\nBeta多样性能够量化微生物群落之间的差异，从而揭示微生物组组成与环境特性或宿主表型之间的关联。Beta多样性分析所依赖的群落间的距离，目前均采用所有微生物特征来计算。\n然而，在某些情况下，群落中只有一小部分成员发挥着关键作用。这么小的比例不足以影响和改变整体距离。另一方面，当只关注其中一小部分微生物时，由于数据稀疏性，Beta多样性模式也会受到干扰。\n开发了Flex Meta-Storms (FMS) 距离算法，该算法首次实现了微生物组的”局部对齐”。 采用一种基于微生物加权系统发育和功能关系的特征”弹性提取”策略，FMS能够计算复杂微生物组之间，所关注的群落成员之间标准化的系统发育距离。我们展示了FMS 在使用人工和真实数据集检测不同状态下微生物组的细微变化方面的优势，而这些变化会被常规距离度量所忽略。因此，FMS能够以更高的灵敏度和灵活性有效区分不同状态下的微生物组，从而有助于深入理解微生物与宿主的相互作用，并促进微生物组数据在疾病筛查和预测等方面的利用。\n地址：qdu-bioinfo/flex-meta-storms: Flex Meta-Storms (FMS) can mine potential relationships generated by a small subset of microbes in community samples. (github.com)\n我之前以为感兴趣的直接提出来再做降维分析即可😂，看来想的太简单了\nDKI 刘洋彧老师现任哈佛大学医学院副教授，在美国东北大学物理系和复杂网络研究中心先后担任博士后，他实验室 (https://yangyuliu.bwh.harvard.edu) 目前的研究重点是从群落生态学，网络科学，控制论，和机器学习等多个角度研究复杂微生物群落，尤其关注人类微生物组的一系列根本性问题以及人类微生物组在疾病治疗和精准营养上的应用目前的研究重点是从群落生态学，网络科学，控制论，和机器学习等多个角度研究复杂微生物群落，尤其关注人类微生物组的一系列根本性问题以及人类微生物组在疾病治疗和精准营养上的应用。\n报告：在微生物群落中寻找基石物种 (chinagut.cn)\n微生物群落中含有基石物种，去除这些基石物种会导致微生物组结构和功能发生巨大变化。然而，我们仍然缺乏一种有效的方法来系统地识别微生物群落中的基石物种。\n我们之前经常在网络分析中见到这个概念 (6)，通过计算生态网络中每个物种的拓扑指标反映keystone。\n而这里刘老师提到，网络分析中的keystone有些问题：\nA recent numerical study claimed that those highly connected species (i.e., “hubs”) in the microbial correlation network are keystone species of microbial communities. We think this claim is problematic for at least two reasons.\n首先，微生物相关网络中的边并不代表直接的生态相互作用，而只是具有统计学意义的物种共现或相互排斥。 其次，物种迁移的影响自然取决于群落。这强调了基石物种识别的根本挑战——群落特异性，基于微生物相关网络中的枢纽（由一组微生物组样本构建）或生态网络中的任何拓扑指数（从实验数据推断出有针对性的种间相互作用）来识别关键物种完全忽略了这种群落特异性。\n刘洋彧老师提出一种基于深度学习和数据驱动的基石物种识别框架（DKI，Data-driven Keystone species Identification）。核心想法是用从某特定环境中收集的大量的微生物组样本来训练一个深度学习模型，从而隐式地学习该环境中微生物群落的组装规则。训练好的深度学习模型可以帮我们通过进行物种清除的假想实验来量化来自该环境中的任何微生物组样本中任何物种的基石性（keystoneness）。\n目前文章还是preprint (7)，主要的工作流程如下：\nDKI 工作原理 考虑一个特定的栖息地（或宏群落），包含不同微生物物种。假设我们从这个栖息地收集了大量微生物组样本。每个微生物组样本可以被视为栖息地的本地群落。样本的物种组合可以用二元向量表示，如果物种在某个样本存在（或不存在）。而该样本的微生物组成或分类学特征由组成向量表征，其中每个条目表示物种的相对丰度。假设收集的样本大致代表当地社区的稳定状态，以便它们可用于学习这些群落的构建规则。\n在第一阶段（图 1a），我们使用深度学习方法以训练数据隐式学习该栖息地微生物群落的组装规则。\n在第二阶段（图 1b），为了量化某一个物种i在当地群落或微生物组样本中的群落特异性基石性。我们可以这样考虑，一个是保留物种i的二元数据，使用cNODE2计算最终的群落组成，再删除i重新计算相对丰度得到零模型的群落组成。另一个则是直接删除i的二元数据，使用cNODE2计算最终的群落组成。\n然后便可以比较两者来量化移除物种i造成的影响：通过组成变化和功能变化来量化。具体的算法和公式可以阅读原文章了解。\nDKI vs co-network 这个DKI模型也在广义 Lotka-Volterra的模拟群落中进行了验证。发现DKI框架计算的keystoneness和真实的keystoneness相关性很高（左a~f），但是传统网络指标与真实的keystoneness相关性不强（右a~f）。\n随后作者在其他人体或环境栖息地如肠道，口腔，土壤宏基因组数据中运用DKI计算评估了微生物的keystoneness。\nMicrobiome SV 丁涛老师的报告是”从微生物组特征研究肠道肿瘤：更加精确的视角和方法“，但是他提到了基因组的结构变异对于细菌有重要的功能影响 (8)：\n目前看到的应用于宏基因组的结构变异分析还比较少，丁涛老师团队也开发了一个名为MicroSVsProfiler 的框架，但是目前暂未发表，找不到更多资料。\n已有的可以识别细菌基因组SVs的软件有SGVFinder：https://github.com/segalab/SGVFinder。\n有一篇Nature用二代测序专门在人体肠道微生物组做了这个 (9)，利用的是已有的基因组数据作为参考基因组，里面提到了 SVs 富含 CRISPR 相关和产生抗生素的功能的基因，而管家基因比较少，表明它们在微生物适应中发挥作用。\n然后又有一篇NC 结合二三代测序做了SV检测 (10)，通过利用 Oxford Nanopore Technology (ONT) 提供的长读长优势，鉴定肠道微生物组中结构变异 (SV) 的精细遗传变异，这里他们用的是MAG作为参考基因组。也提到了在 SV 中，前噬菌体和高度可变的 CRISPR 元件占很大比例。\n我觉得现在测序数据那么多，还是很值得进一步从基因组结构，进化角度进一步挖掘的。\n土壤与环境 在肠道大会听土壤介绍(有点神奇😂)，但有个老师说得好：土壤就像地球的肠道一样，集中了很多的微生物与功能基因，是一个资源宝库，所以也合理。\n这次大会上基本是跟农田相关的报告，而且大多是实验假设驱动的微生物研究，如退化农田，植物多样性，施肥，堆肥等实验条件对土壤表层微生物组或根际微生物组的影响。\n分析方法也较为传统：多样性、群落演替、群落稳定性（生态网络）等等，功能基因关注ARG，固氮潜能等，当然一般会做一些实验验证。\n有一个壁报倒是关注元素循环多一些：\nMetagenomic insights into the sustainability of the rice-crayfish co-culture model: from the perspective of microbial biogeochemical cycling-2023肠道大会 (chinagut.cn)\n研究的是稻虾共生模型（RCFP，rice-crayfish co-culture model），对水体、土壤、虾肠道都进行了微生物组测序，主要结果有：\n碳 (C) 循环 RCFP 在生境环境中具有更强的碳水化合物代谢能力，但在小龙虾肠道中没有。 氮 (N) 循环 RCFP 在N 同化和N 污染去除方面具有优势，而非RCFP 具有更高的N 分解和反硝化能力。 RCFP 具有较高的N同化和N污染物（如NO、N、O）去除能力，这与其独特的环境有关。 硫 (S) 循环 三个S 途径：同化硫酸盐还原(ASR)、(ASR)、异化硫酸盐还原(DSR) 和SOX 复合物对硫代硫酸盐的氧化。 S-cycling 基因分布在水产养殖模型中差异很大。RCFP 含有较少的 S 相关污染物（例如 H.S）。 在人类相关微生物组倒很少看到关注这些元素循环的，说不定也会有重要作用。\n总结 精力有限，这里先记录下这些。 除了精彩的报告，还有很多亮眼的posters和有趣的产业，出去参加一次大型学术会议对现在的我来说，不仅能够学到不少东西，还能开阔眼界，帮助想到一些新的ideas，看到这么多优秀的同行，自己还是要继续加油呀💪！\nReference 1. Z. Sun, S. Huang, P. Zhu, L. Tzehau, H. Zhao, J. Lv, R. Zhang, L. Zhou, Q. Niu, X. Wang, M. Zhang, G. Jing, Z. Bao, J. Liu, S. Wang, J. Xu, Species-resolved sequencing of low-biomass or degraded microbiomes using 2bRAD-M. Genome Biology. 23, 36 (2022).\n2. S. Louca, M. F. Polz, F. Mazel, M. B. N. Albright, J. A. Huber, M. I. O’Connor, M. Ackermann, A. S. Hahn, D. S. Srivastava, S. A. Crowe, M. Doebeli, L. W. Parfrey, Function and functional redundancy in microbial systems. Nature Ecology \u0026amp; Evolution. 2, 936–943 (2018).\n3. V. Lloréns-Rico, J. A. Simcock, G. R. B. Huys, J. Raes, Single-cell approaches in human microbiome research. Cell. 185, 2725–2738 (2022).\n4. W. Zheng, S. Zhao, Y. Yin, H. Zhang, D. M. Needham, E. D. Evans, C. L. Dai, P. J. Lu, E. J. Alm, D. A. Weitz, High-throughput, single-microbe genomics with strain resolution, applied to a human gut microbiome. Science. 376, eabm1483 (2022).\n5. W. Shen, H. Xiang, T. Huang, H. Tang, M. Peng, D. Cai, P. Hu, H. Ren, KMCP: Accurate metagenomic profiling of both prokaryotic and viral populations by pseudo-mapping. Bioinformatics. 39, btac845 (2023).\n6. S. Liu, H. Yu, Y. Yu, J. Huang, Z. Zhou, J. Zeng, P. Chen, F. Xiao, Z. He, Q. Yan, Ecological stability of microbial communities in Lake Donghu regulated by keystone taxa. Ecological Indicators. 136, 108695 (2022).\n7. X.-W. Wang, Z. Sun, H. Jia, S. Michel-Mata, M. T. Angulo, L. Dai, X. He, S. T. Weiss, Y.-Y. Liu, Identifying keystone species in microbial communities using deep learning (2023), p. 2023.03.15.532858.\n8. M. G. Durrant, A. S. Bhatt, Microbiome genome structure drives function. Nature Microbiology. 4, 912–913 (2019).\n9. D. Zeevi, T. Korem, A. Godneva, N. Bar, A. Kurilshikov, M. Lotan-Pompan, A. Weinberger, J. Fu, C. Wijmenga, A. Zhernakova, E. Segal, Structural variation in the gut microbiome associates with host health. Nature. 568, 43–48 (2019).\n10. L. Chen, N. Zhao, J. Cao, X. Liu, J. Xu, Y. Ma, Y. Yu, X. Zhang, W. Zhang, X. Guan, X. Yu, Z. Liu, Y. Fan, Y. Wang, F. Liang, D. Wang, L. Zhao, M. Song, J. Wang, Short- and long-read metagenomics expand individualized structural variations in gut microbiomes. Nature Communications. 13, 3175 (2022).\n","date":"2023-05-25T00:00:00Z","image":"/p/gut-2023/images/gut2023_hu_3c8f80a009bd2a4d.jpeg","permalink":"/p/gut-2023/","title":"gut 2023 肠道大会个人总结"},{"content":" Introduction 抗生素 抗生素是一类药物，用于治疗或预防由细菌引起的感染。它们通过抑制细菌的生长或杀死细菌，帮助人体抵抗细菌感染。\nAn antibiotic is a type of antimicrobial substance active against bacteria.\n图1: Mechanisms of Antibiotics (YouTube (Antibiotics - Lecture 3)) 抗生素可以通过不同的机制对细菌产生作用。以下是几种常见的抗生素类型及其作用机制（图1）：\n青霉素类抗生素：作用于细菌细胞壁的合成，干扰其结构，导致细菌细胞壁破裂，细菌死亡。\n大环内酯类抗生素：通过阻断细菌蛋白质的合成过程，阻碍细菌的生长和复制。\n氨基糖苷类抗生素：抑制细菌蛋白质的合成，通过与细菌的核糖体结合，阻碍蛋白质合成的进行。\n四环素类抗生素：抑制细菌的蛋白质合成，通过与细菌的核糖体结合，阻碍蛋白质链的延伸。\n氟喹诺酮类抗生素：抑制细菌DNA的复制和转录过程，阻断细菌的生长。\n抗生素抗性 图2: Mechanisms of Antibiotic Resistance (Courtesy of E. Wistrand-Yuen.) 抗生素抗性是指细菌或其他微生物对抗生素的治疗效果降低或完全失效的现象。当细菌暴露在抗生素的作用下，一些细菌可能具有抗药性，能够存活和继续繁殖，导致感染的持续存在或进一步扩散。\nAntibiotic resistance is the ability of a microorganism to withstand the effects of antibiotic(s).\n抗生素抗性可以是天然的，即细菌天生具有抗药性。然而，更为严重的是通过基因突变或水平基因转移等机制，细菌可以获得抗药性。\n同样，为了对付抗生素的作用机制有多种耐药机制，CARD数据库 (1) 将其分为7类：\n导致抗生素耐药性的抗生素靶标的突变改变或酶促修饰。\n抗生素作用靶点的更换或替代，该过程会导致抗生素耐药性。\n保护抗生素作用靶点免受抗生素结合，该过程将导致抗生素耐药性。\n抗生素的酶促灭活赋予耐药性。\n通过将抗生素转运出细胞而产生的抗生素耐药性。\n通常通过减少孔蛋白的产生来降低对抗生素的渗透性，可以提供耐药性。\n基因缺失（通常是孔蛋白）赋予抗生素耐药性的机制。\n抗生素抗性基因（Antibiotics resistance genes，ARGs） 是指存在于细菌或其他微生物基因组中的基因，使它们具有对抗生素的抵抗能力。 这些基因编码了一系列的蛋白质或其他分子机制，使细菌能够对抗生素产生耐药性。\nARG被视为是一种新出现的生物污染物，由ARG引起的抗生素耐药性被认为是当代医学最重要的挑战之一，也是严重的公共卫生问题。抗生素耐药性阻碍了临床上对细菌感染的有效治疗，并成为流行病威胁和高死亡率的原因。\n根据获得的欧盟和欧洲经济活动国家的数据，抗生素抗性细菌（ARB）在2015年造成671,689人感染，每年导致超过33,000人死亡 (2)。\nARGs在环境中的广泛传播提高了其作为污染物的危害性。 抗生素在人类、兽医和农业用途中的大量使用导致它们不断释放到环境中，同时，ARG也被引入各种环境中，如临床（医院、诊所）和兽医环境、人体（胃肠道微生物组）以及废水处理厂和自然环境（土壤、水、空气）等。\n移动遗传元件（MGE）如质粒、转座子、整合子被证明与ARG的转移传播具有很强的相关性 (3)，将 ARG 与移动遗传元件联系起来是十分重要的。\nMethods \u0026amp; Tools 生物信息学在ARG研究上的主要目标是开发分析流程，用于准确检测抗性组（抗性基因的补充延伸）并随后根据基因组和宏基因组数据准确预测抗菌谱（AMR 的表型范围和易感性）以及ARG宿主等信息。\n目前已开发出很多的ARG相关的生物信息学软件工具（表1)和数据库（表2），注释管理不一致，每个工具和数据库都有不同的重点领域和不同的预测范围。\nTools 图3: 宏基因组测序数据ARG分析的工作流程 目前使用宏基因组测序数据对存在于微生物群落中的ARG进行识别鉴定的计算工作流程主要有两种：基于组装的contigs的分析和基于原始reads的比对分析（图3）。\n且大多数方法从宏基因组数据中获得的序列(原始reads或contigs)通常不能明确地确定其属于物种起源，分析的范围通常仅限于基于同源性就能识别的ARG家族，而缺乏高度依赖环境的抗性决定因素，如点突变的分析。\nTable 1: 用于鉴定、预测ARGs的生信软件 软件名 描述 ARG-ANNOT 使用 BLAST 针对抗菌素耐药性 (AMR) 参考序列和 SNP 的精选数据库检测细菌基因组中现有的和假定的新抗生素耐药性基因。 ARGs-OAP 用于从宏基因组序列中快速注释和分类抗生素抗性基因样序列（使用 BLASTX 针对 SARG 数据库）的在线管道。 BacAnt 允许同时注释 ARG、整合子和转座子的，可用于比较基因组分析的应用程序 DeepARG 通过深度学习方法，分别为短读序列和全基因长度序列构建了两个深度学习模型 DeepARG-SS 和 DeepARG-LS，提供了准确的抗菌素耐药性注释。 Mykrobe predictor 快速筛选金黄色葡萄球菌和结核分枝杆菌原始 FASTQ 测序结果中的 AMR 基因和 SNP，并对 12 种抗菌药物进行抗生素谱预测。 ResFinder 通过 BLAST 针对 AMR 参考序列的精选数据库，在全基因组数据中识别水平获得的 AMR 基因。 RGI 根据综合抗生素耐药性数据库 (CARD) 中的同源性和 SNP 模型，从蛋白质或核苷酸数据中预测耐药性组。 SEAR 使用 ARG-ANNOT 数据库检测基因组或宏基因组测序数据中水平获得的 AMR 基因。 SRST 一种快速测序读取映射工具，用于快速准确地检测 MLST、毒力、AMR 或其他标记。包括 ResFinder 和 ARG-ANNOT 参考数据库。 AMRFinder NCBI开发的一种使用高质量精选 AMR 基因参考数据库识别 AMR 基因的工具。 Database 近年来随着ARG数据的快速增长，数据管理、分析和访问需要更完善的数据库来承载。\nARG命名本身就是一个难题，同义词经常使用，名称冲突，基因名称有时基于核苷酸序列有时基于蛋白质序列，一些基因家族使用通用名称，而另一些则命名每个等位基因，加上各种ARG数据库非正式地交换有关 AMR 管理、命名和分类的信息，导致管理较为混乱。\n当然，没有一个ARG数据库是完整的，ARG在各种病原体间移动与突变会增加大量数据，突变数据的管理是最具挑战性的任务。\nTable 2: ARGs综合信息数据库 数据库 描述 ARDB 一个手动管理的数据库，其中每个基因和抗性类型都用抗性概况、作用机制、本体论和序列和蛋白质数据库的外部链接进行注释。自 2009 年以来未更新，所有数据均已整理到 CARD 中。 ARG-ANNOT AMR 参考序列和 SNP 的精选数据库。 CARD 手动管理的抗性基因和突变、其产物和相关表型数据库，涵盖 AMR 的所有机制。由抗生素耐药性本体论 (ARO) 组织管理。 CBMAR 提供对 β-内酰胺酶家族的分子和生化表征有用的信息。 MvirDB 通过整合来自多个来源的数据，专注于对生物防御应用至关重要的毒素、毒力因子和抗生素抗性基因。 NCBI BioProject PRJNA313047 以抗性为重点的 AMR 基因序列整理。 PATRIC 细菌感染性疾病信息系统，以ARDB和CARD为基础，辅以AMR元数据，对完整的病原体基因组进行注释。 Resfams 蛋白质家族和相关配置文件隐藏马尔可夫模型 (HMM) 的精选数据库，确认具有抗生素抗性功能并按本体组织。 ResFinder 水平获得的 AMR 基因数据库。 SARG 抗生素抗性基因、亚型和参考序列，整合来自ARDB和CARD的信息。 很多ARG数据库已经很久没有管理升级了，目前CARD是注释比较全面，管理完善，很多ARG条目经过实验验证的数据库。\nCARD提供参考 DNA 和蛋白质序列、检测模型和基于细菌抗菌素耐药性(AMR)分子基础的生物信息学工具，设计了抗生素抗性本体论 (ARO)。\nARO 分为三个主要分支：抗生素耐药性决定因素(ARO:3000000)、抗生素分子(ARO:1000003)和抗生素耐药机制(ARO:1000002)，最新的CARD现在已经有6000多个本体术语，这些还得到了很多研究论文的支持。\nCARD 开发了抗性基因标识符（RGI) 软件（v5.0）。\nRGI软件利用四种CARD模型类型来预测抵抗组：蛋白质同源模型（使用BLASTP或DIAMOND检测AMR基因的功能同源物）、蛋白质变异模型（用于准确区分易感内在基因和获得赋予AMR的突变的内在基因，基CARD的精选SNP矩阵）、rRNA突变模型（用于检测抗药性rRNA靶序列）和蛋白质过度表达模型（检测与AMR相关的外排亚基，但也突出显示存在时赋予过度表达的突变）。\n所以我一般用的也是RGI+CARD来做宏基因组的ARG鉴定。当然鉴定后的下游分析就跟其他的功能基因类似，有很多可以做的，最好跟实验设计紧紧联系说明问题。\nRGI RGI（Resistance Gene Identifier）是一个用于检测和注释细菌基因组中抗生素抗性基因的工具。\n地址：https://github.com/arpcard/rgi\nRGI有网页版应用https://card.mcmaster.ca/analyze/rgi，可以选择两种输入，右侧调节参数：\nEnter a GenBank accession(s): Upload FASTA sequence file(s): GenBank: JN420336.1，试试这个 Klebsiella pneumoniae plasmid pNDM-MAR, complete sequence，肺炎克雷伯菌质粒 pNDM-MAR，完整序列， 267242 bp。\n结果会返回一个表，多个旭日图： 当然我们要做宏基因组分析的话肯定要用命令行版本的rgi软件：\n安装方法：\n最简单的方式就是conda新建环境后直接安装：\n1 2 3 4 5 6 7 8 # searches rgi package and show available versions $ conda search --channel bioconda rgi # install rgi package $ conda install --channel bioconda rgi # install rgi specific version $ conda install --channel bioconda rgi=3.1.1 # remove rgi package $ conda remove --channel bioconda rgi 如果上述方法有问题的话（比如我当时的环境），可以考虑源码编译：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 # 克隆仓库， git clone https://github.com/arpcard/rgi # 在rgi文件夹内新建环境 conda env create -f conda_env.yml conda activate rgi # 在rgi文件夹内build python setup.py build python setup.py test python setup.py install #test cd tests pytest -v -rxs #这里可能会有几个问题，需要把card.json，和由card_database_v3.1.4.fasta创建的card_reference.fasta放在合适位置 #查看安装情况 rgi main -h #成功的话会输出帮助文件 usage: rgi main [-h] -i INPUT_SEQUENCE -o OUTPUT_FILE [-t {contig,protein}] [-a {DIAMOND,BLAST}] [-n THREADS] [--include_loose] [--include_nudge] [--local] [--clean] [--keep] [--debug] [--low_quality] [-d {wgs,plasmid,chromosome,NA}] [-v] [-g {PRODIGAL,PYRODIGAL}] [--split_prodigal_jobs] Resistance Gene Identifier - 6.0.2 - Main #下载card数据库 wget https://card.mcmaster.ca/latest/data tar -xvf data ./card.json #在本地或工作目录中加载card数据库 rgi load --card_json /path/to/card.json --local #查看本地数据库版本 rgi database --version --local #注意不加--local的话数据库会加载到全局环境中，在任意目录都可以运行 安装成功后，就可以来对我们的序列进行鉴定了，常用的有两种模式：\n基因组或组装序列（DNA/蛋白质） 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 rgi main --input_sequence /path/to/nucleotide_input.fasta --output_file /path/to/output_file --local --clean 部分可选参数： -h, --help 显示此帮助信息并退出 -i 输入序列, --input_sequence 输入序列 输入文件必须在 FASTA（重叠群和蛋白质）或 gzip 格式！例如 myFile.fasta -o 输出文件, --output_file 输出文件，输出文件夹和文件名 -t {contig,protein}, --input_type {contig,protein} 指定数据输入类型（默认 = contig） -a {DIAMOND,BLAST}, --alignment_tool {DIAMOND,BLAST} 指定比对工具（默认 = BLAST） -n 线程，--num_threads 线程 BLAST 搜索中使用的线程数 (CPU)（默认值=16） --include_loose 除了严格和完美之外还包括宽松的命中点击（默认值：False） --include_nudge 包括从宽松到严格命中的命中（默认值：False） --local 使用本地数据库（默认：使用数据库可执行目录） --clean 删除临时文件（默认值：False） 结果表格每列的内容如下：\nField Content ORF_ID 开放阅读框架标识符（RGI 内部） Contig 源序列 Start ORF起始坐标 Stop ORF的结束坐标 Orientation ORF链 Cut_Off RGI 检测范式（完美、严格、松散） Pass_Bitscore 严格检测模型 bitscore 截断 Best_Hit_Bitscore 与 CARD 中的最高命中匹配的 Bitscore 值 Best_Hit_ARO CARD 中的最高命中匹配的 ARO 术语 Best_Identities 与 CARD 中的最高命中匹配的同一性百分比 ARO ARO 匹配到 CARD 中的最高命中的Accession号 Model_type CARD检测模型类型 SNPs_in_Best_Hit_ARO 在 CARD 中最高命中的 ARO 术语中观察到的突变 Other_SNPs 以模型 ID 指示的其他匹配项的 ARO 术语观察到的突变 Drug Class ARO分类 Resistance Mechanism ARO分类 AMR Gene Family ARO分类 Predicted_DNA ORF预测核苷酸序列 Predicted_Protein ORF预测的蛋白质序列 CARD_Protein_Sequence CARD中top hit的蛋白质序列 Percentage Length of Reference Sequence ORF蛋白长度/CARD参考蛋白长度 ID HSP 标识符（RGI 内部） Model_id CARD检测型号id Nudged TRUE = 命中从松散微调到严格 Note 其他注意事项的原因 宏基因组reads，基因组reads 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 rgi bwt --read_one /path/to/fastq/R1.fastq.gz --read_two /path/to/fastq/R2.fastq.gz --output_file output_prefix --local 部分可选参数： -h, --help 显示此帮助信息并退出 -1 READ_ONE, --read_one READ_ONE -2 READ_TWO，--read_two READ_TWO -a {kma,bowtie2,bwa}, --aligner {kma,bowtie2,bwa} 选择读取对齐器（默认=kma） -n 线程，--threads 线程 要使用的线程 (CPU) 数（默认值=16） -o 输出文件, --output_file 输出文件 输出文件名的名称 --debug 调试模式（默认=False） --clean 删除临时文件（默认=False） --local 使用本地数据库（默认：使用可执行目录中的数据库） --include_wildcard 包含wild数据库（默认=False） 最终结果有5个文件：\nFile Contents output_prefix.allele_mapping_data.txt RGI bwt read mapping results at allele level output_prefix.gene_mapping_data.txt RGI bwt read mapping results at gene level output_prefix.artifacts_mapping_stats.txt Statistics for read mapping artifacts output_prefix.overall_mapping_stats.txt Statistics for overall read mapping results output_prefix.reference_mapping_stats.txt Statistics for reference matches 常用的进一步分析的是 at allele level，这个表格每列的内容如下：\nField Contents Reference Sequence read映射到的参考等位基因 ARO Term ARO Term ARO Accession ARO Accession Reference Model Type CARD 检测模型类型 Reference DB 参考等位基因来自 CARD 或 WildCARD Reference Allele Source See below Resistomes \u0026amp; Variants: Observed in Genome(s) 这个等位基因序列是否在 CARD 患病率基因组序列中被观察到？ Resistomes \u0026amp; Variants: Observed in Plasmid(s) 是否已在 CARD Prevalence 质粒序列中观察到该等位基因序列？ Resistomes \u0026amp; Variants: Observed Pathogen(s) CARD 携带此等位基因序列的流行病原体。 如果 Reference DB 是 CARD，将显示在 CARD 检测模型中用作参考的病原体。 使用 k-mers 验证病原体来源。 Completely Mapped Reads 完全映射到等位基因的read数量 Mapped Reads with Flanking Sequence 未完全映射到等位基因的read数量 All Mapped Reads 前两列的总和 Percent Coverage 读数覆盖的参考等位基因百分比 Length Coverage (bp) Base pairs of reference allele covered by reads Average MAPQ (Completely Mapped Reads) 平均 MAPQ 值，映射质量得分量化了读取错位的可能性。 Heng Li 和 Richard Durbin 在他们描述 MAQ 的论文中介绍了它们，并且通常以 Phred 量表进行报告。 Mate Pair Linkage 对于配对双端测序，如果姐妹读取映射到不同的 AMR 基因，则会列出 Reference Length 参考等位基因的长度 (bp) AMR Gene Family ARO分类 Drug Class ARO分类 Resistance Mechanism ARO分类 Depth 覆盖深度（仅在使用 kma 时报告） SNPs 从映射读取中观察到的单核苷酸多态性（仅在使用 kma 时报告） Consensus Sequence DNA 使用映射读取的核苷酸一致序列（仅在使用 kma 时报告） Consensus Sequence Protein 从 DNA 翻译的蛋白质共有序列（仅在使用 kma 时报告） Reference 1. B. P. Alcock, A. R. Raphenya, T. T. Y. Lau, K. K. Tsang, et al., CARD 2020: Antibiotic resistome surveillance with the comprehensive antibiotic resistance database. Nucleic Acids Research. 48, D517–D525 (2020).\n2. A. Cassini, L. D. Högberg, D. Plachouras, A. Quattrocchi, et al., Attributable deaths and disability-adjusted life-years caused by infections with antibiotic-resistant bacteria in the EU and the european economic area in 2015: A population-level modelling analysis. The Lancet. Infectious Diseases. 19, 56–66 (2019).\n3. J. Wang, J. Gu, X. Wang, Z. Song, et al., Enhanced removal of antibiotic resistance genes and mobile genetic elements during swine manure composting inoculated with mature compost. Journal of Hazardous materials. 411, 125135 (2021).\n","date":"2023-05-16T00:00:00Z","image":"/p/antibiotics-resistance/images/ARG_mechanism_hu_cd90a66461e6153f.png","permalink":"/p/antibiotics-resistance/","title":"抗生素抗性基因（ARG）基础学习"},{"content":" Introduction 功能富集分析是一种用于分析基因集合或基因组数据中功能模式富集程度的计算方法。它可以帮助揭示在特定生物学背景下，哪些功能模块、代谢通路、基因家族等在统计上富集或显著过表示。\n功能富集分析通常包括以下步骤：\n数据预处理：根据研究问题和数据类型，选择适当的基因集合或基因组数据，例如基因表达数据、基因注释数据或基因列表。\n注释和功能分类：将基因集合与已知的功能注释数据库进行比较，例如基因本体论（Gene Ontology）、KEGG（Kyoto Encyclopedia of Genes and Genomes）通路数据库等。这一步将基因与特定的功能或生物过程相关联。\n统计分析：使用合适的统计方法，如超几何分布、Fisher’s exact test、GSEA（基因集富集分析）等，评估每个功能的富集程度。这些方法会计算一个得分或P值，用于判断功能是否在给定基因集合中富集。\n结果解释和可视化：根据统计分析的结果，识别在给定条件下显著富集的功能模块，并将结果进行解释和可视化。这可以帮助研究人员理解基因集合或基因组数据中的生物学特征和功能。\n功能富集分析可应用于多个研究领域，如基因表达分析、蛋白质组学、微生物组学等。它可以帮助研究人员理解基因集合的生物学意义，从而揭示生物过程、代谢通路、细胞组分等在特定条件下的调控机制，并为进一步的实验设计和研究提供有价值的指导。\n$$ P=1-\\sum_{i=0}^{m-1}\\frac{C_M^iC_{N-M}^{n-i}}{C_N^n} $$\nP： 某pathway的富集显著性； N： 注释上KEGG的所有基因的数量； n： 所有显著差异的基因数量； M： 所有基因中注释到某pathway的基因数量； m： 所有差异基因中注释到某pathway的基因数量\nR函数phyper:\n1 2 3 4 5 6 7 1-phyper(m-1,M, N-M, n) phyper(m-1,M, N-M, n, lower.tail=F) d \u0026lt;- data.frame(gene.not.interest=c(M-m, N-M-n+m), gene.in.interest=c(m, n-m)) row.names(d) \u0026lt;- c(\u0026#34;In_category\u0026#34;, \u0026#34;not_in_category\u0026#34;) d fisher.test(d,alternative = \u0026#34;greater\u0026#34;) Table 1: Methods for microbial enrichment analysis. Method Type Notes Hypergeometric test / Fisher’ exact test algorithm The most common method used in enrichment analysis. There are many enrichment analysis platforms or software developed based on it, including DAVID, clusterprofile, etc. Gene set enrichment analysis (GSEA) software Gene Set Enrichment Analysis (GSEA) is a computational method that determines whether an a priori defined set of genes shows statistically significant, concordant differences between two biological states (e.g. phenotypes). Clusterprofiler R package ClusterProfiler automates the process of biological-term classification and the enrichment analysis of gene clusters, which calculates enrichment test for GO terms and KEGG pathways based on hypergeometric distribution. Reporter score algorithm The plus or minus sign of reporter score does not represent regulation direction. Reporter feature analysis algorithm Reporter feature can achieve enrichment ananlysis for non-directional, mixed-directional up/down-regulation, and distinct-directional up/down-regulation classes. Piano R package Piano is a R package that implements the Reporter Features algorithm. Piano performs gene set analysis using various statistical methods, from different gene level statistics and a wide range of gene-set collections. Furthermore, the Piano package contains functions for combining the results of multiple runs of gene set analyses. Reporter score是一种改良的微生物富集分析的新方法，此方法最初是为了揭示代谢网络中的转录调控模式而开发的，目前已被引入微生物研究中进行功能富集分析。\nMethod Reporter score算法最初由Patil和Nielsen于2005年开发，用于识别代谢调节热点的代谢物 (1)。\n应用于宏基因组分析，则是基于基因的KO（KEGG orthology，同源基因）注释，获得KO的差异信息，再”上升”至KEGG pathway的功能层面。主要步骤如下：\n使用Wilcoxon秩和检验获得两分组间每个KO差异显著性的P值（即$P_{koi}$，i代表某个KO）；\n采用逆正态分布，将每个KO的P值转化为Z值（$Z_{koi}$）,公式：$Z_{koi}=\\theta ^{-1}(1-P_{koi})$；\n将KO”上升”为pathway：$Z_{koi}$，计算通路的Z值,$Z_{pathway}=\\frac{1}{\\sqrt{k}}\\sum Z_{koi}$，其中k表示对应通路共注释到k个KO；\n评估显著程度：置换（permutation）1000次，获得$Z_{pathway}$的随机分布，公式：$Z_{adjustedpathway}=(Z_{pathway}-\\mu _k)/\\sigma _k$，$μ_k$为随机分布的均值，$σ_k$为随机分布的标准差。\n最终获得的$Z_{adjustedpathway}$，即为每条代谢通路富集的Reporter score值，Reporter score是非方向性的，Reporter score越大代表富集越显著，但不能指示通路的上下调信息。\nMisuse 最近有一篇文章就讨论了reporter-score的正负号误用问题 (2)：\nhttps://mp.weixin.qq.com/s?__biz=MzUzMjA4Njc1MA==\u0026mid=2247507105\u0026idx=1\u0026sn=d5a0f0aaf176e245de7976f0a48f87a8#rd\n主要结论是 reporter score算法（上述）是一种忽略通路中KOs上/下调节信息的富集方法，直接将reporter score的符号视为通路的调节方向是不正确的。\n但是我们应该可以将其改为能够考虑通路内KO上下调的方式，我称为directed 模式, 参考自https://github.com/wangpeng407/ReporterScore。\n具体步骤如下:\n使用Wilcoxon秩和检验或者t.test获得两分组间每个KO差异显著性的P值（即$P_{koi}$，i代表某个KO），再将P值除以2，即将(0,1]的范围变为(0,0.5]，$P_{koi}=P_{koi}/2$；\n采用逆正态分布，将每个KO的P值转化为Z值（$Z_{koi}$）,公式：$Z_{koi}=\\theta ^{-1}(1-P_{koi})$，由于上述P值小于0.5，则Z值将全部大于0；\n考虑每个KO是上调还是下调，计算$\\Delta KO_i$，\n$$ \\Delta KO_i=\\overline {KO_{i_{g1}}}-\\overline {KO_{i_{g2}}} $$\n其中，$\\overline {KO_{i_{g1}}}$ 是组1的$KO_i$ 的平均丰度,$\\overline {KO_{i_{g2}}}$ 是组2的$KO_i$ 的平均丰度，然后：\n$$ Z_{koi} = \\begin{cases} -Z_{koi}, \u0026amp; (\\Delta KO_i\u0026lt;0) \\ Z_{koi}, \u0026amp; (\\Delta KO_i \\ge 0) \\end{cases} $$\n这样的话$Z_{koi}$大于0为上调，$Z_{koi}$小于0为下调。\n将KO”上升”为pathway：$Z_{koi}$，计算通路的Z值,$Z_{pathway}=\\frac{1}{\\sqrt{k}}\\sum Z_{koi}$，其中k表示对应通路共注释到k个KO；\n评估显著程度：置换（permutation）1000次，获得$Z_{pathway}$的随机分布，公式：$Z_{adjustedpathway}=(Z_{pathway}-\\mu _k)/\\sigma _k$，$μ_k$为随机分布的均值，$σ_k$为随机分布的标准差。\n最终获得的$Z_{adjustedpathway}$，即为每条代谢通路富集的Reporter score值，在这种模式下，Reporter score是方向性的，更大的正值代表显著上调富集，更小的负值代表显著下调富集。\n但是这种方法的缺点是当一条通路显著上调KO和显著下调KO差不多时，最终的Reporter score绝对值可能会趋近0，成为没有被显著富集的通路。\nRpackage 因为我看目前没有现成的工具完成Reporter Score分析（除了一些云平台，但可能不太方便），所以我参考https://github.com/wangpeng407/ReporterScore 写了一个R包帮助分析（虽然也不是特别复杂）\n地址：https://github.com/Asa12138/ReporterScore\n安装方法：\n1 2 install.packages(\u0026#34;devtools\u0026#34;) devtools::install_github(\u0026#39;Asa12138/ReporterScore\u0026#39;,dependencies=T) 使用方法：\n1 2 3 4 5 6 7 library(ReporterScore) library(dplyr) library(ggplot2) #准备KO丰度表和实验metadata data(KO_test) head(KO_abundance) ## CG1 CG2 CG3 CG4 CG5 CG6 ## K03169 0.002653545 0.005096380 0.002033923 0.000722349 0.003468322 0.001483028 ## K07133 0.000308237 0.000280458 0.000596527 0.000859854 0.000308719 0.000878098 ## K03088 0.002147068 0.002030742 0.003797459 0.004161979 0.002076596 0.003091182 ## CG7 CG8 CG9 CG10 CG11 CG12 ## K03169 0.002261685 0.004114644 0.002494258 0.002793671 0.004053729 0.002437170 ## K07133 0.000525566 0.000356138 0.000445409 0.000268306 0.000293546 0.000465780 ## K03088 0.003098506 0.002558730 0.002896506 0.002618472 0.002367986 0.002082786 ## CG13 CG14 CG15 EG1 EG2 EG3 ## K03169 0.002187500 0.001988374 0.002304885 0.003317368 0.001150671 0.002610814 ## K07133 0.000507992 0.000409447 0.000327910 0.002916018 0.004820742 0.001973789 ## K03088 0.002680792 0.003066870 0.002975895 0.002257401 0.002889640 0.001997586 ## EG4 EG5 EG6 EG7 EG8 EG9 ## K03169 0.000900673 0.001545374 0.001640295 0.001445024 0.001096728 0.001026556 ## K07133 0.003359927 0.001913932 0.001384079 0.001321643 0.002376473 0.004391014 ## K03088 0.002613441 0.002803388 0.002251835 0.002981244 0.002944061 0.003113215 ## EG10 EG11 EG12 EG13 EG14 EG15 ## K03169 0.001513195 0.001812732 0.003256782 0.006723067 0.001769819 0.001233307 ## K07133 0.002479040 0.003484868 0.000790457 0.000127818 0.000634529 0.004746572 ## K03088 0.003177522 0.002790092 0.001607913 0.002574928 0.001662157 0.002614489 ## [ reached 'max' / getOption(\u0026quot;max.print\u0026quot;) -- omitted 3 rows ] 1 head(Group_tab) ## Group ## CG1 CG ## CG2 CG ## CG3 CG ## CG4 CG ## CG5 CG ## CG6 CG 分组检验获得P值,threads多线程可加速 1 ko_pvalue=ko_test(KO_abundance,\u0026#34;Group\u0026#34;,Group_tab,threads = 1,verbose = F) ## Compared groups: CG and EG ## Total KO number: 4535 ## Time use: 1.348 1 head(ko_pvalue) ## KO_id avg_CG sd_CG avg_EG sd_EG diff_mean ## 1 K03169 0.0026728975 0.0011094132 0.0020694937 0.0014922004 0.00060340387 ## 2 K07133 0.0004554658 0.0001951678 0.0024480601 0.0014916566 -0.00199259427 ## 3 K03088 0.0027767713 0.0006253559 0.0025519275 0.0004966801 0.00022484380 ## 4 K03530 0.0005779169 0.0008952163 0.0005197504 0.0001435245 0.00005816647 ## 5 K06147 0.0020807307 0.0007731661 0.0014321838 0.0004273716 0.00064854693 ## 6 K05349 0.0021064422 0.0005243558 0.0017419317 0.0005382770 0.00036451047 ## p.value ## 1 0.03671754164 ## 2 0.00002654761 ## 3 0.48636476395 ## 4 0.01125600770 ## 5 0.00987482265 ## 6 0.12614740102 2.将P值矫正并转为Z-Score，这里提供两种方法（mixed就是经典的方法，另一种是directed方法）\n1 ko_stat=pvalue2zs(ko_pvalue,mode=\u0026#34;directed\u0026#34;) ## ================================================================================ ## ## Chi-squared test for given probabilities ## ## data: up_down_ratio ## X-squared = 21.823, df = 1, p-value = 0.000002991 1 head(ko_stat) ## KO_id avg_CG sd_CG avg_EG sd_EG diff_mean ## 1 K03169 0.0026728975 0.0011094132 0.0020694937 0.0014922004 0.00060340387 ## 2 K07133 0.0004554658 0.0001951678 0.0024480601 0.0014916566 -0.00199259427 ## 3 K03088 0.0027767713 0.0006253559 0.0025519275 0.0004966801 0.00022484380 ## 4 K03530 0.0005779169 0.0008952163 0.0005197504 0.0001435245 0.00005816647 ## 5 K06147 0.0020807307 0.0007731661 0.0014321838 0.0004273716 0.00064854693 ## 6 K05349 0.0021064422 0.0005243558 0.0017419317 0.0005382770 0.00036451047 ## p.value sign type q.value Z_score ## 1 0.01835877082 1 Enriched 0.0669268695 1.4990767 ## 2 0.00001327381 -1 Depleted 0.0004777517 -3.3033110 ## 3 0.24318238198 1 Enriched 0.3058325297 0.5076981 ## 4 0.00562800385 1 Enriched 0.0304570375 1.8741186 ## 5 0.00493741133 1 Enriched 0.0277461715 1.9150013 ## 6 0.06307370051 1 Enriched 0.1607865272 0.9912305 3.将KO”上升”为pathway，计算ReporterScore：\n1 reporter_s=get_reporter_score(ko_stat) ## =================================Checking file================================= ## ==================================load KOlist================================== ## ===================KOlist download time: 2023-05-12 00:07:41=================== ## ============================Calculating each pathway============================ ## ID number: 479 ## Time use: 4.641 1 head(reporter_s) ## ID ReporterScore Description K_num ## 1 map00010 -1.6255358 Glycolysis / Gluconeogenesis 106 ## 2 map00020 -1.8906022 Citrate cycle (TCA cycle) 67 ## 3 map00030 -0.8261448 Pentose phosphate pathway 88 ## 4 map00040 -0.6685755 Pentose and glucuronate interconversions 89 ## 5 map00051 -2.2494558 Fructose and mannose metabolism 112 ## 6 map00052 -0.4196662 Galactose metabolism 78 结果进行绘图 1 2 plot_report(reporter_s,rs_threshold=c(2,-7),y_text_size=10,str_width=40)+ labs(title = \u0026#34;CG vs EG\u0026#34;) 1 2 plot_report(reporter_s,rs_threshold=c(2,-7),mode = 2,y_text_size=10,str_width=40)+ labs(title = \u0026#34;CG vs EG\u0026#34;) 5.挑选一条通路进行绘制\n1 plot_KOs_in_pathway(map_id = \u0026#34;map00780\u0026#34;,ko_stat = ko_stat) Reference 1. K. R. Patil, J. Nielsen, Uncovering transcriptional regulation of metabolism by using metabolic network topology. Proceedings of the National Academy of Sciences of the United States of America. 102, 2685–2689 (2005).\n2. L. Liu, R. Zhu, D. Wu, Misuse of reporter score in microbial enrichment analysis. iMeta. 2, e95 (2023).\n","date":"2023-05-10T00:00:00Z","image":"/p/reporter-score/images/misuse2_hu_1a4d126e9c203d48.jpeg","permalink":"/p/reporter-score/","title":"Reporter Score 微生物功能富集分析"},{"content":"上次已经介绍过了使用R绘制系统发育树的基本用法，也埋下一个小坑：复现文章里好看的树，现在过来填坑了，哈哈哈。\n我准备了一些文章里自己觉得很不错的树（当然尽可能风格不同），然后自己生成随机的树和一些随机的无科学意义的注释（仅供画图参考！！！），主要是用ggtree和ggtreeExtra进行代码复现，争取把树的主体都用代码完成，当然一些小细节就还是不得不使用AI等pdf编辑软件进行添加了。\nPreparation 首先还是要把我们要用的一些包都安装好并导入进来。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 #tree if (!requireNamespace(\u0026#34;BiocManager\u0026#34;, quietly=TRUE)) install.packages(\u0026#34;BiocManager\u0026#34;) BiocManager::install(\u0026#34;YuLab-SMU/treedataverse\u0026#34;) BiocManager::install(\u0026#34;ggtree\u0026#34;) BiocManager::install(\u0026#34;ggtreeExtra\u0026#34;) library(treedataverse) library(ggtree) library(ggtreeExtra) library(treeio) #plot library(dplyr) library(ggplot2) library(ggnewscale) library(reshape2) library(ggrepel) 然后需要准备一些函数：\n1 2 3 4 5 6 7 #写个函数类似child获取子节点，但是可以指定层数 child2=function(tree,node,depth=1){ if(depth==1){return(child(tree,node))} else { return(child2(tree,child(tree,node)%\u0026gt;%unlist()%\u0026gt;%unname(),depth-1)%\u0026gt;%unlist()%\u0026gt;%unname()) } } Example1 第一个例子来自Nature Communication的一篇文章 (1)，这是一个相对简单的树。\n按照ggplot搭积木的逻辑，我们看看有哪些需要画的：\n树的主体，圆形布局，并打开一个小角度，方便展示注释信息的x轴label 外圈注释1，热图形式（tile），颜色代表每一个tip的Phylum，透明度代表相对丰度 外圈注释2，柱形图形式（col或bar），颜色代表每一个tip的Phylum，高度代表SVM系数 相应的我们生成数据：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 #生成一个2000tip的树 ntips=2000 set.seed(123) tree=rtree(ntips,rooted = T) #变成tbl_tree对象，方便操作 ggtree::fortify(tree)-\u0026gt;tree_df #生成一些假的taxonomy信息 phylums=c(\u0026#34;Arthropoda\u0026#34;,\u0026#34;Streptophyta\u0026#34;,\u0026#34;Cyanobacteria\u0026#34;,\u0026#34;Acidobacteriota\u0026#34;,\u0026#34;Bacteroidetes\u0026#34;,\u0026#34;Firmicutes\u0026#34;,\u0026#34;Actinobacteria\u0026#34;,\u0026#34;Proteobacteria\u0026#34;,\u0026#34;Others\u0026#34;) phy_nodes=child2(tree,ntips+1,depth = 4) set.seed(123) phy_nodes=setNames(phy_nodes,sample(phylums,length(phy_nodes),replace = T)) tree_df=groupClade(tree_df,phy_nodes,group_name = \u0026#34;Phylum\u0026#34;) anno=filter(tree_df,isTip==\u0026#34;TRUE\u0026#34;)%\u0026gt;%select(label,Phylum) #生成随机数作为丰度和SVM anno=cbind(anno,sapply(1:4, \\(i)rexp(ntips,3))%\u0026gt;%vegan::decostand(.,\u0026#34;total\u0026#34;,2)) anno=cbind(anno,rexp(ntips)/10) colnames(anno)=c(\u0026#34;node\u0026#34;,\u0026#34;Phylum\u0026#34;,\u0026#34;Ice/Snow\u0026#34;,\u0026#34;Terrestrial\u0026#34;,\u0026#34;Marine\u0026#34;,\u0026#34;Freshwater\u0026#34;,\u0026#34;SVM\u0026#34;) head(anno) ## node Phylum Ice/Snow Terrestrial Marine Freshwater ## 1 t339 Cyanobacteria 0.0007693819 0.000448952905 0.00003100616 0.00034017986 ## 2 t1180 Cyanobacteria 0.0002356377 0.000483643521 0.00124672220 0.00009722752 ## 3 t1807 Cyanobacteria 0.0002908480 0.000035084895 0.00074445757 0.00011096549 ## 4 t572 Cyanobacteria 0.0019889166 0.000108407239 0.00098076293 0.00014436096 ## 5 t1739 Cyanobacteria 0.0004149838 0.000004413762 0.00006021236 0.00006270886 ## 6 t1245 Cyanobacteria 0.0004753852 0.000004451763 0.00015540813 0.00011400371 ## SVM ## 1 0.0001332960 ## 2 0.0474528998 ## 3 0.0222924708 ## 4 0.0001208082 ## 5 0.0169753369 ## 6 0.0277805382 有了树和注释数据，我们开始绘图：\n1 2 3 4 # 1. 树的主体,树枝太多把size调小，圆形布局，并打开一个小角度 p=ggtree(tree,size=0.1,layout = \u0026#34;fan\u0026#34;,open.angle = 10) #(p=ggtree(tree_df,aes(color=Phylum),size=0.1,layout = \u0026#34;fan\u0026#34;,open.angle = 20)) p 1 2 3 # 2. 外圈注释1，热图形式（tile），颜色代表每一个tip的Phylum，透明度代表相对丰度 anno1=melt(anno[,1:6],id.vars =1:2,variable.name = \u0026#34;Env\u0026#34;,value.name = \u0026#34;Abundance\u0026#34;) head(anno1) ## node Phylum Env Abundance ## 1 t339 Cyanobacteria Ice/Snow 0.0007693819 ## 2 t1180 Cyanobacteria Ice/Snow 0.0002356377 ## 3 t1807 Cyanobacteria Ice/Snow 0.0002908480 ## 4 t572 Cyanobacteria Ice/Snow 0.0019889166 ## 5 t1739 Cyanobacteria Ice/Snow 0.0004149838 ## 6 t1245 Cyanobacteria Ice/Snow 0.0004753852 1 2 3 4 5 6 7 8 9 p1=p+geom_fruit( data=anno1, geom = geom_tile, mapping = aes(y=node,x=Env,fill=Phylum,alpha=Abundance), pwidth = 0.2, axis.params=list(axis=\u0026#34;x\u0026#34;,text.size = 2,text.angle=270) )+scale_alpha(range = c(0,1),guide=guide_none())+ ggsci::scale_fill_npg() p1 1 2 3 4 5 6 7 8 9 10 # 3. 外圈注释2，柱形图形式（col或bar），颜色代表每一个tip的Phylum，高度代表SVM系数 p2=p1+geom_fruit( data=anno, geom = geom_col, mapping = aes(y=node,x=SVM,fill=Phylum), pwidth = 0.3, axis.params=list(axis=\u0026#34;x\u0026#34;,text.size = 2), grid.params = list() )+theme(legend.position = c(0,0.3)) p2 Example2 第二个例子来自Nature Microbiology的一篇文章 (2)。\n我们看看有哪些需要画的：\n树的主体，比较特别的布局（equal_angle），并且树枝要加上一些Form的分类颜色信息,再加上一个scale标尺 外圈注释1，标签，在每类分支附近，背景颜色是Form的分类 外圈注释2，点和文字，应该是手动挑选的一些节点，在树枝顶端加上了灰点以及黑色文字 相应的我们生成数据：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 #生成一个400tip的树 ntips=400 set.seed(123) tree=rtree(ntips,rooted = T) #变成tbl_tree对象，方便操作 ggtree::fortify(tree,layout =\u0026#34;equal_angle\u0026#34; )-\u0026gt;tree_df #生成一些假的Form信息 forms=paste0(\u0026#34;Form \u0026#34;,c(\u0026#34;I\u0026#34;,\u0026#34;II\u0026#34;,\u0026#34;II/III\u0026#34;,\u0026#34;III-a\u0026#34;,\u0026#34;III-b\u0026#34;,\u0026#34;III-c\u0026#34;,\u0026#34;III-like\u0026#34;,\u0026#34;IV\u0026#34;)) phy_nodes=child2(tree,ntips+1,depth = 3) set.seed(123) phy_nodes=setNames(phy_nodes,sample(forms,length(phy_nodes),replace = F)) tree_df=groupClade(tree_df,phy_nodes,group_name = \u0026#34;Form\u0026#34;) #指定颜色 colors=c(\u0026#34;#1F77B4FF\u0026#34;,\u0026#34;#FF7F0EFF\u0026#34;,\u0026#34;#2CA02CFF\u0026#34;,\u0026#34;#D62728FF\u0026#34;,\u0026#34;#9467BDFF\u0026#34;,\u0026#34;#8C564BFF\u0026#34;,\u0026#34;#E377C2FF\u0026#34;,\u0026#34;#BCBD22FF\u0026#34;,\u0026#34;#17BECFFF\u0026#34;) #挑选一些nodes set.seed(123) label_node=sample(seq_len(ntips),20) 有了树和注释数据，我们开始绘图：\n1 2 3 4 5 6 # 1. 树的主体，比较特别的布局（equal_angle），并且树枝要加上一些Form的分类颜色信息 p=ggtree(tree_df,aes(color=Form),layout = \u0026#34;equal_angle\u0026#34;)+ geom_treescale(-5,7,fontsize=3, linesize=0.5,width=1)+ scale_color_manual(values = c(\u0026#34;black\u0026#34;,colors))+ coord_flip()+theme(legend.position = \u0026#34;none\u0026#34;) p 1 2 3 4 5 # 2. 外圈注释1，标签，在每类分支附近，背景颜色是Form的分类 p1=p+geom_label_repel(data = subset(tree_df,node%in%phy_nodes), mapping = aes(x=x,y=y,label=Form,fill=Form),color=\u0026#34;black\u0026#34;,alpha=0.7)+ scale_fill_manual(values = colors) p1 1 2 3 4 5 6 # 3. 外圈注释2，点和文字，应该是手动挑选的一些节点，在树枝顶端加上了灰点以及黑色文字 p2=p1+geom_point(data = subset(tree_df,node%in%label_node), mapping = aes(x=x*1.03,y=y*1.03),color=\u0026#34;grey50\u0026#34;)+ geom_text_repel(data = subset(tree_df,node%in%label_node), mapping = aes(x=x*1.05,y=y*1.05,label=label),color=\u0026#34;black\u0026#34;) p2 当然文字和标签的位置有点不太好，需要导出pdf再稍微调整一下。\nExample3 第三个例子来自Nature Biotechnology的一篇文章 (3) 。\n我们看看有哪些需要画的：\n树的主体，层级树的感觉（把branch.length忽略了，所有的tip在一个位置），打开角度为180，灰色树枝 内圈注释，给部分clade加上不同Phylum的背景颜色 外圈注释1，3圈热图，用的是有无数据 外圈注释2，2圈柱形图，Size和GC含量 相应的我们生成数据：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 #生成一个1000tip的树 ntips=1000 set.seed(123) tree=rtree(ntips,rooted = T) #变成tbl_tree对象，方便操作 ggtree::fortify(tree)-\u0026gt;tree_df #生成一些假的taxonomy信息 phylums=rev(c(\u0026#34;Arthropoda\u0026#34;,\u0026#34;Streptophyta\u0026#34;,\u0026#34;Cyanobacteria\u0026#34;,\u0026#34;Acidobacteriota\u0026#34;,\u0026#34;Bacteroidetes\u0026#34;,\u0026#34;Firmicutes\u0026#34;,\u0026#34;Actinobacteria\u0026#34;,\u0026#34;Proteobacteria\u0026#34;)) #把8个phylum赋给最多tip的几个clade，其他的是others phy_nodes=child2(tree,ntips+1,depth = 4) phy_nodes_tips=sapply(phy_nodes, \\(i)nrow(offspring(tree_df,i))) names(phy_nodes)=rep(\u0026#34;Others\u0026#34;,length(phy_nodes)) names(phy_nodes)[which(phy_nodes_tips%in%tail(sort(phy_nodes_tips),8))]=phylums tree_df=groupClade(tree_df,phy_nodes,group_name = \u0026#34;Phylum1\u0026#34;) anno=filter(tree_df,isTip==\u0026#34;TRUE\u0026#34;)%\u0026gt;%select(label,Phylum1) #添加每个phylum的个数和百分比 anno%\u0026gt;%count(Phylum1)%\u0026gt;%mutate(per=100*n/sum(n))%\u0026gt;% mutate(Phylum=paste0(Phylum1,\u0026#34; (\u0026#34;,n,\u0026#34;, \u0026#34;,per,\u0026#34;%)\u0026#34;))%\u0026gt;%select(Phylum1,Phylum)-\u0026gt;in_anno in_anno=right_join(in_anno,data.frame(node=phy_nodes,Phylum1=names(phy_nodes))) set.seed(123) #生成随机变量作为Source,16S rRNA presence,Newly identified anno$Source=sample(c(\u0026#34;Cultivated\u0026#34;,\u0026#34;MAG\u0026#34;),ntips,T,c(0.1,0.9)) anno$`16S rRNA presence`=sample(c(\u0026#34;Yes\u0026#34;,\u0026#34;No\u0026#34;),ntips,T,c(0.3,0.7)) anno$`Newly identified`=sample(c(\u0026#34;Yes\u0026#34;,\u0026#34;No\u0026#34;),ntips,T,c(0.9,0.1)) #生成随机数作为Size和GC含量 anno$`Size (Mb)`=10-rpois(ntips,2) anno$`GC (%)`=runif(ntips,30,80) colnames(anno)[1]=\u0026#34;node\u0026#34; head(anno) ## # A tibble: 6 × 7 ## node Phylum1 Source `16S rRNA presence` Newly identifie…¹ Size …² GC (%…³ ## \u0026lt;chr\u0026gt; \u0026lt;fct\u0026gt; \u0026lt;chr\u0026gt; \u0026lt;chr\u0026gt; \u0026lt;chr\u0026gt; \u0026lt;dbl\u0026gt; \u0026lt;dbl\u0026gt; ## 1 t876 Others MAG No Yes 9 45.2 ## 2 t896 Others MAG No Yes 6 71.6 ## 3 t437 Others MAG No Yes 9 59.7 ## 4 t750 Others MAG Yes Yes 8 70.4 ## 5 t270 Others Cultivated Yes Yes 9 44.7 ## 6 t412 Others MAG No Yes 8 37.1 ## # … with abbreviated variable names ¹​`Newly identified`, ²​`Size (Mb)`, ## # ³​`GC (%)` 1 2 3 # 1. 树的主体，层级树的感觉（把branch.length忽略了，所有的tip在一个位置），打开角度为180，灰色树枝 p=ggtree(tree,layout = \u0026#34;fan\u0026#34;,open.angle = 180,branch.length = \u0026#34;none\u0026#34;,size=0.2,color=\u0026#34;grey\u0026#34;) p 1 2 3 4 5 # 2. 内圈注释，给部分clade加上不同Phylum的背景颜色 p1=p+geom_highlight(data = in_anno, mapping = aes(node=node,fill=Phylum),to.bottom = T,alpha=1)+ ggsci::scale_fill_rickandmorty(guide=guide_legend(ncol = 2,title.position = \u0026#34;top\u0026#34;,title = \u0026#34;Clade: Phylum\u0026#34;,order = 4)) p1 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 # 3. 外圈注释1，3圈热图，用的是有无数据 p2=p1+ggnewscale::new_scale_fill()+ geom_fruit( data=anno, geom = geom_tile, mapping = aes(y=node,fill=`Newly identified`), pwidth = 0.05,offset = 0.05,color=NA )+scale_fill_manual(values = c(\u0026#34;white\u0026#34;,\u0026#34;red\u0026#34;), guide=guide_legend(ncol = 2,title.position = \u0026#34;top\u0026#34;,override.aes = list(color=\u0026#34;red\u0026#34;,size=3),order = 3))+ ggnewscale::new_scale_fill()+ geom_fruit( data=anno, geom = geom_tile, mapping = aes(y=node,fill=`16S rRNA presence`), pwidth = 0.05,offset = 0.1,color=NA )+scale_fill_manual(values = c(\u0026#34;white\u0026#34;,\u0026#34;blue4\u0026#34;), guide=guide_legend(ncol = 2,title.position = \u0026#34;top\u0026#34;,override.aes = list(color=\u0026#34;blue4\u0026#34;,size=3),order = 2))+ ggnewscale::new_scale_fill()+ geom_fruit( data=anno, geom = geom_tile, mapping = aes(y=node,fill=Source), pwidth = 0.05,offset = 0.1,color=NA )+scale_fill_manual(values = c(\u0026#34;green4\u0026#34;,\u0026#34;white\u0026#34;), guide=guide_legend(ncol = 2,title.position = \u0026#34;top\u0026#34;,override.aes = list(color=\u0026#34;green4\u0026#34;,size=3),order = 1)) p2 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 # 4. 外圈注释2，2圈柱形图，Size和GC含量 p3=p2+geom_fruit( data=anno, geom = geom_col, mapping = aes(y=node,x=`Size (Mb)`),fill=\u0026#34;purple3\u0026#34;, pwidth = 0.15,offset = 0.1, axis.params=list(axis=\u0026#34;x\u0026#34;,text.size = 2,text.angle=90,hjust=1,nbreak=3,line.color=\u0026#34;black\u0026#34;), grid.params = NULL )+geom_fruit( data=anno, geom = geom_col, mapping = aes(y=node,x=`GC (%)`),fill=\u0026#34;#F7C194\u0026#34;, pwidth = 0.2,offset = 0.05, axis.params=list(axis=\u0026#34;x\u0026#34;,text.size = 2,text.angle=90,hjust=1,nbreak=2,line.color=\u0026#34;black\u0026#34;), grid.params = NULL )+theme(legend.position = c(0.5,0.3),legend.box = \u0026#34;horizontal\u0026#34;, legend.text = element_text(size=8)) #最后再加上几个标签 p3+geom_text(data = data.frame(x=c(20,22,24,27,31),y=c(10), label=c(\u0026#34;Source \u0026#34;,\u0026#34;16S rRNA presence \u0026#34;,\u0026#34;Newly identified \u0026#34;,\u0026#34;Size (Mb) \u0026#34;,\u0026#34;GC (%) \u0026#34;)), aes(x,y,label=label),angle=90,hjust=1,size=3) Example4 第四个例子来自Nature的一篇文章 (4)。这个图是用iTOL做的，因为iTOL支持直接画tip到圆等半径的空间颜色填充。但是我觉得用R还是一样能画。\n我们看看有哪些需要画的：\n树的主体，很正常，打开小角度，开口在左上角 内圈注释，给部分clade加上不同Phylum的颜色，但是这个色块是加在tip到圆等半径的空间（这个很有意思，还没有看到过别人用R实现过） 外圈注释1，方块代表phage，颜色代表family 外圈注释2，灰色五角星代表Genome contains Thoeris 外圈注释3，绿色菱形加上文字 相应的我们生成数据：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 #生成一个200tip的树 ntips=200 set.seed(123) tree=rtree(ntips,rooted = T) #变成tbl_tree对象，方便操作 ggtree::fortify(tree)-\u0026gt;tree_df #生成一些假的taxonomy信息 phylums=rev(c(\u0026#34;Arthropoda\u0026#34;,\u0026#34;Streptophyta\u0026#34;,\u0026#34;Cyanobacteria\u0026#34;,\u0026#34;Acidobacteriota\u0026#34;,\u0026#34;Bacteroidetes\u0026#34;,\u0026#34;Firmicutes\u0026#34;,\u0026#34;Actinobacteria\u0026#34;,\u0026#34;Proteobacteria\u0026#34;)) #把8个phylum赋给最多tip的几个clade，其他的是others phy_nodes=child2(tree,ntips+1,depth = 4) phy_nodes_tips=sapply(phy_nodes, \\(i)nrow(offspring(tree_df,i))) names(phy_nodes)=rep(\u0026#34;Unknown\u0026#34;,length(phy_nodes)) names(phy_nodes)[which(phy_nodes_tips%in%tail(sort(phy_nodes_tips),8))]=phylums tree_df=groupClade(tree_df,phy_nodes,group_name = \u0026#34;Phylum\u0026#34;) anno=filter(tree_df,isTip==\u0026#34;TRUE\u0026#34;)%\u0026gt;%select(label,Phylum)%\u0026gt;%rename(node=\u0026#34;label\u0026#34;) colors=c(\u0026#34;Firmicutes\u0026#34;=\u0026#34;#d3edeb\u0026#34;,\u0026#34;Actinobacteria\u0026#34;=\u0026#34;#019a99\u0026#34;,\u0026#34;Bacteroidetes\u0026#34;=\u0026#34;#0077b0\u0026#34;, \u0026#34;Proteobacteria\u0026#34;=\u0026#34;#ffba4d\u0026#34;,\u0026#34;Acidobacteriota\u0026#34;=\u0026#34;#282152\u0026#34;,\u0026#34;Cyanobacteria\u0026#34;=\u0026#34;#caa59a\u0026#34;, \u0026#34;Streptophyta\u0026#34;=\u0026#34;#ff7880\u0026#34;,\u0026#34;Arthropoda\u0026#34;=\u0026#34;#aac8eb\u0026#34;,Unknown=\u0026#34;white\u0026#34;) set.seed(123) #生成随机变量作为Source,16S rRNA presence,Newly identified anno$`Phage family`=anno$`Thoeris`=anno$`bac`=NA anno$`Phage family`[sample(seq_len(ntips),30)]=sample(c(\u0026#34;Myoviridae\u0026#34;,\u0026#34;Podoviridae\u0026#34;,\u0026#34;Siphoviridae\u0026#34;),30,replace = T,prob = c(0.2,0.1,0.7)) anno$`Thoeris`[sample(seq_len(ntips),5)]=\u0026#34;Genome contains Thoeris\u0026#34; anno$bac[sample(seq_len(ntips),10)]=\u0026#34;Bac\u0026#34; 1 2 3 4 5 6 7 # 1. 树的主体，很正常，打开小角度，开口在左上角 p=ggtree(tree,layout = \u0026#34;fan\u0026#34;,open.angle = 5) # 2. 内圈注释，给部分clade加上不同Phylum的颜色，但是这个色块是加在tip到圆等半径的空间（这个很有意思，还没有看到过别人用R实现过） p1=p+geom_tiplab(data=tree_df,mapping = aes(color=Phylum),align = T,linetype = 1,linesize = 3.5,size=0)+ scale_color_manual(values = colors,guide=guide_legend(title = \u0026#34;Host phylum\u0026#34;,nrow = 3))+geom_tree(layout = \u0026#34;fan\u0026#34;) p1 1 2 3 4 5 6 7 8 9 10 11 12 # 3. 外圈注释1，方块代表phage，颜色代表family library(ggstar) p2=p1+geom_fruit( geom = geom_star, data = anno, mapping = aes( y=node,fill=`Phage family` ), starshape=13, starstroke=0,size=4 )+scale_fill_manual(values = c(\u0026#34;#de255c\u0026#34;,\u0026#34;#496db6\u0026#34;,\u0026#34;#c4c64f\u0026#34;),na.translate=FALSE,guide=guide_legend(ncol = 1)) p2 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 # 4. 外圈注释2，灰色五角星代表Genome contains Thoeris p3=p2+new_scale_fill()+ geom_fruit( geom = geom_star, data = anno, mapping = aes( y=node,fill=`Thoeris` ), starshape=1,offset = 0, starstroke=0,size=5 )+scale_fill_manual(name=\u0026#34;\u0026#34;,values = c(\u0026#34;grey\u0026#34;),na.translate=FALSE) # 5. 外圈注释3，绿色菱形加上文字 p4=p3+new_scale_fill()+ geom_fruit( geom = geom_star, data = anno, mapping = aes( y=node,fill=`bac` ), starshape=12,offset = 0.1, starstroke=0,size=3 )+scale_fill_manual(values = c(\u0026#34;#74cfd2\u0026#34;),na.translate=FALSE,guide=guide_none())+ geom_tiplab(data = tree_df%\u0026gt;%filter(label%in%(anno$node[which(!is.na(anno$bac))])), mapping = aes(label=label),angle=0,align = T,linetype = 0,offset = 2.5) p4+theme(legend.position = \u0026#34;bottom\u0026#34;) 呼～，暂时先做这几个图吧，再次强调，这是生成随机的树和一些随机的无科学意义的注释（仅供画图参考！！！）。\n如果你有好看的图需要复现或者有什么绘图上的问题，欢迎联系。\nReference 1. M. Bourquin, S. B. Busi, S. Fodelianakis, H. Peter, et al., The microbiome of cryospheric ecosystems. Nature Communications. 13, 3087 (2022).\n2. M. Royo-Llonch, P. Sánchez, C. Ruiz-González, G. Salazar, et al., Compendium of 530 metagenome-assembled bacterial and archaeal genomes from the polar Arctic Ocean. Nature Microbiology. 6, 1561–1574 (2021).\n3. Y. Liu, M. Ji, T. Yu, J. Zaugg, et al., A genome and gene catalog of glacier microbiomes. Nature Biotechnology. 40, 1341–1348 (2022).\n4. A. Leavitt, E. Yirmiya, G. Amitai, A. Lu, et al., Viruses inhibit TIR gcADPR signalling to overcome bacterial defence. Nature. 611, 326–331 (2022).\n","date":"2023-05-05T00:00:00Z","image":"/p/r-tree2/images/example3_hu_b2f6f354c0525eee.png","permalink":"/p/r-tree2/","title":"R绘制优美的进化树（进阶）"},{"content":"这篇文章主要是介绍绘制进化树用的ggtree以及一些拓展包的基础用法，因为gg系列绘图的逻辑基本是搭积木，这种介绍性的文章能够帮助快速的找到想要的“积木”以及拼接的方法，剩下的就是随心所欲设计想要的图了。所以这篇出的图可能不是很“漂亮”，下次一定搞一篇提供复现各种文章美图的代码的推文💪。\nIntroduction 在数学中，“树”是一种特殊的无向图，它没有任何循环，并且任意两个顶点之间都只有一条简单路径。树通常用于建立层次关系，比如在计算机科学中，用树来表示文件系统、程序的调用关系、HTML文档的DOM结构等等。树也是算法和数据结构中非常重要的概念，许多问题可以用树来解决，比如搜索、排序、编码等等。\n系统发育树（Phylogenetic tree） 是一种用于描述不同物种或生物体系之间进化关系的树形结构。它是一种分支图，用于表示生命的进化历史，从共同祖先开始，沿着时间轴向后展开。系统发育树通常是基于各种生物学数据的分析所建立的，如形态特征、基因序列、蛋白质序列、生化反应等，以便识别物种之间的遗传变异和演化趋势。\n系统发育树的树枝代表演化分支，节点表示各个物种的最近共同祖先，树枝的长度表示演化距离或进化时间。系统发育树的形状和结构可以帮助我们理解不同物种之间的亲缘关系，了解生物进化和演化过程。在生物分类学、生态学、生物地理学和生物技术等领域中，系统发育树都具有重要的应用价值。\nVisualization 有很多软件平台可以用来可视化Phylogenetic tree，下面列举一些比较常用的：\niTOL (Interactive Tree Of Life)：这是一个在线工具，可以方便地创建、注释和可视化Phylogenetic tree。它提供了多种样式和注释选项，可以根据需求自定义显示效果。网址为：https://itol.embl.de/（不付费的话无法保存中间步骤，注释方法不太友好[Doge]）\nFigTree：这是一个免费的软件，可以在Mac和Windows系统上运行。它可以可视化Nexus、Newick和Nexml等格式的Phylogenetic tree，并提供了多种样式和注释选项。网址为：http://tree.bio.ed.ac.uk/software/figtree/\nPhylo.io：这也是一个在线工具，可以可视化Phylogenetic tree并进行自定义注释。它还提供了交互式功能，可以探索和比较不同部分之间的关系。网址为：https://phylo.io/\nDendroscope：这是一个基于Java的软件，可以用来可视化Phylogenetic tree并进行比较和注释。它支持多种文件格式，包括Nexus、Newick、Phylip等。网址为：http://dendroscope.org/\nMEGA (Molecular Evolutionary Genetics Analysis)：这是一个免费的软件，可以用于分子进化分析和可视化。它可以创建、注释和可视化Phylogenetic tree，并提供了多种样式和注释选项。网址为：https://www.megasoftware.net/\n当然，在线平台和带GUI界面的软件有一定弊端，操纵不是那么自由。在R语言中，用于可视化Phylogenetic tree的包也有很多：\nggtree (1) +ggtreeExtra (2) ：Y叔的神包，基于ggplot2语法，学起来比较流畅，提供高度可定制化的绘图，支持各种不同类型的进化树。是我们要讲的重点，画树掌握这两个包基本就够了。官方英文教程；现在Y叔的中文教程也在热卖中。\nape：提供了用于绘制基本的进化树和一些简单的树的可视化函数，基础函数还是非常有用的，phylo对象也是一直要用的。\nphytools：提供了多种用于绘制进化树的函数，包括变形进化树的函数。\nggphylo：基于ggplot2语法，提供了一些用于绘制进化树的函数，支持多种不同的树形态。\n我们可以先安装载入一些包。\n1 2 3 4 5 6 7 8 9 10 11 12 if (!requireNamespace(\u0026#34;BiocManager\u0026#34;, quietly=TRUE)) install.packages(\u0026#34;BiocManager\u0026#34;) BiocManager::install(\u0026#34;YuLab-SMU/treedataverse\u0026#34;) BiocManager::install(\u0026#34;ggtree\u0026#34;) BiocManager::install(\u0026#34;ggtreeExtra\u0026#34;) library(dplyr) library(ggplot2) library(treedataverse) library(ggtree) library(ggtreeExtra) format 首先我们还是介绍一下存储树的一些文件格式和读取方法（毕竟读入数据一直是可视化的第一步）。\nNewick格式 (.newick 或 .nwk)：Newick格式是最常见的用于存储和传输系统发育树的格式之一。它是一种文本格式，可以使用文本编辑器打开和编辑。在Newick格式中，每个节点由一个括号表示，其后面跟着一个表示该节点的标签和一个冒号，然后是一个表示该节点的分支长度的数字，最后跟着逗号和下一个节点的括号。叶节点是没有子节点的节点。\nNexus格式 (.nex 或 .nexus)：Nexus格式是一种广泛使用的用于存储分子系统发育树和其他分子生物学数据的格式。它是一种文本格式，可以使用文本编辑器打开和编辑。Nexus格式允许存储多个数据集和多个树，并提供了一些其他的扩展功能，如注释、区分字符等。\nPhyloXML格式 (.xml)：PhyloXML格式是一种基于XML的格式，专门用于存储和传输系统发育树。它提供了许多其他格式所不具备的灵活性和扩展性，可以存储大量的信息，如节点注释、支持值、分支长度、支持率等。\nNeXML格式 (.xml)：NeXML格式是一种基于XML的格式，用于存储和传输生物多样性和系统发育树数据。它提供了PhyloXML格式的所有功能，并添加了一些额外的功能，如存储生物多样性元数据、事件、传输网格数据等。\n其他还有Phylip 格式 (.phy 或 .phylip)，PAUP 格式 (.paup)，IQ-TREE 格式 (.tree)，RAxML 格式 (.raxml)，MEGA 格式 (.meg)等等。\n在R中，可以使用不同的包和函数来读取不同格式的系统发育树文件。如 ape 包中的 read.tree() 函数可以读取Newick格式的系统发育树文件、 phangorn 包中的 read.phyDat() 和 read.phylo() 函数读取包括Nexus、Newick、Phylip等格式。\n当然，Y叔团队也贴心地准备好了一个包 treeio 用于读取、处理各种系统发育树文件格式：\n1 2 3 4 5 6 7 library(treeio) # 从 Newick 格式读取系统发育树数据 tree \u0026lt;- read.tree(\u0026#34;tree.nwk\u0026#34;) # 从 Nexus 格式读取系统发育树数据 tree \u0026lt;- read.nexus(\u0026#34;tree.nexus\u0026#34;) # 从 Phylip 格式读取系统发育树数据 tree \u0026lt;- read.phylo(\u0026#34;tree.phy\u0026#34;) Nexus、Newick、Phylip这几种格式读入后会变成常见的phylo S3对象，其他格式读入后一般会变成treedata S4对象（更高级全面的一个对象，当然亦可以和phylo相互转换），这两种对象都可以直接使用ggtree画图的，我们只要读入就好。\nbasic plot 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 set.seed(1234) #生成示例树 tree=rtree(50) (main_p=ggtree(tree, mapping = NULL, layout = \u0026#34;rectangular\u0026#34;,#常用circular，daylight open.angle = 0,#部分支持，如fan mrsd = NULL,#时间轴 as.Date = FALSE, yscale = \u0026#34;none\u0026#34;, yscale_mapping = NULL, ladderize = TRUE,#阶梯状排列树 right = FALSE, branch.length = \u0026#34;branch.length\u0026#34;,#\u0026#34;none\u0026#34;就会让branch末端都对齐 root.position = 0, xlim = NULL, #线段风格 color=\u0026#34;black\u0026#34;, size=0.5, linetype=1)) layout 整棵树的布局方式有很多’rectangular’, ‘dendrogram’, ‘slanted’, ‘ellipse’, ‘roundrect’, ‘fan’, ‘circular’, ‘inward_circular’, ‘radial’, ‘equal_angle’, ‘daylight’ or ‘ape’，也可以用其它一些参数调节：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 ggtree(tree) ggtree(tree, layout=\u0026#34;roundrect\u0026#34;) ggtree(tree, layout=\u0026#34;slanted\u0026#34;) ggtree(tree, layout=\u0026#34;ellipse\u0026#34;) ggtree(tree, layout=\u0026#34;circular\u0026#34;) ggtree(tree, layout=\u0026#34;fan\u0026#34;, open.angle=120) ggtree(tree, layout=\u0026#34;equal_angle\u0026#34;) ggtree(tree, layout=\u0026#34;daylight\u0026#34;) ggtree(tree, branch.length=\u0026#39;none\u0026#39;) ggtree(tree, layout=\u0026#34;ellipse\u0026#34;, branch.length=\u0026#34;none\u0026#34;) ggtree(tree, layout=\u0026#39;circular\u0026#39;, branch.length=\u0026#39;none\u0026#39;) ggtree(tree, layout=\u0026#34;daylight\u0026#34;, branch.length = \u0026#39;none\u0026#39;) 1 2 3 4 5 6 7 8 9 10 11 ggtree(tree) + scale_x_reverse()#左右颠倒 ggtree(tree) + coord_flip()#上下颠倒 ggtree(tree) + layout_dendrogram()#只看骨架 ggplotify::as.ggplot(ggtree(tree), angle=-30, scale=.9)#旋转特定角度和缩放 ggtree(tree, layout=\u0026#39;slanted\u0026#39;) + coord_flip() ggtree(tree, layout=\u0026#39;slanted\u0026#39;, branch.length=\u0026#39;none\u0026#39;) + layout_dendrogram() ggtree(tree, layout=\u0026#39;circular\u0026#39;) + xlim(-10, NA)#扩大树中间的空白区域 ggtree(tree) + layout_inward_circular()#内外颠倒 ggtree(tree) + layout_inward_circular(xlim=15) label 1 2 #对齐加虚线 main_p+geom_tiplab(align = T,linetype = 3,linesize = 0.5,size=2,color=\u0026#34;red\u0026#34;) 1 2 #对齐不加虚线 main_p+geom_tiplab(align = F,size=4,color=\u0026#34;blue\u0026#34;,as_ylab = T) 1 2 #加上内部节点名称 ggtree(tree)+geom_nodelab(mapping = aes(label=node)) 1 2 #比例尺 main_p+geom_treescale(fontsize=6, linesize=1, offset=1, width=1, color=\u0026#39;red\u0026#39;) manipulate 我们可以使用tidytree::as_tibble或者ggtree::fortify把整个树（phylo对象）转为一个易于阅读的dataframe。\nparent和node两列展示了整个树的连接关系,branch.length是每个枝（连接parent和node）的枝长，label是node的label，一般每个tip（端点）都会有一个label，内部的点可能没有label（比如这个示例），我们也可以手动加上。\n1 tidytree::as_tibble(tree)%\u0026gt;%head() ## # A tibble: 6 × 4 ## parent node branch.length label ## \u0026lt;int\u0026gt; \u0026lt;int\u0026gt; \u0026lt;dbl\u0026gt; \u0026lt;chr\u0026gt; ## 1 58 1 0.318 t2 ## 2 59 2 0.634 t47 ## 3 59 3 0.127 t40 ## 4 57 4 0.423 t20 ## 5 56 5 0.914 t44 ## 6 55 6 0.468 t3 1 2 tree_df=ggtree::fortify(tree) head(tree_df) ## # A tibble: 6 × 9 ## parent node branch.length label isTip x y branch angle ## \u0026lt;int\u0026gt; \u0026lt;int\u0026gt; \u0026lt;dbl\u0026gt; \u0026lt;chr\u0026gt; \u0026lt;lgl\u0026gt; \u0026lt;dbl\u0026gt; \u0026lt;dbl\u0026gt; \u0026lt;dbl\u0026gt; \u0026lt;dbl\u0026gt; ## 1 58 1 0.318 t2 TRUE 4.28 48 4.12 346. ## 2 59 2 0.634 t47 TRUE 5.55 49 5.24 353. ## 3 59 3 0.127 t40 TRUE 5.05 50 4.98 360 ## 4 57 4 0.423 t20 TRUE 3.88 47 3.67 338. ## 5 56 5 0.914 t44 TRUE 3.87 46 3.42 331. ## 6 55 6 0.468 t3 TRUE 3.17 45 2.94 324 我们可以用以下方法访问树的节点（node）的关系节点，可以通过tree或者tree生成的dataframe查询：\n1 2 library(tidytree) child(tree, 53)#子节点,一层 ## [1] 54 63 1 parent(tree, 1)#父节点，一层 ## [1] 58 1 offspring(tree, 53)#所有的子节点，包括子节点的子节点 ## [1] 54 63 55 60 56 6 57 5 58 4 1 59 2 3 7 61 62 10 8 9 64 67 65 66 11 ## [26] 12 13 14 15 16 1 ancestor(tree, 1)#所有的父节点，包括父节点的父节点 ## [1] 58 57 56 55 54 53 52 51 1 sibling(tree, 1)#兄弟节点 ## [1] 59 1 MRCA(tree, 1, 2)#最近祖先 ## [1] 58 节点分组\ngroupOTU() 和 groupClade() 方法旨在将分类群分组信息添加到输入树对象，这种分组信息可以直接用在 ggtree 的树可视化中。\ngroupOTU() 输入的是要给分组下的每个node。\ngroupClade() 输入给每个分组的最高级node即可，会自动分配该node下所有offspring node同一个分组。\n1 groupOTU(tree, .node = c(52,53),group_name = \u0026#34;OTU\u0026#34;)%\u0026gt;%as_tibble()%\u0026gt;%head ## # A tibble: 6 × 5 ## parent node branch.length label OTU ## \u0026lt;int\u0026gt; \u0026lt;int\u0026gt; \u0026lt;dbl\u0026gt; \u0026lt;chr\u0026gt; \u0026lt;fct\u0026gt; ## 1 58 1 0.318 t2 0 ## 2 59 2 0.634 t47 0 ## 3 59 3 0.127 t40 0 ## 4 57 4 0.423 t20 0 ## 5 56 5 0.914 t44 0 ## 6 55 6 0.468 t3 0 1 groupClade(tree, .node = c(52,53),group_name = \u0026#34;Clade\u0026#34;)%\u0026gt;%as_tibble()%\u0026gt;%head ## # A tibble: 6 × 5 ## parent node branch.length label Clade ## \u0026lt;int\u0026gt; \u0026lt;int\u0026gt; \u0026lt;dbl\u0026gt; \u0026lt;chr\u0026gt; \u0026lt;fct\u0026gt; ## 1 58 1 0.318 t2 2 ## 2 59 2 0.634 t47 2 ## 3 59 3 0.127 t40 2 ## 4 57 4 0.423 t20 2 ## 5 56 5 0.914 t44 2 ## 6 55 6 0.468 t3 2 取树的子集\n1 2 3 4 5 6 7 clade \u0026lt;- tree_subset(tree, node=53, levels_back=0) clade2 \u0026lt;- tree_subset(tree, node=53, levels_back=1) p1 \u0026lt;- ggtree(clade) + geom_tiplab() + xlim(0, 5) p2 \u0026lt;- ggtree(clade2, aes(color=group)) + geom_tiplab() + xlim(0, 9) + scale_color_manual(values=c(\u0026#34;black\u0026#34;, \u0026#34;red\u0026#34;)) p1+p2 其他一些操作:\n1 2 3 4 5 6 7 8 #重设树根,指定外类群 trda2 \u0026lt;- root(tree, outgroup = 104, edgelabel = TRUE) #缩放树枝 rescale_tree(tree, \u0026#39;dN\u0026#39;) #删除tip drop.tip(tree,1:5) annotation tip annotation 这类注释方法使用的注释数据集基本是一列是tip的node号或label，其他列为注释数据（分类数据/连续数值数据），每一行是一个tip。\nggtree本身自带一些实现tip注释（添加热图等对象）的功能，基于facet以及数据对齐tip：\n1 2 3 4 5 6 #生成测试注释文件 anno=data.frame(row.names = tree$tip.label,node=tree$tip.label, Group=sample(LETTERS[1:3],50,replace = T), Type=sample(letters[1:3],50,replace = T), value1=abs(rnorm(50)),high=abs(rnorm(50,5))) head(anno) ## node Group Type value1 high ## t2 t2 B a 1.41126240 5.287710 ## t47 t47 B c 0.83758243 4.340230 ## t40 t40 B a 1.12376279 7.919140 ## t20 t20 A a 3.04376589 5.677416 ## t44 t44 A b 0.23502131 4.315680 ## t3 t3 C a 0.03325861 5.186492 1 2 3 p=ggtree(tree)+geom_tiplab(align = T) gheatmap(p, anno[\u0026#34;Group\u0026#34;], offset=0, width=0.2) 或者使用aplot包进行会自动对齐tip的组图（用cowplot无法实现），但缺点就是组图时候的一些细节不好调节，且要考虑清楚各个分面insert的关系和宽度。\n1 2 3 4 5 6 library(aplot) ap1=ggplot(anno,aes(x=node,y=\u0026#34;Group\u0026#34;,fill=Group))+geom_tile()+ coord_flip() + theme_tree2() + theme(legend.position=\u0026#39;none\u0026#39;) ap2=ggplot(anno,aes(x=node,y=high,fill=Group))+geom_col()+ coord_flip() + theme_tree2() + theme(legend.position=\u0026#39;none\u0026#39;) ap1%\u0026gt;% insert_left(p,width = 4) %\u0026gt;% insert_right(ap2, width=2) 目前感觉最好用的tip注释方法就是 ggtreeExtra，有统一的注释逻辑geom_fruit,按照图层一个一个添加，比较易学和调节。具体能用来注释的图层有’geom_bar’, ‘geom_col’, ‘geom_boxplot’, ‘geom_violin’，‘ggstar’,’ggimage’等。\n每一个geom图层就像一个积木块一样，我们要做的就是挑选合适的积木，用同样的方法搭上去即可（也是整个ggplot的绘图逻辑，优雅），对每个geom图层，我们同样可以使用ggplot的各种scale方法调节颜色、大小、形状等。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 p=ggtree(tree,layout = \u0026#34;fan\u0026#34;) #geom_star library(ggstar) p1=p + geom_fruit( data=anno, geom=geom_star, mapping=aes(y=`node`,fill=Type, size=value1, starshape=Group), position=\u0026#34;identity\u0026#34;, starstroke=0.1 )+ #调节star的大小以及其legend scale_size_continuous( range=c(1, 3), # the range of size. guide=guide_legend( keywidth=0.5, keyheight=0.5, override.aes=list(starshape=15), order=2 #legend的顺序 ) ) + #调节star的颜色以及其legend scale_fill_manual( values=c(\u0026#34;#8dd3c7\u0026#34;, \u0026#34;#ffed6f\u0026#34;, \u0026#34;#bebada\u0026#34;), guide=\u0026#34;none\u0026#34; ) + #调节star的形状以及其legend scale_starshape_manual( values=c(1, 16,15), guide=guide_legend( keywidth=0.5, keyheight=0.5, order=1 ) ) p1 要注意的是！在添加多个图层时，有时候我们要用多次的fill或color属性，但是ggplot的scale_fill_manual会对全局生效，结果就会比较奇怪，所以我们在图层之间一般要使用ggnewscale包来产生一个新的scale，之后就可以分别调节了。\n1 2 3 4 5 6 7 8 9 10 11 12 13 library(ggnewscale) p2=p1 + ggnewscale::new_scale_fill() + geom_fruit( data=anno, geom=geom_tile, mapping=aes(y=node, fill=value1), offset=0.08, # 调节 pwidth=0.25 # width of the external layer, default is 0.2 times of x range of tree. ) + scale_fill_gradient(low = \u0026#34;white\u0026#34;,high = \u0026#34;red\u0026#34;) p2 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 p2+ ggnewscale::new_scale_fill() + geom_fruit( data=anno, geom=geom_col, mapping=aes(y=node, x=high, fill=Type), pwidth=0.4,offset = 0.1, axis.params=list( axis=\u0026#34;x\u0026#34;, # 添加x轴文字 text.size=2, #文字大小 text.angle=-45, # 角度 hjust=0 # 调节 ), grid.params=list() # 添加网格线 ) + scale_fill_manual( values=c(\u0026#34;#a6bce3\u0026#34;, \u0026#34;#fb9a99\u0026#34;, \u0026#34;#fdbf6f\u0026#34;), guide=guide_legend(keywidth=0.5, keyheight=0.5, order=6) ) 当然还可以加一些有趣的比如 image注释 。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 library(ggimage) library(ggtree) nwk \u0026lt;- paste0(\u0026#34;((((bufonidae, dendrobatidae), ceratophryidae),\u0026#34;, \u0026#34;(centrolenidae, leptodactylidae)), hylidae);\u0026#34;) imgdir \u0026lt;- system.file(\u0026#34;extdata/frogs\u0026#34;, package = \u0026#34;TDbook\u0026#34;) x = read.tree(text = nwk) ggtree(x)+geom_tiplab()+ geom_fruit( data = data.frame(node=x$tip.label,image=paste0(imgdir, \u0026#39;/\u0026#39;, x$tip.label, \u0026#39;.jpg\u0026#39;)), geom = geom_image, mapping = aes(y=node,image=image), offset=0.5, align=2, size=.2 ) 生物剪影，Phylopic 包含 3200 多个生物剪影，涵盖很多门类。\n1 2 3 4 5 6 7 8 9 10 11 12 13 newick \u0026lt;- paste0(\u0026#34;((Pongo_abelii,(Gorilla_gorilla_gorilla,(Pan_paniscus,\u0026#34;, \u0026#34;Pan_troglodytes)Pan,Homo_sapiens)Homininae)Hominidae,\u0026#34;, \u0026#34;Nomascus_leucogenys)Hominoidea;\u0026#34;) tree \u0026lt;- read.tree(text=newick) #通过phylopic_uid查询剪影 d \u0026lt;- ggimage::phylopic_uid(tree$tip.label) d$body_mass \u0026lt;- c(52, 114, 47, 45, 58, 6) p \u0026lt;- ggtree(tree) %\u0026lt;+% d + geom_tiplab(aes(image=uid, colour=body_mass), geom=\u0026#34;phylopic\u0026#34;, offset=2.5) + geom_tiplab(aes(label=label), offset = .2) + xlim(NA, 7) + scale_color_viridis_c() internal annotation 这类注释方法使用基本是内部的node号或label，加上额外的注释数据（分类数据/连续数值数据）\n可选的对象有cladelab，strip，highlight，taxa_link… 也能直接给一部分树枝上色。\n1 2 3 4 5 6 7 8 9 internal_anno=data.frame(node=c(53,68,79),name=paste0(\u0026#34;clade\u0026#34;,1:3),angle1=c(0,90,0)) tree2 \u0026lt;- groupClade(tree, setNames(internal_anno$node,internal_anno$name),group_name = \u0026#34;test\u0026#34;) (col_p=ggtree(tree2, aes(color=test))+ scale_color_manual(values=c(\u0026#34;black\u0026#34;, \u0026#34;red3\u0026#34;, \u0026#34;skyblue\u0026#34;,\u0026#34;yellow3\u0026#34;)) + #theme(legend.position=\u0026#39;none\u0026#39;)+ guides(color=guide_legend(override.aes = list(linewidth=3))) ) 1 2 3 #添加point注释 ggtree(tree2, layout=\u0026#34;fan\u0026#34;) + geom_point2(mapping = aes(subset=c(test!=0),color=test)) 1 2 ggtree(tree, layout=\u0026#34;fan\u0026#34;) + geom_cladelab(data = internal_anno,mapping = aes(node=node,label=name,color=name,angle=angle1)) 1 2 3 4 5 6 #strip类似cladelab，不过提供的是两个tip，可以横跨不同位置的枝条,不接受mapping ggtree(tree, layout=\u0026#34;fan\u0026#34;) + geom_tiplab() + geom_strip(\u0026#39;t10\u0026#39;, \u0026#39;t33\u0026#39;, barsize=2, color=\u0026#39;red\u0026#39;, label=\u0026#34;group1\u0026#34;, offset.text=.1) + geom_strip(\u0026#39;t12\u0026#39;, \u0026#39;t21\u0026#39;, barsize=2, color=\u0026#39;blue\u0026#39;, label = \u0026#34;group2\u0026#34;, offset.text=.1) 1 2 3 #highlight ggtree(tree, layout=\u0026#34;fan\u0026#34;) + geom_highlight(data = internal_anno,mapping = aes(node=node,label=name,fill=name)) 1 2 3 4 #balance类似highlight，不过可以提供两个有包含关系的clade,不接受mapping ggtree(tree) + geom_balance(node=55, fill=\u0026#39;steelblue\u0026#39;, alpha=0.6, extend=1) + geom_balance(node=56, fill=\u0026#39;darkgreen\u0026#39;, alpha=0.6, extend=1) 1 2 3 4 5 6 7 8 9 10 11 12 links \u0026lt;-data.frame(from=c(\u0026#34;t36\u0026#34;,\u0026#34;t7\u0026#34;,\u0026#34;t23\u0026#34;), to=c(\u0026#34;t6\u0026#34;, \u0026#34;t46\u0026#34;, \u0026#34;t29\u0026#34;), type=c(\u0026#34;l1\u0026#34;, \u0026#34;l2\u0026#34;, \u0026#34;l3\u0026#34;), s=c(2, 1, 2)) ggtree(tree, layout=\u0026#34;inward_circular\u0026#34;, xlim=c(30, 0)) + geom_taxalink(data=links, mapping=aes(taxa1=from, taxa2=to, color=type, size=s)) + geom_tiplab(hjust=1) + scale_size_continuous(range=c(1,3)) 另外一些是通过内部节点改变整个树分布的方法：\n1 2 #通过scaleClade调节某个clade占比 scaleClade(col_p, node=53, scale=.1) 1 2 #通过collapes折叠某个clade collapse(col_p, node=53,mode = c(\u0026#34;mix\u0026#34;,\u0026#34;max\u0026#34;,\u0026#34;min\u0026#34;,\u0026#34;none\u0026#34;)[1],fill=\u0026#34;red3\u0026#34;,alpha=0.4) 1 2 #通过rotate旋转两个clade ggtree::rotate(col_p,node = 52)+geom_nodelab(aes(subset=c(node==52),label=node)) 1 2 #通过flip交换两个clade ggtree::flip(col_p,53,68)+geom_nodelab(aes(label=node)) 1 2 #通过open_tree和rotate_tree调节角度 open_tree(col_p, 180)%\u0026gt;%rotate_tree(90) 掌握以上这些方法，基本上可以绘制出用在文章的树了（当然一定要自己好好找配色，调整细节！！！）\n下次进阶！\nReference 1. G. Yu, D. K. Smith, H. Zhu, Y. Guan, et al., Ggtree: An r package for visualization and annotation of phylogenetic trees with their covariates and other associated data. Methods in Ecology and Evolution. 8, 28–36 (2017).\n2. S. Xu, Z. Dai, P. Guo, X. Fu, et al., ggtreeExtra: Compact Visualization of Richly Annotated Phylogenetic Data. Molecular Biology and Evolution. 38, 4039–4042 (2021).\n","date":"2023-04-14T00:00:00Z","image":"/index.cn_files/figure-html/unnamed-chunk-15-1.png","permalink":"/p/r-tree/","title":"R绘制优美的进化树（基础）"},{"content":"【浙江大学生命科学研究院蒋超实验室】实验技术员招聘火热进行中！🔥\n🌟浙江大学生命科学研究院蒋超实验室诚邀实验技术员 1-2 名加盟！我们邀请您加入我们的课题组，参与全球大型暴露组研究项目，负责 DNA 提取和二代测序的文库构建工作。估计项目周期约为4个月(带薪水)，届时您将有机会深入系统地学习生物信息学，甚至有机会作为共同作者在顶级期刊发表文章！\n🔬我们欢迎具有分子实验基础的同学（大三或即将硕士毕业）加入我们的队伍！\n🔗实验室网站：http://lsi.zju.edu.cn/jianglab_exposome/list.htm\n👨🏻‍🎓导师简介：\n蒋超博士现任浙江大学生命科学研究院研究员，兼聘浙江大学附属第一医院，获得国家级青年人才项目。本科毕业于厦门大学生命科学学院。博士师从美国印第安纳大学的 Yves Brun 教授，从事分子进化层面解析细菌形态进化的机制的研究，于 2014 年取得博士学位。后加入美国斯坦福大学医学院遗传系精准医疗中心 Mike Snyder 教授组进行博士后研究。Mike Snyder 教授是国际著名的精准化医疗和多组学研究的先驱。博士后期间，首次全面解读人类健康研究中未知的重要组成部分-个人环境暴露组。\n于 2019 回国后主要研究围绕环境暴露组、微生物组、精准医学开展，具体方向为：环境暴露组在宏观及个体水平上的精准时空动态测量；环境暴露组与人类疾病健康的关系；微量人、环境微生物组精准时空动态测量及其与人类疾病健康和环境健康的关系；环境暴露组、微生物组以及相关组学的分子实验技术和计算统计方法的开发；个体环境暴露组可穿戴监测设备的开发和运用；微生物进化；微生物组功能原件大规模挖掘；多组学和机器学习在微生物组及精准医学的应用等。\n以第一作者和/或通讯作者（含共同）在国际知名期刊 Cell、Nature、Nature Protocols、Cell Discovery等杂志发表多篇研究论文。以共同作者在Nature Biotechnology、Circulation Research、Genome Research等杂志刊文。近期以通讯作者在 Science 上发表对新冠病毒起源时间模型分析的 eLetter 评论。已取得美国空气暴露组监测设备相关专利，申请国内相关专利若干。\n实验室研究方向 💼职位要求：\n1.具备扎实的分子实验基础，最好熟练掌握 DNA 或 RNA 提取，荧光定量 PCR 或普通 RCR；\n2.具备较强的学习能力、执行力，以及出色的团队合作意识和沟通能力；\n3.每周工作至少 4 天，周一到周日，可根据您的时间安排。大三和即将硕士毕业同学皆可；\n4.实验全程将在博士后的带领和指导下进行；\n5.提供从入门到精通的生信学习机会，包括手把手教授大数据分析和高级可视化技巧。PI 将提供从科研创新思维到项目落实的全方位\u0026quot;博士\u0026quot;级别培养和指导。\n💰待遇： 薪酬待遇为每个月5000元。实验室提供专业的科研指导和一流的科研环境。硕士毕业生待项目结束后可以考虑续聘为全职技术员。\n📧申请方式： 有意向的候选人，请发送个人简历及相关资料（包括学习、工作和研究经历，以及其他证明个人能力、水平的相关资料）至 qiong_chen@zju.edu.cn，并注明\u0026quot;姓名+应聘技术员\u0026quot;。经考核后，我们将择优录取。\n📅招聘时间： 2023年4月10日至4月30日\n🏢实验地址： 浙大紫金港生科院338\n⌚️项目计划开展时间： 约2023年4月30日至2023年8月30日，大概率会提前完成实验工作。若该阶段实验未完成，可酌情续约与否。\n走过路过不要错过，请抓住这次难得的机会，加入我们这个充满活力和创新的团队，开启一段富有挑战和收获的科研之旅！期待您的加入！\n","date":"2023-04-10T00:00:00Z","image":"/p/werving-of-jiang-lab/images/research%20field_hu_fe75baf1dd784487.png","permalink":"/p/werving-of-jiang-lab/","title":"蒋超实验室项目技术员招聘"},{"content":"Introduction 在 R 语言中，有多个软件包可以用来绘制地图，其中最流行的是 ggplot2、sp、maptools 和 leaflet。\nsimple examples 以下是一些简单的示例：\n使用 ggplot2 包绘制世界地图： 1 2 3 4 5 6 7 library(ggplot2) library(maps) world_map \u0026lt;- map_data(\u0026#34;world\u0026#34;) ggplot(world_map, aes(x = long, y = lat, group = group)) + geom_polygon(fill = \u0026#34;lightblue\u0026#34;, color = \u0026#34;white\u0026#34;) 使用 sp 包和 maptools 包绘制美国州界地图： 1 2 3 4 5 6 7 8 library(sp) library(maptools) #sids.shp是一个内置的数据，后面会讲到 us_states \u0026lt;- readShapePoly(system.file(\u0026#34;shapes/sids.shp\u0026#34;, package=\u0026#34;maptools\u0026#34;)[1], proj4string=CRS(\u0026#34;+proj=longlat +datum=WGS84\u0026#34;)) plot(us_states) 使用 leaflet 包绘制交互式地图： 1 2 3 4 5 library(leaflet) leaflet() %\u0026gt;% addTiles() %\u0026gt;% addMarkers(lng=-74.5, lat=40, popup=\u0026#34;New York City\u0026#34;) 如果需要更高级的地图可视化，就需要一些地图相关知。例如在地图上添加标注或进行交互式可视化，也是我们接下来要讨论的地方。\nFormat 首先，在地图绘制中，常用的数据格式包括：\n.shp 文件：地理信息系统 (GIS) 中的一种数据格式，通常用于存储地理矢量数据，例如点、线、面、多边形等地理特征的坐标和属性信息。\n.kml 文件：Google 地图使用的一种数据格式，通常用于存储地理矢量数据和标记，例如点、线、面、图标等地理特征的坐标、属性信息和样式信息。\n.kmz 文件：Google 地图使用的一种数据格式，通常是 .kml 文件的压缩版本，可以方便地共享和传输。\n.gpx 文件：一种常见的 GPS 数据格式，通常用于存储路径、轨迹等 GPS 数据。\n.json 文件：一种常见的数据交换格式，可以存储各种结构化数据，包括地理矢量数据、属性信息等。\n.csv 文件：一种常见的数据格式，可以存储表格数据，例如经纬度、名称、描述等地理信息。\n除了以上列举的格式之外，还有其他一些格式，例如 .gml、.svg、.dxf 等，这些格式通常在不同的 GIS 软件和地图绘制工具之间进行数据交换和共享。需要根据具体需求和使用工具选择合适的数据格式。\nR 可以处理上述列举的地图相关的文件格式。\n对于 .shp 文件，R中的 rgdal、sp、sf 等软件包可以读取和操作该文件格式，可以进行地图绘制、分析和处理等任务。\n对于 .kml 和 .kmz 文件，R中的 plotKML 软件包可以读取和操作该文件格式，可以进行地图绘制和分析等任务。\n对于 .gpx 文件，R中的 maptools、ggmap 等软件包可以读取和操作该文件格式，可以进行路径和轨迹可视化等任务。\n对于 .json 和 .csv 文件，R内置的函数和外部软件包都可以读取和操作该文件格式，可以进行地图数据的转换、处理和可视化等任务。\n总的来说，R 中有许多内置函数和软件包可以读取、操作和可视化地图相关的数据格式，可以帮助我们进行地图制作、数据分析和可视化等任务。\nCRS 坐标参考系统（Coordinate Reference System，CRS）是一个基于地球表面形状和大小的坐标系统。它是通过经度和纬度来描述地球表面上的点和区域的。\n在地理坐标系中，经度是指地球表面上某点所在的经线和地球本初子午线（即0度经线）之间的夹角，以东经为正，以西经为负。纬度是指地球表面上某点所在的纬线和赤道之间的夹角，以北纬为正，以南纬为负。\nWGS84坐标系统是全球定位系统（GPS）使用的一种地理坐标系统。WGS84是\u0026quot;World Geodetic System 1984\u0026quot;的缩写，是由美国国防部和美国国家地球空间情报局共同研制的。WGS84坐标系统使用经度和纬度来描述地球表面上的点和区域。它使用的是大地基准面，与传统的椭球体模型有所不同。WGS84坐标系统的零点定义为通过英国格林尼治天文台的经线（0度经线），也称为本初子午线。R的sf识别\u0026quot;EPSG:4326\u0026quot; or \u0026ldquo;WGS84\u0026rdquo; 都是该坐标系。\n在R里面我们可以定义自己绘图需要的坐标系，如\u0026quot;+proj=laea +lat_0=40 +lon_0=104\u0026quot; ，它表示一个局部等面积投影（LAEA）坐标系，中心纬度为40度，中心经度为104度（后面会用到）。\n如果想将一个地理坐标系（比如经度-纬度坐标系）中的点转换为这个投影坐标系中的点，可以使用R中的proj4库来进行转换。下面是一个简单的R代码示例：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 library(proj4) # 定义源坐标系（经度-纬度坐标系） src_crs \u0026lt;- \u0026#34;+proj=longlat +datum=WGS84\u0026#34; # 定义目标坐标系（局部等面积投影坐标系） dst_crs \u0026lt;- \u0026#34;+proj=laea +lat_0=40 +lon_0=104\u0026#34; # 定义待转换的点（经度、纬度） lon \u0026lt;- 116.4074 lat \u0026lt;- 39.9042 # 转换坐标系 p \u0026lt;- project(cbind(lon, lat), dst_crs) # 输出转换后的坐标（x、y） print(p) # 或者使用sf转换 source_df=st_as_sf(data.frame(lon, lat),coords = c(\u0026#34;lon\u0026#34;, \u0026#34;lat\u0026#34;), crs = 4326) sf::st_transform(source_df,crs=\u0026#34;+proj=laea +lat_0=40 +lon_0=104\u0026#34;) China map basic map 基础的ggplot2绘图代码如下，但是最近maps包好像没有存储中国的数据了，所以我们应该自己去找自己要画的区域的地图文件。\n1 2 3 4 5 6 7 8 9 10 11 12 # 注意，无法正常运行 library(maps) library(ggplot2) # 读取中国地图数据 china_map \u0026lt;- map_data(\u0026#34;china\u0026#34;) # 绘制中国地图 ggplot() + geom_polygon(data = china_map, aes(x = long, y = lat, group = group), fill = \u0026#34;white\u0026#34;, color = \u0026#34;black\u0026#34;) + theme_void() + coord_fixed() 我常用的是geojson文件，网上能够下载到中国地图的地方很多，比如 GeoJSON.cn，yezongyang/china-geojson等等，而世界上其他区域，不同精度（洲，国家，城市，县\u0026hellip;）的地图数据就需要自己按照需求寻找一下，如GeoJSON Maps of the globe (ash.ms)，georgique/world-geojson，datasets/geo-countries等等。\n中国地图绘制主要参考这篇博客：R-ggplot2 标准中国地图制作。\n使用sf包读取地图数据：这里用的是民政局提供的一个API，如果是自己下载的数据就换成文件地址即可，st_read或者read_sf可以以处理geojson文件。\n1 2 3 4 5 6 7 8 9 10 11 library(sf) library(ggplot2) #1.下载数据 dir=getwd() china_shp=paste0(dir,\u0026#34;/china.json\u0026#34;) if(!file.exists(china_shp))download.file(\u0026#34;https://gitcode.net/mirrors/lyhmyd1211/geomapdata_cn/-/raw/master/china.json?inline=false\u0026#34;,china_shp) china \u0026lt;- sf::read_sf(china_shp) #2.民政部API link: https://mp.weixin.qq.com/s/qj1SRc6D8sgYJYaZzDux6Q API_pre = \u0026#34;http://xzqh.mca.gov.cn/data/\u0026#34; china = sf::st_read(dsn = paste0(API_pre, \u0026#34;quanguo.json\u0026#34;), stringsAsFactors=FALSE) 读取数据后变成一个sf对象，sf类型的数据本质还是一个data.frame，但是其中有些元素是MULTIPOLYGON S3对象，这是一种表示多边形几何对象的数据类型，可以用于描述多个不相交的多边形区域，每个多边形可以由一个或多个线性环组成。在R中，MULTIPOLYGON 通常作为空间数据类型的一种表示，用于表示地理区域的空间形状和位置关系。\nst_crs函数可以用来改变地理坐标系：\n1 head(china) 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 ## Simple feature collection with 6 features and 10 fields ## Geometry type: MULTIPOLYGON ## Dimension: XY ## Bounding box: xmin: 97.1729 ymin: 34.58341 xmax: 126.0685 ymax: 53.33701 ## Geodetic CRS: WGS 84 ## # A tibble: 6 × 11 ## adcode name child…¹ level parent subFe…² adchar center centr…³ acrou…⁴ ## \u0026lt;chr\u0026gt; \u0026lt;chr\u0026gt; \u0026lt;int\u0026gt; \u0026lt;chr\u0026gt; \u0026lt;chr\u0026gt; \u0026lt;int\u0026gt; \u0026lt;chr\u0026gt; \u0026lt;list\u0026gt; \u0026lt;list\u0026gt; \u0026lt;list\u0026gt; ## 1 110000 北京市 16 prov… \u0026#34;{ \\\u0026#34;… 0 \u0026lt;NA\u0026gt; \u0026lt;dbl\u0026gt; \u0026lt;dbl\u0026gt; \u0026lt;int\u0026gt; ## 2 120000 天津市 16 prov… \u0026#34;{ \\\u0026#34;… 1 \u0026lt;NA\u0026gt; \u0026lt;dbl\u0026gt; \u0026lt;dbl\u0026gt; \u0026lt;int\u0026gt; ## 3 130000 河北省 11 prov… \u0026#34;{ \\\u0026#34;… 2 \u0026lt;NA\u0026gt; \u0026lt;dbl\u0026gt; \u0026lt;dbl\u0026gt; \u0026lt;int\u0026gt; ## 4 140000 山西省 11 prov… \u0026#34;{ \\\u0026#34;… 3 \u0026lt;NA\u0026gt; \u0026lt;dbl\u0026gt; \u0026lt;dbl\u0026gt; \u0026lt;int\u0026gt; ## 5 150000 内蒙古自治区 12 prov… \u0026#34;{ \\\u0026#34;… 4 \u0026lt;NA\u0026gt; \u0026lt;dbl\u0026gt; \u0026lt;dbl\u0026gt; \u0026lt;int\u0026gt; ## 6 210000 辽宁省 14 prov… \u0026#34;{ \\\u0026#34;… 5 \u0026lt;NA\u0026gt; \u0026lt;dbl\u0026gt; \u0026lt;dbl\u0026gt; \u0026lt;int\u0026gt; ## # … with 1 more variable: geometry \u0026lt;MULTIPOLYGON [°]\u0026gt;, and abbreviated variable ## # names ¹​childrenNum, ²​subFeatureIndex, ³​centroid, ⁴​acroutes 1 2 3 4 5 6 7 library(sf) library(ggplot2) library(ggspatial) # plot ggplot(china)+ geom_sf()+ labs(title=\u0026#34;Ministry of Civil of PRC\u0026#34;,x=\u0026#34;Lon\u0026#34;,y=\u0026#34;Lat\u0026#34;) 1 2 3 4 5 6 #改变crs # plot ggplot(china)+ geom_sf()+ coord_sf(crs = \u0026#34;+proj=laea +lat_0=40 +lon_0=104\u0026#34;)+ labs(title=\u0026#34;Ministry of Civil of PRC\u0026#34;,x=\u0026#34;Lon\u0026#34;,y=\u0026#34;Lat\u0026#34;) 使用ggspatial包添加比例尺和指北针：\n1 2 3 4 5 6 7 8 9 main_map=ggplot()+ geom_sf(data = china,fill=NA,size=1,color=\u0026#34;black\u0026#34;)+ coord_sf(crs = \u0026#34;+proj=laea +lat_0=40 +lon_0=104\u0026#34;)+ labs(title=\u0026#34;Ministry of Civil of PRC\u0026#34;,x=\u0026#34;Lon\u0026#34;,y=\u0026#34;Lat\u0026#34;) + annotation_scale(location = \u0026#34;bl\u0026#34;) + # spatial-aware automagic north arrow annotation_north_arrow(location = \u0026#34;tl\u0026#34;, which_north = \u0026#34;false\u0026#34;, style = north_arrow_fancy_orienteering)+theme_minimal() main_map annotation 使用ggplot常规的注释手段geom_point()或geom_text() 在使用geom_sf 绘制的地图上一般不会成功，而是应该先用st_as_sf转换我们的注释数据，然后用geom_sf() ，geom_sf_text() 或geom_sf_label()。\n不要把注释信息放在coord_sf 的后面，因为ggplot是按照图层添加元素的，coord_sf 转换坐标后加入的注释就会有位置偏差。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 #生成测试数据 anno=data.frame(lon=runif(20,90,120), lat=runif(20,30,40), type=sample(letters[1:3], 20, replace = TRUE), value=runif(20,1,10)) #转换对象 anno_sf \u0026lt;- st_as_sf(anno,coords = c(\u0026#34;lon\u0026#34;, \u0026#34;lat\u0026#34;),crs = 4326) p2=ggplot()+ geom_sf(data = china,fill=NA,size=1,color=\u0026#34;black\u0026#34;)+ #添加散点注释 geom_sf(data = anno_sf,aes(fill=type,size=value),shape=21,colour=\u0026#39;black\u0026#39;,stroke=.25)+ scale_size(range = c(1,5))+ #添加text geom_sf_text(data = anno_sf,aes(label=round(value,1)),size=2,legend=\u0026#34;none\u0026#34;)+ coord_sf(crs = \u0026#34;+proj=laea +lat_0=40 +lon_0=104\u0026#34;)+ labs(title=\u0026#34;Ministry of Civil of PRC\u0026#34;,x=\u0026#34;Lon\u0026#34;,y=\u0026#34;Lat\u0026#34;) + annotation_scale(location = \u0026#34;bl\u0026#34;) + # spatial-aware automagic north arrow annotation_north_arrow(location = \u0026#34;tl\u0026#34;, which_north = \u0026#34;false\u0026#34;, style = north_arrow_fancy_orienteering)+theme_minimal() p2 如果想要添加具体坐标的注释或者使用xlim或，geom_sf_text里调整文本位置的nudge_x等功能，那也需要注意投影坐标系的变化，使用st_transform处理。\n1 2 3 4 5 6 7 8 9 #例如，这个方法是无法取出90E到120E的部分的，而是很窄的一段 p2+xlim(90,120) data.frame(lon=c(90,120),lat=c(30,30))%\u0026gt;% st_as_sf(coords = c(\u0026#34;lon\u0026#34;, \u0026#34;lat\u0026#34;), crs = 4326) %\u0026gt;% sf::st_transform(df2_sf,crs=\u0026#34;+proj=laea +lat_0=40 +lon_0=104\u0026#34;) #发现结果对应的是(-1348988,1539346),这样截取的才是90E到120E的部分。 p2+xlim(-1348988,1539346) Leaflet usage Leaflet是一个开源的JavaScript库，用于创建交互式地图。R中的Leaflet包提供了一个轻量级的接口，允许在R中创建交互式地图。Leaflet包提供了许多基本的地图操作功能，例如缩放、平移和旋转，同时还允许添加标记、文本注释、多边形、线条和点。\n在使用Leaflet包之前，需要先安装并加载它。可以通过以下代码安装和加载Leaflet包：\n1 2 install.packages(\u0026#34;leaflet\u0026#34;) library(leaflet) 在使用Leaflet包创建地图时，需要提供一个起始的中心点和缩放级别。例如，可以使用以下代码创建一个以纽约市为中心的地图，此外，可以使用addTiles()函数添加地图图层，还可以使用addMarkers()函数添加标记，使用addPolygons()函数添加多边形，使用addLines()函数添加线条，使用addPopups()函数添加弹出窗口等等。通过使用这些函数，可以在地图上添加各种各样的元素，从而创建一个自定义的交互式地图，以下是完成上述中国地图的一个完整的例子。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 # Prepare the text for the tooltip (HTML style): gre_text \u0026lt;- paste( \u0026#34;Type: \u0026#34;, anno$type, \u0026#34;\u0026lt;br/\u0026gt;\u0026#34;, \u0026#34;Value: \u0026#34;, round(anno$value,2), \u0026#34;\u0026lt;br/\u0026gt;\u0026#34; )%\u0026gt;% lapply(htmltools::HTML) type_col=colorFactor(palette = c(\u0026#34;red3\u0026#34;,\u0026#34;green3\u0026#34;,\u0026#34;blue3\u0026#34;),domain =anno$type) inter_p=leaflet(anno) %\u0026gt;% #添加图层 addTiles() %\u0026gt;% #确定中心点 setView(lng = 104, lat = 40, zoom = 4)%\u0026gt;% #添加散点注释 addCircleMarkers(~lon, ~lat, fillColor = ~type_col(type), fillOpacity = 0.7, color=\u0026#34;white\u0026#34;, radius=8, stroke=FALSE, label = gre_text, labelOptions = labelOptions( style = list(\u0026#34;font-weight\u0026#34; = \u0026#34;normal\u0026#34;, padding = \u0026#34;3px 8px\u0026#34;), textsize = \u0026#34;13px\u0026#34;, direction = \u0026#34;auto\u0026#34;)) %\u0026gt;% #添加图例 addLegend( pal=type_col, values=~type, opacity=0.7, title = \u0026#34;Type\u0026#34;, position = \u0026#34;bottomright\u0026#34; ) class(inter_p) inter_p add in PPT leaflet最后生成的是一个htmlwidget衍生对象，所以可以用htmlwidgets包保存为html文件并直接用浏览器打开。\n1 2 #保存结果 htmlwidgets::saveWidget(inter_p,file = \u0026#34;leaflet.html\u0026#34;) 有时候这种交互地图在presentation展示时非常好用，要是能插入到ppt就是件美事了。\n可惜的是，没有找到很好的方式完成这个功能😭（除非一开始的ppt都是用Rmarkdown做的）\nWindows上的Powerpoint可以考虑使用插件：\nwebView：PPT：如何在ppt中显示网页，并且实时操作？（但好像也挂掉了）\nLiveWeb：如何将实时网页添加到PowerPoint演示文稿 （新版office不行）\nMac上的Powerpoint更加不太行了。\n看来只能加个超链接到该文件，然后点击后跳转到浏览器了（希望未来有解决方法）。\nGeoTiff manipulate 我本人不是地科相关专业的，不太会用ArcGIS等更为专业的软件，但有时候也需要去收集一些跟地理环境相关的数据，比如气温，土壤元素等等，发现在很多数据库中这些数据以geotiff格式储存。\nGeoTIFF是一种基于TIFF格式的地理信息图像文件格式，它包含了地理空间信息和图像信息。GeoTIFF文件可以包含单一图像或多个图像，并且可以存储地球表面的各种数据，如高程数据、卫星图像、气象数据等等。GeoTIFF文件与普通的TIFF文件相比，增加了一些地理参考信息和投影信息，可以用于地图制作和GIS分析等领域。GeoTIFF文件中的地理参考信息包括地理坐标系和投影坐标系，以及每个像素所表示的地理位置和像素大小等信息。\nRasterLayer 在R语言中，可以使用raster包和gdal包读取和处理GeoTIFF文件。使用raster包中的函数可以读取GeoTIFF文件并将其转换为RasterLayer对象，以进行各种空间分析操作。\nRasterLayer是raster包中的一种对象类型，它代表了一个栅格数据集。栅格数据集是由多个栅格单元组成的二维矩阵，每个栅格单元都有一个特定的值，代表了该位置上的数据信息。在R语言中，使用raster包可以方便地读取和处理栅格数据集，例如遥感影像、地形图等。通过将栅格数据集转换为RasterLayer对象，可以进行各种空间分析操作，例如裁剪、合并、重采样、计算、绘图等。\n下面是一些基于RasterLayer对象（或者sf对象，很多函数都是通用的）的常见操作和分析的R语言代码示例：\n计算栅格数据的基本统计信息 1 2 3 4 5 6 7 8 9 10 library(raster) # 读入一个栅格数据文件 r \u0026lt;- raster(\u0026#34;path/to/raster.tif\u0026#34;) # 计算最小值、最大值、均值、方差 min_val \u0026lt;- minValue(r) max_val \u0026lt;- maxValue(r) mean_val \u0026lt;- mean(r) var_val \u0026lt;- var(r) 对栅格数据进行裁剪、合并、重采样等操作 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 library(raster) # 读入两个栅格数据文件 r1 \u0026lt;- raster(\u0026#34;path/to/raster1.tif\u0026#34;) r2 \u0026lt;- raster(\u0026#34;path/to/raster2.tif\u0026#34;) # 裁剪两个栅格数据文件 r1_crop \u0026lt;- crop(r1, extent(r2)) r2_crop \u0026lt;- crop(r2, extent(r1)) # 合并两个栅格数据文件 r_merge \u0026lt;- merge(r1_crop, r2_crop) # 将一个栅格数据文件的分辨率重采样为另一个栅格数据文件的分辨率 r_resample \u0026lt;- resample(r1_crop, r2_crop) 进行栅格数据的代数、逻辑运算 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 library(raster) # 读入两个栅格数据文件 r1 \u0026lt;- raster(\u0026#34;path/to/raster1.tif\u0026#34;) r2 \u0026lt;- raster(\u0026#34;path/to/raster2.tif\u0026#34;) # 对两个栅格数据文件进行加、减、乘、除运算 r_add \u0026lt;- r1 + r2 r_sub \u0026lt;- r1 - r2 r_mul \u0026lt;- r1 * r2 r_div \u0026lt;- r1 / r2 # 对一个栅格数据文件进行逻辑与、或、非运算 r_and \u0026lt;- r1 \u0026amp; r2 r_or \u0026lt;- r1 | r2 r_not \u0026lt;- !r1 进行栅格数据的可视化 1 2 3 4 5 6 7 8 9 10 11 12 13 library(raster) # 读入一个栅格数据文件 r \u0026lt;- raster(\u0026#34;path/to/raster.tif\u0026#34;) # 绘制等高线图 contour(r, add=FALSE) # 绘制等值线图 image(r, col=terrain.colors(255)) # 绘制渐变色图 plot(r, col=rainbow(255)) Example 继续我们上面的中国地图绘制，我们想要获得某个时间的中国气温图：\n首先在WorldClim网站上可以下载到全球历史天气信息：\n我们下载一个average temperature信息，精度为10minute(即10个经纬度的单位，比较粗略，35M～)，通过把全球的数据map到我们之前已经得到的sf对象china上就可以取出这部分的数据了。\n1 2 3 4 5 library(raster) avgtemp \u0026lt;- raster(\u0026#34;~/Downloads/wc2.1_10m_tavg/wc2.1_10m_tavg_01.tif\u0026#34;) #全球平均气温数据 plot(avgtemp) 1 2 3 #切片 china_tmp=crop(avgtemp,china) plot(china_tmp) 1 2 3 #掩膜 china_tmp=mask(china_tmp,china) plot(china_tmp) 最后再把经过切片掩膜处理的RasterLayer转换为sf对象，就可以根据我们之前绘制annotation的方法把气温数据全部绘制上去了。\n大功告成！这里是最后的结果：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 # 将RasterLayer转换为sf对象 sf_data \u0026lt;- st_as_sf(rasterToPolygons(china_tmp), crs = st_crs(china_tmp)) colnames(sf_data)[1]=\u0026#34;Average_temperature\u0026#34; ggplot()+ geom_sf(data = china,fill=NA,size=1,color=\u0026#34;black\u0026#34;)+ #添加栅格数据 geom_sf(data = sf_data,aes(fill=Average_temperature),shape=22,size=0.5,stroke=0,color=NA)+ scale_fill_gradient2(low = \u0026#34;blue\u0026#34;,mid = \u0026#34;white\u0026#34;,high = \u0026#34;red\u0026#34;)+ #使用ggnewscale产生一个新的fill映射，否则会覆盖报错。 ggnewscale::new_scale_fill()+ #添加散点注释 geom_sf(data = anno_sf,aes(fill=type,size=value),shape=21,colour=\u0026#39;black\u0026#39;,stroke=.25)+ scale_size(range = c(1,5))+ #添加text geom_sf_text(data = anno_sf,aes(label=round(value,1)),size=2,legend=\u0026#34;none\u0026#34;)+ coord_sf(crs = \u0026#34;+proj=laea +lat_0=40 +lon_0=104\u0026#34;)+ labs(title=\u0026#34;Ministry of Civil of PRC\u0026#34;,x=\u0026#34;Lon\u0026#34;,y=\u0026#34;Lat\u0026#34;) + annotation_scale(location = \u0026#34;bl\u0026#34;) + # spatial-aware automagic north arrow annotation_north_arrow(location = \u0026#34;tl\u0026#34;, which_north = \u0026#34;false\u0026#34;, style = north_arrow_fancy_orienteering)+theme_minimal() ","date":"2023-04-06T00:00:00Z","image":"/p/r-map/index_files/figure-html/unnamed-chunk-22-1_hu_bfb841e752c59491.png","permalink":"/p/r-map/","title":"R绘制优美的地图"},{"content":"Theories and Methods of Species Diversity Research\n这是我在一门研究生课程上的课程任务，查阅了一些文献总结整理了物种多样性研究理论与方法，比较基础，没有对一些理论和模型深入讲解，仅做分享。\nIntroduction Biological diversity largely describes the change of life from genes to ecosystems, comprising their existences, genetic variations, their environment, populations and the ecosystem in which they are existing and other evolutionary developments that keep the system functioning, changing and adapting.\n生物多样性是度量生命的变异和变异能力的指标，又分成遗传多样性，物种多样性，生态系统多样性三个层次，我这里主要介绍物种多样性。 他又有三个尺度和三个维度，分别是α，β，γ分类多样性，谱系多样性，功能多样性，这里的每个交集都是可以研究的。\nData collection methods 我们应该如何进行物种多样性研究呢？\n首先当然是制定研究方案，进行取样， 对于自己的研究对象，可以进行随机取样，系统取样，或者其他的一些方法， 也可能是一块有代表性的永久样地，可以研究它的动态变化。\n然后是开始调查获取数据，传统的方法里，植物群落一般会进行实地调查或者使用遥感图像收集数据，动物会用到自动音视频记录，昆虫的话还会有灯光诱捕法等。\n还有对微生物进行调查的，用直接培养方法或者测序手段。\n当然这些方法不是一定专用的，一些新的方法也可以交叉使用，比如eDNA方法： eDNA是指在环境样品中所有被发现的不同生物的基因组DNA的混合，环境可以包括土壤、沉积物、排泄物、空气、水体，甚至生物个体本身。 动物在某个环境中生活，身上的各种痕迹会携带着自身DNA掉落到四周，所以用这个方法有调查各种物种的潜力，有篇文章就用空气的eDNA调查了附近的动物。\n此外还有整合的方法，比如这篇文章就提出，将遥感，田间调查和测序结合在一起，来获得完整的物种风度表。\n有了这些方法后，我们还要明确自己要获取的有哪些数据：\n我认为主要有三个方面：\n第一个就是群落的特征，包括各个物种的丰度，密度，频度，群落的生物量；如果是植物的话，还要收集盖度、树冠直径、树高、位置等等。 第二个重要的方面是我们每个样方的环境因子数据： 包括气候数据，如降水，相对湿度，温度等等，地形数据，如海拔，坡度等等，土壤数据，如土壤的粒径保水量和各种化学元素等等，有条件的话可以做微生物和人类因素的数据收集。 第三个方面是物种的特征：比如植物的生活型，生长型，功能类型等，这个对后面功能多样性的研究很关键 还有就是各个物种的系统发育位置，可以去找各种植物志，动物志或者NCBI的数据库来获得，这个对谱系多样性研究很重要。 Measure methods 获取了以上这些数据后，接下来就是使用一些指标对多样性进行度量。\nTaxa α diversity 首先是分类的a多样性指数，主要有以下几个类别：\n使用物种数指示 物种数和物种总个体数 物种数和物种总个体数和每个物种的个体数（还有一些专门用在测序数据表征多样性的，因为测序手段我们能获得的丰度表是不传统的。这种树我看到了几棵，那个动物有几只等等，而是用测序测到了多少条DNA来表征的，所以会有很多测不到的，或者只能测到几条序列的，就有Chao1和ACE指数来考虑这些非常低的物种） 用信息公示表示（常用的shannon-wiener指数就在这里） 均一性表示 Taxa β diversity beta多样性的三个常用的简单指标： 基于相异系数进行计算： 这里收集了目前会用到的各种距离的算法，比如我们常用的欧式距离，还有这个bray距离等，这样算出来就是一个距离矩阵，我们可以知道哪些样方之间差异大或者差异小 Taxa γ diversity gamma多样性，沿着长江取样来举个例子，图中每个取样点本身的微生物多样性是α-多样性（单个群落水平）；将1～9这九个样点归为一组，则这一组内各样点之间的差异，可以理解为β-多样性（局部或者区域水平）；当我们把所有取样点放在一起，站在一个更高、更广阔的尺度上时，这时候的多样性就是所谓的γ-多样性。这个指标就是α-多样性在尺度上的一个推广。\n一个例子总结三个尺度上的物种多样性：\n三个生态区九座山峰的生物多样性指数。每个符号代表不同的物种；有些物种只在一个峰上有种群，而另一些则在两个或更多峰上。每个峰上物种丰富度的变化导致每个生态区的不同 alpha、gamma 和 beta 多样性值。\n这种变化对我们如何分配有限的资源以最大限度地保护资源有影响。如果只能保护一个生态区，生态区 3可能是一个不错的选择，因为它具有高伽马（总）多样性。但是，如果只能保护一个山峰，是否应该保护生态区 1（有许多分布广泛的物种）或生态区3（有几个独特的、范围受限的物种）中的山峰？\nPhylogenetic α diversity 群落系统发育多样性PD：谱系树的总枝长度 净相关指数NRI： 计算所有物种对的平均谱系距离MPD，保持物种数量和个体数不变 最近邻体指数NTI： 计算所有物种对的平均谱系距离MNPD，保持物种数量和个体数不变 可以看上图右边的例子，3个样方发现的四种物种丰度表，我们确定了他们的系统发育关系就可以进行计算。\nPhylogenetic β diversity Beta的计算会稍微复杂一点，公式没有一个个列出，但是有相关的R包进行计算（vegan）。\nFunctional diversity 最后就是功能多样性指数，他是影响种群生存、群落和生态系统稳定的重要因素， 能更好地反映生态系统生产、养分平衡等功能。\n这个怎么计算呢，要收集好物种的功能类型，比如对于植物来说，有光和途径等等，也同样整理为功能表，功能表和物种丰度表mapping合并一下可以得到功能丰度表，然后就可以计算各种指数了。\nAnalytical methods 我们应该怎么做数据分析呢？（具体的流程和代码下次分享，这里先简单描述一下）\n首先拿到丰度表，可以对整个表进行重采样，每次采样计算一次a多样性指数，就可以做出这个稀释曲线，他可以说明我们在这个样方里的调查或者说测序手段是否是充足的。\n然后是计算每个样方的a多样性指数， 通过结合环境因子数据，我们可以做组间多重比较，比如说 对于一些数值数据，我们可以计算相关性，或者做回归分析。 这个回归又分为很多方式，比如线性回归，广义线性回归等等，这个可以帮我们发现那些因素会以怎样的方式影响a多样性，比如这里，可能海拔越高多样性越低。\n对于beta多样性，我们首先计算相异矩阵，这里就是样本与样本间的距离 我们可以做热图展示各样本间的距离， 或者做一个相似系数-地理距离的回归分析，一般来说，地理距离越远，可能beta多样性越高。\n或者具体看看组间差异，这里可以看到KO_OE组beta多样性最大， 还能做聚类分析，看看到底哪些样本更加类似。\nBeta多样性的另一种展示方法是排序方法，也叫降维分析，我们常用的方法有PCA，PcoA等等， 另外可以加上环境因子数据，做约束排序，比如RDA，CCA等方法，不仅能看到样本间的差异，还可以看到这种差异主要是由那种环境因子影响的，比如这里，在轴一上的差异主要是由env1这个变量引起的。\nTheories 物种多样性的中性理论做出了一个具有挑战性的假设，即所有个体在生态上都是相同的，并且不需要生态位差异来解释生物多样性模式。 根据中性理论，等同物种的高度多样化群落的出现是因为偶然的灭绝被物种形成所平衡。具体来说，适应性等价假设与随机或随机过程相结合，包括死亡、来自区域物种库的移民和物种形成，可以导致物种丰富的种群。（有关生态位和中性作用对多样性影响，专门有研究这种群落构建的）\nReferences ","date":"2023-04-01T00:00:00Z","image":"/p/biodiversity/images/diversity_hu_43699bea50dd389e.png","permalink":"/p/biodiversity/","title":"物种多样性研究的理论和方法"},{"content":"Introduction Shiny 是一个 R 包，可轻松地直接从 R 构建交互式 Web 应用程序。还可以在网页上托管独立应用程序或将它们嵌入 R Markdown 文档或构建仪表板，还可以使用 CSS 主题、html 小部件和 JavaScript 操作扩展您的 Shiny 应用程序。\n1 2 3 4 5 6 7 8 #first app library(shiny) ui \u0026lt;- fluidPage( \u0026#34;Hello, world!\u0026#34; ) server \u0026lt;- function(input, output, session) { } shinyApp(ui, server) 整个app可分为两个部分，ui与sever，可以认为是前端与后端的关系，Rshiny提供了很多内置的小组件帮我们将前后端联系起来，非常方便好用。只需要有一点点的HTML/CSS/Javascript的知识就可以设计出更好看的界面和更多有趣的交互。\n这里是shiny的记忆手册,浓缩了大部分的操作。 Methods UI设计 Layout 最基础的布局就是sidebarLayout,可以分成sidebarPanel,mainPanel两个部分。\n1 2 3 4 5 6 7 8 ui \u0026lt;- fluidPage( titlePanel(\u0026#34;title panel\u0026#34;), sidebarLayout( sidebarPanel(\u0026#34;sidebar panel\u0026#34;), mainPanel(\u0026#34;main panel\u0026#34;) ) ) 可以通过将内容放在 *Panel 函数中来向Shiny 应用程序添加内容，shiny提供了R代码方便插入HTML (Table 1)，更多标签可以查看tag-glossary。\nTable 1: shiny function\tHTML5 equivalent\tcreates shiny function HTML5 equivalent creates p \u0026lt;p\u0026gt; A paragraph of text h1 \u0026lt;h1\u0026gt; A first level header h2 \u0026lt;h2\u0026gt; A second level header h3 \u0026lt;h3\u0026gt; A third level header h4 \u0026lt;h4\u0026gt; A fourth level header h5 \u0026lt;h5\u0026gt; A fifth level header h6 \u0026lt;h6\u0026gt; A sixth level header a \u0026lt;a\u0026gt; A hyper link br \u0026lt;br\u0026gt; A line break (e.g. a blank line) div \u0026lt;div\u0026gt; A division of text with a uniform style span \u0026lt;span\u0026gt; An in-line division of text with a uniform style pre \u0026lt;pre\u0026gt; Text ‘as is’ in a fixed width font code \u0026lt;code\u0026gt; A formatted block of code img \u0026lt;img\u0026gt; An image strong \u0026lt;strong\u0026gt; Bold text em \u0026lt;em\u0026gt; Italicized text HTML NA Directly passes a character string as HTML code Control widgets 这些是常用shiny内置的小控件，提供一种向 Shiny serve发送消息的方式。 Table 2: standard Shiny widgets function widget actionButton Action Button checkboxGroupInput A group of check boxes checkboxInput A single check box dateInput A calendar to aid date selection dateRangeInput A pair of calendars for selecting a date range fileInput A file upload control wizard helpText Help text that can be added to an input form numericInput A field to enter numbers radioButtons A set of radio buttons selectInput A box with choices to select from sliderInput A slider bar submitButton A submit button textInput A field to enter text 可以想想怎么获取更多控件，比如一个color panel等等。\n更多：\n使用 textInput() 收集少量文本，使用 passwordInput()3 收集密码，使用 textAreaInput() 收集文本段落。\n要收集数值，请使用 numericInput() 创建一个受约束的文本框或使用 sliderInput() 创建一个滑块。如果您为 sliderInput() 的默认值提供一个长度为 2 的数值向量，您将得到一个具有两端的“范围”滑块。\n使用 dateInput() 收集一天或使用 dateRangeInput() 收集两天的范围。这些提供了一个方便的日历选择器，并且诸如 datesdisabled 和 daysofweekdisabled 之类的附加参数允许您限制有效输入的集合。\n有两种不同的方法允许用户从一组预先指定的选项中进行选择：selectInput()(还可以设置 multiple = TRUE 以允许用户选择多个元素)和 radioButtons(); 可以使用checkboxGroupInput()形成多选。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 ui \u0026lt;- fluidPage( textInput(\u0026#34;name\u0026#34;, \u0026#34;What\u0026#39;s your name?\u0026#34;), passwordInput(\u0026#34;password\u0026#34;, \u0026#34;What\u0026#39;s your password?\u0026#34;), textAreaInput(\u0026#34;story\u0026#34;, \u0026#34;Tell me about yourself\u0026#34;, rows = 3) ) ui \u0026lt;- fluidPage( numericInput(\u0026#34;num\u0026#34;, \u0026#34;Number one\u0026#34;, value = 0, min = 0, max = 100), sliderInput(\u0026#34;num2\u0026#34;, \u0026#34;Number two\u0026#34;, value = 50, min = 0, max = 100), sliderInput(\u0026#34;rng\u0026#34;, \u0026#34;Range\u0026#34;, value = c(10, 20), min = 0, max = 100) ) ui \u0026lt;- fluidPage( dateInput(\u0026#34;dob\u0026#34;, \u0026#34;When were you born?\u0026#34;), dateRangeInput(\u0026#34;holiday\u0026#34;, \u0026#34;When do you want to go on vacation next?\u0026#34;) ) animals \u0026lt;- c(\u0026#34;dog\u0026#34;, \u0026#34;cat\u0026#34;, \u0026#34;mouse\u0026#34;, \u0026#34;bird\u0026#34;, \u0026#34;other\u0026#34;, \u0026#34;I hate animals\u0026#34;) ui \u0026lt;- fluidPage( selectInput(\u0026#34;state\u0026#34;, \u0026#34;What\u0026#39;s your favourite state?\u0026#34;, state.name), radioButtons(\u0026#34;animal\u0026#34;, \u0026#34;What\u0026#39;s your favourite animal?\u0026#34;, animals), checkboxGroupInput(\u0026#34;animal\u0026#34;, \u0026#34;What animals do you like?\u0026#34;, animals) ) 让用户使用 actionButton() 或 actionLink() 执行操作，可以使用“btn-primary”、“btn-success”、“btn-info”、“btn-warning”或“btn-danger”之一使用类参数自定义外观，使用“btn-lg”、“btn-sm”、“btn-xs”更改大小，可以使用“btn-block”使按钮跨越它们嵌入的元素的整个宽度。\n1 2 3 4 5 6 7 8 9 ui \u0026lt;- fluidPage( fluidRow( actionButton(\u0026#34;click\u0026#34;, \u0026#34;Click me!\u0026#34;, class = \u0026#34;btn-danger\u0026#34;), actionButton(\u0026#34;drink\u0026#34;, \u0026#34;Drink me!\u0026#34;, class = \u0026#34;btn-lg btn-success\u0026#34;) ), fluidRow( actionButton(\u0026#34;eat\u0026#34;, \u0026#34;Eat me!\u0026#34;, class = \u0026#34;btn-block\u0026#34;) ) ) 连接sever general 添加输出对象在ui中 Shiny 提供了一系列函数，可以将 R 对象转换为用户界面的输出。每个函数创建特定类型的输出。\nTable 3: output R objects family Output function Creates dataTableOutput DataTable htmlOutput raw HTML imageOutput image plotOutput plot tableOutput table textOutput text uiOutput raw HTML verbatimTextOutput text 编写构建R对象的代码在serve中 Table 4: render R objects family render function creates renderDataTable DataTable renderImage images (saved as a link to a source file) renderPlot plots renderPrint any printed output renderTable data frame, matrix, other table like structures renderText character strings renderUI a Shiny tag object or HTML 使用input，output连接 以下代码就可以将selectInput选择的值var通过input$var的形式传递到renderText()，再render成output$selected_var的形式，最后通过textOutput()输出到ui界面。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 library(shiny) ui \u0026lt;- fluidPage( titlePanel(\u0026#34;censusVis\u0026#34;), sidebarLayout( sidebarPanel( selectInput(\u0026#34;var\u0026#34;, label = \u0026#34;Choose a variable to display\u0026#34;, choices = c(\u0026#34;Percent White\u0026#34;, \u0026#34;Percent Black\u0026#34;, \u0026#34;Percent Hispanic\u0026#34;, \u0026#34;Percent Asian\u0026#34;), selected = \u0026#34;Percent White\u0026#34;) ), mainPanel( textOutput(\u0026#34;selected_var\u0026#34;) ) ) ) server \u0026lt;- function(input, output) { output$selected_var \u0026lt;- renderText({ paste(\u0026#34;You have selected\u0026#34;, input$var) }) } shinyApp(ui, server) 更多：\n使用 textOutput() 输出常规文本，使用 verbatimTextOutput() 输出固定代码和控制台输出。 renderText() 将结果组合成一个字符串，通常与 textOutput() 配对 renderPrint() 打印结果，就像您在 R 控制台中一样，并且通常与 verbatimTextOutput() 配对。\ntableOutput() 和 renderTable() 呈现静态数据表，同时显示所有数据。 dataTableOutput() 和 renderDataTable() 呈现一个动态表，显示固定数量的行以及用于更改哪些行可见的控件。 tableOutput() 对于小型、固定的摘要（例如模型系数）最有用；如果您想向用户公开完整的数据框，则 dataTableOutput() 是最合适的。\n默认情况下，plotOutput() 将占据其容器的整个宽度（稍后会详细介绍），并且高度为 400 像素。您可以使用高度和宽度参数覆盖这些默认值。我们建议始终设置 res = 96，因为这将使您的 Shiny 图与您在 RStudio 中看到的尽可能接近。\nreactive expressions This difference between commands and recipes is one of the key differences between two important styles of programming:\nIn imperative programming, you issue a specific command and it’s carried out immediately. This is the style of programming you’re used to in your analysis scripts: you command R to load your data, transform it, visualise it, and save the results to disk.\nIn declarative programming, you express higher-level goals or describe important constraints, and rely on someone else to decide how and/or when to translate that into action. This is the style of programming you use in Shiny.\nShiny 中声明式编程的优势之一是它允许应用程序非常懒惰。 Shiny 应用程序只会执行更新您当前可以看到的输出控件所需的最少工作量，优点是快速，缺点是如果你不运行所有代码，可能不会发现错误。\n反应式表达式比常规 R 函数更聪明。它们缓存值并知道它们的值何时会变。第一次运行反应式表达式时，表达式会将其结果保存在计算机的内存中。下次调用反应式表达式时，它可以返回保存的结果而不进行任何计算（这将使您的应用程序更快）。\n如果反应式表达式知道结果是最新的，它只会返回保存的结果。如果反应式表达式得知结果已过时（因为小部件已更改），则表达式将重新计算结果。然后它返回新结果并保存一个新副本。反应式表达式将使用这个新副本，直到它也变得过时为止。 让我们总结一下这种行为：\n反应式表达式会在您第一次运行时保存其结果。\n下次调用反应式表达式时，它会检查保存的值是否已过时（即，它所依赖的小部件是否已更改）。\n如果该值已过期，反应对象将重新计算它（然后保存新结果）。\n如果该值是最新的，反应式表达式将返回保存的值而不进行任何计算。\n建议把文件导入等不需要每次更新的代码放在reactive里。\n在 Shiny 中，应该考虑一个规则：每当复制和粘贴一次东西时，就应该考虑将重复的代码提取到一个反应表达式中，因为反应式表达式不仅让人类更容易理解代码，它们还提高了 Shiny 高效重新运行代码的能力。\n考虑以下代码，reactive()确保只有在改变n或lambda时才会重新计算：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 library(ggplot2) freqpoly \u0026lt;- function(x1, x2, binwidth = 0.1, xlim = c(-3, 3)) { df \u0026lt;- data.frame( x = c(x1, x2), g = c(rep(\u0026#34;x1\u0026#34;, length(x1)), rep(\u0026#34;x2\u0026#34;, length(x2))) ) ggplot(df, aes(x, colour = g)) + geom_freqpoly(binwidth = binwidth, size = 1) + coord_cartesian(xlim = xlim) } ui \u0026lt;- fluidPage( fluidRow( column(3, numericInput(\u0026#34;lambda1\u0026#34;, label = \u0026#34;lambda1\u0026#34;, value = 3), numericInput(\u0026#34;lambda2\u0026#34;, label = \u0026#34;lambda2\u0026#34;, value = 5), numericInput(\u0026#34;n\u0026#34;, label = \u0026#34;n\u0026#34;, value = 1e4, min = 0) ), column(9, plotOutput(\u0026#34;hist\u0026#34;)) ) ) server \u0026lt;- function(input, output, session) { x1 \u0026lt;- reactive(rpois(input$n, input$lambda1)) x2 \u0026lt;- reactive(rpois(input$n, input$lambda2)) output$hist \u0026lt;- renderPlot({ freqpoly(x1(), x2(), binwidth = 1, xlim = c(0, 40)) }, res = 96) } shinyApp(ui,server) 控制reactive行为：\n计时器 reactiveTimer() 是一个响应式表达式，它依赖于隐藏的输入：当前时间。 将server里的reactive修改成下列形式可以让图形每500ms刷新一次。 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 server \u0026lt;- function(input, output, session) { timer \u0026lt;- reactiveTimer(500) x1 \u0026lt;- reactive({ timer() rpois(input$n, input$lambda1) }) x2 \u0026lt;- reactive({ timer() rpois(input$n, input$lambda2) }) output$hist \u0026lt;- renderPlot({ freqpoly(x1(), x2(), binwidth = 1, xlim = c(0, 40)) }, res = 96) } 点击刷新 当你的serve运行一次需要庞大计算和时间时，可能希望要求用户通过单击按钮来选择执行昂贵的计算。这是 actionButton() 的一个很好的用例： 并且我们需要 eventReactive()，它有两个参数：第一个参数指定依赖什么，第二个参数指定计算什么。\n修改ui和serve，添加了按键，用户点击按键即可出现新的模拟结果。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 ui \u0026lt;- fluidPage( fluidRow( column(3, numericInput(\u0026#34;lambda1\u0026#34;, label = \u0026#34;lambda1\u0026#34;, value = 3), numericInput(\u0026#34;lambda2\u0026#34;, label = \u0026#34;lambda2\u0026#34;, value = 5), numericInput(\u0026#34;n\u0026#34;, label = \u0026#34;n\u0026#34;, value = 1e4, min = 0), actionButton(\u0026#34;simulate\u0026#34;, \u0026#34;Simulate!\u0026#34;) ), column(9, plotOutput(\u0026#34;hist\u0026#34;)) ) ) server \u0026lt;- function(input, output, session) { x1 \u0026lt;- eventReactive(input$simulate, { rpois(input$n, input$lambda1) }) x2 \u0026lt;- eventReactive(input$simulate, { rpois(input$n, input$lambda2) }) output$hist \u0026lt;- renderPlot({ freqpoly(x1(), x2(), binwidth = 1, xlim = c(0, 40)) }, res = 96) } observeEvent() 与 eventReactive() 非常相似。它有两个重要的参数：eventExpr 和 handlerExpr。第一个参数是要依赖的输入或表达式；第二个参数是将要运行的代码。例如，对 server() 的以下修改意味着每次更新该名称时，都会向控制台发送一条消息：\n1 2 3 4 5 6 7 8 9 10 11 12 13 ui \u0026lt;- fluidPage( textInput(\u0026#34;name\u0026#34;, \u0026#34;What\u0026#39;s your name?\u0026#34;), textOutput(\u0026#34;greeting\u0026#34;) ) server \u0026lt;- function(input, output, session) { string \u0026lt;- reactive(paste0(\u0026#34;Hello \u0026#34;, input$name, \u0026#34;!\u0026#34;)) output$greeting \u0026lt;- renderText(string()) observeEvent(input$name, { message(\u0026#34;Greeting performed\u0026#34;) }) } file up/download 使用fileInput在ui中上传文件后，得到的input是一个列表，其中的datapath是文件上传后的路径，需要使用read.csv等函数读取file$datapath。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 ui \u0026lt;- fluidPage( sidebarLayout( sidebarPanel( fileInput(\u0026#34;file1\u0026#34;, \u0026#34;Choose CSV File\u0026#34;, accept = \u0026#34;.csv\u0026#34;), checkboxInput(\u0026#34;header\u0026#34;, \u0026#34;Header\u0026#34;, TRUE) ), mainPanel( tableOutput(\u0026#34;contents\u0026#34;) ) ) ) server \u0026lt;- function(input, output) { output$contents \u0026lt;- renderTable({ file \u0026lt;- input$file1 ext \u0026lt;- tools::file_ext(file$datapath) req(file) validate(need(ext == \u0026#34;csv\u0026#34;, \u0026#34;Please upload a csv file\u0026#34;)) read.csv(file$datapath, header = input$header) }) } shinyApp(ui, server) 您可以让用户使用 downloadButton() 或 downloadLink() 下载文件。这些都需要服务器功能中的新技术，因此我们将在第 9 章中回过头来讨论。\nShare 文件形式 任何拥有 R 的人都可以运行Shiny 应用程序，分享你的app.R 文件副本，以及您的应用程序中使用的任何补充材料（例如，www 文件夹或 helpers.R 文件）即可，最好写上代码运行的依赖包安装代码。\nrunUrl() will download and launch a Shiny app straight from a weblink. runGitHub( \u0026quot;\u0026lt;your repository name\u0026gt;\u0026quot;, \u0026quot;\u0026lt;your user name\u0026gt;\u0026quot;) 网页形式 上述方法要求用户在他们的计算机上安装 R 和 Shiny。但如果我们自己搭建好了服务器，也可以直接用浏览器使用我们的APP。\nShinyapps.io 将 Shiny 应用程序转换为网页的最简单方法是使用 shinyapps.io，这是 RStudio 为 Shiny 应用程序提供的托管服务。 2. Shiny Server\nRStudio Connect Reference 官方教程：Shiny Learning Resources\n参考书：Mastering Shiny\n","date":"2023-03-27T00:00:00Z","image":"/p/rshiny/Rshiny_hu_eb0afc259da57c48.jpg","permalink":"/p/rshiny/","title":"R-shiny应用开发（基础）"},{"content":"春分刚过，校园许多花儿都争相绽放。天气还是有点冷，但还是想跟群青同学一起逛逛紫金港，赏赏花，观观鸟。\n这个时候校园里最多的便是蔷薇科的花了，虽然我向来是”桃李杏梅樱，傻傻分不清”的😂，这次在群青同学的帮助下收集到了九宫格：菊花桃，碧桃，垂丝海棠，西府海棠，湖北海棠，大岛樱，日本晚樱，日本樱花，蓬蘽(疑似)\n日本樱花 大岛樱 日本晚樱 西府海棠 湖北海棠 垂丝海棠 菊花桃 碧桃 蓬蘽(疑似) 湖心岛出发，大片的二月兰，刚冒芽的水杉，偷偷绽放的水仙和蝴蝶花。\n二月兰 水仙 蝴蝶花 水杉 早樱 鸟儿大多还是老朋友，快步走的白鹡鸰，悠闲的黑水鸡和斑嘴鸭，大喜鹊和红嘴蓝鹊，一只歌声婉转的乌鸫。本来这次最想看到的就是罕见旅客黑翅长脚鹬的，但是这儿果然只是它们歇歇脚的地方，没能见到😭，偷浙大官微的美图，哈哈。南花园还是夜鹭与白鹭们的领地。\n白鹡鸰 黑水鸡 斑嘴鸭 喜鹊 夜鹭 乌鸫 黑翅长脚鹬 （浙江大学B站号） 红嘴蓝鹊 生物实验中心之前每年这个时候都是大片油菜花，打卡圣地，但今年的试验田搬到了银泉，这里居然种满了麦子，绿油油的麦田非常治愈。去年的油菜花应该还留下了一些种子，这个我叫做单双子叶的碰撞。\n单双子叶的碰撞 惊喜出现在麦田的拐角处，几只可爱的啾啾正在偷麦子吃，原来是白腰文鸟，上次见它也是在偷吃生科院的实验水稻。站在紫荆丛中的文鸟超有气质。\n其他一些瞬间，医学院的一排樱花，LY同学最赞的一株樱花，已经吃了四年还要再吃四年的麦香，晶莹的水珠…\n医学院 药学院 医图 麦香 感谢群青同学的摄影，越来越强了👍。下一个季节再来看看。\n","date":"2023-03-25T00:00:00Z","image":"/p/spring/images/%E8%A5%BF%E5%BA%9C_hu_eb2d96b22e0553a9.jpg","permalink":"/p/spring/","title":"紫金春日"},{"content":"Introduction 统计分析在生物信息学中具有非常重要的意义，因为生物信息学研究的数据量庞大、复杂性高，而统计分析可以帮助我们更好地理解和解释这些数据。下面是统计分析对生物信息学的几个重要意义：\n数据清洗和预处理：生物信息学研究中经常需要处理大规模的数据，而这些数据可能存在噪声、错误和缺失值等问题。统计分析可以帮助我们对数据进行清洗和预处理，以确保数据的质量和可靠性。 数据可视化：统计分析可以帮助我们将复杂的数据转化为可视化图形，从而更好地理解数据的分布、关系和趋势。这些图形可以帮助我们发现隐藏在数据中的模式和规律。 数据分析：生物信息学研究中需要对大量的数据进行分析，例如比较基因组学、转录组学、蛋白质组学等。统计分析可以帮助我们对数据进行建模和预测，从而深入探究生物学的复杂现象和机制。 数据挖掘：生物信息学研究中需要挖掘大量的数据来发现新的生物学现象和机制。统计分析可以帮助我们从数据中提取出有用的信息和知识，进而推动生物学的研究和发展。 R语言是一个专门用于数据分析和统计建模的编程语言，它有以下几个优点，使其成为做统计分析的理想选择：\n免费和开源：R语言是一个免费和开源的软件，可以在不付出额外成本的情况下使用和定制。这使得许多学生、学者和数据分析师选择R语言作为他们的首选统计分析工具。\n强大的数据处理能力：R语言具有强大的数据处理能力，支持多种数据结构和数据类型，可以轻松地进行数据清洗、整合、变换和分析。\n丰富的统计分析函数库：R语言具有丰富的统计分析函数库，包括线性回归、逻辑回归、聚类分析、主成分分析、时间序列分析等等。这些函数库提供了许多常用的统计分析方法，可以满足不同数据分析需求。\n图形可视化功能：R语言具有强大的图形可视化功能，可以轻松地创建各种类型的图表，包括散点图、条形图、折线图、热图等。这些图表可以帮助数据分析师更好地理解数据、发现规律和提取信息。\n社区支持和生态系统：R语言拥有庞大的用户社区和生态系统，用户可以轻松地找到并使用数千种可用的统计分析工具和R包，这些工具和R包可以帮助用户更加高效地完成统计分析任务。\n我想在这里稍微记录一下我使用R常用的一些初等统计分析方法，如回归，方差分析，广义线性模型等，主要参考资料是《R语言教程》 VII部分统计分析的内容。\nStatistics 基础用法 单样本均值检验 1 2 3 4 5 6 7 ?t.test() #install.packages(\u0026#34;ggstatsplot\u0026#34;,dependencies = T) library(ggstatsplot) #这个包会在画图的过程中计算很多统计量，帮我们更好地把握数据的性质 #比如我们想看tooth length均值是否和25有显著差异 t.test(ToothGrowth$len,mu = 25,alternative = \u0026#34;two.sided\u0026#34;) ## ## One Sample t-test ## ## data: ToothGrowth$len ## t = -6.2648, df = 59, p-value = 0.00000004681 ## alternative hypothesis: true mean is not equal to 25 ## 95 percent confidence interval: ## 16.83731 20.78936 ## sample estimates: ## mean of x ## 18.81333 1 2 3 4 5 6 gghistostats( data = ToothGrowth, x = len, xlab = \u0026#34;Tooth length\u0026#34;, test.value = 25 ) 检验的功效， 是指对立假设成立时检验拒绝$H_0$的概率$1-\\beta$， 其中$\\beta$是第二类错误， 即当对立假设成立时错误地接受$H_0$的概率。 需要足够大的样本量才能使得检验能够发现实际存在的显著差异。\n1 2 3 4 5 6 7 pwr::pwr.t.test( type = \u0026#34;one.sample\u0026#34;, alternative=\u0026#34;greater\u0026#34;, d = (7.25 - 7.0)/1.052, sig.level = 0.05, power = 0.80 ) |\u0026gt; plot() 均值比较 独立两样本t检验\n1 t.test(mpg~am,data = mtcars) ## ## Welch Two Sample t-test ## ## data: mpg by am ## t = -3.7671, df = 18.332, p-value = 0.001374 ## alternative hypothesis: true difference in means between group 0 and group 1 is not equal to 0 ## 95 percent confidence interval: ## -11.280194 -3.209684 ## sample estimates: ## mean in group 0 mean in group 1 ## 17.14737 24.39231 1 ggbetweenstats(mtcars, am, mpg) 比例检验 1 2 #抽查400个样本100个异常，异常比例是否显著大于0.2 prop.test(100, 400, p=0.20, alternative = \u0026#34;greater\u0026#34;) ## ## 1-sample proportions test with continuity correction ## ## data: 100 out of 400, null probability 0.2 ## X-squared = 5.9414, df = 1, p-value = 0.007395 ## alternative hypothesis: true p is greater than 0.2 ## 95 percent confidence interval: ## 0.2149649 1.0000000 ## sample estimates: ## p ## 0.25 1 2 #两次抽查的比例是否一致 prop.test(c(35,27), c(250,300), alternative = \u0026#34;two.sided\u0026#34;) ## ## 2-sample test for equality of proportions with continuity correction ## ## data: c(35, 27) out of c(250, 300) ## X-squared = 2.9268, df = 1, p-value = 0.08712 ## alternative hypothesis: two.sided ## 95 percent confidence interval: ## -0.007506845 0.107506845 ## sample estimates: ## prop 1 prop 2 ## 0.14 0.09 方差的假设检验 检查两组数据的方差有误显著差异？\n1 2 3 4 var.test(c( 20.5, 18.8, 19.8, 20.9, 21.5, 19.5, 21.0, 21.2), c( 17.7, 20.3, 20.0, 18.8, 19.0, 20.1, 20.2, 19.1), alternative = \u0026#34;two.sided\u0026#34;) ## ## F test to compare two variances ## ## data: c(20.5, 18.8, 19.8, 20.9, 21.5, 19.5, 21, 21.2) and c(17.7, 20.3, 20, 18.8, 19, 20.1, 20.2, 19.1) ## F = 1.069, num df = 7, denom df = 7, p-value = 0.9322 ## alternative hypothesis: true ratio of variances is not equal to 1 ## 95 percent confidence interval: ## 0.214011 5.339386 ## sample estimates: ## ratio of variances ## 1.068966 拟合优度检验 1 2 #6类face的count比例是否相等，卡方检验 chisq.test(c(168, 159, 168, 180, 167, 158)) ## ## Chi-squared test for given probabilities ## ## data: c(168, 159, 168, 180, 167, 158) ## X-squared = 1.892, df = 5, p-value = 0.8639 1 2 3 4 5 6 7 ggpiestats( data = data.frame(face=1:6, counts=c(168, 159, 168, 180, 167, 158)), x = face, counts = counts, title = \u0026#34;Dice equality\u0026#34; ) 1 2 #各类比例是否为指定值 chisq.test(c(48, 98, 54), p=c(0.3, 0.5, 0.2)) ## ## Chi-squared test for given probabilities ## ## data: c(48, 98, 54) ## X-squared = 7.34, df = 2, p-value = 0.02548 检验分布类型 vcd包提供了一个goodfit函数， 可以用来拟合指定的某种理论分布(包括泊松、二项、负二项分布）， 并检验服从该理论分布的零假设。\n1 2 3 set.seed(101) datax \u0026lt;- rpois(100, 2) summary(vcd::goodfit(datax, \u0026#34;poisson\u0026#34;)) ## ## Goodness-of-fit test for poisson distribution ## ## X^2 df P(\u0026gt; X^2) ## Likelihood Ratio 4.289456 5 0.5085374 独立性卡方检验 1 2 3 4 5 6 ctab.beer \u0026lt;- rbind(c( 20, 40, 20), c(30,30,10)) colnames(ctab.beer) \u0026lt;- c(\u0026#34;Light\u0026#34;, \u0026#34;Regular\u0026#34;, \u0026#34;Dark\u0026#34;) rownames(ctab.beer) \u0026lt;- c(\u0026#34;Male\u0026#34;, \u0026#34;Female\u0026#34;) addmargins(ctab.beer) ## Light Regular Dark Sum ## Male 20 40 20 80 ## Female 30 30 10 70 ## Sum 50 70 30 150 1 2 #列联表独立性检验： chisq.test(ctab.beer) ## ## Pearson's Chi-squared test ## ## data: ctab.beer ## X-squared = 6.1224, df = 2, p-value = 0.04683 1 #在0.05水平下认为啤酒类型偏好与性别有关 非参数检验 常用的有独立两样本比较的Wilcoxon秩和检验， 单样本的符号秩检验和符号检验等\n1 2 3 x \u0026lt;- c(0.80, 0.83, 1.89, 1.04, 1.45, 1.38, 1.91, 1.64, 0.73, 1.46) y \u0026lt;- c(1.15, 0.88, 0.90, 0.74, 1.21) wilcox.test(x,mu = 0.7) ## ## Wilcoxon signed rank exact test ## ## data: x ## V = 55, p-value = 0.001953 ## alternative hypothesis: true location is not equal to 0.7 1 wilcox.test(x, y, alternative = \u0026#34;g\u0026#34;) ## ## Wilcoxon rank sum exact test ## ## data: x and y ## W = 35, p-value = 0.1272 ## alternative hypothesis: true location shift is greater than 0 回归分析 相关分析 Pearson相关系数： $$ \\rho(X,Y)=\\frac{E[(X-E(X))(Y-E(Y))]}{\\sqrt{Var(X)Var(Y)}} $$ 相关系数绝对值在0.8以上认为高度相关。 在0.5到0.8之间认为中度相关。 在0.3到0.5之间认为低度相关。 在0.3以下认为不相关或相关性很弱以至于没有实际价值。 当然，在特别重要的问题中， 只要经过检验显著不等于零的相关都认为是有意义的。\n相关系数检验：\n检验统计量: $$ t=\\frac{r\\sqrt{n-2}}{\\sqrt{1-r^2}} $$ p值为：$P(|t(n-2)|\u0026gt;|t_0|)$\n1 2 3 4 5 6 7 set.seed(1) x \u0026lt;- runif(30, 0, 10) xx \u0026lt;- seq(0, 10, length.out = 100) y \u0026lt;- 40 - (x-7)^2 + rnorm(30) yy \u0026lt;- 40 - (xx-7)^2 plot(x, y, pch=16) lines(xx, yy) 1 cor(x,y,method = \u0026#34;pearson\u0026#34;) ## [1] 0.8244374 1 cor.test(x,y,method = \u0026#34;pearson\u0026#34;) ## ## Pearson's product-moment correlation ## ## data: x and y ## t = 7.7083, df = 28, p-value = 0.00000002136 ## alternative hypothesis: true correlation is not equal to 0 ## 95 percent confidence interval: ## 0.6602859 0.9134070 ## sample estimates: ## cor ## 0.8244374 1 2 3 4 5 ggstatsplot::ggscatterstats( data = data.frame(x,y), x = x, y = y ) 相关性矩阵，`n*n`或`n*m`的$r$ 和$p-value$矩阵 1 2 3 ggstatsplot::ggcorrmat( data = mtcars ) 1 pcutils::cor_plot(mtcars) 1 corrplot::corrplot(cor(mtcars)) 1 ggcorrplot::ggcorrplot(cor(mtcars),method = \u0026#34;circle\u0026#34;) Spearman秩相关系数 Spearman rho系数， 是两个变量的秩统计量的相关系数\nKendall tau系数 当变量正相关性很强时， 任意两个观测的X值的大小顺序应该与Y值的大小顺序相同； 如果独立， 一对观测的X值比较和Y值比较顺序相同与顺序相反的数目应该基本相同。Kandall tau系数也是取值于区间[-1,1]， 用这样的思想表示两个变量的相关性和正负。\n1 cor.test(x,y,method = \u0026#34;spearman\u0026#34;) ## ## Spearman's rank correlation rho ## ## data: x and y ## S = 922, p-value = 0.000001339 ## alternative hypothesis: true rho is not equal to 0 ## sample estimates: ## rho ## 0.7948832 1 cor.test(x,y,method = \u0026#34;kendall\u0026#34;) ## ## Kendall's rank correlation tau ## ## data: x and y ## T = 354, p-value = 0.000000159 ## alternative hypothesis: true tau is not equal to 0 ## sample estimates: ## tau ## 0.6275862 一元回归 $$ Y=a+bX+\\varepsilon, \\varepsilon \\sim N(0,\\sigma^2) $$\n最小二乘法 $$ \\hat{b}=\\frac{\\sum_i(x_i-\\overline{x})(y_i-\\overline{y})}{\\sum_i{(x-x_i)}^2}=r_{xy}\\frac{S_y}{S_x} $$\n$$ \\hat{a}=\\overline{y}-\\hat{b}\\overline{x} $$ 回归有效性可以用$R^2$和$p-valuie$来度量， $R^2=1-\\frac{SSE}{SST}$\n统计量$F=\\frac{SSR}{SSE/(n-2)}$,$p-value$为$P(F(1,n-2)\u0026gt;c)$,c为F的值。\n1 2 lm1 \u0026lt;- lm(y ~ x) summary(lm1) ## ## Call: ## lm(formula = y ~ x) ## ## Residuals: ## Min 1Q Median 3Q Max ## -17.856 -4.549 2.141 6.048 9.664 ## ## Coefficients: ## Estimate Std. Error t value Pr(\u0026gt;|t|) ## (Intercept) 9.9855 2.6930 3.708 0.000914 *** ## x 3.5396 0.4592 7.708 0.0000000214 *** ## --- ## Signif. codes: 0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1 ## ## Residual standard error: 7.302 on 28 degrees of freedom ## Multiple R-squared: 0.6797,\tAdjusted R-squared: 0.6683 ## F-statistic: 59.42 on 1 and 28 DF, p-value: 0.00000002136 1 2 #prediction predict(lm1,newdata =data.frame(x=c(5,10,15))) ## 1 2 3 ## 27.68364 45.38182 63.08000 1 pcutils::my_lm(y,x) 多元回归 1 2 lm2 \u0026lt;- lm(mpg ~ cyl + disp, data=mtcars) summary(lm2) ## ## Call: ## lm(formula = mpg ~ cyl + disp, data = mtcars) ## ## Residuals: ## Min 1Q Median 3Q Max ## -4.4213 -2.1722 -0.6362 1.1899 7.0516 ## ## Coefficients: ## Estimate Std. Error t value Pr(\u0026gt;|t|) ## (Intercept) 34.66099 2.54700 13.609 4.02e-14 *** ## cyl -1.58728 0.71184 -2.230 0.0337 * ## disp -0.02058 0.01026 -2.007 0.0542 . ## --- ## Signif. codes: 0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1 ## ## Residual standard error: 3.055 on 29 degrees of freedom ## Multiple R-squared: 0.7596,\tAdjusted R-squared: 0.743 ## F-statistic: 45.81 on 2 and 29 DF, p-value: 0.000000001058 1 ggstatsplot::ggcoefstats(lm2) 1 2 #回归自变量筛选 lm3 \u0026lt;- step(lm(mpg ~ cyl + disp+hp+drat+vs, data=mtcars)) ## Start: AIC=77.08 ## mpg ~ cyl + disp + hp + drat + vs ## ## Df Sum of Sq RSS AIC ## - vs 1 0.3134 244.90 75.124 ## - cyl 1 7.6839 252.27 76.073 ## - drat 1 14.3330 258.92 76.905 ## - disp 1 14.6709 259.26 76.947 ## \u0026lt;none\u0026gt; 244.59 77.083 ## - hp 1 19.8255 264.41 77.577 ## ## Step: AIC=75.12 ## mpg ~ cyl + disp + hp + drat ## ## Df Sum of Sq RSS AIC ## - cyl 1 8.444 253.35 74.209 ## - disp 1 14.765 259.67 74.997 ## \u0026lt;none\u0026gt; 244.90 75.124 ## - drat 1 16.467 261.37 75.206 ## - hp 1 19.613 264.51 75.589 ## ## Step: AIC=74.21 ## mpg ~ disp + hp + drat ## ## Df Sum of Sq RSS AIC ## \u0026lt;none\u0026gt; 253.35 74.209 ## - drat 1 30.148 283.49 75.806 ## - disp 1 38.107 291.45 76.693 ## - hp 1 49.550 302.90 77.925 多重共线性\n狭义的多重共线性（multicollinearity）： 自变量的数据存在线性组合近似地等于零， 使得解线性方程组求解回归系数时结果不稳定， 回归结果很差。\n广义的多重共线性： 自变量之间存在较强的相关性， 这样自变量是联动的， 互相之间有替代作用。 甚至于斜率项的正负号都因为这种替代作用而可能是错误的方向。\n1 2 #car包的vif()函数计算方差膨胀因子 car::vif(lm3) ## disp hp drat ## 4.621988 2.868264 2.166843 非参数回归 所谓参数回归， 是指回归函数有预先确定的公式， 仅需要估计的未知参数； 非参数回归， 就是没有预先确定的公式， 的形式本身也依赖于输入的样本, 。 下面描述的核回归就是这样典型的非参数回归， 样条平滑、样条函数回归一般也看作是非参数回归。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 #样条平滑 set.seed(1) nsamp \u0026lt;- 30 x \u0026lt;- runif(nsamp, -10, 10) xx \u0026lt;- seq(-10, 10, length.out=100) x \u0026lt;- sort(x) y \u0026lt;- 10*sin(x/10*pi)^2 + rnorm(nsamp,0,0.3) plot(x, y) curve(10*sin(x/10*pi)^2, -10, 10, add=TRUE, lwd=2) library(splines) res \u0026lt;- smooth.spline(x, y) lines(spline(res$x, res$y), col=\u0026#34;red\u0026#34;) res2 \u0026lt;- loess(y ~ x, degree=2, span=0.3) lines(xx, predict(res2, newdata=data.frame(x=xx)), col=\u0026#34;blue\u0026#34;) legend(\u0026#34;top\u0026#34;, lwd=c(2,1,1), col=c(\u0026#34;black\u0026#34;, \u0026#34;red\u0026#34;, \u0026#34;blue\u0026#34;), legend=c(\u0026#34;real data\u0026#34;, \u0026#34;smooth.spline\u0026#34;, \u0026#34;local lm\u0026#34;)) 1 2 3 4 ## 线性可加模型 ## R扩展包mgcv的gam()函数可以执行这样的可加模型的非参数回归拟合。 lm.rock \u0026lt;- lm(log(perm) ~ area + peri + shape, data=rock) summary(lm.rock) ## ## Call: ## lm(formula = log(perm) ~ area + peri + shape, data = rock) ## ## Residuals: ## Min 1Q Median 3Q Max ## -1.8092 -0.5413 0.1734 0.6493 1.4788 ## ## Coefficients: ## Estimate Std. Error t value Pr(\u0026gt;|t|) ## (Intercept) 5.33314499 0.54867792 9.720 1.59e-12 *** ## area 0.00048498 0.00008657 5.602 1.29e-06 *** ## peri -0.00152661 0.00017704 -8.623 5.24e-11 *** ## shape 1.75652601 1.75592362 1.000 0.323 ## --- ## Signif. codes: 0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1 ## ## Residual standard error: 0.8521 on 44 degrees of freedom ## Multiple R-squared: 0.7483,\tAdjusted R-squared: 0.7311 ## F-statistic: 43.6 on 3 and 44 DF, p-value: 3.094e-13 1 2 gam.rock1 \u0026lt;- mgcv::gam(log(perm) ~ s(area) + s(peri) + s(shape), data=rock) summary(gam.rock1) ## ## Family: gaussian ## Link function: identity ## ## Formula: ## log(perm) ~ s(area) + s(peri) + s(shape) ## ## Parametric coefficients: ## Estimate Std. Error t value Pr(\u0026gt;|t|) ## (Intercept) 5.1075 0.1222 41.81 \u0026lt;2e-16 *** ## --- ## Signif. codes: 0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1 ## ## Approximate significance of smooth terms: ## edf Ref.df F p-value ## s(area) 1.000 1.000 29.13 0.00000307 *** ## s(peri) 1.000 1.000 71.30 \u0026lt; 2e-16 *** ## s(shape) 1.402 1.705 0.58 0.437 ## --- ## Signif. codes: 0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1 ## ## R-sq.(adj) = 0.735 Deviance explained = 75.4% ## GCV = 0.78865 Scale est. = 0.71631 n = 48 1 plot(gam.rock1) 方差分析 单因素方差分析可以看成基础统计中两样本t检验的一个推广， 要比较试验观测值的某个因变量（称为“指标”）按照一个分组变量（称为“因素”）分组后， 各组的因变量均值有无显著差异。\n1 2 3 mtcars$cyl=as.factor(mtcars$cyl) aov.manu \u0026lt;- aov(mpg ~ cyl, data=mtcars) summary(aov.manu) ## Df Sum Sq Mean Sq F value Pr(\u0026gt;F) ## cyl 2 824.8 412.4 39.7 0.00000000498 *** ## Residuals 29 301.3 10.4 ## --- ## Signif. codes: 0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1 1 pcutils::group_box(mtcars[\u0026#34;mpg\u0026#34;],group = \u0026#34;cyl\u0026#34;,metadata = mtcars) 1 2 #非参数形式 kruskal.test(mpg ~ cyl, data=mtcars) ## ## Kruskal-Wallis rank sum test ## ## data: mpg by cyl ## Kruskal-Wallis chi-squared = 25.746, df = 2, p-value = 0.000002566 进行多个假设检验（如均值比较）的操作称为*“多重比较”*（multiple comparison， 或multiple testing）， 多次检验会使得总第一类错误概率增大。\n1 pcutils::multitest(mtcars$mpg,mtcars$cyl) ## ====================================1.ANOVA:==================================== ## Df Sum Sq Mean Sq F value Pr(\u0026gt;F) ## group 2 824.8 412.4 39.7 0.00000000498 *** ## Residuals 29 301.3 10.4 ## --- ## Signif. codes: 0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1 ## ================================2.Kruskal.test:================================ ## ## Kruskal-Wallis rank sum test ## ## data: var by group ## Kruskal-Wallis chi-squared = 25.746, df = 2, p-value = 0.000002566 ## ## ==========================3.LSDtest, bonferroni p-adj:========================== ## var groups ## 4 26.66364 a ## 6 19.74286 b ## 8 15.10000 c ## ==================================4.tukeyHSD:================================== ## Tukey multiple comparisons of means ## 95% family-wise confidence level ## ## Fit: aov(formula = var ~ group) ## ## $group ## diff lwr upr p adj ## 6-4 -6.920779 -10.769350 -3.0722086 0.0003424 ## 8-4 -11.563636 -14.770779 -8.3564942 0.0000000 ## 8-6 -4.642857 -8.327583 -0.9581313 0.0112287 ## ## =================================5.Wilcox-test:================================= ## 4 6 8 ## 4 1.00000000000 0.0006658148 0.00002774715 ## 6 0.00066581478 1.0000000000 0.00101304469 ## 8 0.00002774715 0.0010130447 1.00000000000 广义线性模型 泊松回归 1 2 3 4 5 6 counts \u0026lt;- c(18,17,15,20,10,20,25,13,12) outcome \u0026lt;- gl(3,1,9) treatment \u0026lt;- gl(3,3) D93=data.frame(treatment, outcome, counts) ## showing data ggplot(data = D93, mapping = aes(x = counts)) +geom_bar() 1 2 glm.D93 \u0026lt;- glm(counts ~ outcome + treatment,data = D93, family = poisson()) summary(glm.D93) ## ## Call: ## glm(formula = counts ~ outcome + treatment, family = poisson(), ## data = D93) ## ## Deviance Residuals: ## 1 2 3 4 5 6 7 8 ## -0.67125 0.96272 -0.16965 -0.21999 -0.95552 1.04939 0.84715 -0.09167 ## 9 ## -0.96656 ## ## Coefficients: ## Estimate Std. Error z value Pr(\u0026gt;|z|) ## (Intercept) 3.045e+00 1.709e-01 17.815 \u0026lt;2e-16 *** ## outcome2 -4.543e-01 2.022e-01 -2.247 0.0246 * ## outcome3 -2.930e-01 1.927e-01 -1.520 0.1285 ## treatment2 -3.242e-16 2.000e-01 0.000 1.0000 ## treatment3 -2.148e-16 2.000e-01 0.000 1.0000 ## --- ## Signif. codes: 0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1 ## ## (Dispersion parameter for poisson family taken to be 1) ## ## Null deviance: 10.5814 on 8 degrees of freedom ## Residual deviance: 5.1291 on 4 degrees of freedom ## AIC: 56.761 ## ## Number of Fisher Scoring iterations: 4 逻辑斯谛回归 ….\n","date":"2023-03-24T00:00:00Z","image":"/p/r-statistics/index.en_files/figure-html/unnamed-chunk-4-1_hu_867c7a1490322000.png","permalink":"/p/r-statistics/","title":"R-统计分析"},{"content":"在Rblogdown使用stack-theme遇到了几个问题，应该是Rblogdown与原生hugo间的不太兼容。\n我很快发现了问题是Rmd产生的md文件可能跟stack主题不太匹配，一开始想看看yaml文件能不能修改解决，但找了不少地方都没找到😭。\n因为问题还比较确定，可以试试自己写脚本转换Rmd产生的md文件。\n公式问题 rblogdown 渲染Rmd成md会把我写的公式语法改变：\n例如： $a=sum_i^2$变成$a=sum_i^2$\n但是stack主题识别不了后面那种语法，这个比较简单：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 import re # 定义一个正则表达式，匹配LaTeX数学公式中的起始和结束行内数学模式符号 pattern = r\u0026#39;\\\\\\((.*?)\\\\\\)\u0026#39; # 定义一个字符串，包含要处理的LaTeX字符串 latex_string = r\u0026#39;For the equation$\\sum_{i=1}^n i^2$\u0026#39; # 使用sub()函数替换匹配到的文本 processed_string = re.sub(pattern, r\u0026#39;$\\1$\u0026#39;, latex_string) # 输出处理后的字符串 print(processed_string) a=re.sub(r\u0026#39;`\\\\\\((.*?)\\\\\\)`\u0026#39;,r\u0026#39;$\\1$\u0026#39;,$a=sum_i^2$jjjh$a=sum_i^2$\u0026#34;) 图片大小调整 因为![from data to viz website](images/data2viz.png){width=60%}这种语法是stack主题不支持的， 但是\n1 2 3 \u0026#39;\u0026lt;p style=\u0026#34;text-align: center;\u0026#34;\u0026gt; \u0026lt;img src=\u0026#34;images/data2viz.png\u0026#34; width=\u0026#34;60%\u0026#34; title=\u0026#34;from data to viz website\u0026#34;/\u0026gt; \u0026lt;/p\u0026gt;\u0026#39; 这种语法是支持的，所以想写一个小脚本转换一下\n自己不太熟悉正则（上面那个公式转换的也是他帮我写的，哈哈），所以试试问了ChatGPT ：\n可以帮我写一个将插入图片的markdown语法转换为html语法的小脚本吗？ 比如：![A](B.png){width=60%}转换为\u0026lt;img src=\u0026quot;B.png\u0026quot; width=\u0026quot;60%\u0026quot; title=\u0026quot;A\u0026quot;/\u0026gt;\n它立马用python帮我写了：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 import re def convert_markdown_to_html(markdown_text): # 将插入图片的Markdown语法转换为HTML语法 pattern = r\u0026#34;!\\[(.*?)\\]\\((.*?)\\){(.*?)}\u0026#34; matches = re.findall(pattern, markdown_text) for match in matches: title = match[0] src = match[1] attributes = match[2].split(\u0026#34;,\u0026#34;) attr_dict = dict([tuple(attribute.split(\u0026#34;=\u0026#34;)) for attribute in attributes]) html_tag = f\u0026#39;\u0026lt;img src=\u0026#34;{src}\u0026#34; title=\u0026#34;{title}\u0026#34;\u0026#39; for key, value in attr_dict.items(): html_tag += f\u0026#39; {key}=\u0026#34;{value}\u0026#34;\u0026#39; html_tag += \u0026#34;/\u0026gt;\u0026#34; markdown_text = markdown_text.replace(f\u0026#34;![{title}]({src}){{{match[2]}}}\u0026#34;, html_tag) return markdown_text def convert_latex_to_md(markdown_text): html_text=re.sub(r\u0026#39;`\\\\\\((.*?)\\\\\\)`\u0026#39;,r\u0026#39;$\\1$\u0026#39;,markdown_text) return html_text def convert_markdown_file_to_html(file_path): # 读取Markdown文件 with open(file_path, \u0026#34;r\u0026#34;, encoding=\u0026#34;utf-8\u0026#34;) as f: markdown_text = f.read() # 将Markdown语法转换为HTML语法 html_text = convert_markdown_to_html(markdown_text) html_text = convert_latex_to_md(html_text) # 将HTML文本写入文件 with open(file_path, \u0026#34;w\u0026#34;, encoding=\u0026#34;utf-8\u0026#34;) as f: f.write(html_text) if __name__ == \u0026#34;__main__\u0026#34;: file_path = \u0026#34;index.md\u0026#34; convert_markdown_file_to_html(file_path) 牛牛牛！ 再问一下，可以用R语言写一下吗？\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 convert_markdown_to_html \u0026lt;- function(markdown_text) { # 通过正则表达式匹配图片语法 matches \u0026lt;- gregexpr(\u0026#34;!\\\\[(.*?)\\\\]\\\\((.*?)\\\\){(.*?)}\u0026#34;, markdown_text, perl = TRUE) # 遍历匹配结果，将Markdown语法替换为HTML语法 for (i in seq_along(matches[[1]])) { # 判断匹配结果是否为空列表 if (length(matches[[1]][i]) == 0) { next } match \u0026lt;- regmatches(markdown_text, matches[[1]][i]) title \u0026lt;- match[[2]] src \u0026lt;- match[[3]] attributes \u0026lt;- strsplit(match[[4]], \u0026#34;,\u0026#34;)[[1]] attr_dict \u0026lt;- setNames(sapply(strsplit(attributes, \u0026#34;=\u0026#34;), \u0026#34;[\u0026#34;, 2), sapply(strsplit(attributes, \u0026#34;=\u0026#34;), \u0026#34;[\u0026#34;, 1)) # 构造HTML标签 html_tag \u0026lt;- sprintf(\u0026#39;\u0026lt;img src=\u0026#34;%s\u0026#34; title=\u0026#34;%s\u0026#34;\u0026#39;, src, title) for (key in names(attr_dict)) { value \u0026lt;- attr_dict[[key]] html_tag \u0026lt;- paste(html_tag, sprintf(\u0026#39;%s=\u0026#34;%s\u0026#34;\u0026#39;, key, value), sep = \u0026#34; \u0026#34;) } html_tag \u0026lt;- paste(html_tag, \u0026#34;/\u0026gt;\u0026#34;, sep = \u0026#34;\u0026#34;) # 将Markdown语法替换为HTML语法 markdown_text \u0026lt;- sub(\u0026#34;!\\\\[(.*?)\\\\]\\\\((.*?)\\\\){(.*?)}\u0026#34;, html_tag, markdown_text, fixed = TRUE) } return(markdown_text) } markdown_text \u0026lt;- \u0026#34;![A](B.png){width=60%}\u0026#34; html_text \u0026lt;- convert_markdown_to_html(markdown_text) print(html_text) 唉，实际上这个代码没有用，我也不知道bug怎么搞，R的正则表达式一直感觉没有python好用。\n还是用写好的python脚本吧。\n修改新的md文件 我们还需要找到最新render出来的md文件按上述规则进行修改（否则一口气改全部的话，害怕会越来越慢，甚至损坏以前的md文件）：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 import os import datetime # 定义要查找的目录 directory = \u0026#39;./content/post/\u0026#39; # 存储所有的md文件 md_files = [] # 递归查找目录下的所有文件 for root, dirs, files in os.walk(directory): for file in files: if file.endswith(\u0026#39;.md\u0026#39;): file_path = os.path.join(root, file) md_files.append((file_path, os.path.getmtime(file_path))) # 找到最新修改的文件 latest_file = max(md_files, key=lambda x: x[1])[0] print(\u0026#34;最新保存的.md文件是：\u0026#34;, latest_file) 再问问，可以找到目录下所有新保存的.md文件吗，就是修改时间与上次不一致的？\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 import os import datetime # 定义要查找的目录 directory = \u0026#39;./content/\u0026#39; # 存储所有新保存的md文件 new_md_files = [] # 读取上一次检查的时间戳 if os.path.isfile(\u0026#39;last_check_time.txt\u0026#39;): with open(\u0026#39;last_check_time.txt\u0026#39;, \u0026#39;r\u0026#39;) as f: last_check_time = datetime.datetime.strptime(f.read(), \u0026#39;%Y-%m-%d %H:%M:%S.%f\u0026#39;) else: last_check_time = datetime.datetime.now() # 递归查找目录下的所有文件 for root, dirs, files in os.walk(directory): for file in files: if file.endswith(\u0026#39;.md\u0026#39;): file_path = os.path.join(root, file) mod_time = datetime.datetime.fromtimestamp(os.path.getmtime(file_path)) if mod_time \u0026gt; last_check_time: new_md_files.append(file_path) # 更新上一次检查的时间戳 last_check_time = datetime.datetime.now() # 将上一次检查的时间戳保存到文件中 with open(\u0026#39;last_check_time.txt\u0026#39;, \u0026#39;w\u0026#39;) as f: f.write(last_check_time.strftime(\u0026#39;%Y-%m-%d %H:%M:%S.%f\u0026#39;)) # 打印所有新保存的md文件 for file_path in new_md_files: print(\u0026#34;新保存的.md文件：\u0026#34;, file_path) #更新所有新保存的md文件 for file_path in new_md_files: convert_markdown_file_to_html(latest_file) 这个思路真不错，哈哈\n解决方法 调教了一下ChatGPT后，就得到了整个更新问题的方法了： 首先整理一个refresh_md_to_fit_stack.py放在网站根目录下， 然后在R文件夹的（如果你是用Rblogdown生成的网站，那就会有这个文件夹）的build2.R中加入一行：\nsystem(\u0026quot;python refresh_md_to_fit_stack.py\u0026quot;)\n即可。 因为Rblogdown会在每次实时渲染我们的网站后运行build2.R文件，相当于运行了refresh_md_to_fit_stack.py文件，而refresh_md_to_fit_stack.py文件将搜索所有更新的md文件并修改以上两个问题，这样hugo建立的网站就能够契合stack-theme。\n看看结果： 如果调试成功的话，下面显示的即是正常的latex公式:\n$y=\\frac{1}{2} $\n如果不是使用的Rblogdown生成的网站，这种思路的方法也可以帮助改变stack-theme。\n此外，如果是Rblogdown生成的其他主题的网站有类似问题，也可以这样修改。\n最后，ChatGPT真不错！再来一个攻略\n其他调整参考 Hugo主题stack的使用与优化 Stack主题的自定义 使用 Hugo+Stack 简单搭建一个博客 Hugo Stack主题更新小记 使用 Hugo 对博客的重建与 Stack 主题优化记录 ","date":"2023-03-23T00:00:00Z","image":"/p/chatgpt-stack/ChatGPT_hu_903dcb24ec00a5e2.jpg","permalink":"/p/chatgpt-stack/","title":"ChatGPT帮我调整stack主题"},{"content":"简介 linux, python和R语言应该是生信学习中最重要的几个部分。\nlinux是一种操作系统，由于许多生物信息学软件仅提供支持linux平台的命令行版本，而不是图形化界面，所以掌握该操作系统的基础文件管理，安装使用软件，输入输出逻辑，简单shell脚本编写等十分重要。\npython与R都是免费开源多平台的编程语言，并且都是较为容易学习上手的模仿自然语言语法的编程语言，且支持面向对象编程，两者在数据科学上都有着非常重要的应用。Python的生态系统非常丰富，拥有大量的数据科学库和框架，例如：NumPy、Pandas、Matplotlib、Seaborn、Scikit-learn、PyTorch、TensorFlow等，这些库可以帮助数据科学家快速处理和分析数据，构建模型。\nR是一种专门用于统计分析和数据可视化的语言，其生态系统也非常丰富，拥有大量的统计分析库和可视化工具，例如：ggplot2、dplyr、tidyr、shiny等。 R拥有非常强大的数据分析和可视化能力，它提供了很多专业的统计分析函数和图形，这些函数和图形可以直接用于数据分析和可视化，使分析和可视化变得更加轻松和高效。\n在此，我想先记录一下我使用的最多的R语言。\n常用功能 全面教程 小白上手首推北大李老师的课程讲义《R语言教程》，中文讲义，简单易读，甚至整本书就是用Rbookdown编写的，电子书也比较好复制代码进行学习。\n《R语言实战》,也有中文版，介绍地更加全面且有不少进阶知识，值得一看！\n然后是著名的英文书和参考手册：\n《An Introduction to R》 《R Cookbook》 更多关于R的书可以在Home | Bookdown这里找到。\n数据处理 我目前用的最多的是dplyr包进行数据处理，最开始是冲着类似linux下的|管道符去的，%\u0026gt;%符号真的挺好用的，可以让我们无需产生许多中间结果 (准确来说%\u0026gt;%来自magrittr包，并且R4.1+也支持了原生管道符|\u0026gt;，但用起来还是%\u0026gt;%顺手，还有%\u0026lt;\u0026gt;%等变体)：\n1 2 library(dplyr) head(iris)%\u0026gt;%select(Species)%\u0026gt;%unique() 随后便发现了tidyverse全家桶，其中包含ggplot2，tibble，dplyr，readr，stringr等常用的全面的数据处理包，能够很好的满足我们下有数据处理需求：\n读取数据\n清洗数据\n转换数据\n合并数据\n筛选数据\n可视化\n这里给出官方教程：《R for Data Science》，非常建议熟读并使用。\n可视化 可视化一直是R的突出优点，basic graphic和ggplot是我最常用的绘图系统（偶尔会用plotly画一些交互图形，但大多数是只需要presentation和文章里要用的静态图形），两者的绘图逻辑有所差异，推荐在学会R的基础使用和数据处理后就体验ggplot。\nggplot是由Hadley Wickham创建的，并被包含在R语言的ggplot2包中。主要思想是将数据可视化看作是图层的堆叠，其中每个图层代表了一个数据属性的可视化。ggplot提供了一系列的函数和参数，让用户能够轻松地组合这些图层，以及调整颜色、标签、轴等其他属性。\nggplot支持的图形类型包括散点图、折线图、直方图、密度图、箱线图等等，可以满足大多数数据可视化的需求。优点在于其语法简洁、易于理解和使用，并且生成的图表质量高、美观、易于理解。它也被广泛地应用于学术研究、数据分析、商业报告等领域。\n同样给出官方教程：《ggplot2: Elegant Graphics for Data Analysis》，优雅，太优雅了。这本书也是可以找到大佬们翻译的中文版的，可以当作作图工具书使用，许多无法直接Google到的细节问题可能能在书中找到。\n此外要提一下ggpubr包，其名为Publication Ready Plots，提供一些方便的做出出版级figure的函数。ggpubr: Publication Ready Plots - Articles - STHDA 这个网站提供了不少好看图的绘制流程。\n当掌握了基本的ggplot绘制逻辑后，还可以尝试各种基于同样逻辑的扩展包，如ggcor，ggtree等等。\ngg_extensions 这个网站收集了很多此类拓展包并支持制作上传自创的gg拓展（当然暂时有点难😮‍💨）\n最后，强烈推荐一个为可视化而建的网站From data to Viz | Find the graphic you need (data-to-viz.com)，就像网站名一样，丰富多彩的可视化形式帮我们找到适合自己数据的样式，并提供画某一类图的python，R甚至D3.js代码，真的非常方便地copy代码，替换我们的数据，少量的修改就能有很不错的效果😄。\nR编程 R是一个宝库，几乎总能在上面找到合适的包实现我们想要的功能，但他也是一种编程语言，熟悉其编程语法对进阶使用十分重要。\n基本的数据读取与输出，if else、switch、for循环与简单函数编写需要掌握。\n同时因为R是一个比较\u0026quot;慢\u0026quot;的语言，尽量使用向量式编程、apply替代for循环、RCpp编写函数等方法提高其效率（后面可能会专门讲讲）。\n这里推荐大佬的《Advanced R》，对R高级编程技术进行讲解。\nRmarkdown R Markdown是一种文本格式和工具，用于创建具有代码、文本、图形和输出结果的可重复性报告。它是在R语言环境中开发的，但也可以与其他编程语言（如Python）结合使用。\n使用R Markdown，您可以将代码、文本和图形组合到一个文件中，并使用R Markdown语法将它们组织成结构化的文档。然后，您可以使用R Markdown编译器将文档转换为HTML、PDF、Word或其他格式的报告。\nR Markdown具有以下优点：\n可重复性：报告中的所有代码和结果都是可重复的，这有助于确保研究结果的可靠性和透明度。\n效率：使用R Markdown，您可以在单个文件中组织和记录所有内容，从而节省时间和精力。\n灵活性：R Markdown支持多种格式和输出选项，因此您可以根据需要自定义报告的样式和布局。\nYihui Xie大佬的官方文档介绍：R Markdown: The Definitive Guide (bookdown.org)\n以及参考书：R Markdown Cookbook (bookdown.org)\nRbookdown R的bookdown扩展包(https://github.com/rstudio/bookdown) 是继knitr和rmarkdown扩展包之后， 另一个增强markdown格式的扩展， 使得Rmd格式可以支持公式、定理、图表自动编号和引用、链接， 文献引用和链接等适用于编写书籍的功能。相当方便，我也稍微尝试写了一下：MetaNet Tutorial (asa12138.github.io)。\n参考书：bookdown: Authoring Books and Technical Documents with R Markdown\nRblogdown R扩展包blogdown可以与Hugo软件配合制作简单的静态网站。 网站的所有文件都存在于一个目录中， 只要上传到任意的网站服务器就可以发布， 没有任何限制。这篇博客就是基于Rblogdown写的，还是非常友好易上手的。\n参考书：blogdown: Creating Websites with R Markdown (bookdown.org)\n3.21更新：\n大多数网站的修改要在themes中实现，比如我现在使用的主题不支持latex渲染，想要加上这个功能，我先找到了yihui大佬的主题实现这个功能的Javascript代码，即hugo-lithium/layouts/partials/footer_mathjax.html，然后把它复制到目前用的主题的footer目录下（可能没有这个目录，而是footer.html同目录下），记得在include.html或者其他layout文件中加入{{ partial \u0026quot;footer/footer_mathjax.html\u0026quot; . }}，这样就能顺利调用mathjax了。\nR Presentation R Markdown文件(.Rmd)支持生成网页格式的幻灯片(slidy_presentation)， 以及LaTeX beamer格式的PDF幻灯片(beamer_presentation)， 和Microsoft Office的PowerPoint幻灯片(powerpoint_presentation)格式。\n目前稍微尝试了一些Yihui大佬的\u0026quot;写轮眼\u0026quot;包，但没有试着做自己的slides，以后有机会一定试试。\n写R包 包是可重现 R 代码的基本单元，包括可重用的 R 函数、描述如何使用它们的文档和示例数据。一个包将代码、数据、文档和测试捆绑在一起，并且很容易与他人共享。\n积极尝试（以后讲讲）\n参考书：R Packages (2e) (r-pkgs.org)\n制作shiny应用 Shiny 是一个 R 包，可轻松地直接从 R 构建交互式 Web 应用程序。还可以在网页上托管独立应用程序或将它们嵌入 R Markdown 文档或构建仪表板，还可以使用 CSS 主题、html 小部件和 JavaScript 操作扩展您的 Shiny 应用程序。\n积极尝试（以后讲讲）\n官方教程：Shiny Learning Resources\n参考书：Mastering Shiny\n","date":"2023-03-16T00:00:00Z","image":"/p/r-learning/images/data2viz_hu_4c2c6b3977aeb86a.png","permalink":"/p/r-learning/","title":"R语言学习"},{"content":"最近倒腾了不少新玩意，比如这个博客系统，在此写下第一篇博客。\n从刚开始接触生信到现在已经3年了，我也从本科生变成了博士生，专业从生物科学变成了生物信息学。走上科研道路，可能是种种巧合与选择的结果，但现在脑子里想的就是将二十来年的各种知识运用在研究上，做一些有意思的东西。\n希望自己有空可以多更新，帮助自己整理思路，记录一些实验和数据分析的方法技巧，调节一下心情😂。\n","date":"2023-03-14T00:00:00Z","image":"/p/%E6%98%A5%E4%B9%8B%E4%BC%8A%E5%A7%8B/spring_hu_4bae4012cd0e8609.jpeg","permalink":"/p/%E6%98%A5%E4%B9%8B%E4%BC%8A%E5%A7%8B/","title":"春之伊始"},{"content":"This article offers a sample of basic Markdown syntax that can be used in Hugo content files, also it shows whether basic HTML elements are decorated with CSS in a Hugo theme.\nFormula $a=sum_i^2$ $a=sum_i$\nHeadings The following HTML \u0026lt;h1\u0026gt;—\u0026lt;h6\u0026gt; elements represent six levels of section headings. \u0026lt;h1\u0026gt; is the highest section level while \u0026lt;h6\u0026gt; is the lowest.\nH1 H2 H3 H4 H5 H6 Paragraph Xerum, quo qui aut unt expliquam qui dolut labo. Aque venitatiusda cum, voluptionse latur sitiae dolessi aut parist aut dollo enim qui voluptate ma dolestendit peritin re plis aut quas inctum laceat est volestemque commosa as cus endigna tectur, offic to cor sequas etum rerum idem sintibus eiur? Quianimin porecus evelectur, cum que nis nust voloribus ratem aut omnimi, sitatur? Quiatem. Nam, omnis sum am facea corem alique molestrunt et eos evelece arcillit ut aut eos eos nus, sin conecerem erum fuga. Ri oditatquam, ad quibus unda veliamenimin cusam et facea ipsamus es exerum sitate dolores editium rerore eost, temped molorro ratiae volorro te reribus dolorer sperchicium faceata tiustia prat.\nItatur? Quiatae cullecum rem ent aut odis in re eossequodi nonsequ idebis ne sapicia is sinveli squiatum, core et que aut hariosam ex eat.\nBlockquotes The blockquote element represents content that is quoted from another source, optionally with a citation which must be within a footer or cite element, and optionally with in-line changes such as annotations and abbreviations.\nBlockquote without attribution Tiam, ad mint andaepu dandae nostion secatur sequo quae. Note that you can use Markdown syntax within a blockquote.\nBlockquote with attribution Don\u0026rsquo;t communicate by sharing memory, share memory by communicating.\n— Rob Pike1\nTables Tables aren\u0026rsquo;t part of the core Markdown spec, but Hugo supports supports them out-of-the-box.\nName Age Bob 27 Alice 23 Inline Markdown within tables Italics Bold Code italics bold code A B C D E F Lorem ipsum dolor sit amet, consectetur adipiscing elit. Phasellus ultricies, sapien non euismod aliquam, dui ligula tincidunt odio, at accumsan nulla sapien eget ex. Proin eleifend dictum ipsum, non euismod ipsum pulvinar et. Vivamus sollicitudin, quam in pulvinar aliquam, metus elit pretium purus Proin sit amet velit nec enim imperdiet vehicula. Ut bibendum vestibulum quam, eu egestas turpis gravida nec Sed scelerisque nec turpis vel viverra. Vivamus vitae pretium sapien Code Blocks Code block with backticks 1 2 3 4 5 6 7 8 9 10 \u0026lt;!doctype html\u0026gt; \u0026lt;html lang=\u0026#34;en\u0026#34;\u0026gt; \u0026lt;head\u0026gt; \u0026lt;meta charset=\u0026#34;utf-8\u0026#34;\u0026gt; \u0026lt;title\u0026gt;Example HTML5 Document\u0026lt;/title\u0026gt; \u0026lt;/head\u0026gt; \u0026lt;body\u0026gt; \u0026lt;p\u0026gt;Test\u0026lt;/p\u0026gt; \u0026lt;/body\u0026gt; \u0026lt;/html\u0026gt; Code block indented with four spaces \u0026lt;!doctype html\u0026gt; \u0026lt;html lang=\u0026quot;en\u0026quot;\u0026gt; \u0026lt;head\u0026gt; \u0026lt;meta charset=\u0026quot;utf-8\u0026quot;\u0026gt; \u0026lt;title\u0026gt;Example HTML5 Document\u0026lt;/title\u0026gt; \u0026lt;/head\u0026gt; \u0026lt;body\u0026gt; \u0026lt;p\u0026gt;Test\u0026lt;/p\u0026gt; \u0026lt;/body\u0026gt; \u0026lt;/html\u0026gt; Code block with Hugo\u0026rsquo;s internal highlight shortcode 1 2 3 4 5 6 7 8 9 10 \u0026lt;!doctype html\u0026gt; \u0026lt;html lang=\u0026#34;en\u0026#34;\u0026gt; \u0026lt;head\u0026gt; \u0026lt;meta charset=\u0026#34;utf-8\u0026#34;\u0026gt; \u0026lt;title\u0026gt;Example HTML5 Document\u0026lt;/title\u0026gt; \u0026lt;/head\u0026gt; \u0026lt;body\u0026gt; \u0026lt;p\u0026gt;Test\u0026lt;/p\u0026gt; \u0026lt;/body\u0026gt; \u0026lt;/html\u0026gt; Diff code block 1 2 3 4 5 [dependencies.bevy] git = \u0026#34;https://github.com/bevyengine/bevy\u0026#34; rev = \u0026#34;11f52b8c72fc3a568e8bb4a4cd1f3eb025ac2e13\u0026#34; - features = [\u0026#34;dynamic\u0026#34;] + features = [\u0026#34;jpeg\u0026#34;, \u0026#34;dynamic\u0026#34;] List Types Ordered List First item Second item Third item Unordered List List item Another item And another item Nested list Fruit Apple Orange Banana Dairy Milk Cheese Other Elements — abbr, sub, sup, kbd, mark GIF is a bitmap image format.\nH2O\nXn + Yn = Zn\nPress CTRL+ALT+Delete to end the session.\nMost salamanders are nocturnal, and hunt for insects, worms, and other small creatures.\nHyperlinked image The above quote is excerpted from Rob Pike\u0026rsquo;s talk during Gopherfest, November 18, 2015.\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n","date":"2023-03-11T00:00:00Z","image":"/p/markdown-syntax-guide/pawel-czerwinski-8uZPynIu-rQ-unsplash_hu_e95a4276bf860a84.jpg","permalink":"/p/markdown-syntax-guide/","title":"Markdown Syntax Guide"}]